{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_compas import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import torch\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "from divexplorer.outcomes import get_false_positive_rate_outcome\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il CSV\n",
    "df = pd.read_csv(\"cox-violent-parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1339, 16977)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df[\"is_violent_recid\"].sum()\n",
    "count_0 = len(df) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning = 0.00\n",
    "epsilon = pruning\n",
    "min_sup = 0.02\n",
    "percentage = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "VALIDATION SET ROWS:  2439\n",
      "HOLDOUT SET ROWS:  2440\n",
      "TEST SET ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) \n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0])\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         # Distinct Values\n",
      "Attribute                                 \n",
      "sex                                      2\n",
      "race                                     6\n",
      "Recidivism_Risk                         10\n",
      "Violent_Recidivist                       2\n",
      "Risk_Level                               3\n",
      "Violent_Recidivism_Risk                 10\n",
      "Violent_Risk_Level                       3\n",
      "Juvenile_Offenses                       15\n",
      "age_group                                6\n",
      "Prior_Offensesgroup                      8\n"
     ]
    }
   ],
   "source": [
    "distinct_values = pd.DataFrame(df_train.nunique(), columns=[\"# Distinct Values\"])\n",
    "distinct_values.index.name = \"Attribute\"\n",
    "print(distinct_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Attribute</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Violent_Recidivist</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14003</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>8</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>7</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>6-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>17-24</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Attribute   sex              race  Recidivism_Risk  Violent_Recidivist  \\\n",
       "14003      Male         Caucasian                8                   0   \n",
       "1531       Male  African-American               10                   1   \n",
       "1543       Male  African-American                7                   0   \n",
       "15999      Male  African-American                3                   0   \n",
       "3837       Male             Asian                5                   0   \n",
       "\n",
       "Attribute Risk_Level  Violent_Recidivism_Risk Violent_Risk_Level  \\\n",
       "14003           High                        3                Low   \n",
       "1531            High                        8               High   \n",
       "1543          Medium                        7             Medium   \n",
       "15999            Low                        5             Medium   \n",
       "3837          Medium                        4                Low   \n",
       "\n",
       "Attribute  Juvenile_Offenses age_group Prior_Offensesgroup  \n",
       "14003                      0     45-54                 0-5  \n",
       "1531                       0     17-24               11-15  \n",
       "1543                       0     25-34                6-10  \n",
       "15999                      2     17-24                 0-5  \n",
       "3837                       0     17-24                 0-5  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "VALIDATION SET ROWS:  2439\n",
      "HOLDOUT SET ROWS:  2440\n",
      "TEST SET ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosit√† precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) \n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) \n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_no_Violent_Recidivist = df_train_enc.drop(columns = 'Violent_Recidivist')\n",
    "plt.figure(figsize=(4, 3))\n",
    "g = sns.heatmap(df_train_no_Violent_Recidivist.corr(),\n",
    "                annot = False,\n",
    "                cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.927     0.032                0.002   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.983                4              175   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       2439  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "X_train = df_train_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_train = df_train_enc['Violent_Recidivist']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_test = df_test_enc['Violent_Recidivist']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_val = df_val_enc['Violent_Recidivist']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_holdout = df_holdout_enc['Violent_Recidivist']\n",
    "\n",
    "classifier_train = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()\n",
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione √® giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  race  Recidivism_Risk  Risk_Level  Violent_Recidivism_Risk  \\\n",
       "10676    1     0                4           1                        2   \n",
       "13123    1     2                1           1                        1   \n",
       "2611     1     0                8           0                        6   \n",
       "7945     1     2                1           1                        1   \n",
       "5727     1     2                6           2                        6   \n",
       "\n",
       "       Violent_Risk_Level  Juvenile_Offenses  age_group  Prior_Offensesgroup  \\\n",
       "10676                   1                  0          3                    7   \n",
       "13123                   1                  0          3                    0   \n",
       "2611                    2                  2          2                    1   \n",
       "7945                    1                  0          5                    0   \n",
       "5727                    2                  0          1                    0   \n",
       "\n",
       "       y_val_true  y_pred  \n",
       "10676           0       0  \n",
       "13123           0       0  \n",
       "2611            0       0  \n",
       "7945            0       0  \n",
       "5727            0       0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set, queste mi servono solo per il div explorer che ha bisogno di ground truth e predizioni\n",
    "y_pred_val = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Violent_Recidivist</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>fp</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>6-10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>35-44</td>\n",
       "      <td>11-15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>65-100</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex              race  Recidivism_Risk  Violent_Recidivist Risk_Level  \\\n",
       "10676  Male  African-American                4                   0        Low   \n",
       "13123  Male         Caucasian                1                   0        Low   \n",
       "2611   Male  African-American                8                   0       High   \n",
       "7945   Male         Caucasian                1                   0        Low   \n",
       "5727   Male         Caucasian                6                   0     Medium   \n",
       "\n",
       "       Violent_Recidivism_Risk Violent_Risk_Level  Juvenile_Offenses  \\\n",
       "10676                        2                Low                  0   \n",
       "13123                        1                Low                  0   \n",
       "2611                         6             Medium                  2   \n",
       "7945                         1                Low                  0   \n",
       "5727                         6             Medium                  0   \n",
       "\n",
       "      age_group Prior_Offensesgroup    fp  y_pred  accuracy  \n",
       "10676     45-54                6-10 0.000       0         1  \n",
       "13123     45-54                 0-5 0.000       0         1  \n",
       "2611      35-44               11-15 0.000       0         1  \n",
       "7945     65-100                 0-5 0.000       0         1  \n",
       "5727      25-34                 0-5 0.000       0         1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]\n",
    "\n",
    "df_val_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_val['fp'] = df_val_class['fp']\n",
    "\n",
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione √® giusta 0 se la predizione √® sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['accuracy'] = (df_val_class['y_val_true']==df_val_class['y_pred']).astype(int)\n",
    "df_val.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI CONDOTTA CON LA FEATURE FP (PASSATA A BOOLEAN OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Violent_Recidivist</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>fp</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>6-10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>35-44</td>\n",
       "      <td>11-15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>65-100</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>55-64</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>9</td>\n",
       "      <td>High</td>\n",
       "      <td>21</td>\n",
       "      <td>25-34</td>\n",
       "      <td>16-20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>55-64</td>\n",
       "      <td>11-15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2439 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sex              race  Recidivism_Risk  Violent_Recidivist  \\\n",
       "10676    Male  African-American                4                   0   \n",
       "13123    Male         Caucasian                1                   0   \n",
       "2611     Male  African-American                8                   0   \n",
       "7945     Male         Caucasian                1                   0   \n",
       "5727     Male         Caucasian                6                   0   \n",
       "...       ...               ...              ...                 ...   \n",
       "4183     Male         Caucasian                1                   0   \n",
       "9445     Male         Caucasian                8                   0   \n",
       "8674   Female         Caucasian                5                   0   \n",
       "6392     Male          Hispanic                1                   0   \n",
       "6524   Female         Caucasian                5                   0   \n",
       "\n",
       "      Risk_Level  Violent_Recidivism_Risk Violent_Risk_Level  \\\n",
       "10676        Low                        2                Low   \n",
       "13123        Low                        1                Low   \n",
       "2611        High                        6             Medium   \n",
       "7945         Low                        1                Low   \n",
       "5727      Medium                        6             Medium   \n",
       "...          ...                      ...                ...   \n",
       "4183         Low                        1                Low   \n",
       "9445        High                        9               High   \n",
       "8674      Medium                        4                Low   \n",
       "6392         Low                        1                Low   \n",
       "6524      Medium                        2                Low   \n",
       "\n",
       "       Juvenile_Offenses age_group Prior_Offensesgroup    fp  y_pred  accuracy  \n",
       "10676                  0     45-54                6-10 0.000       0         1  \n",
       "13123                  0     45-54                 0-5 0.000       0         1  \n",
       "2611                   2     35-44               11-15 0.000       0         1  \n",
       "7945                   0    65-100                 0-5 0.000       0         1  \n",
       "5727                   0     25-34                 0-5 0.000       0         1  \n",
       "...                  ...       ...                 ...   ...     ...       ...  \n",
       "4183                   0     55-64                 0-5 0.000       0         1  \n",
       "9445                  21     25-34               16-20 0.000       0         1  \n",
       "8674                   0     55-64               11-15 0.000       0         1  \n",
       "6392                   0     35-44                 0-5 0.000       0         1  \n",
       "6524                   0     35-44                 0-5 0.000       0         1  \n",
       "\n",
       "[2439 rows x 13 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['sex', 'race', 'Recidivism_Risk', 'Risk_Level', 'Violent_Recidivism_Risk', 'Violent_Risk_Level', 'Juvenile_Offenses', 'age_group', 'Prior_Offensesgroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fp</th>\n",
       "      <th>fp_div</th>\n",
       "      <th>fp_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021</td>\n",
       "      <td>(Prior_Offensesgroup=6-10, sex=Male, Recidivism_Risk=10)</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1.427</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021</td>\n",
       "      <td>(Prior_Offensesgroup=6-10, Risk_Level=High, Recidivism_Risk=10, sex=Male)</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1.427</td>\n",
       "      <td>4</td>\n",
       "      <td>50.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020</td>\n",
       "      <td>(Risk_Level=High, Violent_Risk_Level=High, sex=Male, Violent_Recidivism_Risk=10, race=African-American)</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>1.421</td>\n",
       "      <td>5</td>\n",
       "      <td>49.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020</td>\n",
       "      <td>(race=African-American, sex=Male, Violent_Recidivism_Risk=10, Risk_Level=High)</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>1.421</td>\n",
       "      <td>4</td>\n",
       "      <td>49.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021</td>\n",
       "      <td>(race=African-American, Risk_Level=High, Violent_Recidivism_Risk=10)</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>1.419</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.021   \n",
       "1    0.021   \n",
       "2    0.020   \n",
       "3    0.020   \n",
       "4    0.021   \n",
       "\n",
       "                                                                                                   itemset  \\\n",
       "0                                                 (Prior_Offensesgroup=6-10, sex=Male, Recidivism_Risk=10)   \n",
       "1                                (Prior_Offensesgroup=6-10, Risk_Level=High, Recidivism_Risk=10, sex=Male)   \n",
       "2  (Risk_Level=High, Violent_Risk_Level=High, sex=Male, Violent_Recidivism_Risk=10, race=African-American)   \n",
       "3                           (race=African-American, sex=Male, Violent_Recidivism_Risk=10, Risk_Level=High)   \n",
       "4                                     (race=African-American, Risk_Level=High, Violent_Recidivism_Risk=10)   \n",
       "\n",
       "     fp  fp_div  fp_t  length  support_count  \n",
       "0 0.026   0.025 1.427       3         50.000  \n",
       "1 0.026   0.025 1.427       4         50.000  \n",
       "2 0.024   0.023 1.421       5         49.000  \n",
       "3 0.024   0.023 1.421       4         49.000  \n",
       "4 0.023   0.022 1.419       3         50.000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_diver = DivergenceExplorer(df_val)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"fp_div\", \"fp_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp = FP_fm\n",
    "#df_pruned_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 4200\n",
      "total problematic 141\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_fp)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_fp[(df_pruned_fp['fp_div'] > 0)]) #& (df_pruned_fp['fp_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (4200, 7)\n",
      "Dim pruned th_redundancy  (4200, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_fp.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset_and_or li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "df_holdout_filtered_solo0 = df_holdout_filtered[df_holdout_filtered['Violent_Recidivist']==0]\n",
    "\n",
    "\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered_solo0, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "df_holdout_filtered = df_holdout_filtered_solo0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "print(len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "TRAIN SET MITIGATED ROWS:  11145\n",
      "VALIDATION SET ROWS:  2439\n",
      "FILTERED DF holdout ROWS:  170\n",
      "TEST SET FILTERED ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['Violent_Recidivist']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "#cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "verifica : 170\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"Violent_Recidivist\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.966</td>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.927     0.032                0.002   \n",
       "After Mitigation(K=5, fp)     0.928     0.064                0.001   \n",
       "After RANDOM mitigation       0.927     0.043                0.002   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.983                4   \n",
       "After Mitigation(K=5, fp)                0.966                3   \n",
       "After RANDOM mitigation                  0.978                4   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      175       10975       2439  \n",
       "After Mitigation(K=5, fp)              172       11145       2439  \n",
       "After RANDOM mitigation                174       11145       2439  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE\n",
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>170.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "      <td>170.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.927     0.032             0.001   \n",
       "After Mitigation(K=5 fp)            0.928     0.064             0.001   \n",
       "After RANDOM Mitigation(K=5 fp)     0.927     0.043             0.001   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.043               0.037   \n",
       "After Mitigation(K=5 fp)           0.025               0.024   \n",
       "After RANDOM Mitigation(K=5 fp)    0.043               0.037   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.032               0.027   \n",
       "After Mitigation(K=5 fp)                      0.022               0.020   \n",
       "After RANDOM Mitigation(K=5 fp)               0.032               0.027   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)               170.000  \n",
       "After RANDOM Mitigation(K=5 fp)        170.000  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline1  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline1\n",
    "\n",
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "#attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_random_per_confrontare_con_baseline1\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline1 = abs(sum(fp_div_list_baseline1) / len(fp_div_list_baseline1))\n",
    "media_fp_div_list_baseline1_primi10 = abs(sum(fp_div_list_baseline1[:10]) / len(fp_div_list_baseline1[:10]))\n",
    "media_fp_div_list_baseline1_primi20 = abs(sum(fp_div_list_baseline1[:20]) / len(fp_div_list_baseline1[:20]))\n",
    "media_fp_div_list_baseline1_primi40 = abs(sum(fp_div_list_baseline1[:40]) / len(fp_div_list_baseline1[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_baseline1 = max(abs(x) for x in fp_div_list_baseline1)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_fp_div_list_baseline1, fp_div_massimo_valore_assoluto_fp_div_baseline1,\n",
    "        media_fp_div_list_baseline1_primi10, media_fp_div_list_baseline1_primi20, media_fp_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGUE CODICE USANDO SMOTE \n",
    "DIVIDO IN TRAIN, TEST E VALIDATION -- ora uso quelli gia esistenti\n",
    "DIV EXPLORER SUL VALIDATION  -- gi√† fatto \n",
    "GENERO NUOVI DATI CON SMOTE a partire dai dati di divexplorer sul validation\n",
    "INSERISCO QUESTI NUOVI DATI NEL TRAIN SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p √® la probabilit√† che il campione simulato sia di classe 0 qui (perch√® voglio diminuire il numero di falsi positivi)\n",
    "- FISSO p VARIA N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 304\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['fp', 'y_pred', 'accuracy', \"Violent_Recidivist\"], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered[\"Violent_Recidivist\"]\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 1, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 258)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered[\"Violent_Recidivist\"].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = np.arange(0.5, 1.05, 0.05)\n",
    "p_values = np.round(p_values, 2).tolist()\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N come holdout filtered e targeted acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 170</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.5</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.961</td>\n",
       "      <td>3</td>\n",
       "      <td>171</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.55</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.961</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.65</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.961</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.7</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.75</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.85</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.9</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.95</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>11145</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.927     0.032                0.002   \n",
       "After RANDOM mitigation N = 170          0.927     0.043                0.002   \n",
       "After SMOTE N = 170 p_class 0 = 0.5      0.929     0.074                0.001   \n",
       "After SMOTE N = 170 p_class 0 = 0.55     0.928     0.074                0.002   \n",
       "After SMOTE N = 170 p_class 0 = 0.6      0.927     0.043                0.002   \n",
       "After SMOTE N = 170 p_class 0 = 0.65     0.928     0.074                0.002   \n",
       "After SMOTE N = 170 p_class 0 = 0.7      0.928     0.043                0.001   \n",
       "After SMOTE N = 170 p_class 0 = 0.75     0.928     0.054                0.001   \n",
       "After SMOTE N = 170 p_class 0 = 0.8      0.928     0.054                0.001   \n",
       "After SMOTE N = 170 p_class 0 = 0.85     0.928     0.054                0.001   \n",
       "After SMOTE N = 170 p_class 0 = 0.9      0.927     0.043                0.001   \n",
       "After SMOTE N = 170 p_class 0 = 0.95     0.927     0.033                0.001   \n",
       "After SMOTE N = 170 p_class 0 = 1.0      0.927     0.033                0.001   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.983                4   \n",
       "After RANDOM mitigation N = 170                     0.978                4   \n",
       "After SMOTE N = 170 p_class 0 = 0.5                 0.961                3   \n",
       "After SMOTE N = 170 p_class 0 = 0.55                0.961                4   \n",
       "After SMOTE N = 170 p_class 0 = 0.6                 0.978                4   \n",
       "After SMOTE N = 170 p_class 0 = 0.65                0.961                4   \n",
       "After SMOTE N = 170 p_class 0 = 0.7                 0.978                2   \n",
       "After SMOTE N = 170 p_class 0 = 0.75                0.972                3   \n",
       "After SMOTE N = 170 p_class 0 = 0.8                 0.972                2   \n",
       "After SMOTE N = 170 p_class 0 = 0.85                0.972                3   \n",
       "After SMOTE N = 170 p_class 0 = 0.9                 0.978                3   \n",
       "After SMOTE N = 170 p_class 0 = 0.95                0.983                3   \n",
       "After SMOTE N = 170 p_class 0 = 1.0                 0.983                2   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 175       10975       2439  \n",
       "After RANDOM mitigation N = 170                   174       11145       2439  \n",
       "After SMOTE N = 170 p_class 0 = 0.5               171       11145       2439  \n",
       "After SMOTE N = 170 p_class 0 = 0.55              171       11145       2439  \n",
       "After SMOTE N = 170 p_class 0 = 0.6               174       11145       2439  \n",
       "After SMOTE N = 170 p_class 0 = 0.65              171       11145       2439  \n",
       "After SMOTE N = 170 p_class 0 = 0.7               174       11145       2439  \n",
       "After SMOTE N = 170 p_class 0 = 0.75              173       11145       2439  \n",
       "After SMOTE N = 170 p_class 0 = 0.8               173       11145       2439  \n",
       "After SMOTE N = 170 p_class 0 = 0.85              173       11145       2439  \n",
       "After SMOTE N = 170 p_class 0 = 0.9               174       11145       2439  \n",
       "After SMOTE N = 170 p_class 0 = 0.95              175       11145       2439  \n",
       "After SMOTE N = 170 p_class 0 = 1.0               175       11145       2439  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = FP_fm\n",
    "    df_pruned_fp = FP_fm\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 170</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.5</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.074</td>\n",
       "      <td>3</td>\n",
       "      <td>171</td>\n",
       "      <td>174</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.55</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.074</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.65</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.074</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.7</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.75</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.85</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.9</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 0.95</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 170 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.927     0.032                4   \n",
       "After RANDOM mitigation N = 170          0.927     0.043                4   \n",
       "After SMOTE N = 170 p_class 0 = 0.5      0.929     0.074                3   \n",
       "After SMOTE N = 170 p_class 0 = 0.55     0.928     0.074                4   \n",
       "After SMOTE N = 170 p_class 0 = 0.6      0.927     0.043                4   \n",
       "After SMOTE N = 170 p_class 0 = 0.65     0.928     0.074                4   \n",
       "After SMOTE N = 170 p_class 0 = 0.7      0.928     0.043                2   \n",
       "After SMOTE N = 170 p_class 0 = 0.75     0.928     0.054                3   \n",
       "After SMOTE N = 170 p_class 0 = 0.8      0.928     0.054                2   \n",
       "After SMOTE N = 170 p_class 0 = 0.85     0.928     0.054                3   \n",
       "After SMOTE N = 170 p_class 0 = 0.9      0.927     0.043                3   \n",
       "After SMOTE N = 170 p_class 0 = 0.95     0.927     0.033                3   \n",
       "After SMOTE N = 170 p_class 0 = 1.0      0.927     0.033                2   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 175           179   \n",
       "After RANDOM mitigation N = 170                   174           178   \n",
       "After SMOTE N = 170 p_class 0 = 0.5               171           174   \n",
       "After SMOTE N = 170 p_class 0 = 0.55              171           175   \n",
       "After SMOTE N = 170 p_class 0 = 0.6               174           178   \n",
       "After SMOTE N = 170 p_class 0 = 0.65              171           175   \n",
       "After SMOTE N = 170 p_class 0 = 0.7               174           176   \n",
       "After SMOTE N = 170 p_class 0 = 0.75              173           176   \n",
       "After SMOTE N = 170 p_class 0 = 0.8               173           175   \n",
       "After SMOTE N = 170 p_class 0 = 0.85              173           176   \n",
       "After SMOTE N = 170 p_class 0 = 0.9               174           177   \n",
       "After SMOTE N = 170 p_class 0 = 0.95              175           178   \n",
       "After SMOTE N = 170 p_class 0 = 1.0               175           177   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                              -0.001           0.043   \n",
       "After RANDOM mitigation N = 170                -0.001           0.043   \n",
       "After SMOTE N = 170 p_class 0 = 0.5            -0.001           0.043   \n",
       "After SMOTE N = 170 p_class 0 = 0.55           -0.001           0.065   \n",
       "After SMOTE N = 170 p_class 0 = 0.6            -0.001           0.065   \n",
       "After SMOTE N = 170 p_class 0 = 0.65           -0.001           0.065   \n",
       "After SMOTE N = 170 p_class 0 = 0.7            -0.001           0.037   \n",
       "After SMOTE N = 170 p_class 0 = 0.75           -0.001           0.043   \n",
       "After SMOTE N = 170 p_class 0 = 0.8            -0.001           0.037   \n",
       "After SMOTE N = 170 p_class 0 = 0.85           -0.001           0.043   \n",
       "After SMOTE N = 170 p_class 0 = 0.9            -0.001           0.043   \n",
       "After SMOTE N = 170 p_class 0 = 0.95           -0.001           0.043   \n",
       "After SMOTE N = 170 p_class 0 = 1.0            -0.001           0.037   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.037       0.032       0.027  \n",
       "After RANDOM mitigation N = 170            0.037       0.032       0.027  \n",
       "After SMOTE N = 170 p_class 0 = 0.5        0.038       0.033       0.027  \n",
       "After SMOTE N = 170 p_class 0 = 0.55       0.055       0.048       0.038  \n",
       "After SMOTE N = 170 p_class 0 = 0.6        0.055       0.048       0.038  \n",
       "After SMOTE N = 170 p_class 0 = 0.65       0.055       0.048       0.038  \n",
       "After SMOTE N = 170 p_class 0 = 0.7        0.034       0.028       0.023  \n",
       "After SMOTE N = 170 p_class 0 = 0.75       0.038       0.033       0.027  \n",
       "After SMOTE N = 170 p_class 0 = 0.8        0.034       0.028       0.023  \n",
       "After SMOTE N = 170 p_class 0 = 0.85       0.038       0.033       0.027  \n",
       "After SMOTE N = 170 p_class 0 = 0.9        0.038       0.033       0.027  \n",
       "After SMOTE N = 170 p_class 0 = 0.95       0.038       0.033       0.027  \n",
       "After SMOTE N = 170 p_class 0 = 1.0        0.034       0.028       0.023  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = FP_fm\n",
    "        df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_confronto = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_confronto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N  = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 500</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.5</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.949</td>\n",
       "      <td>3</td>\n",
       "      <td>169</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.55</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.6</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.961</td>\n",
       "      <td>3</td>\n",
       "      <td>171</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.65</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.7</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.961</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.85</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.95</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.927     0.032                0.002   \n",
       "After RANDOM mitigation N = 500          0.926     0.032                0.002   \n",
       "After SMOTE N = 500 p_class 0 = 0.5      0.929     0.095                0.001   \n",
       "After SMOTE N = 500 p_class 0 = 0.55     0.928     0.054                0.001   \n",
       "After SMOTE N = 500 p_class 0 = 0.6      0.929     0.074                0.001   \n",
       "After SMOTE N = 500 p_class 0 = 0.65     0.928     0.054                0.001   \n",
       "After SMOTE N = 500 p_class 0 = 0.7      0.928     0.074                0.002   \n",
       "After SMOTE N = 500 p_class 0 = 0.75     0.927     0.043                0.001   \n",
       "After SMOTE N = 500 p_class 0 = 0.8      0.928     0.043                0.001   \n",
       "After SMOTE N = 500 p_class 0 = 0.85     0.927     0.053                0.002   \n",
       "After SMOTE N = 500 p_class 0 = 0.9      0.928     0.054                0.001   \n",
       "After SMOTE N = 500 p_class 0 = 0.95     0.928     0.043                0.001   \n",
       "After SMOTE N = 500 p_class 0 = 1.0      0.927     0.033                0.001   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.983                4   \n",
       "After RANDOM mitigation N = 500                     0.983                5   \n",
       "After SMOTE N = 500 p_class 0 = 0.5                 0.949                3   \n",
       "After SMOTE N = 500 p_class 0 = 0.55                0.972                2   \n",
       "After SMOTE N = 500 p_class 0 = 0.6                 0.961                3   \n",
       "After SMOTE N = 500 p_class 0 = 0.65                0.972                2   \n",
       "After SMOTE N = 500 p_class 0 = 0.7                 0.961                4   \n",
       "After SMOTE N = 500 p_class 0 = 0.75                0.978                3   \n",
       "After SMOTE N = 500 p_class 0 = 0.8                 0.978                2   \n",
       "After SMOTE N = 500 p_class 0 = 0.85                0.972                4   \n",
       "After SMOTE N = 500 p_class 0 = 0.9                 0.972                2   \n",
       "After SMOTE N = 500 p_class 0 = 0.95                0.978                2   \n",
       "After SMOTE N = 500 p_class 0 = 1.0                 0.983                3   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 175       10975       2439  \n",
       "After RANDOM mitigation N = 500                   175       11475       2439  \n",
       "After SMOTE N = 500 p_class 0 = 0.5               169       11475       2439  \n",
       "After SMOTE N = 500 p_class 0 = 0.55              173       11475       2439  \n",
       "After SMOTE N = 500 p_class 0 = 0.6               171       11475       2439  \n",
       "After SMOTE N = 500 p_class 0 = 0.65              173       11475       2439  \n",
       "After SMOTE N = 500 p_class 0 = 0.7               171       11475       2439  \n",
       "After SMOTE N = 500 p_class 0 = 0.75              174       11475       2439  \n",
       "After SMOTE N = 500 p_class 0 = 0.8               174       11475       2439  \n",
       "After SMOTE N = 500 p_class 0 = 0.85              173       11475       2439  \n",
       "After SMOTE N = 500 p_class 0 = 0.9               173       11475       2439  \n",
       "After SMOTE N = 500 p_class 0 = 0.95              174       11475       2439  \n",
       "After SMOTE N = 500 p_class 0 = 1.0               175       11475       2439  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionari per salvare i risultati\n",
    "N = 500\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "                  \n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = FP_fm\n",
    "    df_pruned_fp = FP_fm\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 500</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.032</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>180</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.5</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.095</td>\n",
       "      <td>3</td>\n",
       "      <td>169</td>\n",
       "      <td>172</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.55</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.6</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.074</td>\n",
       "      <td>3</td>\n",
       "      <td>171</td>\n",
       "      <td>174</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.65</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.7</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.074</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.85</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.95</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.927     0.032                4   \n",
       "After RANDOM mitigation N = 500          0.926     0.032                5   \n",
       "After SMOTE N = 500 p_class 0 = 0.5      0.929     0.095                3   \n",
       "After SMOTE N = 500 p_class 0 = 0.55     0.928     0.054                2   \n",
       "After SMOTE N = 500 p_class 0 = 0.6      0.929     0.074                3   \n",
       "After SMOTE N = 500 p_class 0 = 0.65     0.928     0.054                2   \n",
       "After SMOTE N = 500 p_class 0 = 0.7      0.928     0.074                4   \n",
       "After SMOTE N = 500 p_class 0 = 0.75     0.927     0.043                3   \n",
       "After SMOTE N = 500 p_class 0 = 0.8      0.928     0.043                2   \n",
       "After SMOTE N = 500 p_class 0 = 0.85     0.927     0.053                4   \n",
       "After SMOTE N = 500 p_class 0 = 0.9      0.928     0.054                2   \n",
       "After SMOTE N = 500 p_class 0 = 0.95     0.928     0.043                2   \n",
       "After SMOTE N = 500 p_class 0 = 1.0      0.927     0.033                3   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 175           179   \n",
       "After RANDOM mitigation N = 500                   175           180   \n",
       "After SMOTE N = 500 p_class 0 = 0.5               169           172   \n",
       "After SMOTE N = 500 p_class 0 = 0.55              173           175   \n",
       "After SMOTE N = 500 p_class 0 = 0.6               171           174   \n",
       "After SMOTE N = 500 p_class 0 = 0.65              173           175   \n",
       "After SMOTE N = 500 p_class 0 = 0.7               171           175   \n",
       "After SMOTE N = 500 p_class 0 = 0.75              174           177   \n",
       "After SMOTE N = 500 p_class 0 = 0.8               174           176   \n",
       "After SMOTE N = 500 p_class 0 = 0.85              173           177   \n",
       "After SMOTE N = 500 p_class 0 = 0.9               173           175   \n",
       "After SMOTE N = 500 p_class 0 = 0.95              174           176   \n",
       "After SMOTE N = 500 p_class 0 = 1.0               175           178   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                              -0.001           0.043   \n",
       "After RANDOM mitigation N = 500                -0.001           0.043   \n",
       "After SMOTE N = 500 p_class 0 = 0.5            -0.001           0.043   \n",
       "After SMOTE N = 500 p_class 0 = 0.55           -0.001           0.037   \n",
       "After SMOTE N = 500 p_class 0 = 0.6            -0.001           0.043   \n",
       "After SMOTE N = 500 p_class 0 = 0.65           -0.001           0.037   \n",
       "After SMOTE N = 500 p_class 0 = 0.7            -0.001           0.065   \n",
       "After SMOTE N = 500 p_class 0 = 0.75           -0.001           0.043   \n",
       "After SMOTE N = 500 p_class 0 = 0.8            -0.000           0.025   \n",
       "After SMOTE N = 500 p_class 0 = 0.85           -0.001           0.065   \n",
       "After SMOTE N = 500 p_class 0 = 0.9            -0.001           0.037   \n",
       "After SMOTE N = 500 p_class 0 = 0.95           -0.001           0.037   \n",
       "After SMOTE N = 500 p_class 0 = 1.0            -0.001           0.043   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.037       0.032       0.027  \n",
       "After RANDOM mitigation N = 500            0.037       0.032       0.027  \n",
       "After SMOTE N = 500 p_class 0 = 0.5        0.038       0.033       0.027  \n",
       "After SMOTE N = 500 p_class 0 = 0.55       0.034       0.028       0.023  \n",
       "After SMOTE N = 500 p_class 0 = 0.6        0.038       0.033       0.027  \n",
       "After SMOTE N = 500 p_class 0 = 0.65       0.034       0.028       0.023  \n",
       "After SMOTE N = 500 p_class 0 = 0.7        0.055       0.048       0.038  \n",
       "After SMOTE N = 500 p_class 0 = 0.75       0.038       0.033       0.027  \n",
       "After SMOTE N = 500 p_class 0 = 0.8        0.024       0.022       0.020  \n",
       "After SMOTE N = 500 p_class 0 = 0.85       0.055       0.048       0.038  \n",
       "After SMOTE N = 500 p_class 0 = 0.9        0.034       0.028       0.023  \n",
       "After SMOTE N = 500 p_class 0 = 0.95       0.034       0.028       0.023  \n",
       "After SMOTE N = 500 p_class 0 = 1.0        0.038       0.033       0.027  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes=attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = FP_fm\n",
    "        df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.966</td>\n",
       "      <td>7</td>\n",
       "      <td>172</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.972</td>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.972</td>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.75</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.85</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.95</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.989</td>\n",
       "      <td>2</td>\n",
       "      <td>176</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.989</td>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.927     0.032   \n",
       "After RANDOM mitigation N = 1000          0.928     0.054   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5      0.927     0.063   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55     0.927     0.053   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6      0.927     0.053   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65     0.927     0.053   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7      0.927     0.043   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75     0.928     0.043   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8      0.928     0.054   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85     0.927     0.033   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9      0.928     0.054   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95     0.927     0.022   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0      0.927     0.022   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.002   \n",
       "After RANDOM mitigation N = 1000                     0.001   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5                 0.003   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55                0.003   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6                 0.003   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65                0.002   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7                 0.002   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75                0.001   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8                 0.001   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85                0.001   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9                 0.001   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95                0.001   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0                 0.001   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.983                4   \n",
       "After RANDOM mitigation N = 1000                     0.972                3   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5                 0.966                7   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55                0.972                6   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6                 0.972                6   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65                0.972                5   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7                 0.978                4   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75                0.978                2   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8                 0.972                2   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85                0.983                3   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9                 0.972                3   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95                0.989                2   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0                 0.989                3   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  175       10975       2439  \n",
       "After RANDOM mitigation N = 1000                   173       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.5               172       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.55              173       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.6               173       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.65              173       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.7               174       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.75              174       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.8               173       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.85              175       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.9               173       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.95              176       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 1.0               176       11975       2439  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = FP_fm\n",
    "    df_pruned_fp = FP_fm\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.063</td>\n",
       "      <td>7</td>\n",
       "      <td>172</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.75</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.85</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.95</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.022</td>\n",
       "      <td>2</td>\n",
       "      <td>176</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.022</td>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.927     0.032                4   \n",
       "After RANDOM mitigation N = 1000          0.928     0.054                3   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5      0.927     0.063                7   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55     0.927     0.053                6   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6      0.927     0.053                6   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65     0.927     0.053                5   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7      0.927     0.043                4   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75     0.928     0.043                2   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8      0.928     0.054                2   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85     0.927     0.033                3   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9      0.928     0.054                3   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95     0.927     0.022                2   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0      0.927     0.022                3   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  175           179   \n",
       "After RANDOM mitigation N = 1000                   173           176   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5               172           179   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55              173           179   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6               173           179   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65              173           178   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7               174           178   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75              174           176   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8               173           175   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85              175           178   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9               173           176   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95              176           178   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0               176           179   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               -0.001           0.043   \n",
       "After RANDOM mitigation N = 1000                -0.001           0.043   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5            -0.001           0.072   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55           -0.001           0.073   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6            -0.001           0.064   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65           -0.001           0.064   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7            -0.001           0.065   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75           -0.001           0.037   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8            -0.001           0.037   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85           -0.001           0.055   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9            -0.001           0.043   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95           -0.001           0.037   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0            -0.001           0.043   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.037       0.032       0.027  \n",
       "After RANDOM mitigation N = 1000            0.037       0.032       0.027  \n",
       "After SMOTE N = 1000 p_class 0 = 0.5        0.063       0.057       0.051  \n",
       "After SMOTE N = 1000 p_class 0 = 0.55       0.064       0.058       0.050  \n",
       "After SMOTE N = 1000 p_class 0 = 0.6        0.052       0.048       0.042  \n",
       "After SMOTE N = 1000 p_class 0 = 0.65       0.051       0.045       0.040  \n",
       "After SMOTE N = 1000 p_class 0 = 0.7        0.048       0.043       0.038  \n",
       "After SMOTE N = 1000 p_class 0 = 0.75       0.034       0.028       0.023  \n",
       "After SMOTE N = 1000 p_class 0 = 0.8        0.034       0.028       0.023  \n",
       "After SMOTE N = 1000 p_class 0 = 0.85       0.051       0.046       0.035  \n",
       "After SMOTE N = 1000 p_class 0 = 0.9        0.038       0.033       0.027  \n",
       "After SMOTE N = 1000 p_class 0 = 0.95       0.034       0.028       0.023  \n",
       "After SMOTE N = 1000 p_class 0 = 1.0        0.038       0.033       0.027  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes=attributes\n",
    "                     \n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = FP_fm\n",
    "        df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_1000 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1500</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.5</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.955</td>\n",
       "      <td>18</td>\n",
       "      <td>170</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.55</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.955</td>\n",
       "      <td>13</td>\n",
       "      <td>170</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.966</td>\n",
       "      <td>11</td>\n",
       "      <td>172</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.966</td>\n",
       "      <td>7</td>\n",
       "      <td>172</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.972</td>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.75</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.85</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.9</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.972</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.95</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.927     0.032   \n",
       "After RANDOM mitigation N = 1500          0.928     0.054   \n",
       "After SMOTE N = 1500 p_class 0 = 0.5      0.923     0.078   \n",
       "After SMOTE N = 1500 p_class 0 = 0.55     0.925     0.080   \n",
       "After SMOTE N = 1500 p_class 0 = 0.6      0.925     0.062   \n",
       "After SMOTE N = 1500 p_class 0 = 0.65     0.927     0.063   \n",
       "After SMOTE N = 1500 p_class 0 = 0.7      0.927     0.053   \n",
       "After SMOTE N = 1500 p_class 0 = 0.75     0.928     0.054   \n",
       "After SMOTE N = 1500 p_class 0 = 0.8      0.928     0.043   \n",
       "After SMOTE N = 1500 p_class 0 = 0.85     0.927     0.043   \n",
       "After SMOTE N = 1500 p_class 0 = 0.9      0.929     0.054   \n",
       "After SMOTE N = 1500 p_class 0 = 0.95     0.928     0.033   \n",
       "After SMOTE N = 1500 p_class 0 = 1.0      0.927     0.033   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.002   \n",
       "After RANDOM mitigation N = 1500                     0.001   \n",
       "After SMOTE N = 1500 p_class 0 = 0.5                 0.008   \n",
       "After SMOTE N = 1500 p_class 0 = 0.55                0.006   \n",
       "After SMOTE N = 1500 p_class 0 = 0.6                 0.005   \n",
       "After SMOTE N = 1500 p_class 0 = 0.65                0.003   \n",
       "After SMOTE N = 1500 p_class 0 = 0.7                 0.003   \n",
       "After SMOTE N = 1500 p_class 0 = 0.75                0.001   \n",
       "After SMOTE N = 1500 p_class 0 = 0.8                 0.001   \n",
       "After SMOTE N = 1500 p_class 0 = 0.85                0.001   \n",
       "After SMOTE N = 1500 p_class 0 = 0.9                 0.000   \n",
       "After SMOTE N = 1500 p_class 0 = 0.95                0.000   \n",
       "After SMOTE N = 1500 p_class 0 = 1.0                 0.001   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.983                4   \n",
       "After RANDOM mitigation N = 1500                     0.972                2   \n",
       "After SMOTE N = 1500 p_class 0 = 0.5                 0.955               18   \n",
       "After SMOTE N = 1500 p_class 0 = 0.55                0.955               13   \n",
       "After SMOTE N = 1500 p_class 0 = 0.6                 0.966               11   \n",
       "After SMOTE N = 1500 p_class 0 = 0.65                0.966                7   \n",
       "After SMOTE N = 1500 p_class 0 = 0.7                 0.972                6   \n",
       "After SMOTE N = 1500 p_class 0 = 0.75                0.972                2   \n",
       "After SMOTE N = 1500 p_class 0 = 0.8                 0.978                2   \n",
       "After SMOTE N = 1500 p_class 0 = 0.85                0.978                3   \n",
       "After SMOTE N = 1500 p_class 0 = 0.9                 0.972                1   \n",
       "After SMOTE N = 1500 p_class 0 = 0.95                0.983                1   \n",
       "After SMOTE N = 1500 p_class 0 = 1.0                 0.983                3   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  175       10975       2439  \n",
       "After RANDOM mitigation N = 1500                   173       12475       2439  \n",
       "After SMOTE N = 1500 p_class 0 = 0.5               170       12475       2439  \n",
       "After SMOTE N = 1500 p_class 0 = 0.55              170       12475       2439  \n",
       "After SMOTE N = 1500 p_class 0 = 0.6               172       12475       2439  \n",
       "After SMOTE N = 1500 p_class 0 = 0.65              172       12475       2439  \n",
       "After SMOTE N = 1500 p_class 0 = 0.7               173       12475       2439  \n",
       "After SMOTE N = 1500 p_class 0 = 0.75              173       12475       2439  \n",
       "After SMOTE N = 1500 p_class 0 = 0.8               174       12475       2439  \n",
       "After SMOTE N = 1500 p_class 0 = 0.85              174       12475       2439  \n",
       "After SMOTE N = 1500 p_class 0 = 0.9               173       12475       2439  \n",
       "After SMOTE N = 1500 p_class 0 = 0.95              175       12475       2439  \n",
       "After SMOTE N = 1500 p_class 0 = 1.0               175       12475       2439  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1500\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "                  \n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = FP_fm\n",
    "    df_pruned_fp = FP_fm\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1500</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.5</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.078</td>\n",
       "      <td>18</td>\n",
       "      <td>170</td>\n",
       "      <td>188</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.55</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.080</td>\n",
       "      <td>13</td>\n",
       "      <td>170</td>\n",
       "      <td>183</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.062</td>\n",
       "      <td>11</td>\n",
       "      <td>172</td>\n",
       "      <td>183</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.063</td>\n",
       "      <td>7</td>\n",
       "      <td>172</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.75</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.85</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.9</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.054</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.95</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.033</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.927     0.032                4   \n",
       "After RANDOM mitigation N = 1500          0.928     0.054                2   \n",
       "After SMOTE N = 1500 p_class 0 = 0.5      0.923     0.078               18   \n",
       "After SMOTE N = 1500 p_class 0 = 0.55     0.925     0.080               13   \n",
       "After SMOTE N = 1500 p_class 0 = 0.6      0.925     0.062               11   \n",
       "After SMOTE N = 1500 p_class 0 = 0.65     0.927     0.063                7   \n",
       "After SMOTE N = 1500 p_class 0 = 0.7      0.927     0.053                6   \n",
       "After SMOTE N = 1500 p_class 0 = 0.75     0.928     0.054                2   \n",
       "After SMOTE N = 1500 p_class 0 = 0.8      0.928     0.043                2   \n",
       "After SMOTE N = 1500 p_class 0 = 0.85     0.927     0.043                3   \n",
       "After SMOTE N = 1500 p_class 0 = 0.9      0.929     0.054                1   \n",
       "After SMOTE N = 1500 p_class 0 = 0.95     0.928     0.033                1   \n",
       "After SMOTE N = 1500 p_class 0 = 1.0      0.927     0.033                3   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  175           179   \n",
       "After RANDOM mitigation N = 1500                   173           175   \n",
       "After SMOTE N = 1500 p_class 0 = 0.5               170           188   \n",
       "After SMOTE N = 1500 p_class 0 = 0.55              170           183   \n",
       "After SMOTE N = 1500 p_class 0 = 0.6               172           183   \n",
       "After SMOTE N = 1500 p_class 0 = 0.65              172           179   \n",
       "After SMOTE N = 1500 p_class 0 = 0.7               173           179   \n",
       "After SMOTE N = 1500 p_class 0 = 0.75              173           175   \n",
       "After SMOTE N = 1500 p_class 0 = 0.8               174           176   \n",
       "After SMOTE N = 1500 p_class 0 = 0.85              174           177   \n",
       "After SMOTE N = 1500 p_class 0 = 0.9               173           174   \n",
       "After SMOTE N = 1500 p_class 0 = 0.95              175           176   \n",
       "After SMOTE N = 1500 p_class 0 = 1.0               175           178   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               -0.001           0.043   \n",
       "After RANDOM mitigation N = 1500                -0.001           0.043   \n",
       "After SMOTE N = 1500 p_class 0 = 0.5            -0.002           0.237   \n",
       "After SMOTE N = 1500 p_class 0 = 0.55           -0.001           0.185   \n",
       "After SMOTE N = 1500 p_class 0 = 0.6            -0.001           0.146   \n",
       "After SMOTE N = 1500 p_class 0 = 0.65           -0.002           0.086   \n",
       "After SMOTE N = 1500 p_class 0 = 0.7            -0.001           0.073   \n",
       "After SMOTE N = 1500 p_class 0 = 0.75           -0.000           0.026   \n",
       "After SMOTE N = 1500 p_class 0 = 0.8            -0.001           0.037   \n",
       "After SMOTE N = 1500 p_class 0 = 0.85           -0.001           0.055   \n",
       "After SMOTE N = 1500 p_class 0 = 0.9            -0.000           0.022   \n",
       "After SMOTE N = 1500 p_class 0 = 0.95           -0.000           0.022   \n",
       "After SMOTE N = 1500 p_class 0 = 1.0            -0.001           0.043   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.037       0.032       0.027  \n",
       "After RANDOM mitigation N = 1500            0.037       0.032       0.027  \n",
       "After SMOTE N = 1500 p_class 0 = 0.5        0.229       0.210       0.180  \n",
       "After SMOTE N = 1500 p_class 0 = 0.55       0.180       0.167       0.142  \n",
       "After SMOTE N = 1500 p_class 0 = 0.6        0.135       0.125       0.106  \n",
       "After SMOTE N = 1500 p_class 0 = 0.65       0.069       0.061       0.051  \n",
       "After SMOTE N = 1500 p_class 0 = 0.7        0.064       0.058       0.050  \n",
       "After SMOTE N = 1500 p_class 0 = 0.75       0.025       0.023       0.021  \n",
       "After SMOTE N = 1500 p_class 0 = 0.8        0.034       0.028       0.023  \n",
       "After SMOTE N = 1500 p_class 0 = 0.85       0.051       0.046       0.035  \n",
       "After SMOTE N = 1500 p_class 0 = 0.9        0.019       0.018       0.016  \n",
       "After SMOTE N = 1500 p_class 0 = 0.95       0.019       0.018       0.016  \n",
       "After SMOTE N = 1500 p_class 0 = 1.0        0.038       0.033       0.027  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes=attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = FP_fm\n",
    "        df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_1500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1500\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.5</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.955</td>\n",
       "      <td>19</td>\n",
       "      <td>170</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.55</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.955</td>\n",
       "      <td>16</td>\n",
       "      <td>170</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.6</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.972</td>\n",
       "      <td>12</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.65</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.978</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.85</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.95</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.989</td>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.927     0.032   \n",
       "After RANDOM mitigation N = 2000          0.927     0.053   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5      0.923     0.078   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55     0.924     0.079   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6      0.924     0.051   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65     0.926     0.043   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7      0.927     0.043   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75     0.927     0.053   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8      0.928     0.054   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85     0.928     0.043   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9      0.928     0.054   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95     0.928     0.033   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0      0.927     0.022   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.002   \n",
       "After RANDOM mitigation N = 2000                     0.002   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5                 0.008   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55                0.007   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6                 0.005   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65                0.003   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7                 0.002   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75                0.002   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8                 0.001   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85                0.001   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9                 0.001   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95                0.000   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0                 0.001   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.983                4   \n",
       "After RANDOM mitigation N = 2000                     0.972                4   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5                 0.955               19   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55                0.955               16   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6                 0.972               12   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65                0.978                6   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7                 0.978                5   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75                0.972                4   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8                 0.972                3   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85                0.978                2   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9                 0.972                2   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95                0.983                1   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0                 0.989                3   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  175       10975       2439  \n",
       "After RANDOM mitigation N = 2000                   173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.5               170       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.55              170       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.6               173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.65              174       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.7               174       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.75              173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.8               173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.85              174       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.9               173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.95              175       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 1.0               176       12975       2439  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = FP_fm\n",
    "    df_pruned_fp = FP_fm\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.5</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.078</td>\n",
       "      <td>19</td>\n",
       "      <td>170</td>\n",
       "      <td>189</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.55</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.079</td>\n",
       "      <td>16</td>\n",
       "      <td>170</td>\n",
       "      <td>186</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.6</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.051</td>\n",
       "      <td>12</td>\n",
       "      <td>173</td>\n",
       "      <td>185</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.65</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>180</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.85</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.95</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.033</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.022</td>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.927     0.032                4   \n",
       "After RANDOM mitigation N = 2000          0.927     0.053                4   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5      0.923     0.078               19   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55     0.924     0.079               16   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6      0.924     0.051               12   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65     0.926     0.043                6   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7      0.927     0.043                5   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75     0.927     0.053                4   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8      0.928     0.054                3   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85     0.928     0.043                2   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9      0.928     0.054                2   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95     0.928     0.033                1   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0      0.927     0.022                3   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  175           179   \n",
       "After RANDOM mitigation N = 2000                   173           177   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5               170           189   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55              170           186   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6               173           185   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65              174           180   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7               174           179   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75              173           177   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8               173           176   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85              174           176   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9               173           175   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95              175           176   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0               176           179   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               -0.001           0.043   \n",
       "After RANDOM mitigation N = 2000                -0.001           0.043   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5            -0.002           0.262   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55           -0.002           0.215   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6            -0.001           0.185   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65           -0.001           0.092   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7            -0.001           0.073   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75           -0.001           0.065   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8            -0.001           0.065   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85           -0.001           0.037   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9            -0.001           0.037   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95           -0.000           0.022   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0            -0.001           0.043   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.037       0.032       0.027  \n",
       "After RANDOM mitigation N = 2000            0.037       0.032       0.027  \n",
       "After SMOTE N = 2000 p_class 0 = 0.5        0.253       0.237       0.203  \n",
       "After SMOTE N = 2000 p_class 0 = 0.55       0.205       0.196       0.168  \n",
       "After SMOTE N = 2000 p_class 0 = 0.6        0.181       0.165       0.141  \n",
       "After SMOTE N = 2000 p_class 0 = 0.65       0.079       0.071       0.062  \n",
       "After SMOTE N = 2000 p_class 0 = 0.7        0.064       0.058       0.051  \n",
       "After SMOTE N = 2000 p_class 0 = 0.75       0.052       0.046       0.039  \n",
       "After SMOTE N = 2000 p_class 0 = 0.8        0.048       0.043       0.036  \n",
       "After SMOTE N = 2000 p_class 0 = 0.85       0.034       0.028       0.023  \n",
       "After SMOTE N = 2000 p_class 0 = 0.9        0.034       0.028       0.023  \n",
       "After SMOTE N = 2000 p_class 0 = 0.95       0.019       0.018       0.016  \n",
       "After SMOTE N = 2000 p_class 0 = 1.0        0.038       0.033       0.027  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes=attributes\n",
    "                      \n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = FP_fm\n",
    "        df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_2000 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2500</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.5</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.944</td>\n",
       "      <td>27</td>\n",
       "      <td>168</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.55</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.944</td>\n",
       "      <td>21</td>\n",
       "      <td>168</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.955</td>\n",
       "      <td>12</td>\n",
       "      <td>170</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.65</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.966</td>\n",
       "      <td>12</td>\n",
       "      <td>172</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.7</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.983</td>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.75</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.978</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.85</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.9</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.95</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1</td>\n",
       "      <td>176</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.927     0.032   \n",
       "After RANDOM mitigation N = 2500          0.927     0.033   \n",
       "After SMOTE N = 2500 p_class 0 = 0.5      0.920     0.093   \n",
       "After SMOTE N = 2500 p_class 0 = 0.55     0.923     0.096   \n",
       "After SMOTE N = 2500 p_class 0 = 0.6      0.925     0.081   \n",
       "After SMOTE N = 2500 p_class 0 = 0.65     0.925     0.061   \n",
       "After SMOTE N = 2500 p_class 0 = 0.7      0.926     0.032   \n",
       "After SMOTE N = 2500 p_class 0 = 0.75     0.926     0.043   \n",
       "After SMOTE N = 2500 p_class 0 = 0.8      0.928     0.054   \n",
       "After SMOTE N = 2500 p_class 0 = 0.85     0.928     0.043   \n",
       "After SMOTE N = 2500 p_class 0 = 0.9      0.927     0.033   \n",
       "After SMOTE N = 2500 p_class 0 = 0.95     0.928     0.033   \n",
       "After SMOTE N = 2500 p_class 0 = 1.0      0.927     0.022   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.002   \n",
       "After RANDOM mitigation N = 2500                     0.001   \n",
       "After SMOTE N = 2500 p_class 0 = 0.5                 0.012   \n",
       "After SMOTE N = 2500 p_class 0 = 0.55                0.009   \n",
       "After SMOTE N = 2500 p_class 0 = 0.6                 0.005   \n",
       "After SMOTE N = 2500 p_class 0 = 0.65                0.005   \n",
       "After SMOTE N = 2500 p_class 0 = 0.7                 0.003   \n",
       "After SMOTE N = 2500 p_class 0 = 0.75                0.003   \n",
       "After SMOTE N = 2500 p_class 0 = 0.8                 0.001   \n",
       "After SMOTE N = 2500 p_class 0 = 0.85                0.001   \n",
       "After SMOTE N = 2500 p_class 0 = 0.9                 0.001   \n",
       "After SMOTE N = 2500 p_class 0 = 0.95                0.000   \n",
       "After SMOTE N = 2500 p_class 0 = 1.0                 0.000   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.983                4   \n",
       "After RANDOM mitigation N = 2500                     0.983                3   \n",
       "After SMOTE N = 2500 p_class 0 = 0.5                 0.944               27   \n",
       "After SMOTE N = 2500 p_class 0 = 0.55                0.944               21   \n",
       "After SMOTE N = 2500 p_class 0 = 0.6                 0.955               12   \n",
       "After SMOTE N = 2500 p_class 0 = 0.65                0.966               12   \n",
       "After SMOTE N = 2500 p_class 0 = 0.7                 0.983                6   \n",
       "After SMOTE N = 2500 p_class 0 = 0.75                0.978                6   \n",
       "After SMOTE N = 2500 p_class 0 = 0.8                 0.972                3   \n",
       "After SMOTE N = 2500 p_class 0 = 0.85                0.978                2   \n",
       "After SMOTE N = 2500 p_class 0 = 0.9                 0.983                2   \n",
       "After SMOTE N = 2500 p_class 0 = 0.95                0.983                1   \n",
       "After SMOTE N = 2500 p_class 0 = 1.0                 0.989                1   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  175       10975       2439  \n",
       "After RANDOM mitigation N = 2500                   175       13475       2439  \n",
       "After SMOTE N = 2500 p_class 0 = 0.5               168       13475       2439  \n",
       "After SMOTE N = 2500 p_class 0 = 0.55              168       13475       2439  \n",
       "After SMOTE N = 2500 p_class 0 = 0.6               170       13475       2439  \n",
       "After SMOTE N = 2500 p_class 0 = 0.65              172       13475       2439  \n",
       "After SMOTE N = 2500 p_class 0 = 0.7               175       13475       2439  \n",
       "After SMOTE N = 2500 p_class 0 = 0.75              174       13475       2439  \n",
       "After SMOTE N = 2500 p_class 0 = 0.8               173       13475       2439  \n",
       "After SMOTE N = 2500 p_class 0 = 0.85              174       13475       2439  \n",
       "After SMOTE N = 2500 p_class 0 = 0.9               175       13475       2439  \n",
       "After SMOTE N = 2500 p_class 0 = 0.95              175       13475       2439  \n",
       "After SMOTE N = 2500 p_class 0 = 1.0               176       13475       2439  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2500\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "                 \n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = FP_fm\n",
    "    df_pruned_fp = FP_fm\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2500</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.5</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.093</td>\n",
       "      <td>27</td>\n",
       "      <td>168</td>\n",
       "      <td>195</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.55</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.096</td>\n",
       "      <td>21</td>\n",
       "      <td>168</td>\n",
       "      <td>189</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.081</td>\n",
       "      <td>12</td>\n",
       "      <td>170</td>\n",
       "      <td>182</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.65</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.061</td>\n",
       "      <td>12</td>\n",
       "      <td>172</td>\n",
       "      <td>184</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.7</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.032</td>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>181</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.75</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>180</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.85</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.9</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.95</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.033</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.022</td>\n",
       "      <td>1</td>\n",
       "      <td>176</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.927     0.032                4   \n",
       "After RANDOM mitigation N = 2500          0.927     0.033                3   \n",
       "After SMOTE N = 2500 p_class 0 = 0.5      0.920     0.093               27   \n",
       "After SMOTE N = 2500 p_class 0 = 0.55     0.923     0.096               21   \n",
       "After SMOTE N = 2500 p_class 0 = 0.6      0.925     0.081               12   \n",
       "After SMOTE N = 2500 p_class 0 = 0.65     0.925     0.061               12   \n",
       "After SMOTE N = 2500 p_class 0 = 0.7      0.926     0.032                6   \n",
       "After SMOTE N = 2500 p_class 0 = 0.75     0.926     0.043                6   \n",
       "After SMOTE N = 2500 p_class 0 = 0.8      0.928     0.054                3   \n",
       "After SMOTE N = 2500 p_class 0 = 0.85     0.928     0.043                2   \n",
       "After SMOTE N = 2500 p_class 0 = 0.9      0.927     0.033                2   \n",
       "After SMOTE N = 2500 p_class 0 = 0.95     0.928     0.033                1   \n",
       "After SMOTE N = 2500 p_class 0 = 1.0      0.927     0.022                1   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  175           179   \n",
       "After RANDOM mitigation N = 2500                   175           178   \n",
       "After SMOTE N = 2500 p_class 0 = 0.5               168           195   \n",
       "After SMOTE N = 2500 p_class 0 = 0.55              168           189   \n",
       "After SMOTE N = 2500 p_class 0 = 0.6               170           182   \n",
       "After SMOTE N = 2500 p_class 0 = 0.65              172           184   \n",
       "After SMOTE N = 2500 p_class 0 = 0.7               175           181   \n",
       "After SMOTE N = 2500 p_class 0 = 0.75              174           180   \n",
       "After SMOTE N = 2500 p_class 0 = 0.8               173           176   \n",
       "After SMOTE N = 2500 p_class 0 = 0.85              174           176   \n",
       "After SMOTE N = 2500 p_class 0 = 0.9               175           177   \n",
       "After SMOTE N = 2500 p_class 0 = 0.95              175           176   \n",
       "After SMOTE N = 2500 p_class 0 = 1.0               176           177   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               -0.001           0.043   \n",
       "After RANDOM mitigation N = 2500                -0.001           0.043   \n",
       "After SMOTE N = 2500 p_class 0 = 0.5            -0.002           0.384   \n",
       "After SMOTE N = 2500 p_class 0 = 0.55           -0.002           0.282   \n",
       "After SMOTE N = 2500 p_class 0 = 0.6            -0.001           0.202   \n",
       "After SMOTE N = 2500 p_class 0 = 0.65           -0.001           0.185   \n",
       "After SMOTE N = 2500 p_class 0 = 0.7            -0.001           0.086   \n",
       "After SMOTE N = 2500 p_class 0 = 0.75           -0.001           0.073   \n",
       "After SMOTE N = 2500 p_class 0 = 0.8            -0.001           0.065   \n",
       "After SMOTE N = 2500 p_class 0 = 0.85           -0.001           0.037   \n",
       "After SMOTE N = 2500 p_class 0 = 0.9            -0.001           0.037   \n",
       "After SMOTE N = 2500 p_class 0 = 0.95           -0.000           0.022   \n",
       "After SMOTE N = 2500 p_class 0 = 1.0            -0.000           0.022   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.037       0.032       0.027  \n",
       "After RANDOM mitigation N = 2500            0.037       0.032       0.027  \n",
       "After SMOTE N = 2500 p_class 0 = 0.5        0.327       0.295       0.255  \n",
       "After SMOTE N = 2500 p_class 0 = 0.55       0.274       0.254       0.217  \n",
       "After SMOTE N = 2500 p_class 0 = 0.6        0.181       0.164       0.144  \n",
       "After SMOTE N = 2500 p_class 0 = 0.65       0.181       0.165       0.141  \n",
       "After SMOTE N = 2500 p_class 0 = 0.7        0.069       0.063       0.054  \n",
       "After SMOTE N = 2500 p_class 0 = 0.75       0.064       0.058       0.050  \n",
       "After SMOTE N = 2500 p_class 0 = 0.8        0.048       0.043       0.036  \n",
       "After SMOTE N = 2500 p_class 0 = 0.85       0.034       0.028       0.023  \n",
       "After SMOTE N = 2500 p_class 0 = 0.9        0.034       0.028       0.023  \n",
       "After SMOTE N = 2500 p_class 0 = 0.95       0.019       0.018       0.016  \n",
       "After SMOTE N = 2500 p_class 0 = 1.0        0.019       0.018       0.016  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes=attributes\n",
    "                          \n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = FP_fm\n",
    "        df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_2500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati salvati in false_positives_K_compas.json\n",
      "‚úÖ Variabili salvate con successo in false_positives_K_compas.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"false_positives_K_compas.json\"\n",
    "\n",
    "# Controlla se il file esiste gi√† per evitare di sovrascrivere\n",
    "if os.path.exists(json_filename):\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        false_positives_data = json.load(f)\n",
    "else:\n",
    "    false_positives_data = {}\n",
    "\n",
    "# Lista dei diversi metrics_after_fp_SMOTE_XK\n",
    "metrics_dict = {\n",
    "    \"500_run1\": metrics_after_fp_SMOTE_500,\n",
    "    \"1000_run1\": metrics_after_fp_SMOTE_1000,\n",
    "    \"1500_run1\": metrics_after_fp_SMOTE_1500,\n",
    "    \"2000_run1\": metrics_after_fp_SMOTE_2000,\n",
    "    \"2500_run1\": metrics_after_fp_SMOTE_2500,\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni dataset e salviamo i falsi positivi\n",
    "for J, metrics in metrics_dict.items():\n",
    "    false_positives_data[f\"N={J}\"] = metrics[\"False Positives\"].to_dict()\n",
    "\n",
    "# Salviamo il JSON aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(false_positives_data, f, indent=4)\n",
    "\n",
    "print(f\"Dati salvati in {json_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "#per i parametri # Nome del file JSON\n",
    "json_filename = \"false_positives_K_compas.json\"\n",
    "\n",
    "# Valori da salvare (sostituiscili con i tuoi valori reali)\n",
    "min_sup_run1 = min_sup\n",
    "percentage_run1 = percentage\n",
    "th_redundancy_run1 = pruning\n",
    "K_run1 = K\n",
    "L_run1 = filtered_instances  # Supponiamo sia la lunghezza di filtered_instances\n",
    "\n",
    "# 1Ô∏è‚É£ Caricare i dati esistenti (se il file esiste)\n",
    "try:\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        false_positives_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    false_positives_data = {}  # Se il file non esiste, inizializza un dizionario vuoto\n",
    "\n",
    "# 2Ô∏è‚É£ Aggiungere le nuove variabili sotto una chiave dedicata\n",
    "false_positives_data[\"run1_parameters\"] = {\n",
    "    \"min_sup\": min_sup_run1,\n",
    "    \"percentage\": percentage_run1,\n",
    "    \"th_redundancy\": th_redundancy_run1,\n",
    "    \"K\": percentage,\n",
    "    \"L\": L_run1\n",
    "}\n",
    "\n",
    "# 3Ô∏è‚É£ Salvare il file aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(false_positives_data, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ Variabili salvate con successo in\", json_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"false_positives_K_compas.json\"\n",
    "\n",
    "# Caricare i dati dal file JSON\n",
    "with open(json_filename, \"r\") as f:\n",
    "    false_positives_data = json.load(f)\n",
    "\n",
    "# Estrarre parametri dal JSON\n",
    "run1_params = false_positives_data.get(\"run1_parameters\", {})\n",
    "min_sup = run1_params.get(\"min_sup\", \"N/A\")\n",
    "percentage = run1_params.get(\"percentage\", \"N/A\")\n",
    "th_redundancy = run1_params.get(\"th_redundancy\", \"N/A\")\n",
    "L = run1_params.get(\"L\", \"N/A\")\n",
    "K = int((percentage / 100) * L)  # K rappresenta il numero di sottogruppi\n",
    "\n",
    "# Lista dei valori di p da 0.5 a 1.0 con step 0.05\n",
    "p_values = np.arange(0.5, 1.05, 0.05)\n",
    "\n",
    "# Definiamo i colori per ogni N\n",
    "colors = [\"blue\", \"red\", \"orange\", \"pink\", \"green\"]\n",
    "labels = [f\"N={n}K\" for n in range(500, 2501, 500)]\n",
    "\n",
    "# Creazione della figura\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig.suptitle(\"FALSE POSITIVE MITIGATION\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Disegniamo la linea tratteggiata \"Before Mitigation\"\n",
    "before_mitigation = false_positives_data.get(\"N=500_run1\", {}).get(\"Before Mitigation\", None)\n",
    "if before_mitigation is not None:\n",
    "    ax.axhline(y=before_mitigation, color=\"purple\", linestyle=\"--\", linewidth=2, label=\"Before Mitigation\")\n",
    "\n",
    "# Aggiungere linee verticali per ogni valore di p\n",
    "for p in p_values:\n",
    "    ax.axvline(x=p, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Inizializziamo la lista per la legenda\n",
    "legend_handles = []\n",
    "\n",
    "# Loop sui vari N (da 500 a 2500)\n",
    "for i, n in enumerate(range(500, 2501, 500)):  # da 500 a 2500 con passo 500\n",
    "    N_key = f\"N={n}_run1\"\n",
    "    if N_key not in false_positives_data:\n",
    "        continue\n",
    "    \n",
    "    data = false_positives_data[N_key]\n",
    "    \n",
    "    # Estrarre i valori di falsi positivi per ogni p\n",
    "    false_positives = [\n",
    "        data.get(f\"After SMOTE N = {n} p_class 0 = {round(p, 2)}\", None) \n",
    "        for p in p_values\n",
    "    ]\n",
    "    \n",
    "    # Filtriamo solo i valori validi\n",
    "    p_values_filtered = [p for j, p in enumerate(p_values) if false_positives[j] is not None]\n",
    "    false_positives_filtered = [fp for fp in false_positives if fp is not None]\n",
    "    \n",
    "    # Se ci sono dati validi, plottiamo la linea\n",
    "    if false_positives_filtered:\n",
    "        line, = ax.plot(\n",
    "            p_values_filtered, false_positives_filtered, \n",
    "            marker=\"o\", linestyle=\"-\", color=colors[i], label=labels[i]\n",
    "        )\n",
    "        legend_handles.append(line)\n",
    "\n",
    "# Impostazioni asse\n",
    "ax.set_title(f\"Minsup = {min_sup}, pruning = {th_redundancy}, K% = {percentage}, subgroups: {K}/{L}\")\n",
    "ax.set_xlabel(\"p_class 0\")\n",
    "ax.set_ylabel(\"False Positives\")\n",
    "ax.grid()\n",
    "\n",
    "# Aggiungere la leggenda\n",
    "ax.legend(handles=legend_handles, loc=\"upper right\", fontsize=10, frameon=True, title=\"Legend\")\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
