{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1989,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_for_adult import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "\n",
    "from divexplorer.outcomes import get_false_negative_rate_outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1990,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv(\"adult.data\", header = None, names = col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1991,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1992,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.01\n",
    "pruning = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1993,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = 0.30\n",
    "percentage = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1994,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1995,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosità precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1996,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GDecisioN tree predictions\n",
    "X_train = df_train_enc.drop(columns = 'income', axis = 1)\n",
    "y_train = df_train_enc['income']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'income', axis = 1)\n",
    "y_test = df_test_enc['income']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'income', axis = 1)\n",
    "y_val = df_val_enc['income']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'income', axis = 1)\n",
    "y_holdout = df_holdout_enc['income']\n",
    "\n",
    "classifier_train = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1997,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.803     0.593                0.130   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.407              641              638   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       6508  "
      ]
     },
     "execution_count": 1997,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione è giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1998,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>2</td>\n",
       "      <td>0.077</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0</td>\n",
       "      <td>0.284</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass  fnlwgt  education  marital-status  occupation  relationship  \\\n",
       "18761          2   0.077          3               0           4             1   \n",
       "27582          3   0.048          3               1           4             0   \n",
       "30911          2   0.174          3               3           4             4   \n",
       "11128          0   0.012          2               1           2             0   \n",
       "683            0   0.284          3               3           2             4   \n",
       "\n",
       "       race  sex  capital-gain  capital-loss  native-country  age_group  \\\n",
       "18761     4    0         0.000         0.000               5          2   \n",
       "27582     4    1         0.000         0.000               5          5   \n",
       "30911     2    0         0.039         0.000               5          1   \n",
       "11128     2    1         0.000         0.507               5          3   \n",
       "683       2    1         0.000         0.000               5          0   \n",
       "\n",
       "       edu_num_group  hours_per_week_group  y_val_true  y_pred  \n",
       "18761              1                     1           0       0  \n",
       "27582              1                     2           1       0  \n",
       "30911              1                     1           0       0  \n",
       "11128              4                     1           1       1  \n",
       "683                1                     1           0       0  "
      ]
     },
     "execution_count": 1998,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set\n",
    "y_pred_val_dt = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val_dt\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1999,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>fn</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.077</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>Self-emp</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>65-100</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.174</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.012</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>45-54</td>\n",
       "      <td>14 Master's Degree</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.284</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        workclass  fnlwgt        education marital-status    occupation  \\\n",
       "18761     Private   0.077    Non Graduated       Divorced  Self-emp-occ   \n",
       "27582    Self-emp   0.048    Non Graduated        Married  Self-emp-occ   \n",
       "30911     Private   0.174    Non Graduated      Separated  Self-emp-occ   \n",
       "11128  Government   0.012  Master's Degree        Married   Private-occ   \n",
       "683    Government   0.284    Non Graduated      Separated   Private-occ   \n",
       "\n",
       "         relationship    race      sex  capital-gain  capital-loss  \\\n",
       "18761   Not-in-family   White   Female         0.000         0.000   \n",
       "27582         Husband   White     Male         0.000         0.000   \n",
       "30911       Unmarried   Black   Female         0.039         0.000   \n",
       "11128         Husband   Black     Male         0.000         0.507   \n",
       "683         Unmarried   Black     Male         0.000         0.000   \n",
       "\n",
       "      native-country  income age_group       edu_num_group  \\\n",
       "18761  United-States       0     35-44          10 College   \n",
       "27582  United-States       1    65-100          10 College   \n",
       "30911  United-States       0     25-34          10 College   \n",
       "11128  United-States       1     45-54  14 Master's Degree   \n",
       "683    United-States       0     17-24          10 College   \n",
       "\n",
       "      hours_per_week_group    fn  y_pred  accuracy  \n",
       "18761             Overtime   NaN       0         1  \n",
       "27582            Part-time 1.000       0         0  \n",
       "30911             Overtime   NaN       0         1  \n",
       "11128             Overtime 0.000       1         1  \n",
       "683               Overtime   NaN       0         1  "
      ]
     },
     "execution_count": 1999,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]\n",
    "\n",
    "df_val_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_val['fn'] = df_val_class['fn']\n",
    "\n",
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione è giusta 0 se la predizione è sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['accuracy'] = (df_val_class['y_val_true']==df_val_class['y_pred']).astype(int)\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2000,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_div</th>\n",
       "      <th>fn_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.380</td>\n",
       "      <td>(education=Non Graduated, workclass=Private, race= White, capital-gain=0.0, capital-loss=0.0)</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.324</td>\n",
       "      <td>11.316</td>\n",
       "      <td>5</td>\n",
       "      <td>2474.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.399</td>\n",
       "      <td>(education=Non Graduated, workclass=Private, native-country=United-States, capital-gain=0.0, capital-loss=0.0)</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.324</td>\n",
       "      <td>11.371</td>\n",
       "      <td>5</td>\n",
       "      <td>2598.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344</td>\n",
       "      <td>(education=Non Graduated, workclass=Private, native-country=United-States, race= White, capital-gain=0.0, capital-loss=0.0)</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.324</td>\n",
       "      <td>11.116</td>\n",
       "      <td>6</td>\n",
       "      <td>2237.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.453</td>\n",
       "      <td>(workclass=Private, capital-loss=0.0, education=Non Graduated, capital-gain=0.0)</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.323</td>\n",
       "      <td>11.669</td>\n",
       "      <td>4</td>\n",
       "      <td>2945.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333</td>\n",
       "      <td>(education=Non Graduated, workclass=Private, hours_per_week_group=Overtime, capital-gain=0.0, capital-loss=0.0)</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.319</td>\n",
       "      <td>11.121</td>\n",
       "      <td>5</td>\n",
       "      <td>2168.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.380   \n",
       "1    0.399   \n",
       "2    0.344   \n",
       "3    0.453   \n",
       "4    0.333   \n",
       "\n",
       "                                                                                                                       itemset  \\\n",
       "0                                (education=Non Graduated, workclass=Private, race= White, capital-gain=0.0, capital-loss=0.0)   \n",
       "1               (education=Non Graduated, workclass=Private, native-country=United-States, capital-gain=0.0, capital-loss=0.0)   \n",
       "2  (education=Non Graduated, workclass=Private, native-country=United-States, race= White, capital-gain=0.0, capital-loss=0.0)   \n",
       "3                                             (workclass=Private, capital-loss=0.0, education=Non Graduated, capital-gain=0.0)   \n",
       "4              (education=Non Graduated, workclass=Private, hours_per_week_group=Overtime, capital-gain=0.0, capital-loss=0.0)   \n",
       "\n",
       "     fn  fn_div   fn_t  length  support_count  \n",
       "0 0.706   0.324 11.316       5       2474.000  \n",
       "1 0.706   0.324 11.371       5       2598.000  \n",
       "2 0.706   0.324 11.116       6       2237.000  \n",
       "3 0.705   0.323 11.669       4       2945.000  \n",
       "4 0.701   0.319 11.121       5       2168.000  "
      ]
     },
     "execution_count": 2000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_diver = DivergenceExplorer(df_val)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2001,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_div</th>\n",
       "      <th>fn_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.453</td>\n",
       "      <td>(workclass=Private, capital-loss=0.0, education=Non Graduated, capital-gain=0.0)</td>\n",
       "      <td>4</td>\n",
       "      <td>2945.000</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.323</td>\n",
       "      <td>11.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.311</td>\n",
       "      <td>(marital-status=Never-married, capital-gain=0.0)</td>\n",
       "      <td>2</td>\n",
       "      <td>2021.000</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.307</td>\n",
       "      <td>5.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.608</td>\n",
       "      <td>(capital-loss=0.0, education=Non Graduated, capital-gain=0.0)</td>\n",
       "      <td>3</td>\n",
       "      <td>3958.000</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.305</td>\n",
       "      <td>12.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.301</td>\n",
       "      <td>(edu_num_group=9 High School Graduate, capital-gain=0.0)</td>\n",
       "      <td>2</td>\n",
       "      <td>1956.000</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.292</td>\n",
       "      <td>9.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.471</td>\n",
       "      <td>(education=Non Graduated, workclass=Private, capital-gain=0.0)</td>\n",
       "      <td>3</td>\n",
       "      <td>3062.000</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.272</td>\n",
       "      <td>9.884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support  \\\n",
       "3     0.453   \n",
       "5     0.311   \n",
       "7     0.608   \n",
       "17    0.301   \n",
       "24    0.471   \n",
       "\n",
       "                                                                             itemset  \\\n",
       "3   (workclass=Private, capital-loss=0.0, education=Non Graduated, capital-gain=0.0)   \n",
       "5                                   (marital-status=Never-married, capital-gain=0.0)   \n",
       "7                      (capital-loss=0.0, education=Non Graduated, capital-gain=0.0)   \n",
       "17                          (edu_num_group=9 High School Graduate, capital-gain=0.0)   \n",
       "24                    (education=Non Graduated, workclass=Private, capital-gain=0.0)   \n",
       "\n",
       "    length  support_count    fn  fn_div   fn_t  \n",
       "3        4       2945.000 0.705   0.323 11.669  \n",
       "5        2       2021.000 0.689   0.307  5.051  \n",
       "7        3       3958.000 0.687   0.305 12.546  \n",
       "17       2       1956.000 0.674   0.292  9.557  \n",
       "24       3       3062.000 0.654   0.272  9.884  "
      ]
     },
     "execution_count": 2001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2002,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 43\n",
      "total problematic 30\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_fp)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_fp[(df_pruned_fp['fn_div'] > 0) & (df_pruned_fp['fn_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2003,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (338, 7)\n",
      "Dim pruned th_redundancy  (43, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_fp.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2004,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2004,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset3 li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2005,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prima 2904\n",
      "dopo 316\n"
     ]
    }
   ],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "print('prima', len(df_holdout_filtered))\n",
    "df_holdout_filtered_solo1 = df_holdout_filtered[df_holdout_filtered['income']==1]\n",
    "\n",
    "\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered_solo1, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "df_holdout_filtered = df_holdout_filtered_solo1 \n",
    "\n",
    "print(\"dopo\", len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2006,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "TRAIN SET MITIGATED ROWS:  13330\n",
      "VALIDATION SET ROWS:  6508\n",
      "FILTERED DF holdout ROWS:  316\n",
      "TEST SET FILTERED ROWS:  6507\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2007,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'income', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['income']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2008,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "verifica : 316\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['income']\n",
    "\n",
    "classifier_train_mitigated_random = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2009,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Gradient Boosting performance when boolean outcomes = fn \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.380</td>\n",
       "      <td>686</td>\n",
       "      <td>596</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.400</td>\n",
       "      <td>608</td>\n",
       "      <td>627</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.803     0.593                0.130   \n",
       "After Mitigation(K=5, fp)     0.803     0.603                0.139   \n",
       "After RANDOM mitigation       0.810     0.604                0.123   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.407              641   \n",
       "After Mitigation(K=5, fp)                0.380              686   \n",
       "After RANDOM mitigation                  0.400              608   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      638       13014       6508  \n",
       "After Mitigation(K=5, fp)              596       13330       6508  \n",
       "After RANDOM mitigation                627       13330       6508  "
      ]
     },
     "execution_count": 2009,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "print(\"Overall Gradient Boosting performance when boolean outcomes = fn \")\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2010,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.704</td>\n",
       "      <td>222</td>\n",
       "      <td>231</td>\n",
       "      <td>13014</td>\n",
       "      <td>2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.625</td>\n",
       "      <td>262</td>\n",
       "      <td>205</td>\n",
       "      <td>13330</td>\n",
       "      <td>2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.692</td>\n",
       "      <td>214</td>\n",
       "      <td>227</td>\n",
       "      <td>13330</td>\n",
       "      <td>2957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                         Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                    0.847     0.300   \n",
       "After Mitigation(K=5, on subgroups, fp)            0.842     0.345   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)     0.851     0.314   \n",
       "\n",
       "Metrics                                         False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                               0.084   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.100   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.081   \n",
       "\n",
       "Metrics                                         False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                               0.704   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.625   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.692   \n",
       "\n",
       "Metrics                                         False Positives  \\\n",
       "Before Mitigation, on subgroups                             222   \n",
       "After Mitigation(K=5, on subgroups, fp)                     262   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              214   \n",
       "\n",
       "Metrics                                         False Negatives  Train Size  \\\n",
       "Before Mitigation, on subgroups                             231       13014   \n",
       "After Mitigation(K=5, on subgroups, fp)                     205       13330   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              227       13330   \n",
       "\n",
       "Metrics                                         Test Size  \n",
       "Before Mitigation, on subgroups                      2957  \n",
       "After Mitigation(K=5, on subgroups, fp)              2957  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)       2957  "
      ]
     },
     "execution_count": 2010,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered_fp = K_subgroups_dataset_and_or(df_pruned_fp, df_test, K)\n",
    "inutile, df_test_filtered_enc_fp, inutile2, inutile3 = encoding_funct(df_train, df_test_filtered_fp, df_holdout, df_val)\n",
    "\n",
    "X_test_filtered_fp = df_test_filtered_enc_fp.drop(columns='income', axis = 1)\n",
    "y_true_test_filtered_fp = df_test_filtered_enc_fp['income']\n",
    "\n",
    "y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after = classifier_train_mitigated.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_random = classifier_train_mitigated_random.predict(X_test_filtered_fp)\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after )\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_random)\n",
    "\n",
    "\n",
    "metrics_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after, len(y_train_mitigated), len(y_pred_test_filtered_fp_after)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(y_train_mitigated_random), len(y_pred_test_filtered_fp_after_random)]\n",
    "})\n",
    "metrics_after_fp_sottogruppi = metrics_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi[metric] = metrics_after_fp_sottogruppi[metric].astype(int)\n",
    "\n",
    "metrics_after_fp\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fn\")\n",
    "metrics_after_fp_sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2011,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values([\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fn_div_list_no_mitigation  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fn_div_list_no_mitigation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2012,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fn_div_list_baseline1  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fn_div_list_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2013,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values([\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fn_div_list_random_per_confrontare_con_baseline1  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fn_div_list_random_per_confrontare_con_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2014,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.164</td>\n",
       "      <td>316.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.147</td>\n",
       "      <td>316.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.803     0.593             0.097   \n",
       "After Mitigation(K=5 fp)            0.803     0.603             0.081   \n",
       "After RANDOM Mitigation(K=5 fp)     0.810     0.604             0.093   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.429               0.260   \n",
       "After Mitigation(K=5 fp)           0.410               0.250   \n",
       "After RANDOM Mitigation(K=5 fp)    0.473               0.292   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.203               0.137   \n",
       "After Mitigation(K=5 fp)                      0.216               0.164   \n",
       "After RANDOM Mitigation(K=5 fp)               0.228               0.147   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)               316.000  \n",
       "After RANDOM Mitigation(K=5 fp)        316.000  "
      ]
     },
     "execution_count": 2014,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fn_div_list_no_mitigation = np.nanmean(fn_div_list_no_mitigation)\n",
    "media_fn_div_list_nomitigation_primi10 = np.nanmean(fn_div_list_no_mitigation[:10])\n",
    "media_fn_div_list_nomitigation_primi20 = np.nanmean(fn_div_list_no_mitigation[:20])\n",
    "media_fn_div_list_nomitigation_primi40 = np.nanmean(fn_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fn_div_no_mitigation = max(abs(x) for x in fn_div_list_no_mitigation)\n",
    "\n",
    "media_fn_div_list_baseline1 = np.nanmean(fn_div_list_baseline1)\n",
    "media_fn_div_list_baseline1_primi10 = np.nanmean(fn_div_list_baseline1[:10])\n",
    "media_fn_div_list_baseline1_primi20 = np.nanmean(fn_div_list_baseline1[:20])\n",
    "media_fn_div_list_baseline1_primi40 = np.nanmean(fn_div_list_baseline1[:40])\n",
    "fn_div_massimo_valore_assoluto_fn_div_baseline1 = max(abs(x) for x in fn_div_list_baseline1)\n",
    "\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fn_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fn_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fn_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fn_div_list_no_mitigation, massimo_valore_assoluto_fn_div_no_mitigation,\n",
    "        media_fn_div_list_nomitigation_primi10, media_fn_div_list_nomitigation_primi20, media_fn_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_fn_div_list_baseline1, fn_div_massimo_valore_assoluto_fn_div_baseline1,\n",
    "        media_fn_div_list_baseline1_primi10, media_fn_div_list_baseline1_primi20, media_fn_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fn_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fn_div_random_per_confrontare_con_baseline1, media_fn_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fn_div_list_random_per_confrontare_con_baseline1_primi20, media_fn_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fn_sottogruppi = divergence_after_fn_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fn_sottogruppi\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUI INIZIA SMOTE come si deve DA METTERE NEL REPORT\n",
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p è la probabilità che il campione simulato sia di classe 0 qui (perchè voglio diminuire il numero di falsi negativi)\n",
    "- FISSO p VARIA N , aumento il numero di 0 per diminuire il numero di falsi negativi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2015,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 1947\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['fn', 'y_pred', 'accuracy', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2016,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 1895)"
      ]
     },
     "execution_count": 2016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered['income'].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUI MODIFICO FACENDO SMOTE SU DF_VAL_FILTERED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2017,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smote_nc = SMOTENC(categorical_features=categorical_features,random_state=seed)\\nX_to_SMOTE, y_to_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\ncount_1 = y_to_SMOTE.sum()\\ncount_0 = len(y_to_SMOTE)-count_1\\ncount_0, count_1'"
      ]
     },
     "execution_count": 2017,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''smote_nc = SMOTENC(categorical_features=categorical_features,random_state=seed)\n",
    "X_to_SMOTE, y_to_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "count_1 = y_to_SMOTE.sum()\n",
    "count_0 = len(y_to_SMOTE)-count_1\n",
    "count_0, count_1'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2018,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2018,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2019,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]"
      ]
     },
     "execution_count": 2019,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = np.arange(0.5, 1.05, 0.05)\n",
    "p_values = np.round(p_values, 2).tolist()\n",
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2020,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 316</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.400</td>\n",
       "      <td>608</td>\n",
       "      <td>627</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.5</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.402</td>\n",
       "      <td>649</td>\n",
       "      <td>631</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.55</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.399</td>\n",
       "      <td>659</td>\n",
       "      <td>625</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.6</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.404</td>\n",
       "      <td>655</td>\n",
       "      <td>634</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.65</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.402</td>\n",
       "      <td>649</td>\n",
       "      <td>630</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.7</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.402</td>\n",
       "      <td>653</td>\n",
       "      <td>630</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.75</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.402</td>\n",
       "      <td>664</td>\n",
       "      <td>631</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.8</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.406</td>\n",
       "      <td>651</td>\n",
       "      <td>636</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.85</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.404</td>\n",
       "      <td>655</td>\n",
       "      <td>633</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.9</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.406</td>\n",
       "      <td>649</td>\n",
       "      <td>637</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.95</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.403</td>\n",
       "      <td>673</td>\n",
       "      <td>632</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 1.0</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.404</td>\n",
       "      <td>645</td>\n",
       "      <td>633</td>\n",
       "      <td>13330</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 316          0.810     0.604                0.123   \n",
       "After SMOTE N = 316 p_class 1 = 0.5      0.803     0.594                0.131   \n",
       "After SMOTE N = 316 p_class 1 = 0.55     0.803     0.595                0.133   \n",
       "After SMOTE N = 316 p_class 1 = 0.6      0.802     0.592                0.133   \n",
       "After SMOTE N = 316 p_class 1 = 0.65     0.803     0.595                0.131   \n",
       "After SMOTE N = 316 p_class 1 = 0.7      0.803     0.594                0.132   \n",
       "After SMOTE N = 316 p_class 1 = 0.75     0.801     0.591                0.134   \n",
       "After SMOTE N = 316 p_class 1 = 0.8      0.802     0.592                0.132   \n",
       "After SMOTE N = 316 p_class 1 = 0.85     0.802     0.592                0.133   \n",
       "After SMOTE N = 316 p_class 1 = 0.9      0.802     0.591                0.131   \n",
       "After SMOTE N = 316 p_class 1 = 0.95     0.799     0.589                0.136   \n",
       "After SMOTE N = 316 p_class 1 = 1.0      0.804     0.594                0.131   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 316                     0.400              608   \n",
       "After SMOTE N = 316 p_class 1 = 0.5                 0.402              649   \n",
       "After SMOTE N = 316 p_class 1 = 0.55                0.399              659   \n",
       "After SMOTE N = 316 p_class 1 = 0.6                 0.404              655   \n",
       "After SMOTE N = 316 p_class 1 = 0.65                0.402              649   \n",
       "After SMOTE N = 316 p_class 1 = 0.7                 0.402              653   \n",
       "After SMOTE N = 316 p_class 1 = 0.75                0.402              664   \n",
       "After SMOTE N = 316 p_class 1 = 0.8                 0.406              651   \n",
       "After SMOTE N = 316 p_class 1 = 0.85                0.404              655   \n",
       "After SMOTE N = 316 p_class 1 = 0.9                 0.406              649   \n",
       "After SMOTE N = 316 p_class 1 = 0.95                0.403              673   \n",
       "After SMOTE N = 316 p_class 1 = 1.0                 0.404              645   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 316                   627       13330       6508  \n",
       "After SMOTE N = 316 p_class 1 = 0.5               631       13330       6508  \n",
       "After SMOTE N = 316 p_class 1 = 0.55              625       13330       6508  \n",
       "After SMOTE N = 316 p_class 1 = 0.6               634       13330       6508  \n",
       "After SMOTE N = 316 p_class 1 = 0.65              630       13330       6508  \n",
       "After SMOTE N = 316 p_class 1 = 0.7               630       13330       6508  \n",
       "After SMOTE N = 316 p_class 1 = 0.75              631       13330       6508  \n",
       "After SMOTE N = 316 p_class 1 = 0.8               636       13330       6508  \n",
       "After SMOTE N = 316 p_class 1 = 0.85              633       13330       6508  \n",
       "After SMOTE N = 316 p_class 1 = 0.9               637       13330       6508  \n",
       "After SMOTE N = 316 p_class 1 = 0.95              632       13330       6508  \n",
       "After SMOTE N = 316 p_class 1 = 1.0               633       13330       6508  "
      ]
     },
     "execution_count": 2020,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['fp'] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2021,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 316</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.604</td>\n",
       "      <td>608</td>\n",
       "      <td>627</td>\n",
       "      <td>1235</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.5</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.594</td>\n",
       "      <td>649</td>\n",
       "      <td>631</td>\n",
       "      <td>1280</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.55</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.595</td>\n",
       "      <td>659</td>\n",
       "      <td>625</td>\n",
       "      <td>1284</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.6</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.592</td>\n",
       "      <td>655</td>\n",
       "      <td>634</td>\n",
       "      <td>1289</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.65</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.595</td>\n",
       "      <td>649</td>\n",
       "      <td>630</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.7</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.594</td>\n",
       "      <td>653</td>\n",
       "      <td>630</td>\n",
       "      <td>1283</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.75</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.591</td>\n",
       "      <td>664</td>\n",
       "      <td>631</td>\n",
       "      <td>1295</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.8</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.592</td>\n",
       "      <td>651</td>\n",
       "      <td>636</td>\n",
       "      <td>1287</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.85</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.592</td>\n",
       "      <td>655</td>\n",
       "      <td>633</td>\n",
       "      <td>1288</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.9</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.591</td>\n",
       "      <td>649</td>\n",
       "      <td>637</td>\n",
       "      <td>1286</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 0.95</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.589</td>\n",
       "      <td>673</td>\n",
       "      <td>632</td>\n",
       "      <td>1305</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 316 p_class 1 = 1.0</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.594</td>\n",
       "      <td>645</td>\n",
       "      <td>633</td>\n",
       "      <td>1278</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.803     0.593              641   \n",
       "After RANDOM mitigation N = 316          0.810     0.604              608   \n",
       "After SMOTE N = 316 p_class 1 = 0.5      0.803     0.594              649   \n",
       "After SMOTE N = 316 p_class 1 = 0.55     0.803     0.595              659   \n",
       "After SMOTE N = 316 p_class 1 = 0.6      0.802     0.592              655   \n",
       "After SMOTE N = 316 p_class 1 = 0.65     0.803     0.595              649   \n",
       "After SMOTE N = 316 p_class 1 = 0.7      0.803     0.594              653   \n",
       "After SMOTE N = 316 p_class 1 = 0.75     0.801     0.591              664   \n",
       "After SMOTE N = 316 p_class 1 = 0.8      0.802     0.592              651   \n",
       "After SMOTE N = 316 p_class 1 = 0.85     0.802     0.592              655   \n",
       "After SMOTE N = 316 p_class 1 = 0.9      0.802     0.591              649   \n",
       "After SMOTE N = 316 p_class 1 = 0.95     0.799     0.589              673   \n",
       "After SMOTE N = 316 p_class 1 = 1.0      0.804     0.594              645   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 638          1279   \n",
       "After RANDOM mitigation N = 316                   627          1235   \n",
       "After SMOTE N = 316 p_class 1 = 0.5               631          1280   \n",
       "After SMOTE N = 316 p_class 1 = 0.55              625          1284   \n",
       "After SMOTE N = 316 p_class 1 = 0.6               634          1289   \n",
       "After SMOTE N = 316 p_class 1 = 0.65              630          1279   \n",
       "After SMOTE N = 316 p_class 1 = 0.7               630          1283   \n",
       "After SMOTE N = 316 p_class 1 = 0.75              631          1295   \n",
       "After SMOTE N = 316 p_class 1 = 0.8               636          1287   \n",
       "After SMOTE N = 316 p_class 1 = 0.85              633          1288   \n",
       "After SMOTE N = 316 p_class 1 = 0.9               637          1286   \n",
       "After SMOTE N = 316 p_class 1 = 0.95              632          1305   \n",
       "After SMOTE N = 316 p_class 1 = 1.0               633          1278   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.097           0.429   \n",
       "After RANDOM mitigation N = 316                 0.093           0.473   \n",
       "After SMOTE N = 316 p_class 1 = 0.5             0.095           0.303   \n",
       "After SMOTE N = 316 p_class 1 = 0.55            0.110           0.359   \n",
       "After SMOTE N = 316 p_class 1 = 0.6             0.091           0.354   \n",
       "After SMOTE N = 316 p_class 1 = 0.65            0.095           0.324   \n",
       "After SMOTE N = 316 p_class 1 = 0.7             0.090           0.389   \n",
       "After SMOTE N = 316 p_class 1 = 0.75            0.091           0.340   \n",
       "After SMOTE N = 316 p_class 1 = 0.8             0.109           0.352   \n",
       "After SMOTE N = 316 p_class 1 = 0.85            0.106           0.387   \n",
       "After SMOTE N = 316 p_class 1 = 0.9             0.096           0.368   \n",
       "After SMOTE N = 316 p_class 1 = 0.95            0.104           0.339   \n",
       "After SMOTE N = 316 p_class 1 = 1.0             0.092           0.387   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.260       0.203       0.137  \n",
       "After RANDOM mitigation N = 316            0.292       0.228       0.147  \n",
       "After SMOTE N = 316 p_class 1 = 0.5        0.245       0.195       0.128  \n",
       "After SMOTE N = 316 p_class 1 = 0.55       0.259       0.211       0.149  \n",
       "After SMOTE N = 316 p_class 1 = 0.6        0.249       0.194       0.121  \n",
       "After SMOTE N = 316 p_class 1 = 0.65       0.241       0.196       0.144  \n",
       "After SMOTE N = 316 p_class 1 = 0.7        0.254       0.202       0.140  \n",
       "After SMOTE N = 316 p_class 1 = 0.75       0.239       0.183       0.115  \n",
       "After SMOTE N = 316 p_class 1 = 0.8        0.260       0.216       0.157  \n",
       "After SMOTE N = 316 p_class 1 = 0.85       0.251       0.204       0.140  \n",
       "After SMOTE N = 316 p_class 1 = 0.9        0.253       0.206       0.140  \n",
       "After SMOTE N = 316 p_class 1 = 0.95       0.249       0.202       0.144  \n",
       "After SMOTE N = 316 p_class 1 = 1.0        0.246       0.193       0.133  "
      ]
     },
     "execution_count": 2021,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_confronto = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_confronto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2022,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.389</td>\n",
       "      <td>652</td>\n",
       "      <td>610</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.5</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.409</td>\n",
       "      <td>636</td>\n",
       "      <td>641</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.55</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.395</td>\n",
       "      <td>659</td>\n",
       "      <td>619</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.6</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.403</td>\n",
       "      <td>659</td>\n",
       "      <td>632</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.65</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.411</td>\n",
       "      <td>652</td>\n",
       "      <td>644</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.7</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.411</td>\n",
       "      <td>644</td>\n",
       "      <td>644</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.75</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.418</td>\n",
       "      <td>647</td>\n",
       "      <td>656</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.8</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.398</td>\n",
       "      <td>641</td>\n",
       "      <td>624</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.85</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.399</td>\n",
       "      <td>648</td>\n",
       "      <td>625</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.9</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.407</td>\n",
       "      <td>657</td>\n",
       "      <td>638</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.95</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.400</td>\n",
       "      <td>677</td>\n",
       "      <td>627</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 1.0</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.401</td>\n",
       "      <td>674</td>\n",
       "      <td>628</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 1000          0.806     0.603   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5      0.804     0.592   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55     0.804     0.598   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6      0.802     0.592   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65     0.801     0.588   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7      0.802     0.589   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75     0.800     0.583   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8      0.806     0.599   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85     0.804     0.597   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9      0.801     0.590   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95     0.800     0.591   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0      0.800     0.591   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 1000                     0.132   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5                 0.129   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55                0.133   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6                 0.133   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65                0.132   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7                 0.130   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75                0.131   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8                 0.130   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85                0.131   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9                 0.133   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95                0.137   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0                 0.136   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 1000                     0.389              652   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5                 0.409              636   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55                0.395              659   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6                 0.403              659   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65                0.411              652   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7                 0.411              644   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75                0.418              647   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8                 0.398              641   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85                0.399              648   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9                 0.407              657   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95                0.400              677   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0                 0.401              674   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 1000                   610       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.5               641       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.55              619       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.6               632       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.65              644       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.7               644       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.75              656       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.8               624       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.85              625       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.9               638       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.95              627       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 1.0               628       14014       6508  "
      ]
     },
     "execution_count": 2022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['fp'] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2023,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.603</td>\n",
       "      <td>652</td>\n",
       "      <td>610</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.5</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.592</td>\n",
       "      <td>636</td>\n",
       "      <td>641</td>\n",
       "      <td>1277</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.55</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.598</td>\n",
       "      <td>659</td>\n",
       "      <td>619</td>\n",
       "      <td>1278</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.6</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.592</td>\n",
       "      <td>659</td>\n",
       "      <td>632</td>\n",
       "      <td>1291</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.65</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.588</td>\n",
       "      <td>652</td>\n",
       "      <td>644</td>\n",
       "      <td>1296</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.7</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.589</td>\n",
       "      <td>644</td>\n",
       "      <td>644</td>\n",
       "      <td>1288</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.75</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.583</td>\n",
       "      <td>647</td>\n",
       "      <td>656</td>\n",
       "      <td>1303</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.8</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.599</td>\n",
       "      <td>641</td>\n",
       "      <td>624</td>\n",
       "      <td>1265</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.85</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.597</td>\n",
       "      <td>648</td>\n",
       "      <td>625</td>\n",
       "      <td>1273</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.9</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.590</td>\n",
       "      <td>657</td>\n",
       "      <td>638</td>\n",
       "      <td>1295</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.95</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.591</td>\n",
       "      <td>677</td>\n",
       "      <td>627</td>\n",
       "      <td>1304</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 1.0</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.591</td>\n",
       "      <td>674</td>\n",
       "      <td>628</td>\n",
       "      <td>1302</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 1000          0.806     0.603              652   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5      0.804     0.592              636   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55     0.804     0.598              659   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6      0.802     0.592              659   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65     0.801     0.588              652   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7      0.802     0.589              644   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75     0.800     0.583              647   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8      0.806     0.599              641   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85     0.804     0.597              648   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9      0.801     0.590              657   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95     0.800     0.591              677   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0      0.800     0.591              674   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 1000                   610          1262   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5               641          1277   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55              619          1278   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6               632          1291   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65              644          1296   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7               644          1288   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75              656          1303   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8               624          1265   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85              625          1273   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9               638          1295   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95              627          1304   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0               628          1302   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.097           0.429   \n",
       "After RANDOM mitigation N = 1000                 0.093           0.473   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5             0.097           0.414   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55            0.095           0.331   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6             0.089           0.355   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65            0.103           0.396   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7             0.100           0.412   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75            0.103           0.372   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8             0.107           0.360   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85            0.105           0.359   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9             0.128           0.335   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95            0.121           0.314   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0             0.111           0.323   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.260       0.203       0.137  \n",
       "After RANDOM mitigation N = 1000            0.292       0.228       0.147  \n",
       "After SMOTE N = 1000 p_class 1 = 0.5        0.277       0.229       0.178  \n",
       "After SMOTE N = 1000 p_class 1 = 0.55       0.262       0.203       0.142  \n",
       "After SMOTE N = 1000 p_class 1 = 0.6        0.238       0.190       0.139  \n",
       "After SMOTE N = 1000 p_class 1 = 0.65       0.273       0.219       0.152  \n",
       "After SMOTE N = 1000 p_class 1 = 0.7        0.276       0.217       0.154  \n",
       "After SMOTE N = 1000 p_class 1 = 0.75       0.280       0.231       0.160  \n",
       "After SMOTE N = 1000 p_class 1 = 0.8        0.263       0.213       0.149  \n",
       "After SMOTE N = 1000 p_class 1 = 0.85       0.245       0.186       0.109  \n",
       "After SMOTE N = 1000 p_class 1 = 0.9        0.251       0.201       0.128  \n",
       "After SMOTE N = 1000 p_class 1 = 0.95       0.253       0.212       0.142  \n",
       "After SMOTE N = 1000 p_class 1 = 1.0        0.280       0.240       0.182  "
      ]
     },
     "execution_count": 2023,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_1K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2024,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.390</td>\n",
       "      <td>664</td>\n",
       "      <td>611</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.5</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.399</td>\n",
       "      <td>641</td>\n",
       "      <td>626</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.55</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.399</td>\n",
       "      <td>637</td>\n",
       "      <td>626</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.6</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.408</td>\n",
       "      <td>645</td>\n",
       "      <td>640</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.65</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.401</td>\n",
       "      <td>649</td>\n",
       "      <td>629</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.7</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.404</td>\n",
       "      <td>641</td>\n",
       "      <td>633</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.75</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.412</td>\n",
       "      <td>651</td>\n",
       "      <td>646</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.8</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.409</td>\n",
       "      <td>651</td>\n",
       "      <td>642</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.85</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.410</td>\n",
       "      <td>639</td>\n",
       "      <td>643</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.9</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.413</td>\n",
       "      <td>631</td>\n",
       "      <td>647</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.95</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.408</td>\n",
       "      <td>668</td>\n",
       "      <td>639</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 1.0</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.406</td>\n",
       "      <td>662</td>\n",
       "      <td>636</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 2000          0.804     0.600   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5      0.805     0.598   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55     0.806     0.599   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6      0.803     0.591   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65     0.804     0.595   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7      0.804     0.595   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75     0.801     0.587   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8      0.801     0.589   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85     0.803     0.591   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9      0.804     0.590   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95     0.799     0.587   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0      0.801     0.590   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 2000                     0.134   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5                 0.130   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55                0.129   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6                 0.131   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65                0.131   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7                 0.130   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75                0.132   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8                 0.132   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85                0.129   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9                 0.128   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95                0.135   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0                 0.134   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 2000                     0.390              664   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5                 0.399              641   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55                0.399              637   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6                 0.408              645   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65                0.401              649   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7                 0.404              641   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75                0.412              651   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8                 0.409              651   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85                0.410              639   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9                 0.413              631   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95                0.408              668   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0                 0.406              662   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 2000                   611       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.5               626       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.55              626       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.6               640       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.65              629       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.7               633       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.75              646       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.8               642       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.85              643       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.9               647       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.95              639       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 1.0               636       15014       6508  "
      ]
     },
     "execution_count": 2024,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['fp'] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2025,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.600</td>\n",
       "      <td>664</td>\n",
       "      <td>611</td>\n",
       "      <td>1275</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.5</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.598</td>\n",
       "      <td>641</td>\n",
       "      <td>626</td>\n",
       "      <td>1267</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.55</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.599</td>\n",
       "      <td>637</td>\n",
       "      <td>626</td>\n",
       "      <td>1263</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.6</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.591</td>\n",
       "      <td>645</td>\n",
       "      <td>640</td>\n",
       "      <td>1285</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.65</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.595</td>\n",
       "      <td>649</td>\n",
       "      <td>629</td>\n",
       "      <td>1278</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.7</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.595</td>\n",
       "      <td>641</td>\n",
       "      <td>633</td>\n",
       "      <td>1274</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.75</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.587</td>\n",
       "      <td>651</td>\n",
       "      <td>646</td>\n",
       "      <td>1297</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.8</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.589</td>\n",
       "      <td>651</td>\n",
       "      <td>642</td>\n",
       "      <td>1293</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.85</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.591</td>\n",
       "      <td>639</td>\n",
       "      <td>643</td>\n",
       "      <td>1282</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.9</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.590</td>\n",
       "      <td>631</td>\n",
       "      <td>647</td>\n",
       "      <td>1278</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.95</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.587</td>\n",
       "      <td>668</td>\n",
       "      <td>639</td>\n",
       "      <td>1307</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 1.0</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.590</td>\n",
       "      <td>662</td>\n",
       "      <td>636</td>\n",
       "      <td>1298</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 2000          0.804     0.600              664   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5      0.805     0.598              641   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55     0.806     0.599              637   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6      0.803     0.591              645   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65     0.804     0.595              649   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7      0.804     0.595              641   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75     0.801     0.587              651   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8      0.801     0.589              651   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85     0.803     0.591              639   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9      0.804     0.590              631   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95     0.799     0.587              668   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0      0.801     0.590              662   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 2000                   611          1275   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5               626          1267   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55              626          1263   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6               640          1285   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65              629          1278   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7               633          1274   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75              646          1297   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8               642          1293   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85              643          1282   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9               647          1278   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95              639          1307   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0               636          1298   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.097           0.429   \n",
       "After RANDOM mitigation N = 2000                 0.093           0.473   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5             0.116           0.327   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55            0.128           0.375   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6             0.100           0.334   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65            0.112           0.341   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7             0.114           0.320   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75            0.100           0.362   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8             0.092           0.349   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85            0.097           0.364   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9             0.099           0.313   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95            0.109           0.334   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0             0.113           0.321   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.260       0.203       0.137  \n",
       "After RANDOM mitigation N = 2000            0.292       0.228       0.147  \n",
       "After SMOTE N = 2000 p_class 1 = 0.5        0.259       0.201       0.123  \n",
       "After SMOTE N = 2000 p_class 1 = 0.55       0.257       0.202       0.128  \n",
       "After SMOTE N = 2000 p_class 1 = 0.6        0.253       0.204       0.142  \n",
       "After SMOTE N = 2000 p_class 1 = 0.65       0.290       0.249       0.193  \n",
       "After SMOTE N = 2000 p_class 1 = 0.7        0.274       0.227       0.154  \n",
       "After SMOTE N = 2000 p_class 1 = 0.75       0.245       0.197       0.123  \n",
       "After SMOTE N = 2000 p_class 1 = 0.8        0.259       0.214       0.149  \n",
       "After SMOTE N = 2000 p_class 1 = 0.85       0.259       0.212       0.149  \n",
       "After SMOTE N = 2000 p_class 1 = 0.9        0.247       0.190       0.116  \n",
       "After SMOTE N = 2000 p_class 1 = 0.95       0.276       0.236       0.183  \n",
       "After SMOTE N = 2000 p_class 1 = 1.0        0.266       0.219       0.161  "
      ]
     },
     "execution_count": 2025,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE_2K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2026,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.395</td>\n",
       "      <td>622</td>\n",
       "      <td>620</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.5</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.404</td>\n",
       "      <td>641</td>\n",
       "      <td>633</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.55</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.409</td>\n",
       "      <td>648</td>\n",
       "      <td>642</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.6</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.411</td>\n",
       "      <td>642</td>\n",
       "      <td>645</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.65</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.409</td>\n",
       "      <td>650</td>\n",
       "      <td>642</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.7</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.402</td>\n",
       "      <td>648</td>\n",
       "      <td>631</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.75</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.416</td>\n",
       "      <td>658</td>\n",
       "      <td>652</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.8</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.404</td>\n",
       "      <td>651</td>\n",
       "      <td>633</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.85</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.413</td>\n",
       "      <td>652</td>\n",
       "      <td>647</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.9</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.406</td>\n",
       "      <td>673</td>\n",
       "      <td>636</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.95</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.403</td>\n",
       "      <td>661</td>\n",
       "      <td>632</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 1.0</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.410</td>\n",
       "      <td>653</td>\n",
       "      <td>643</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 3000          0.809     0.604   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5      0.804     0.595   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55     0.802     0.589   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6      0.802     0.589   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65     0.801     0.589   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7      0.803     0.594   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75     0.799     0.583   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8      0.803     0.593   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85     0.800     0.586   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9      0.799     0.587   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95     0.801     0.591   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0      0.801     0.588   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 3000                     0.126   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5                 0.130   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55                0.131   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6                 0.130   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65                0.132   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7                 0.131   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75                0.133   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8                 0.132   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85                0.132   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9                 0.136   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95                0.134   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0                 0.132   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 3000                     0.395              622   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5                 0.404              641   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55                0.409              648   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6                 0.411              642   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65                0.409              650   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7                 0.402              648   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75                0.416              658   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8                 0.404              651   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85                0.413              652   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9                 0.406              673   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95                0.403              661   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0                 0.410              653   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 3000                   620       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.5               633       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.55              642       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.6               645       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.65              642       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.7               631       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.75              652       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.8               633       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.85              647       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.9               636       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.95              632       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 1.0               643       16014       6508  "
      ]
     },
     "execution_count": 2026,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['fp'] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2027,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.604</td>\n",
       "      <td>622</td>\n",
       "      <td>620</td>\n",
       "      <td>1242</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.5</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.595</td>\n",
       "      <td>641</td>\n",
       "      <td>633</td>\n",
       "      <td>1274</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.55</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.589</td>\n",
       "      <td>648</td>\n",
       "      <td>642</td>\n",
       "      <td>1290</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.6</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.589</td>\n",
       "      <td>642</td>\n",
       "      <td>645</td>\n",
       "      <td>1287</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.65</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.589</td>\n",
       "      <td>650</td>\n",
       "      <td>642</td>\n",
       "      <td>1292</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.7</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.594</td>\n",
       "      <td>648</td>\n",
       "      <td>631</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.75</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.583</td>\n",
       "      <td>658</td>\n",
       "      <td>652</td>\n",
       "      <td>1310</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.8</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>651</td>\n",
       "      <td>633</td>\n",
       "      <td>1284</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.85</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.586</td>\n",
       "      <td>652</td>\n",
       "      <td>647</td>\n",
       "      <td>1299</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.9</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.587</td>\n",
       "      <td>673</td>\n",
       "      <td>636</td>\n",
       "      <td>1309</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.95</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.591</td>\n",
       "      <td>661</td>\n",
       "      <td>632</td>\n",
       "      <td>1293</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 1.0</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.588</td>\n",
       "      <td>653</td>\n",
       "      <td>643</td>\n",
       "      <td>1296</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 3000          0.809     0.604              622   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5      0.804     0.595              641   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55     0.802     0.589              648   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6      0.802     0.589              642   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65     0.801     0.589              650   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7      0.803     0.594              648   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75     0.799     0.583              658   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8      0.803     0.593              651   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85     0.800     0.586              652   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9      0.799     0.587              673   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95     0.801     0.591              661   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0      0.801     0.588              653   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 3000                   620          1242   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5               633          1274   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55              642          1290   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6               645          1287   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65              642          1292   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7               631          1279   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75              652          1310   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8               633          1284   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85              647          1299   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9               636          1309   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95              632          1293   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0               643          1296   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.097           0.429   \n",
       "After RANDOM mitigation N = 3000                 0.093           0.473   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5             0.101           0.370   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55            0.103           0.332   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6             0.099           0.331   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65            0.127           0.397   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7             0.108           0.340   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75            0.099           0.358   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8             0.129           0.396   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85            0.121           0.424   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9             0.106           0.394   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95            0.109           0.379   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0             0.112           0.335   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.260       0.203       0.137  \n",
       "After RANDOM mitigation N = 3000            0.292       0.228       0.147  \n",
       "After SMOTE N = 3000 p_class 1 = 0.5        0.236       0.190       0.131  \n",
       "After SMOTE N = 3000 p_class 1 = 0.55       0.256       0.202       0.143  \n",
       "After SMOTE N = 3000 p_class 1 = 0.6        0.264       0.208       0.150  \n",
       "After SMOTE N = 3000 p_class 1 = 0.65       0.299       0.254       0.193  \n",
       "After SMOTE N = 3000 p_class 1 = 0.7        0.268       0.223       0.166  \n",
       "After SMOTE N = 3000 p_class 1 = 0.75       0.267       0.218       0.153  \n",
       "After SMOTE N = 3000 p_class 1 = 0.8        0.303       0.255       0.180  \n",
       "After SMOTE N = 3000 p_class 1 = 0.85       0.307       0.242       0.148  \n",
       "After SMOTE N = 3000 p_class 1 = 0.9        0.304       0.253       0.179  \n",
       "After SMOTE N = 3000 p_class 1 = 0.95       0.293       0.241       0.173  \n",
       "After SMOTE N = 3000 p_class 1 = 1.0        0.292       0.249       0.187  "
      ]
     },
     "execution_count": 2027,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE_3K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_3K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2028,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 4000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.388</td>\n",
       "      <td>634</td>\n",
       "      <td>609</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.5</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.402</td>\n",
       "      <td>628</td>\n",
       "      <td>630</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.55</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.404</td>\n",
       "      <td>641</td>\n",
       "      <td>634</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.6</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.409</td>\n",
       "      <td>649</td>\n",
       "      <td>642</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.65</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.416</td>\n",
       "      <td>646</td>\n",
       "      <td>652</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.7</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.404</td>\n",
       "      <td>641</td>\n",
       "      <td>633</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.75</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.404</td>\n",
       "      <td>642</td>\n",
       "      <td>634</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.8</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.404</td>\n",
       "      <td>657</td>\n",
       "      <td>633</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.85</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.399</td>\n",
       "      <td>634</td>\n",
       "      <td>625</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.9</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.406</td>\n",
       "      <td>635</td>\n",
       "      <td>637</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.95</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.402</td>\n",
       "      <td>648</td>\n",
       "      <td>630</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 1.0</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.406</td>\n",
       "      <td>625</td>\n",
       "      <td>636</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 4000          0.809     0.607   \n",
       "After SMOTE N = 4000 p_class 1 = 0.5      0.807     0.599   \n",
       "After SMOTE N = 4000 p_class 1 = 0.55     0.804     0.594   \n",
       "After SMOTE N = 4000 p_class 1 = 0.6      0.802     0.589   \n",
       "After SMOTE N = 4000 p_class 1 = 0.65     0.801     0.585   \n",
       "After SMOTE N = 4000 p_class 1 = 0.7      0.804     0.595   \n",
       "After SMOTE N = 4000 p_class 1 = 0.75     0.804     0.594   \n",
       "After SMOTE N = 4000 p_class 1 = 0.8      0.802     0.592   \n",
       "After SMOTE N = 4000 p_class 1 = 0.85     0.807     0.600   \n",
       "After SMOTE N = 4000 p_class 1 = 0.9      0.805     0.594   \n",
       "After SMOTE N = 4000 p_class 1 = 0.95     0.804     0.595   \n",
       "After SMOTE N = 4000 p_class 1 = 1.0      0.806     0.596   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 4000                     0.128   \n",
       "After SMOTE N = 4000 p_class 1 = 0.5                 0.127   \n",
       "After SMOTE N = 4000 p_class 1 = 0.55                0.130   \n",
       "After SMOTE N = 4000 p_class 1 = 0.6                 0.131   \n",
       "After SMOTE N = 4000 p_class 1 = 0.65                0.131   \n",
       "After SMOTE N = 4000 p_class 1 = 0.7                 0.130   \n",
       "After SMOTE N = 4000 p_class 1 = 0.75                0.130   \n",
       "After SMOTE N = 4000 p_class 1 = 0.8                 0.133   \n",
       "After SMOTE N = 4000 p_class 1 = 0.85                0.128   \n",
       "After SMOTE N = 4000 p_class 1 = 0.9                 0.129   \n",
       "After SMOTE N = 4000 p_class 1 = 0.95                0.131   \n",
       "After SMOTE N = 4000 p_class 1 = 1.0                 0.127   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 4000                     0.388              634   \n",
       "After SMOTE N = 4000 p_class 1 = 0.5                 0.402              628   \n",
       "After SMOTE N = 4000 p_class 1 = 0.55                0.404              641   \n",
       "After SMOTE N = 4000 p_class 1 = 0.6                 0.409              649   \n",
       "After SMOTE N = 4000 p_class 1 = 0.65                0.416              646   \n",
       "After SMOTE N = 4000 p_class 1 = 0.7                 0.404              641   \n",
       "After SMOTE N = 4000 p_class 1 = 0.75                0.404              642   \n",
       "After SMOTE N = 4000 p_class 1 = 0.8                 0.404              657   \n",
       "After SMOTE N = 4000 p_class 1 = 0.85                0.399              634   \n",
       "After SMOTE N = 4000 p_class 1 = 0.9                 0.406              635   \n",
       "After SMOTE N = 4000 p_class 1 = 0.95                0.402              648   \n",
       "After SMOTE N = 4000 p_class 1 = 1.0                 0.406              625   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 4000                   609       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.5               630       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.55              634       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.6               642       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.65              652       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.7               633       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.75              634       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.8               633       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.85              625       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.9               637       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.95              630       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 1.0               636       17014       6508  "
      ]
     },
     "execution_count": 2028,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['fp'] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2029,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 4000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.607</td>\n",
       "      <td>634</td>\n",
       "      <td>609</td>\n",
       "      <td>1243</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.5</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.599</td>\n",
       "      <td>628</td>\n",
       "      <td>630</td>\n",
       "      <td>1258</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.55</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.594</td>\n",
       "      <td>641</td>\n",
       "      <td>634</td>\n",
       "      <td>1275</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.6</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.589</td>\n",
       "      <td>649</td>\n",
       "      <td>642</td>\n",
       "      <td>1291</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.65</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.585</td>\n",
       "      <td>646</td>\n",
       "      <td>652</td>\n",
       "      <td>1298</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.7</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.595</td>\n",
       "      <td>641</td>\n",
       "      <td>633</td>\n",
       "      <td>1274</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.75</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.594</td>\n",
       "      <td>642</td>\n",
       "      <td>634</td>\n",
       "      <td>1276</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.8</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.592</td>\n",
       "      <td>657</td>\n",
       "      <td>633</td>\n",
       "      <td>1290</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.85</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.600</td>\n",
       "      <td>634</td>\n",
       "      <td>625</td>\n",
       "      <td>1259</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.9</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.594</td>\n",
       "      <td>635</td>\n",
       "      <td>637</td>\n",
       "      <td>1272</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.95</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.595</td>\n",
       "      <td>648</td>\n",
       "      <td>630</td>\n",
       "      <td>1278</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 1.0</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.596</td>\n",
       "      <td>625</td>\n",
       "      <td>636</td>\n",
       "      <td>1261</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 4000          0.809     0.607              634   \n",
       "After SMOTE N = 4000 p_class 1 = 0.5      0.807     0.599              628   \n",
       "After SMOTE N = 4000 p_class 1 = 0.55     0.804     0.594              641   \n",
       "After SMOTE N = 4000 p_class 1 = 0.6      0.802     0.589              649   \n",
       "After SMOTE N = 4000 p_class 1 = 0.65     0.801     0.585              646   \n",
       "After SMOTE N = 4000 p_class 1 = 0.7      0.804     0.595              641   \n",
       "After SMOTE N = 4000 p_class 1 = 0.75     0.804     0.594              642   \n",
       "After SMOTE N = 4000 p_class 1 = 0.8      0.802     0.592              657   \n",
       "After SMOTE N = 4000 p_class 1 = 0.85     0.807     0.600              634   \n",
       "After SMOTE N = 4000 p_class 1 = 0.9      0.805     0.594              635   \n",
       "After SMOTE N = 4000 p_class 1 = 0.95     0.804     0.595              648   \n",
       "After SMOTE N = 4000 p_class 1 = 1.0      0.806     0.596              625   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 4000                   609          1243   \n",
       "After SMOTE N = 4000 p_class 1 = 0.5               630          1258   \n",
       "After SMOTE N = 4000 p_class 1 = 0.55              634          1275   \n",
       "After SMOTE N = 4000 p_class 1 = 0.6               642          1291   \n",
       "After SMOTE N = 4000 p_class 1 = 0.65              652          1298   \n",
       "After SMOTE N = 4000 p_class 1 = 0.7               633          1274   \n",
       "After SMOTE N = 4000 p_class 1 = 0.75              634          1276   \n",
       "After SMOTE N = 4000 p_class 1 = 0.8               633          1290   \n",
       "After SMOTE N = 4000 p_class 1 = 0.85              625          1259   \n",
       "After SMOTE N = 4000 p_class 1 = 0.9               637          1272   \n",
       "After SMOTE N = 4000 p_class 1 = 0.95              630          1278   \n",
       "After SMOTE N = 4000 p_class 1 = 1.0               636          1261   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.097           0.429   \n",
       "After RANDOM mitigation N = 4000                 0.093           0.473   \n",
       "After SMOTE N = 4000 p_class 1 = 0.5             0.098           0.356   \n",
       "After SMOTE N = 4000 p_class 1 = 0.55            0.111           0.354   \n",
       "After SMOTE N = 4000 p_class 1 = 0.6             0.100           0.349   \n",
       "After SMOTE N = 4000 p_class 1 = 0.65            0.081           0.358   \n",
       "After SMOTE N = 4000 p_class 1 = 0.7             0.137           0.396   \n",
       "After SMOTE N = 4000 p_class 1 = 0.75            0.107           0.359   \n",
       "After SMOTE N = 4000 p_class 1 = 0.8             0.115           0.396   \n",
       "After SMOTE N = 4000 p_class 1 = 0.85            0.114           0.401   \n",
       "After SMOTE N = 4000 p_class 1 = 0.9             0.105           0.357   \n",
       "After SMOTE N = 4000 p_class 1 = 0.95            0.124           0.389   \n",
       "After SMOTE N = 4000 p_class 1 = 1.0             0.109           0.358   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.260       0.203       0.137  \n",
       "After RANDOM mitigation N = 4000            0.292       0.228       0.147  \n",
       "After SMOTE N = 4000 p_class 1 = 0.5        0.263       0.206       0.146  \n",
       "After SMOTE N = 4000 p_class 1 = 0.55       0.287       0.235       0.172  \n",
       "After SMOTE N = 4000 p_class 1 = 0.6        0.264       0.221       0.166  \n",
       "After SMOTE N = 4000 p_class 1 = 0.65       0.251       0.198       0.135  \n",
       "After SMOTE N = 4000 p_class 1 = 0.7        0.298       0.243       0.164  \n",
       "After SMOTE N = 4000 p_class 1 = 0.75       0.295       0.251       0.186  \n",
       "After SMOTE N = 4000 p_class 1 = 0.8        0.301       0.253       0.193  \n",
       "After SMOTE N = 4000 p_class 1 = 0.85       0.295       0.253       0.179  \n",
       "After SMOTE N = 4000 p_class 1 = 0.9        0.299       0.248       0.188  \n",
       "After SMOTE N = 4000 p_class 1 = 0.95       0.303       0.264       0.203  \n",
       "After SMOTE N = 4000 p_class 1 = 1.0        0.294       0.258       0.201  "
      ]
     },
     "execution_count": 2029,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_4K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_4K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2030,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.402</td>\n",
       "      <td>654</td>\n",
       "      <td>631</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.5</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.399</td>\n",
       "      <td>657</td>\n",
       "      <td>625</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.55</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.401</td>\n",
       "      <td>657</td>\n",
       "      <td>629</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.6</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.398</td>\n",
       "      <td>635</td>\n",
       "      <td>624</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.65</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.408</td>\n",
       "      <td>627</td>\n",
       "      <td>639</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.7</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.409</td>\n",
       "      <td>629</td>\n",
       "      <td>641</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.75</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.402</td>\n",
       "      <td>629</td>\n",
       "      <td>631</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.8</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.400</td>\n",
       "      <td>629</td>\n",
       "      <td>627</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.85</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.418</td>\n",
       "      <td>604</td>\n",
       "      <td>655</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.9</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.403</td>\n",
       "      <td>633</td>\n",
       "      <td>632</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.95</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.404</td>\n",
       "      <td>621</td>\n",
       "      <td>634</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 1.0</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.409</td>\n",
       "      <td>628</td>\n",
       "      <td>641</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 5000          0.803     0.593   \n",
       "After SMOTE N = 5000 p_class 1 = 0.5      0.803     0.595   \n",
       "After SMOTE N = 5000 p_class 1 = 0.55     0.802     0.594   \n",
       "After SMOTE N = 5000 p_class 1 = 0.6      0.807     0.600   \n",
       "After SMOTE N = 5000 p_class 1 = 0.65     0.805     0.595   \n",
       "After SMOTE N = 5000 p_class 1 = 0.7      0.805     0.593   \n",
       "After SMOTE N = 5000 p_class 1 = 0.75     0.806     0.598   \n",
       "After SMOTE N = 5000 p_class 1 = 0.8      0.807     0.600   \n",
       "After SMOTE N = 5000 p_class 1 = 0.85     0.807     0.592   \n",
       "After SMOTE N = 5000 p_class 1 = 0.9      0.806     0.597   \n",
       "After SMOTE N = 5000 p_class 1 = 0.95     0.807     0.598   \n",
       "After SMOTE N = 5000 p_class 1 = 1.0      0.805     0.594   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 5000                     0.132   \n",
       "After SMOTE N = 5000 p_class 1 = 0.5                 0.133   \n",
       "After SMOTE N = 5000 p_class 1 = 0.55                0.133   \n",
       "After SMOTE N = 5000 p_class 1 = 0.6                 0.129   \n",
       "After SMOTE N = 5000 p_class 1 = 0.65                0.127   \n",
       "After SMOTE N = 5000 p_class 1 = 0.7                 0.127   \n",
       "After SMOTE N = 5000 p_class 1 = 0.75                0.127   \n",
       "After SMOTE N = 5000 p_class 1 = 0.8                 0.127   \n",
       "After SMOTE N = 5000 p_class 1 = 0.85                0.122   \n",
       "After SMOTE N = 5000 p_class 1 = 0.9                 0.128   \n",
       "After SMOTE N = 5000 p_class 1 = 0.95                0.126   \n",
       "After SMOTE N = 5000 p_class 1 = 1.0                 0.127   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 5000                     0.402              654   \n",
       "After SMOTE N = 5000 p_class 1 = 0.5                 0.399              657   \n",
       "After SMOTE N = 5000 p_class 1 = 0.55                0.401              657   \n",
       "After SMOTE N = 5000 p_class 1 = 0.6                 0.398              635   \n",
       "After SMOTE N = 5000 p_class 1 = 0.65                0.408              627   \n",
       "After SMOTE N = 5000 p_class 1 = 0.7                 0.409              629   \n",
       "After SMOTE N = 5000 p_class 1 = 0.75                0.402              629   \n",
       "After SMOTE N = 5000 p_class 1 = 0.8                 0.400              629   \n",
       "After SMOTE N = 5000 p_class 1 = 0.85                0.418              604   \n",
       "After SMOTE N = 5000 p_class 1 = 0.9                 0.403              633   \n",
       "After SMOTE N = 5000 p_class 1 = 0.95                0.404              621   \n",
       "After SMOTE N = 5000 p_class 1 = 1.0                 0.409              628   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                   631       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.5               625       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.55              629       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.6               624       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.65              639       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.7               641       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.75              631       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.8               627       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.85              655       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.9               632       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.95              634       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 1.0               641       18014       6508  "
      ]
     },
     "execution_count": 2030,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['fp'] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2031,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>654</td>\n",
       "      <td>631</td>\n",
       "      <td>1285</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.5</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.595</td>\n",
       "      <td>657</td>\n",
       "      <td>625</td>\n",
       "      <td>1282</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.55</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.594</td>\n",
       "      <td>657</td>\n",
       "      <td>629</td>\n",
       "      <td>1286</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.6</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.600</td>\n",
       "      <td>635</td>\n",
       "      <td>624</td>\n",
       "      <td>1259</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.65</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.595</td>\n",
       "      <td>627</td>\n",
       "      <td>639</td>\n",
       "      <td>1266</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.7</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.593</td>\n",
       "      <td>629</td>\n",
       "      <td>641</td>\n",
       "      <td>1270</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.75</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.598</td>\n",
       "      <td>629</td>\n",
       "      <td>631</td>\n",
       "      <td>1260</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.8</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.600</td>\n",
       "      <td>629</td>\n",
       "      <td>627</td>\n",
       "      <td>1256</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.85</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.592</td>\n",
       "      <td>604</td>\n",
       "      <td>655</td>\n",
       "      <td>1259</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.9</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.597</td>\n",
       "      <td>633</td>\n",
       "      <td>632</td>\n",
       "      <td>1265</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.95</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.598</td>\n",
       "      <td>621</td>\n",
       "      <td>634</td>\n",
       "      <td>1255</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 1.0</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.594</td>\n",
       "      <td>628</td>\n",
       "      <td>641</td>\n",
       "      <td>1269</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 5000          0.803     0.593              654   \n",
       "After SMOTE N = 5000 p_class 1 = 0.5      0.803     0.595              657   \n",
       "After SMOTE N = 5000 p_class 1 = 0.55     0.802     0.594              657   \n",
       "After SMOTE N = 5000 p_class 1 = 0.6      0.807     0.600              635   \n",
       "After SMOTE N = 5000 p_class 1 = 0.65     0.805     0.595              627   \n",
       "After SMOTE N = 5000 p_class 1 = 0.7      0.805     0.593              629   \n",
       "After SMOTE N = 5000 p_class 1 = 0.75     0.806     0.598              629   \n",
       "After SMOTE N = 5000 p_class 1 = 0.8      0.807     0.600              629   \n",
       "After SMOTE N = 5000 p_class 1 = 0.85     0.807     0.592              604   \n",
       "After SMOTE N = 5000 p_class 1 = 0.9      0.806     0.597              633   \n",
       "After SMOTE N = 5000 p_class 1 = 0.95     0.807     0.598              621   \n",
       "After SMOTE N = 5000 p_class 1 = 1.0      0.805     0.594              628   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 5000                   631          1285   \n",
       "After SMOTE N = 5000 p_class 1 = 0.5               625          1282   \n",
       "After SMOTE N = 5000 p_class 1 = 0.55              629          1286   \n",
       "After SMOTE N = 5000 p_class 1 = 0.6               624          1259   \n",
       "After SMOTE N = 5000 p_class 1 = 0.65              639          1266   \n",
       "After SMOTE N = 5000 p_class 1 = 0.7               641          1270   \n",
       "After SMOTE N = 5000 p_class 1 = 0.75              631          1260   \n",
       "After SMOTE N = 5000 p_class 1 = 0.8               627          1256   \n",
       "After SMOTE N = 5000 p_class 1 = 0.85              655          1259   \n",
       "After SMOTE N = 5000 p_class 1 = 0.9               632          1265   \n",
       "After SMOTE N = 5000 p_class 1 = 0.95              634          1255   \n",
       "After SMOTE N = 5000 p_class 1 = 1.0               641          1269   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.097           0.429   \n",
       "After RANDOM mitigation N = 5000                 0.093           0.473   \n",
       "After SMOTE N = 5000 p_class 1 = 0.5             0.103           0.376   \n",
       "After SMOTE N = 5000 p_class 1 = 0.55            0.129           0.373   \n",
       "After SMOTE N = 5000 p_class 1 = 0.6             0.121           0.384   \n",
       "After SMOTE N = 5000 p_class 1 = 0.65            0.120           0.334   \n",
       "After SMOTE N = 5000 p_class 1 = 0.7             0.108           0.446   \n",
       "After SMOTE N = 5000 p_class 1 = 0.75            0.135           0.379   \n",
       "After SMOTE N = 5000 p_class 1 = 0.8             0.111           0.400   \n",
       "After SMOTE N = 5000 p_class 1 = 0.85            0.111           0.419   \n",
       "After SMOTE N = 5000 p_class 1 = 0.9             0.125           0.415   \n",
       "After SMOTE N = 5000 p_class 1 = 0.95            0.103           0.414   \n",
       "After SMOTE N = 5000 p_class 1 = 1.0             0.091           0.373   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.260       0.203       0.137  \n",
       "After RANDOM mitigation N = 5000            0.292       0.228       0.147  \n",
       "After SMOTE N = 5000 p_class 1 = 0.5        0.271       0.212       0.153  \n",
       "After SMOTE N = 5000 p_class 1 = 0.55       0.290       0.254       0.190  \n",
       "After SMOTE N = 5000 p_class 1 = 0.6        0.296       0.242       0.174  \n",
       "After SMOTE N = 5000 p_class 1 = 0.65       0.290       0.242       0.170  \n",
       "After SMOTE N = 5000 p_class 1 = 0.7        0.306       0.250       0.183  \n",
       "After SMOTE N = 5000 p_class 1 = 0.75       0.305       0.260       0.191  \n",
       "After SMOTE N = 5000 p_class 1 = 0.8        0.318       0.279       0.218  \n",
       "After SMOTE N = 5000 p_class 1 = 0.85       0.297       0.241       0.178  \n",
       "After SMOTE N = 5000 p_class 1 = 0.9        0.324       0.282       0.216  \n",
       "After SMOTE N = 5000 p_class 1 = 0.95       0.309       0.260       0.197  \n",
       "After SMOTE N = 5000 p_class 1 = 1.0        0.282       0.223       0.158  "
      ]
     },
     "execution_count": 2031,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_5K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_5K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2032,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.386</td>\n",
       "      <td>651</td>\n",
       "      <td>606</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.5</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.402</td>\n",
       "      <td>666</td>\n",
       "      <td>630</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.55</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.408</td>\n",
       "      <td>625</td>\n",
       "      <td>639</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.6</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.404</td>\n",
       "      <td>620</td>\n",
       "      <td>634</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.65</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.399</td>\n",
       "      <td>627</td>\n",
       "      <td>625</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.7</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.409</td>\n",
       "      <td>614</td>\n",
       "      <td>642</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.75</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.415</td>\n",
       "      <td>608</td>\n",
       "      <td>651</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.8</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.413</td>\n",
       "      <td>619</td>\n",
       "      <td>647</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.85</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.398</td>\n",
       "      <td>607</td>\n",
       "      <td>624</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.9</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.409</td>\n",
       "      <td>614</td>\n",
       "      <td>641</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.95</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.413</td>\n",
       "      <td>609</td>\n",
       "      <td>647</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 1.0</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.415</td>\n",
       "      <td>619</td>\n",
       "      <td>650</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 6000          0.807     0.605   \n",
       "After SMOTE N = 6000 p_class 1 = 0.5      0.801     0.591   \n",
       "After SMOTE N = 6000 p_class 1 = 0.55     0.806     0.595   \n",
       "After SMOTE N = 6000 p_class 1 = 0.6      0.807     0.598   \n",
       "After SMOTE N = 6000 p_class 1 = 0.65     0.808     0.601   \n",
       "After SMOTE N = 6000 p_class 1 = 0.7      0.807     0.596   \n",
       "After SMOTE N = 6000 p_class 1 = 0.75     0.807     0.593   \n",
       "After SMOTE N = 6000 p_class 1 = 0.8      0.805     0.593   \n",
       "After SMOTE N = 6000 p_class 1 = 0.85     0.811     0.605   \n",
       "After SMOTE N = 6000 p_class 1 = 0.9      0.807     0.596   \n",
       "After SMOTE N = 6000 p_class 1 = 0.95     0.807     0.595   \n",
       "After SMOTE N = 6000 p_class 1 = 1.0      0.805     0.591   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 6000                     0.132   \n",
       "After SMOTE N = 6000 p_class 1 = 0.5                 0.135   \n",
       "After SMOTE N = 6000 p_class 1 = 0.55                0.127   \n",
       "After SMOTE N = 6000 p_class 1 = 0.6                 0.126   \n",
       "After SMOTE N = 6000 p_class 1 = 0.65                0.127   \n",
       "After SMOTE N = 6000 p_class 1 = 0.7                 0.124   \n",
       "After SMOTE N = 6000 p_class 1 = 0.75                0.123   \n",
       "After SMOTE N = 6000 p_class 1 = 0.8                 0.125   \n",
       "After SMOTE N = 6000 p_class 1 = 0.85                0.123   \n",
       "After SMOTE N = 6000 p_class 1 = 0.9                 0.124   \n",
       "After SMOTE N = 6000 p_class 1 = 0.95                0.123   \n",
       "After SMOTE N = 6000 p_class 1 = 1.0                 0.125   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 6000                     0.386              651   \n",
       "After SMOTE N = 6000 p_class 1 = 0.5                 0.402              666   \n",
       "After SMOTE N = 6000 p_class 1 = 0.55                0.408              625   \n",
       "After SMOTE N = 6000 p_class 1 = 0.6                 0.404              620   \n",
       "After SMOTE N = 6000 p_class 1 = 0.65                0.399              627   \n",
       "After SMOTE N = 6000 p_class 1 = 0.7                 0.409              614   \n",
       "After SMOTE N = 6000 p_class 1 = 0.75                0.415              608   \n",
       "After SMOTE N = 6000 p_class 1 = 0.8                 0.413              619   \n",
       "After SMOTE N = 6000 p_class 1 = 0.85                0.398              607   \n",
       "After SMOTE N = 6000 p_class 1 = 0.9                 0.409              614   \n",
       "After SMOTE N = 6000 p_class 1 = 0.95                0.413              609   \n",
       "After SMOTE N = 6000 p_class 1 = 1.0                 0.415              619   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 6000                   606       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.5               630       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.55              639       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.6               634       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.65              625       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.7               642       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.75              651       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.8               647       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.85              624       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.9               641       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.95              647       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 1.0               650       19014       6508  "
      ]
     },
     "execution_count": 2032,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 6000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['fp'] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2033,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.605</td>\n",
       "      <td>651</td>\n",
       "      <td>606</td>\n",
       "      <td>1257</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.5</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.591</td>\n",
       "      <td>666</td>\n",
       "      <td>630</td>\n",
       "      <td>1296</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.55</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.595</td>\n",
       "      <td>625</td>\n",
       "      <td>639</td>\n",
       "      <td>1264</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.6</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.598</td>\n",
       "      <td>620</td>\n",
       "      <td>634</td>\n",
       "      <td>1254</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.65</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.601</td>\n",
       "      <td>627</td>\n",
       "      <td>625</td>\n",
       "      <td>1252</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.7</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.596</td>\n",
       "      <td>614</td>\n",
       "      <td>642</td>\n",
       "      <td>1256</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.75</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.593</td>\n",
       "      <td>608</td>\n",
       "      <td>651</td>\n",
       "      <td>1259</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.8</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.593</td>\n",
       "      <td>619</td>\n",
       "      <td>647</td>\n",
       "      <td>1266</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.85</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.605</td>\n",
       "      <td>607</td>\n",
       "      <td>624</td>\n",
       "      <td>1231</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.9</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.596</td>\n",
       "      <td>614</td>\n",
       "      <td>641</td>\n",
       "      <td>1255</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.95</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.595</td>\n",
       "      <td>609</td>\n",
       "      <td>647</td>\n",
       "      <td>1256</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 1.0</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.591</td>\n",
       "      <td>619</td>\n",
       "      <td>650</td>\n",
       "      <td>1269</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 6000          0.807     0.605              651   \n",
       "After SMOTE N = 6000 p_class 1 = 0.5      0.801     0.591              666   \n",
       "After SMOTE N = 6000 p_class 1 = 0.55     0.806     0.595              625   \n",
       "After SMOTE N = 6000 p_class 1 = 0.6      0.807     0.598              620   \n",
       "After SMOTE N = 6000 p_class 1 = 0.65     0.808     0.601              627   \n",
       "After SMOTE N = 6000 p_class 1 = 0.7      0.807     0.596              614   \n",
       "After SMOTE N = 6000 p_class 1 = 0.75     0.807     0.593              608   \n",
       "After SMOTE N = 6000 p_class 1 = 0.8      0.805     0.593              619   \n",
       "After SMOTE N = 6000 p_class 1 = 0.85     0.811     0.605              607   \n",
       "After SMOTE N = 6000 p_class 1 = 0.9      0.807     0.596              614   \n",
       "After SMOTE N = 6000 p_class 1 = 0.95     0.807     0.595              609   \n",
       "After SMOTE N = 6000 p_class 1 = 1.0      0.805     0.591              619   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 6000                   606          1257   \n",
       "After SMOTE N = 6000 p_class 1 = 0.5               630          1296   \n",
       "After SMOTE N = 6000 p_class 1 = 0.55              639          1264   \n",
       "After SMOTE N = 6000 p_class 1 = 0.6               634          1254   \n",
       "After SMOTE N = 6000 p_class 1 = 0.65              625          1252   \n",
       "After SMOTE N = 6000 p_class 1 = 0.7               642          1256   \n",
       "After SMOTE N = 6000 p_class 1 = 0.75              651          1259   \n",
       "After SMOTE N = 6000 p_class 1 = 0.8               647          1266   \n",
       "After SMOTE N = 6000 p_class 1 = 0.85              624          1231   \n",
       "After SMOTE N = 6000 p_class 1 = 0.9               641          1255   \n",
       "After SMOTE N = 6000 p_class 1 = 0.95              647          1256   \n",
       "After SMOTE N = 6000 p_class 1 = 1.0               650          1269   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.097           0.429   \n",
       "After RANDOM mitigation N = 6000                 0.093           0.473   \n",
       "After SMOTE N = 6000 p_class 1 = 0.5             0.119           0.372   \n",
       "After SMOTE N = 6000 p_class 1 = 0.55            0.123           0.374   \n",
       "After SMOTE N = 6000 p_class 1 = 0.6             0.119           0.354   \n",
       "After SMOTE N = 6000 p_class 1 = 0.65            0.107           0.392   \n",
       "After SMOTE N = 6000 p_class 1 = 0.7             0.117           0.409   \n",
       "After SMOTE N = 6000 p_class 1 = 0.75            0.121           0.403   \n",
       "After SMOTE N = 6000 p_class 1 = 0.8             0.116           0.345   \n",
       "After SMOTE N = 6000 p_class 1 = 0.85            0.102           0.384   \n",
       "After SMOTE N = 6000 p_class 1 = 0.9             0.104           0.355   \n",
       "After SMOTE N = 6000 p_class 1 = 0.95            0.091           0.351   \n",
       "After SMOTE N = 6000 p_class 1 = 1.0             0.099           0.404   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.260       0.203       0.137  \n",
       "After RANDOM mitigation N = 6000            0.292       0.228       0.147  \n",
       "After SMOTE N = 6000 p_class 1 = 0.5        0.295       0.242       0.159  \n",
       "After SMOTE N = 6000 p_class 1 = 0.55       0.295       0.248       0.180  \n",
       "After SMOTE N = 6000 p_class 1 = 0.6        0.276       0.220       0.137  \n",
       "After SMOTE N = 6000 p_class 1 = 0.65       0.276       0.229       0.172  \n",
       "After SMOTE N = 6000 p_class 1 = 0.7        0.303       0.249       0.185  \n",
       "After SMOTE N = 6000 p_class 1 = 0.75       0.301       0.259       0.197  \n",
       "After SMOTE N = 6000 p_class 1 = 0.8        0.285       0.245       0.186  \n",
       "After SMOTE N = 6000 p_class 1 = 0.85       0.304       0.259       0.195  \n",
       "After SMOTE N = 6000 p_class 1 = 0.9        0.288       0.235       0.172  \n",
       "After SMOTE N = 6000 p_class 1 = 0.95       0.271       0.213       0.151  \n",
       "After SMOTE N = 6000 p_class 1 = 1.0        0.278       0.219       0.145  "
      ]
     },
     "execution_count": 2033,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_6K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_6K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2034,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati salvati in false_negatives_K.json\n",
      "✅ Variabili salvate con successo in false_negatives_K.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"false_negatives_K.json\"\n",
    "\n",
    "# Controlla se il file esiste già per evitare di sovrascrivere\n",
    "if os.path.exists(json_filename):\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        false_negatives_data = json.load(f)\n",
    "else:\n",
    "    false_negatives_data = {}\n",
    "\n",
    "# Lista dei diversi metrics_after_fp_SMOTE_XK\n",
    "metrics_dict = {\n",
    "    \"1K_run6\": metrics_after_fp_SMOTE_1K,\n",
    "    \"2K_run6\": metrics_after_fp_SMOTE_2K,\n",
    "    \"3K_run6\": metrics_after_fp_SMOTE_3K,\n",
    "    \"4K_run6\": metrics_after_fp_SMOTE_4K,\n",
    "    \"5K_run6\": metrics_after_fp_SMOTE_5K,\n",
    "    \"6K_run6\": metrics_after_fp_SMOTE_6K\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni dataset e salviamo i falsi positivi\n",
    "for J, metrics in metrics_dict.items():\n",
    "    false_negatives_data[f\"N={J}\"] = metrics[\"False Negatives\"].to_dict()\n",
    "\n",
    "# Salviamo il JSON aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(false_negatives_data, f, indent=4)\n",
    "\n",
    "print(f\"Dati salvati in {json_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "#per i parametri # Nome del file JSON\n",
    "json_filename = \"false_negatives_K.json\"\n",
    "\n",
    "# Valori da salvare (sostituiscili con i tuoi valori reali)\n",
    "min_sup_run6 = min_sup\n",
    "percentage_run6 = percentage\n",
    "th_redundancy_run6 = epsilon\n",
    "K_run6 = K\n",
    "L_run6 = filtered_instances  # Supponiamo sia la lunghezza di filtered_instances\n",
    "\n",
    "# 1️⃣ Caricare i dati esistenti (se il file esiste)\n",
    "try:\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        false_negatives_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    false_negatives_data = {}  # Se il file non esiste, inizializza un dizionario vuoto\n",
    "\n",
    "# 2️⃣ Aggiungere le nuove variabili sotto una chiave dedicata\n",
    "false_negatives_data[\"run6_parameters\"] = {\n",
    "    \"min_sup\": min_sup_run6,\n",
    "    \"percentage\": percentage_run6,\n",
    "    \"th_redundancy\": th_redundancy_run6,\n",
    "    \"K\": percentage,\n",
    "    \"L\": L_run6\n",
    "}\n",
    "\n",
    "# 3️⃣ Salvare il file aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(false_negatives_data, f, indent=4)\n",
    "\n",
    "print(\"✅ Variabili salvate con successo in\", json_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2035,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"false_negatives_K.json\"\n",
    "\n",
    "# Caricare i dati dal file JSON\n",
    "with open(json_filename, \"r\") as f:\n",
    "    false_negatives_data = json.load(f)\n",
    "\n",
    "# Estrarre parametri dal JSON\n",
    "run6_params = false_negatives_data.get(\"run6_parameters\", {})\n",
    "min_sup = run6_params.get(\"min_sup\", \"N/A\")\n",
    "percentage = run6_params.get(\"percentage\", \"N/A\")\n",
    "th_redundancy = run6_params.get(\"th_redundancy\", \"N/A\")\n",
    "L = run6_params.get(\"L\", \"N/A\")\n",
    "K = int((float(percentage) / 100) * int(L)) # K rappresenta il numero di sottogruppi\n",
    "\n",
    "# Lista dei valori di p da 0.5 a 1.0 con step 0.05\n",
    "p_values = np.arange(0.5, 1.05, 0.05)\n",
    "\n",
    "# Definiamo i colori per ogni N\n",
    "colors = [\"blue\", \"red\", \"green\", \"orange\", \"brown\", \"pink\"]\n",
    "labels = [f\"N={k}K\" for k in range(1, 7)]\n",
    "\n",
    "# Creazione della figura\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig.suptitle(\"FALSE NEGATIVE MITIGATION\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Disegniamo la linea tratteggiata \"Before Mitigation\"\n",
    "before_mitigation = false_negatives_data.get(\"N=1K_run6\", {}).get(\"Before Mitigation\", None)\n",
    "if before_mitigation is not None:\n",
    "    ax.axhline(y=before_mitigation, color=\"purple\", linestyle=\"--\", linewidth=2, label=\"Before Mitigation\")\n",
    "\n",
    "# Aggiungere linee verticali per ogni valore di p\n",
    "for p in p_values:\n",
    "    ax.axvline(x=p, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Loop sui vari N (da 1K a 6K)\n",
    "legend_handles = []\n",
    "for i, n in enumerate(range(1, 7)):\n",
    "    N_key = f\"N={n}K_run6\"\n",
    "    if N_key not in false_negatives_data:\n",
    "        continue\n",
    "    \n",
    "    data = false_negatives_data[N_key]\n",
    "    \n",
    "    # Estrarre i valori di falsi positivi per ogni p\n",
    "    false_positives = [data.get(f\"After SMOTE N = {n*1000} p_class 1 = {round(p, 2)}\", None) for p in p_values]\n",
    "    \n",
    "    # Filtriamo solo i valori validi\n",
    "    p_values_filtered = [p for j, p in enumerate(p_values) if false_positives[j] is not None]\n",
    "    false_positives_filtered = [fp for fp in false_positives if fp is not None]\n",
    "    \n",
    "    # Plottiamo la linea corrispondente\n",
    "    line, = ax.plot(\n",
    "        p_values_filtered, false_positives_filtered, \n",
    "        marker=\"o\", linestyle=\"-\", color=colors[i], label=labels[i]\n",
    "    )\n",
    "    legend_handles.append(line)\n",
    "\n",
    "# Impostazioni asse\n",
    "ax.set_title(f\"Minsup = {min_sup}, pruning = {th_redundancy}, K% = {percentage}, subgroups: {K}/{L}\")\n",
    "ax.set_xlabel(\"p_class 1\")\n",
    "ax.set_ylabel(\"False Negatives\")\n",
    "ax.grid()\n",
    "\n",
    "# Aggiungere la leggenda\n",
    "ax.legend(handles=legend_handles, loc=\"upper right\", fontsize=10, frameon=True, title=\"Legend\")\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
