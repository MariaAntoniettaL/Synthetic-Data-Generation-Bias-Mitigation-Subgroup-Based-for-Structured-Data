{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_compas import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "from divexplorer.outcomes import get_false_positive_rate_outcome\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il CSV\n",
    "df = pd.read_csv(\"cox-violent-parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1339, 16977)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df[\"is_violent_recid\"].sum()\n",
    "count_0 = len(df) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning = 0.00\n",
    "epsilon = pruning\n",
    "min_sup = 0.02\n",
    "percentage = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "VALIDATION SET ROWS:  2439\n",
      "HOLDOUT SET ROWS:  2440\n",
      "TEST SET ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) \n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0])\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         # Distinct Values\n",
      "Attribute                                 \n",
      "sex                                      2\n",
      "race                                     6\n",
      "Recidivism_Risk                         10\n",
      "Violent_Recidivist                       2\n",
      "Risk_Level                               3\n",
      "Violent_Recidivism_Risk                 10\n",
      "Violent_Risk_Level                       3\n",
      "Juvenile_Offenses                       15\n",
      "age_group                                6\n",
      "Prior_Offensesgroup                      8\n"
     ]
    }
   ],
   "source": [
    "distinct_values = pd.DataFrame(df_train.nunique(), columns=[\"# Distinct Values\"])\n",
    "distinct_values.index.name = \"Attribute\"\n",
    "print(distinct_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Attribute</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Violent_Recidivist</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14003</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>8</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>7</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>6-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>17-24</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Attribute   sex              race  Recidivism_Risk  Violent_Recidivist  \\\n",
       "14003      Male         Caucasian                8                   0   \n",
       "1531       Male  African-American               10                   1   \n",
       "1543       Male  African-American                7                   0   \n",
       "15999      Male  African-American                3                   0   \n",
       "3837       Male             Asian                5                   0   \n",
       "\n",
       "Attribute Risk_Level  Violent_Recidivism_Risk Violent_Risk_Level  \\\n",
       "14003           High                        3                Low   \n",
       "1531            High                        8               High   \n",
       "1543          Medium                        7             Medium   \n",
       "15999            Low                        5             Medium   \n",
       "3837          Medium                        4                Low   \n",
       "\n",
       "Attribute  Juvenile_Offenses age_group Prior_Offensesgroup  \n",
       "14003                      0     45-54                 0-5  \n",
       "1531                       0     17-24               11-15  \n",
       "1543                       0     25-34                6-10  \n",
       "15999                      2     17-24                 0-5  \n",
       "3837                       0     17-24                 0-5  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "VALIDATION SET ROWS:  2439\n",
      "HOLDOUT SET ROWS:  2440\n",
      "TEST SET ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosit√† precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) \n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) \n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_no_Violent_Recidivist = df_train_enc.drop(columns = 'Violent_Recidivist')\n",
    "plt.figure(figsize=(4, 3))\n",
    "g = sns.heatmap(df_train_no_Violent_Recidivist.corr(),\n",
    "                annot = False,\n",
    "                cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.753</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.926     0.327                0.021   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.753               47              134   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       2439  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "X_train = df_train_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_train = df_train_enc['Violent_Recidivist']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_test = df_test_enc['Violent_Recidivist']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_val = df_val_enc['Violent_Recidivist']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_holdout = df_holdout_enc['Violent_Recidivist']\n",
    "\n",
    "classifier_train = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()\n",
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione √® giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  race  Recidivism_Risk  Risk_Level  Violent_Recidivism_Risk  \\\n",
       "10676    1     0                4           1                        2   \n",
       "13123    1     2                1           1                        1   \n",
       "2611     1     0                8           0                        6   \n",
       "7945     1     2                1           1                        1   \n",
       "5727     1     2                6           2                        6   \n",
       "\n",
       "       Violent_Risk_Level  Juvenile_Offenses  age_group  Prior_Offensesgroup  \\\n",
       "10676                   1                  0          3                    7   \n",
       "13123                   1                  0          3                    0   \n",
       "2611                    2                  2          2                    1   \n",
       "7945                    1                  0          5                    0   \n",
       "5727                    2                  0          1                    0   \n",
       "\n",
       "       y_val_true  y_pred  \n",
       "10676           0       0  \n",
       "13123           0       0  \n",
       "2611            0       0  \n",
       "7945            0       0  \n",
       "5727            0       0  "
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set, queste mi servono solo per il div explorer che ha bisogno di ground truth e predizioni\n",
    "y_pred_val = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Violent_Recidivist</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>fp</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>6-10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>35-44</td>\n",
       "      <td>11-15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>65-100</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex              race  Recidivism_Risk  Violent_Recidivist Risk_Level  \\\n",
       "10676  Male  African-American                4                   0        Low   \n",
       "13123  Male         Caucasian                1                   0        Low   \n",
       "2611   Male  African-American                8                   0       High   \n",
       "7945   Male         Caucasian                1                   0        Low   \n",
       "5727   Male         Caucasian                6                   0     Medium   \n",
       "\n",
       "       Violent_Recidivism_Risk Violent_Risk_Level  Juvenile_Offenses  \\\n",
       "10676                        2                Low                  0   \n",
       "13123                        1                Low                  0   \n",
       "2611                         6             Medium                  2   \n",
       "7945                         1                Low                  0   \n",
       "5727                         6             Medium                  0   \n",
       "\n",
       "      age_group Prior_Offensesgroup    fp  y_pred  accuracy  \n",
       "10676     45-54                6-10 0.000       0         1  \n",
       "13123     45-54                 0-5 0.000       0         1  \n",
       "2611      35-44               11-15 0.000       0         1  \n",
       "7945     65-100                 0-5 0.000       0         1  \n",
       "5727      25-34                 0-5 0.000       0         1  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]\n",
    "\n",
    "df_val_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_val['fp'] = df_val_class['fp']\n",
    "\n",
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione √® giusta 0 se la predizione √® sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['accuracy'] = (df_val_class['y_val_true']==df_val_class['y_pred']).astype(int)\n",
    "df_val.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI CONDOTTA CON LA FEATURE FP (PASSATA A BOOLEAN OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Violent_Recidivist</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>fp</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>6-10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>35-44</td>\n",
       "      <td>11-15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>65-100</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>55-64</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>9</td>\n",
       "      <td>High</td>\n",
       "      <td>21</td>\n",
       "      <td>25-34</td>\n",
       "      <td>16-20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>55-64</td>\n",
       "      <td>11-15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2439 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sex              race  Recidivism_Risk  Violent_Recidivist  \\\n",
       "10676    Male  African-American                4                   0   \n",
       "13123    Male         Caucasian                1                   0   \n",
       "2611     Male  African-American                8                   0   \n",
       "7945     Male         Caucasian                1                   0   \n",
       "5727     Male         Caucasian                6                   0   \n",
       "...       ...               ...              ...                 ...   \n",
       "4183     Male         Caucasian                1                   0   \n",
       "9445     Male         Caucasian                8                   0   \n",
       "8674   Female         Caucasian                5                   0   \n",
       "6392     Male          Hispanic                1                   0   \n",
       "6524   Female         Caucasian                5                   0   \n",
       "\n",
       "      Risk_Level  Violent_Recidivism_Risk Violent_Risk_Level  \\\n",
       "10676        Low                        2                Low   \n",
       "13123        Low                        1                Low   \n",
       "2611        High                        6             Medium   \n",
       "7945         Low                        1                Low   \n",
       "5727      Medium                        6             Medium   \n",
       "...          ...                      ...                ...   \n",
       "4183         Low                        1                Low   \n",
       "9445        High                        9               High   \n",
       "8674      Medium                        4                Low   \n",
       "6392         Low                        1                Low   \n",
       "6524      Medium                        2                Low   \n",
       "\n",
       "       Juvenile_Offenses age_group Prior_Offensesgroup    fp  y_pred  accuracy  \n",
       "10676                  0     45-54                6-10 0.000       0         1  \n",
       "13123                  0     45-54                 0-5 0.000       0         1  \n",
       "2611                   2     35-44               11-15 0.000       0         1  \n",
       "7945                   0    65-100                 0-5 0.000       0         1  \n",
       "5727                   0     25-34                 0-5 0.000       0         1  \n",
       "...                  ...       ...                 ...   ...     ...       ...  \n",
       "4183                   0     55-64                 0-5 0.000       0         1  \n",
       "9445                  21     25-34               16-20 0.000       0         1  \n",
       "8674                   0     55-64               11-15 0.000       0         1  \n",
       "6392                   0     35-44                 0-5 0.000       0         1  \n",
       "6524                   0     35-44                 0-5 0.000       0         1  \n",
       "\n",
       "[2439 rows x 13 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['sex', 'race', 'Recidivism_Risk', 'Risk_Level', 'Violent_Recidivism_Risk', 'Violent_Risk_Level', 'Juvenile_Offenses', 'age_group', 'Prior_Offensesgroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fp</th>\n",
       "      <th>fp_div</th>\n",
       "      <th>fp_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021</td>\n",
       "      <td>(Recidivism_Risk=10, sex=Male, Prior_Offensesgroup=6-10)</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.188</td>\n",
       "      <td>3.164</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021</td>\n",
       "      <td>(Recidivism_Risk=10, Prior_Offensesgroup=6-10, sex=Male, Risk_Level=High)</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.188</td>\n",
       "      <td>3.164</td>\n",
       "      <td>4</td>\n",
       "      <td>50.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025</td>\n",
       "      <td>(Recidivism_Risk=10, Prior_Offensesgroup=6-10, Risk_Level=High)</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.143</td>\n",
       "      <td>2.995</td>\n",
       "      <td>3</td>\n",
       "      <td>61.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025</td>\n",
       "      <td>(Recidivism_Risk=10, Prior_Offensesgroup=6-10)</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.143</td>\n",
       "      <td>2.995</td>\n",
       "      <td>2</td>\n",
       "      <td>61.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021</td>\n",
       "      <td>(Recidivism_Risk=10, Violent_Risk_Level=Medium, Risk_Level=High)</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.130</td>\n",
       "      <td>2.612</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.021   \n",
       "1    0.021   \n",
       "2    0.025   \n",
       "3    0.025   \n",
       "4    0.021   \n",
       "\n",
       "                                                                     itemset  \\\n",
       "0                   (Recidivism_Risk=10, sex=Male, Prior_Offensesgroup=6-10)   \n",
       "1  (Recidivism_Risk=10, Prior_Offensesgroup=6-10, sex=Male, Risk_Level=High)   \n",
       "2            (Recidivism_Risk=10, Prior_Offensesgroup=6-10, Risk_Level=High)   \n",
       "3                             (Recidivism_Risk=10, Prior_Offensesgroup=6-10)   \n",
       "4           (Recidivism_Risk=10, Violent_Risk_Level=Medium, Risk_Level=High)   \n",
       "\n",
       "     fp  fp_div  fp_t  length  support_count  \n",
       "0 0.205   0.188 3.164       3         50.000  \n",
       "1 0.205   0.188 3.164       4         50.000  \n",
       "2 0.160   0.143 2.995       3         61.000  \n",
       "3 0.160   0.143 2.995       2         61.000  \n",
       "4 0.146   0.130 2.612       3         50.000  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_diver = DivergenceExplorer(df_val)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"fp_div\", \"fp_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "      <th>fp</th>\n",
       "      <th>fp_div</th>\n",
       "      <th>fp_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021</td>\n",
       "      <td>(Recidivism_Risk=10, sex=Male, Prior_Offensesgroup=6-10)</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.188</td>\n",
       "      <td>3.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025</td>\n",
       "      <td>(Recidivism_Risk=10, Prior_Offensesgroup=6-10)</td>\n",
       "      <td>2</td>\n",
       "      <td>61.000</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.143</td>\n",
       "      <td>2.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021</td>\n",
       "      <td>(Recidivism_Risk=10, Violent_Risk_Level=Medium)</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.130</td>\n",
       "      <td>2.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.023</td>\n",
       "      <td>(Violent_Recidivism_Risk=7, age_group=25-34, Risk_Level=High)</td>\n",
       "      <td>3</td>\n",
       "      <td>56.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.114</td>\n",
       "      <td>2.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.024</td>\n",
       "      <td>(sex=Male, Violent_Risk_Level=Medium, Prior_Offensesgroup=6-10, Risk_Level=High)</td>\n",
       "      <td>4</td>\n",
       "      <td>58.000</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.111</td>\n",
       "      <td>2.534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.021   \n",
       "3    0.025   \n",
       "5    0.021   \n",
       "7    0.023   \n",
       "8    0.024   \n",
       "\n",
       "                                                                            itemset  \\\n",
       "0                          (Recidivism_Risk=10, sex=Male, Prior_Offensesgroup=6-10)   \n",
       "3                                    (Recidivism_Risk=10, Prior_Offensesgroup=6-10)   \n",
       "5                                   (Recidivism_Risk=10, Violent_Risk_Level=Medium)   \n",
       "7                     (Violent_Recidivism_Risk=7, age_group=25-34, Risk_Level=High)   \n",
       "8  (sex=Male, Violent_Risk_Level=Medium, Prior_Offensesgroup=6-10, Risk_Level=High)   \n",
       "\n",
       "   length  support_count    fp  fp_div  fp_t  \n",
       "0       3         50.000 0.205   0.188 3.164  \n",
       "3       2         61.000 0.160   0.143 2.995  \n",
       "5       2         50.000 0.146   0.130 2.612  \n",
       "7       3         56.000 0.130   0.114 2.547  \n",
       "8       4         58.000 0.128   0.111 2.534  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 1194\n",
      "total problematic 125\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_fp)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_fp[(df_pruned_fp['fp_div'] > 0) & (df_pruned_fp['fp_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (4200, 7)\n",
      "Dim pruned th_redundancy  (1194, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_fp.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset_and_or li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Violent_Recidivist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[344], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df_holdout_filtered \u001b[38;5;241m=\u001b[39m K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K) \u001b[38;5;66;03m#da aggiungere a train set e ripetere train e test\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_holdout_filtered_solo0 \u001b[38;5;241m=\u001b[39m df_holdout_filtered[\u001b[43mdf_holdout_filtered\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mViolent_Recidivist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m df_combinated \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_holdout_filtered_solo0, df_train], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m df_train_mitigated\u001b[38;5;241m=\u001b[39m df_combinated\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mseed)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/TESI/.tesi/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/TESI/.tesi/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Violent_Recidivist'"
     ]
    }
   ],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "df_holdout_filtered_solo0 = df_holdout_filtered[df_holdout_filtered['Violent_Recidivist']==0]\n",
    "\n",
    "\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered_solo0, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "df_holdout_filtered = df_holdout_filtered_solo0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    }
   ],
   "source": [
    "print(len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "TRAIN SET MITIGATED ROWS:  11178\n",
      "VALIDATION SET ROWS:  2439\n",
      "FILTERED DF holdout ROWS:  203\n",
      "TEST SET FILTERED ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['Violent_Recidivist']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "#cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "verifica : 203\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"Violent_Recidivist\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.753</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.747</td>\n",
       "      <td>43</td>\n",
       "      <td>133</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.747</td>\n",
       "      <td>47</td>\n",
       "      <td>133</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.926     0.327                0.021   \n",
       "After Mitigation(K=5, fp)     0.928     0.338                0.019   \n",
       "After RANDOM mitigation       0.926     0.333                0.021   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.753               47   \n",
       "After Mitigation(K=5, fp)                0.747               43   \n",
       "After RANDOM mitigation                  0.747               47   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      134       10975       2439  \n",
       "After Mitigation(K=5, fp)              133       11178       2439  \n",
       "After RANDOM mitigation                133       11178       2439  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE\n",
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.055</td>\n",
       "      <td>203.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.064</td>\n",
       "      <td>203.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.926     0.327             0.020   \n",
       "After Mitigation(K=5 fp)            0.928     0.338             0.021   \n",
       "After RANDOM Mitigation(K=5 fp)     0.926     0.333             0.018   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.119               0.098   \n",
       "After Mitigation(K=5 fp)           0.092               0.074   \n",
       "After RANDOM Mitigation(K=5 fp)    0.119               0.092   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.084               0.067   \n",
       "After Mitigation(K=5 fp)                      0.065               0.055   \n",
       "After RANDOM Mitigation(K=5 fp)               0.080               0.064   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)               203.000  \n",
       "After RANDOM Mitigation(K=5 fp)        203.000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline1  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline1\n",
    "\n",
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "#attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_random_per_confrontare_con_baseline1\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline1 = abs(sum(fp_div_list_baseline1) / len(fp_div_list_baseline1))\n",
    "media_fp_div_list_baseline1_primi10 = abs(sum(fp_div_list_baseline1[:10]) / len(fp_div_list_baseline1[:10]))\n",
    "media_fp_div_list_baseline1_primi20 = abs(sum(fp_div_list_baseline1[:20]) / len(fp_div_list_baseline1[:20]))\n",
    "media_fp_div_list_baseline1_primi40 = abs(sum(fp_div_list_baseline1[:40]) / len(fp_div_list_baseline1[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_baseline1 = max(abs(x) for x in fp_div_list_baseline1)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_fp_div_list_baseline1, fp_div_massimo_valore_assoluto_fp_div_baseline1,\n",
    "        media_fp_div_list_baseline1_primi10, media_fp_div_list_baseline1_primi20, media_fp_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGUE CODICE USANDO SMOTE \n",
    "DIVIDO IN TRAIN, TEST E VALIDATION -- ora uso quelli gia esistenti\n",
    "DIV EXPLORER SUL VALIDATION  -- gi√† fatto \n",
    "GENERO NUOVI DATI CON SMOTE a partire dai dati di divexplorer sul validation\n",
    "INSERISCO QUESTI NUOVI DATI NEL TRAIN SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p √® la probabilit√† che il campione simulato sia di classe 0 qui (perch√® voglio diminuire il numero di falsi positivi)\n",
    "- FISSO p VARIA N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 348\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['fp', 'y_pred', 'accuracy', \"Violent_Recidivist\"], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered[\"Violent_Recidivist\"]\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 1, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 302)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered[\"Violent_Recidivist\"].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = np.arange(0.5, 1.05, 0.05)\n",
    "p_values = np.round(p_values, 2).tolist()\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N come holdout filtered e targeted acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.753</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 203</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.747</td>\n",
       "      <td>47</td>\n",
       "      <td>133</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.5</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.742</td>\n",
       "      <td>53</td>\n",
       "      <td>132</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.55</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.747</td>\n",
       "      <td>48</td>\n",
       "      <td>133</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.6</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.742</td>\n",
       "      <td>58</td>\n",
       "      <td>132</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.65</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.747</td>\n",
       "      <td>47</td>\n",
       "      <td>133</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.7</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.753</td>\n",
       "      <td>51</td>\n",
       "      <td>134</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.75</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.747</td>\n",
       "      <td>51</td>\n",
       "      <td>133</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.8</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.742</td>\n",
       "      <td>50</td>\n",
       "      <td>132</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.85</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.747</td>\n",
       "      <td>50</td>\n",
       "      <td>133</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.742</td>\n",
       "      <td>48</td>\n",
       "      <td>132</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.95</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.758</td>\n",
       "      <td>50</td>\n",
       "      <td>135</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 1.0</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.758</td>\n",
       "      <td>49</td>\n",
       "      <td>135</td>\n",
       "      <td>11178</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.926     0.327                0.021   \n",
       "After RANDOM mitigation N = 203          0.926     0.333                0.021   \n",
       "After SMOTE N = 203 p_class 0 = 0.5      0.924     0.332                0.023   \n",
       "After SMOTE N = 203 p_class 0 = 0.55     0.926     0.332                0.021   \n",
       "After SMOTE N = 203 p_class 0 = 0.6      0.922     0.326                0.026   \n",
       "After SMOTE N = 203 p_class 0 = 0.65     0.926     0.333                0.021   \n",
       "After SMOTE N = 203 p_class 0 = 0.7      0.924     0.322                0.023   \n",
       "After SMOTE N = 203 p_class 0 = 0.75     0.925     0.328                0.023   \n",
       "After SMOTE N = 203 p_class 0 = 0.8      0.925     0.336                0.022   \n",
       "After SMOTE N = 203 p_class 0 = 0.85     0.925     0.330                0.022   \n",
       "After SMOTE N = 203 p_class 0 = 0.9      0.926     0.338                0.021   \n",
       "After SMOTE N = 203 p_class 0 = 0.95     0.924     0.317                0.022   \n",
       "After SMOTE N = 203 p_class 0 = 1.0      0.925     0.319                0.022   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.753               47   \n",
       "After RANDOM mitigation N = 203                     0.747               47   \n",
       "After SMOTE N = 203 p_class 0 = 0.5                 0.742               53   \n",
       "After SMOTE N = 203 p_class 0 = 0.55                0.747               48   \n",
       "After SMOTE N = 203 p_class 0 = 0.6                 0.742               58   \n",
       "After SMOTE N = 203 p_class 0 = 0.65                0.747               47   \n",
       "After SMOTE N = 203 p_class 0 = 0.7                 0.753               51   \n",
       "After SMOTE N = 203 p_class 0 = 0.75                0.747               51   \n",
       "After SMOTE N = 203 p_class 0 = 0.8                 0.742               50   \n",
       "After SMOTE N = 203 p_class 0 = 0.85                0.747               50   \n",
       "After SMOTE N = 203 p_class 0 = 0.9                 0.742               48   \n",
       "After SMOTE N = 203 p_class 0 = 0.95                0.758               50   \n",
       "After SMOTE N = 203 p_class 0 = 1.0                 0.758               49   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 134       10975       2439  \n",
       "After RANDOM mitigation N = 203                   133       11178       2439  \n",
       "After SMOTE N = 203 p_class 0 = 0.5               132       11178       2439  \n",
       "After SMOTE N = 203 p_class 0 = 0.55              133       11178       2439  \n",
       "After SMOTE N = 203 p_class 0 = 0.6               132       11178       2439  \n",
       "After SMOTE N = 203 p_class 0 = 0.65              133       11178       2439  \n",
       "After SMOTE N = 203 p_class 0 = 0.7               134       11178       2439  \n",
       "After SMOTE N = 203 p_class 0 = 0.75              133       11178       2439  \n",
       "After SMOTE N = 203 p_class 0 = 0.8               132       11178       2439  \n",
       "After SMOTE N = 203 p_class 0 = 0.85              133       11178       2439  \n",
       "After SMOTE N = 203 p_class 0 = 0.9               132       11178       2439  \n",
       "After SMOTE N = 203 p_class 0 = 0.95              135       11178       2439  \n",
       "After SMOTE N = 203 p_class 0 = 1.0               135       11178       2439  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 203</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.333</td>\n",
       "      <td>47</td>\n",
       "      <td>133</td>\n",
       "      <td>180</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.5</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.332</td>\n",
       "      <td>53</td>\n",
       "      <td>132</td>\n",
       "      <td>185</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.55</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.332</td>\n",
       "      <td>48</td>\n",
       "      <td>133</td>\n",
       "      <td>181</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.6</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.326</td>\n",
       "      <td>58</td>\n",
       "      <td>132</td>\n",
       "      <td>190</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.65</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.333</td>\n",
       "      <td>47</td>\n",
       "      <td>133</td>\n",
       "      <td>180</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.7</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.322</td>\n",
       "      <td>51</td>\n",
       "      <td>134</td>\n",
       "      <td>185</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.75</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.328</td>\n",
       "      <td>51</td>\n",
       "      <td>133</td>\n",
       "      <td>184</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.8</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.336</td>\n",
       "      <td>50</td>\n",
       "      <td>132</td>\n",
       "      <td>182</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.85</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.330</td>\n",
       "      <td>50</td>\n",
       "      <td>133</td>\n",
       "      <td>183</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.338</td>\n",
       "      <td>48</td>\n",
       "      <td>132</td>\n",
       "      <td>180</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 0.95</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.317</td>\n",
       "      <td>50</td>\n",
       "      <td>135</td>\n",
       "      <td>185</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 203 p_class 0 = 1.0</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.319</td>\n",
       "      <td>49</td>\n",
       "      <td>135</td>\n",
       "      <td>184</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.926     0.327               47   \n",
       "After RANDOM mitigation N = 203          0.926     0.333               47   \n",
       "After SMOTE N = 203 p_class 0 = 0.5      0.924     0.332               53   \n",
       "After SMOTE N = 203 p_class 0 = 0.55     0.926     0.332               48   \n",
       "After SMOTE N = 203 p_class 0 = 0.6      0.922     0.326               58   \n",
       "After SMOTE N = 203 p_class 0 = 0.65     0.926     0.333               47   \n",
       "After SMOTE N = 203 p_class 0 = 0.7      0.924     0.322               51   \n",
       "After SMOTE N = 203 p_class 0 = 0.75     0.925     0.328               51   \n",
       "After SMOTE N = 203 p_class 0 = 0.8      0.925     0.336               50   \n",
       "After SMOTE N = 203 p_class 0 = 0.85     0.925     0.330               50   \n",
       "After SMOTE N = 203 p_class 0 = 0.9      0.926     0.338               48   \n",
       "After SMOTE N = 203 p_class 0 = 0.95     0.924     0.317               50   \n",
       "After SMOTE N = 203 p_class 0 = 1.0      0.925     0.319               49   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 134           181   \n",
       "After RANDOM mitigation N = 203                   133           180   \n",
       "After SMOTE N = 203 p_class 0 = 0.5               132           185   \n",
       "After SMOTE N = 203 p_class 0 = 0.55              133           181   \n",
       "After SMOTE N = 203 p_class 0 = 0.6               132           190   \n",
       "After SMOTE N = 203 p_class 0 = 0.65              133           180   \n",
       "After SMOTE N = 203 p_class 0 = 0.7               134           185   \n",
       "After SMOTE N = 203 p_class 0 = 0.75              133           184   \n",
       "After SMOTE N = 203 p_class 0 = 0.8               132           182   \n",
       "After SMOTE N = 203 p_class 0 = 0.85              133           183   \n",
       "After SMOTE N = 203 p_class 0 = 0.9               132           180   \n",
       "After SMOTE N = 203 p_class 0 = 0.95              135           185   \n",
       "After SMOTE N = 203 p_class 0 = 1.0               135           184   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.020           0.119   \n",
       "After RANDOM mitigation N = 203                 0.018           0.119   \n",
       "After SMOTE N = 203 p_class 0 = 0.5             0.020           0.122   \n",
       "After SMOTE N = 203 p_class 0 = 0.55            0.018           0.099   \n",
       "After SMOTE N = 203 p_class 0 = 0.6             0.021           0.151   \n",
       "After SMOTE N = 203 p_class 0 = 0.65            0.016           0.135   \n",
       "After SMOTE N = 203 p_class 0 = 0.7             0.020           0.154   \n",
       "After SMOTE N = 203 p_class 0 = 0.75            0.021           0.134   \n",
       "After SMOTE N = 203 p_class 0 = 0.8             0.020           0.142   \n",
       "After SMOTE N = 203 p_class 0 = 0.85            0.017           0.133   \n",
       "After SMOTE N = 203 p_class 0 = 0.9             0.016           0.136   \n",
       "After SMOTE N = 203 p_class 0 = 0.95            0.020           0.135   \n",
       "After SMOTE N = 203 p_class 0 = 1.0             0.019           0.155   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.098       0.084       0.067  \n",
       "After RANDOM mitigation N = 203            0.092       0.080       0.064  \n",
       "After SMOTE N = 203 p_class 0 = 0.5        0.099       0.084       0.070  \n",
       "After SMOTE N = 203 p_class 0 = 0.55       0.077       0.069       0.058  \n",
       "After SMOTE N = 203 p_class 0 = 0.6        0.123       0.107       0.087  \n",
       "After SMOTE N = 203 p_class 0 = 0.65       0.083       0.069       0.055  \n",
       "After SMOTE N = 203 p_class 0 = 0.7        0.108       0.091       0.072  \n",
       "After SMOTE N = 203 p_class 0 = 0.75       0.103       0.089       0.071  \n",
       "After SMOTE N = 203 p_class 0 = 0.8        0.115       0.097       0.075  \n",
       "After SMOTE N = 203 p_class 0 = 0.85       0.091       0.077       0.061  \n",
       "After SMOTE N = 203 p_class 0 = 0.9        0.097       0.080       0.062  \n",
       "After SMOTE N = 203 p_class 0 = 0.95       0.109       0.094       0.073  \n",
       "After SMOTE N = 203 p_class 0 = 1.0        0.114       0.093       0.071  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_confronto = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_confronto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N  = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.753</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.747</td>\n",
       "      <td>52</td>\n",
       "      <td>133</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.5</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.725</td>\n",
       "      <td>54</td>\n",
       "      <td>129</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.55</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.753</td>\n",
       "      <td>58</td>\n",
       "      <td>134</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.730</td>\n",
       "      <td>49</td>\n",
       "      <td>130</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.65</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.736</td>\n",
       "      <td>49</td>\n",
       "      <td>131</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.7</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.742</td>\n",
       "      <td>54</td>\n",
       "      <td>132</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.75</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.753</td>\n",
       "      <td>39</td>\n",
       "      <td>134</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.8</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.753</td>\n",
       "      <td>49</td>\n",
       "      <td>134</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.85</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.747</td>\n",
       "      <td>46</td>\n",
       "      <td>133</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.747</td>\n",
       "      <td>47</td>\n",
       "      <td>133</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.95</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.753</td>\n",
       "      <td>45</td>\n",
       "      <td>134</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 1.0</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.747</td>\n",
       "      <td>43</td>\n",
       "      <td>133</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.926     0.327   \n",
       "After RANDOM mitigation N = 1000          0.924     0.327   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5      0.925     0.349   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55     0.921     0.314   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6      0.927     0.349   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65     0.926     0.343   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7      0.924     0.331   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75     0.929     0.337   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8      0.925     0.325   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85     0.927     0.335   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9      0.926     0.333   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95     0.927     0.330   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0      0.928     0.338   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.021   \n",
       "After RANDOM mitigation N = 1000                     0.023   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5                 0.024   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55                0.026   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6                 0.022   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65                0.022   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7                 0.024   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75                0.017   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8                 0.022   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85                0.020   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9                 0.021   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95                0.020   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0                 0.019   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.753               47   \n",
       "After RANDOM mitigation N = 1000                     0.747               52   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5                 0.725               54   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55                0.753               58   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6                 0.730               49   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65                0.736               49   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7                 0.742               54   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75                0.753               39   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8                 0.753               49   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85                0.747               46   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9                 0.747               47   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95                0.753               45   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0                 0.747               43   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  134       10975       2439  \n",
       "After RANDOM mitigation N = 1000                   133       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.5               129       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.55              134       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.6               130       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.65              131       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.7               132       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.75              134       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.8               134       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.85              133       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.9               133       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 0.95              134       11975       2439  \n",
       "After SMOTE N = 1000 p_class 0 = 1.0               133       11975       2439  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionari per salvare i risultati\n",
    "N = 1000\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "                  \n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.327</td>\n",
       "      <td>52</td>\n",
       "      <td>133</td>\n",
       "      <td>185</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.5</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.349</td>\n",
       "      <td>54</td>\n",
       "      <td>129</td>\n",
       "      <td>183</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.55</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.314</td>\n",
       "      <td>58</td>\n",
       "      <td>134</td>\n",
       "      <td>192</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.349</td>\n",
       "      <td>49</td>\n",
       "      <td>130</td>\n",
       "      <td>179</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.65</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.343</td>\n",
       "      <td>49</td>\n",
       "      <td>131</td>\n",
       "      <td>180</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.7</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.331</td>\n",
       "      <td>54</td>\n",
       "      <td>132</td>\n",
       "      <td>186</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.75</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.337</td>\n",
       "      <td>39</td>\n",
       "      <td>134</td>\n",
       "      <td>173</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.8</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.325</td>\n",
       "      <td>49</td>\n",
       "      <td>134</td>\n",
       "      <td>183</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.85</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.335</td>\n",
       "      <td>46</td>\n",
       "      <td>133</td>\n",
       "      <td>179</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.333</td>\n",
       "      <td>47</td>\n",
       "      <td>133</td>\n",
       "      <td>180</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.95</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.330</td>\n",
       "      <td>45</td>\n",
       "      <td>134</td>\n",
       "      <td>179</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 1.0</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.338</td>\n",
       "      <td>43</td>\n",
       "      <td>133</td>\n",
       "      <td>176</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.926     0.327               47   \n",
       "After RANDOM mitigation N = 1000          0.924     0.327               52   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5      0.925     0.349               54   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55     0.921     0.314               58   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6      0.927     0.349               49   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65     0.926     0.343               49   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7      0.924     0.331               54   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75     0.929     0.337               39   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8      0.925     0.325               49   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85     0.927     0.335               46   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9      0.926     0.333               47   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95     0.927     0.330               45   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0      0.928     0.338               43   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  134           181   \n",
       "After RANDOM mitigation N = 1000                   133           185   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5               129           183   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55              134           192   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6               130           179   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65              131           180   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7               132           186   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75              134           173   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8               134           183   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85              133           179   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9               133           180   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95              134           179   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0               133           176   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.020           0.119   \n",
       "After RANDOM mitigation N = 1000                 0.018           0.119   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5             0.026           0.133   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55            0.022           0.134   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6             0.021           0.118   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65            0.017           0.109   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7             0.023           0.154   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75            0.017           0.094   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8             0.020           0.129   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85            0.021           0.137   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9             0.021           0.139   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95            0.018           0.113   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0             0.023           0.101   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.098       0.084       0.067  \n",
       "After RANDOM mitigation N = 1000            0.092       0.080       0.064  \n",
       "After SMOTE N = 1000 p_class 0 = 0.5        0.111       0.099       0.084  \n",
       "After SMOTE N = 1000 p_class 0 = 0.55       0.110       0.097       0.081  \n",
       "After SMOTE N = 1000 p_class 0 = 0.6        0.103       0.091       0.073  \n",
       "After SMOTE N = 1000 p_class 0 = 0.65       0.084       0.072       0.058  \n",
       "After SMOTE N = 1000 p_class 0 = 0.7        0.120       0.104       0.085  \n",
       "After SMOTE N = 1000 p_class 0 = 0.75       0.069       0.058       0.049  \n",
       "After SMOTE N = 1000 p_class 0 = 0.8        0.091       0.080       0.067  \n",
       "After SMOTE N = 1000 p_class 0 = 0.85       0.104       0.090       0.073  \n",
       "After SMOTE N = 1000 p_class 0 = 0.9        0.098       0.081       0.066  \n",
       "After SMOTE N = 1000 p_class 0 = 0.95       0.078       0.068       0.056  \n",
       "After SMOTE N = 1000 p_class 0 = 1.0        0.080       0.070       0.059  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes=attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_1K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.753</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.719</td>\n",
       "      <td>47</td>\n",
       "      <td>128</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.736</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.55</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.736</td>\n",
       "      <td>52</td>\n",
       "      <td>131</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.730</td>\n",
       "      <td>52</td>\n",
       "      <td>130</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.65</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.736</td>\n",
       "      <td>51</td>\n",
       "      <td>131</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.7</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.736</td>\n",
       "      <td>53</td>\n",
       "      <td>131</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.75</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.747</td>\n",
       "      <td>47</td>\n",
       "      <td>133</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.8</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.747</td>\n",
       "      <td>49</td>\n",
       "      <td>133</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.85</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.736</td>\n",
       "      <td>50</td>\n",
       "      <td>131</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.747</td>\n",
       "      <td>48</td>\n",
       "      <td>133</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.95</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.747</td>\n",
       "      <td>45</td>\n",
       "      <td>133</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.753</td>\n",
       "      <td>43</td>\n",
       "      <td>134</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.926     0.327   \n",
       "After RANDOM mitigation N = 2000          0.928     0.364   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5      0.927     0.344   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55     0.925     0.339   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6      0.925     0.345   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65     0.925     0.341   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7      0.925     0.338   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75     0.926     0.333   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8      0.925     0.331   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85     0.926     0.342   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9      0.926     0.332   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95     0.927     0.336   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0      0.927     0.332   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.021   \n",
       "After RANDOM mitigation N = 2000                     0.021   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5                 0.021   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55                0.023   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6                 0.023   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65                0.023   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7                 0.023   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75                0.021   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8                 0.022   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85                0.022   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9                 0.021   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95                0.020   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0                 0.019   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.753               47   \n",
       "After RANDOM mitigation N = 2000                     0.719               47   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5                 0.736               48   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55                0.736               52   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6                 0.730               52   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65                0.736               51   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7                 0.736               53   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75                0.747               47   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8                 0.747               49   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85                0.736               50   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9                 0.747               48   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95                0.747               45   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0                 0.753               43   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  134       10975       2439  \n",
       "After RANDOM mitigation N = 2000                   128       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.5               131       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.55              131       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.6               130       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.65              131       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.7               131       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.75              133       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.8               133       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.85              131       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.9               133       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 0.95              133       12975       2439  \n",
       "After SMOTE N = 2000 p_class 0 = 1.0               134       12975       2439  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.364</td>\n",
       "      <td>47</td>\n",
       "      <td>128</td>\n",
       "      <td>175</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.344</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>179</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.55</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.339</td>\n",
       "      <td>52</td>\n",
       "      <td>131</td>\n",
       "      <td>183</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.345</td>\n",
       "      <td>52</td>\n",
       "      <td>130</td>\n",
       "      <td>182</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.65</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.341</td>\n",
       "      <td>51</td>\n",
       "      <td>131</td>\n",
       "      <td>182</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.7</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.338</td>\n",
       "      <td>53</td>\n",
       "      <td>131</td>\n",
       "      <td>184</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.75</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.333</td>\n",
       "      <td>47</td>\n",
       "      <td>133</td>\n",
       "      <td>180</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.8</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.331</td>\n",
       "      <td>49</td>\n",
       "      <td>133</td>\n",
       "      <td>182</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.85</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.342</td>\n",
       "      <td>50</td>\n",
       "      <td>131</td>\n",
       "      <td>181</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.332</td>\n",
       "      <td>48</td>\n",
       "      <td>133</td>\n",
       "      <td>181</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.95</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.336</td>\n",
       "      <td>45</td>\n",
       "      <td>133</td>\n",
       "      <td>178</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.332</td>\n",
       "      <td>43</td>\n",
       "      <td>134</td>\n",
       "      <td>177</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.926     0.327               47   \n",
       "After RANDOM mitigation N = 2000          0.928     0.364               47   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5      0.927     0.344               48   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55     0.925     0.339               52   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6      0.925     0.345               52   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65     0.925     0.341               51   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7      0.925     0.338               53   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75     0.926     0.333               47   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8      0.925     0.331               49   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85     0.926     0.342               50   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9      0.926     0.332               48   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95     0.927     0.336               45   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0      0.927     0.332               43   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  134           181   \n",
       "After RANDOM mitigation N = 2000                   128           175   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5               131           179   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55              131           183   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6               130           182   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65              131           182   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7               131           184   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75              133           180   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8               133           182   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85              131           181   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9               133           181   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95              133           178   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0               134           177   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.020           0.119   \n",
       "After RANDOM mitigation N = 2000                 0.018           0.119   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5             0.018           0.099   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55            0.016           0.087   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6             0.017           0.114   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65            0.022           0.117   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7             0.017           0.121   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75            0.015           0.119   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8             0.016           0.087   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85            0.016           0.103   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9             0.022           0.155   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95            0.016           0.100   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0             0.019           0.101   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.098       0.084       0.067  \n",
       "After RANDOM mitigation N = 2000            0.092       0.080       0.064  \n",
       "After SMOTE N = 2000 p_class 0 = 0.5        0.079       0.071       0.058  \n",
       "After SMOTE N = 2000 p_class 0 = 0.55       0.071       0.065       0.055  \n",
       "After SMOTE N = 2000 p_class 0 = 0.6        0.077       0.069       0.059  \n",
       "After SMOTE N = 2000 p_class 0 = 0.65       0.095       0.083       0.071  \n",
       "After SMOTE N = 2000 p_class 0 = 0.7        0.091       0.079       0.064  \n",
       "After SMOTE N = 2000 p_class 0 = 0.75       0.079       0.068       0.056  \n",
       "After SMOTE N = 2000 p_class 0 = 0.8        0.074       0.063       0.052  \n",
       "After SMOTE N = 2000 p_class 0 = 0.85       0.087       0.076       0.064  \n",
       "After SMOTE N = 2000 p_class 0 = 0.9        0.100       0.084       0.069  \n",
       "After SMOTE N = 2000 p_class 0 = 0.95       0.077       0.064       0.052  \n",
       "After SMOTE N = 2000 p_class 0 = 1.0        0.077       0.067       0.055  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes=attributes\n",
    "                     \n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_2K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.753</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3000</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.730</td>\n",
       "      <td>53</td>\n",
       "      <td>130</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.5</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.730</td>\n",
       "      <td>55</td>\n",
       "      <td>130</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.55</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.736</td>\n",
       "      <td>57</td>\n",
       "      <td>131</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.708</td>\n",
       "      <td>58</td>\n",
       "      <td>126</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.65</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.730</td>\n",
       "      <td>43</td>\n",
       "      <td>130</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.7</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.758</td>\n",
       "      <td>49</td>\n",
       "      <td>135</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.75</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.747</td>\n",
       "      <td>48</td>\n",
       "      <td>133</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.8</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.713</td>\n",
       "      <td>53</td>\n",
       "      <td>127</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.85</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.725</td>\n",
       "      <td>46</td>\n",
       "      <td>129</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.9</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.747</td>\n",
       "      <td>39</td>\n",
       "      <td>133</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.95</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.742</td>\n",
       "      <td>41</td>\n",
       "      <td>132</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 1.0</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.753</td>\n",
       "      <td>38</td>\n",
       "      <td>134</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.926     0.327   \n",
       "After RANDOM mitigation N = 3000          0.925     0.344   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5      0.924     0.342   \n",
       "After SMOTE N = 3000 p_class 0 = 0.55     0.923     0.333   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6      0.925     0.361   \n",
       "After SMOTE N = 3000 p_class 0 = 0.65     0.929     0.357   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7      0.925     0.319   \n",
       "After SMOTE N = 3000 p_class 0 = 0.75     0.926     0.332   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8      0.926     0.362   \n",
       "After SMOTE N = 3000 p_class 0 = 0.85     0.928     0.359   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9      0.929     0.344   \n",
       "After SMOTE N = 3000 p_class 0 = 0.95     0.929     0.347   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0      0.929     0.338   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.021   \n",
       "After RANDOM mitigation N = 3000                     0.023   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5                 0.024   \n",
       "After SMOTE N = 3000 p_class 0 = 0.55                0.025   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6                 0.026   \n",
       "After SMOTE N = 3000 p_class 0 = 0.65                0.019   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7                 0.022   \n",
       "After SMOTE N = 3000 p_class 0 = 0.75                0.021   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8                 0.023   \n",
       "After SMOTE N = 3000 p_class 0 = 0.85                0.020   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9                 0.017   \n",
       "After SMOTE N = 3000 p_class 0 = 0.95                0.018   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0                 0.017   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.753               47   \n",
       "After RANDOM mitigation N = 3000                     0.730               53   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5                 0.730               55   \n",
       "After SMOTE N = 3000 p_class 0 = 0.55                0.736               57   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6                 0.708               58   \n",
       "After SMOTE N = 3000 p_class 0 = 0.65                0.730               43   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7                 0.758               49   \n",
       "After SMOTE N = 3000 p_class 0 = 0.75                0.747               48   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8                 0.713               53   \n",
       "After SMOTE N = 3000 p_class 0 = 0.85                0.725               46   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9                 0.747               39   \n",
       "After SMOTE N = 3000 p_class 0 = 0.95                0.742               41   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0                 0.753               38   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  134       10975       2439  \n",
       "After RANDOM mitigation N = 3000                   130       13975       2439  \n",
       "After SMOTE N = 3000 p_class 0 = 0.5               130       13975       2439  \n",
       "After SMOTE N = 3000 p_class 0 = 0.55              131       13975       2439  \n",
       "After SMOTE N = 3000 p_class 0 = 0.6               126       13975       2439  \n",
       "After SMOTE N = 3000 p_class 0 = 0.65              130       13975       2439  \n",
       "After SMOTE N = 3000 p_class 0 = 0.7               135       13975       2439  \n",
       "After SMOTE N = 3000 p_class 0 = 0.75              133       13975       2439  \n",
       "After SMOTE N = 3000 p_class 0 = 0.8               127       13975       2439  \n",
       "After SMOTE N = 3000 p_class 0 = 0.85              129       13975       2439  \n",
       "After SMOTE N = 3000 p_class 0 = 0.9               133       13975       2439  \n",
       "After SMOTE N = 3000 p_class 0 = 0.95              132       13975       2439  \n",
       "After SMOTE N = 3000 p_class 0 = 1.0               134       13975       2439  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "                  \n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3000</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.344</td>\n",
       "      <td>53</td>\n",
       "      <td>130</td>\n",
       "      <td>183</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.5</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.342</td>\n",
       "      <td>55</td>\n",
       "      <td>130</td>\n",
       "      <td>185</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.55</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.333</td>\n",
       "      <td>57</td>\n",
       "      <td>131</td>\n",
       "      <td>188</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.361</td>\n",
       "      <td>58</td>\n",
       "      <td>126</td>\n",
       "      <td>184</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.65</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.357</td>\n",
       "      <td>43</td>\n",
       "      <td>130</td>\n",
       "      <td>173</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.7</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.319</td>\n",
       "      <td>49</td>\n",
       "      <td>135</td>\n",
       "      <td>184</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.75</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.332</td>\n",
       "      <td>48</td>\n",
       "      <td>133</td>\n",
       "      <td>181</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.8</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.362</td>\n",
       "      <td>53</td>\n",
       "      <td>127</td>\n",
       "      <td>180</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.85</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.359</td>\n",
       "      <td>46</td>\n",
       "      <td>129</td>\n",
       "      <td>175</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.9</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.344</td>\n",
       "      <td>39</td>\n",
       "      <td>133</td>\n",
       "      <td>172</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.95</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.347</td>\n",
       "      <td>41</td>\n",
       "      <td>132</td>\n",
       "      <td>173</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 1.0</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.338</td>\n",
       "      <td>38</td>\n",
       "      <td>134</td>\n",
       "      <td>172</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.926     0.327               47   \n",
       "After RANDOM mitigation N = 3000          0.925     0.344               53   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5      0.924     0.342               55   \n",
       "After SMOTE N = 3000 p_class 0 = 0.55     0.923     0.333               57   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6      0.925     0.361               58   \n",
       "After SMOTE N = 3000 p_class 0 = 0.65     0.929     0.357               43   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7      0.925     0.319               49   \n",
       "After SMOTE N = 3000 p_class 0 = 0.75     0.926     0.332               48   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8      0.926     0.362               53   \n",
       "After SMOTE N = 3000 p_class 0 = 0.85     0.928     0.359               46   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9      0.929     0.344               39   \n",
       "After SMOTE N = 3000 p_class 0 = 0.95     0.929     0.347               41   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0      0.929     0.338               38   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  134           181   \n",
       "After RANDOM mitigation N = 3000                   130           183   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5               130           185   \n",
       "After SMOTE N = 3000 p_class 0 = 0.55              131           188   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6               126           184   \n",
       "After SMOTE N = 3000 p_class 0 = 0.65              130           173   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7               135           184   \n",
       "After SMOTE N = 3000 p_class 0 = 0.75              133           181   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8               127           180   \n",
       "After SMOTE N = 3000 p_class 0 = 0.85              129           175   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9               133           172   \n",
       "After SMOTE N = 3000 p_class 0 = 0.95              132           173   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0               134           172   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.020           0.119   \n",
       "After RANDOM mitigation N = 3000                 0.018           0.119   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5             0.018           0.136   \n",
       "After SMOTE N = 3000 p_class 0 = 0.55            0.017           0.097   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6             0.016           0.104   \n",
       "After SMOTE N = 3000 p_class 0 = 0.65            0.022           0.121   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7             0.015           0.118   \n",
       "After SMOTE N = 3000 p_class 0 = 0.75            0.015           0.083   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8             0.025           0.143   \n",
       "After SMOTE N = 3000 p_class 0 = 0.85            0.017           0.102   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9             0.019           0.100   \n",
       "After SMOTE N = 3000 p_class 0 = 0.95            0.013           0.096   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0             0.020           0.103   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.098       0.084       0.067  \n",
       "After RANDOM mitigation N = 3000            0.092       0.080       0.064  \n",
       "After SMOTE N = 3000 p_class 0 = 0.5        0.101       0.085       0.069  \n",
       "After SMOTE N = 3000 p_class 0 = 0.55       0.082       0.071       0.059  \n",
       "After SMOTE N = 3000 p_class 0 = 0.6        0.081       0.072       0.060  \n",
       "After SMOTE N = 3000 p_class 0 = 0.65       0.087       0.076       0.062  \n",
       "After SMOTE N = 3000 p_class 0 = 0.7        0.084       0.069       0.057  \n",
       "After SMOTE N = 3000 p_class 0 = 0.75       0.072       0.065       0.053  \n",
       "After SMOTE N = 3000 p_class 0 = 0.8        0.116       0.102       0.084  \n",
       "After SMOTE N = 3000 p_class 0 = 0.85       0.075       0.065       0.054  \n",
       "After SMOTE N = 3000 p_class 0 = 0.9        0.079       0.066       0.051  \n",
       "After SMOTE N = 3000 p_class 0 = 0.95       0.069       0.057       0.046  \n",
       "After SMOTE N = 3000 p_class 0 = 1.0        0.078       0.067       0.055  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes=attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_3K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_3K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.753</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 4000</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.725</td>\n",
       "      <td>44</td>\n",
       "      <td>129</td>\n",
       "      <td>14975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.5</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.730</td>\n",
       "      <td>62</td>\n",
       "      <td>130</td>\n",
       "      <td>14975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.55</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.725</td>\n",
       "      <td>54</td>\n",
       "      <td>129</td>\n",
       "      <td>14975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.6</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.713</td>\n",
       "      <td>58</td>\n",
       "      <td>127</td>\n",
       "      <td>14975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.65</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.730</td>\n",
       "      <td>60</td>\n",
       "      <td>130</td>\n",
       "      <td>14975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.719</td>\n",
       "      <td>51</td>\n",
       "      <td>128</td>\n",
       "      <td>14975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.719</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>14975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.8</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.736</td>\n",
       "      <td>50</td>\n",
       "      <td>131</td>\n",
       "      <td>14975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.85</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.725</td>\n",
       "      <td>46</td>\n",
       "      <td>129</td>\n",
       "      <td>14975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.730</td>\n",
       "      <td>45</td>\n",
       "      <td>130</td>\n",
       "      <td>14975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.95</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.753</td>\n",
       "      <td>38</td>\n",
       "      <td>134</td>\n",
       "      <td>14975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1.0</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.758</td>\n",
       "      <td>41</td>\n",
       "      <td>135</td>\n",
       "      <td>14975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.926     0.327   \n",
       "After RANDOM mitigation N = 4000          0.929     0.362   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5      0.921     0.333   \n",
       "After SMOTE N = 4000 p_class 0 = 0.55     0.925     0.349   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6      0.924     0.355   \n",
       "After SMOTE N = 4000 p_class 0 = 0.65     0.922     0.336   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7      0.927     0.358   \n",
       "After SMOTE N = 4000 p_class 0 = 0.75     0.927     0.360   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8      0.926     0.342   \n",
       "After SMOTE N = 4000 p_class 0 = 0.85     0.928     0.359   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9      0.928     0.354   \n",
       "After SMOTE N = 4000 p_class 0 = 0.95     0.929     0.338   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0      0.928     0.328   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.021   \n",
       "After RANDOM mitigation N = 4000                     0.019   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5                 0.027   \n",
       "After SMOTE N = 4000 p_class 0 = 0.55                0.024   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6                 0.026   \n",
       "After SMOTE N = 4000 p_class 0 = 0.65                0.027   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7                 0.023   \n",
       "After SMOTE N = 4000 p_class 0 = 0.75                0.022   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8                 0.022   \n",
       "After SMOTE N = 4000 p_class 0 = 0.85                0.020   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9                 0.020   \n",
       "After SMOTE N = 4000 p_class 0 = 0.95                0.017   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0                 0.018   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.753               47   \n",
       "After RANDOM mitigation N = 4000                     0.725               44   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5                 0.730               62   \n",
       "After SMOTE N = 4000 p_class 0 = 0.55                0.725               54   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6                 0.713               58   \n",
       "After SMOTE N = 4000 p_class 0 = 0.65                0.730               60   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7                 0.719               51   \n",
       "After SMOTE N = 4000 p_class 0 = 0.75                0.719               50   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8                 0.736               50   \n",
       "After SMOTE N = 4000 p_class 0 = 0.85                0.725               46   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9                 0.730               45   \n",
       "After SMOTE N = 4000 p_class 0 = 0.95                0.753               38   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0                 0.758               41   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  134       10975       2439  \n",
       "After RANDOM mitigation N = 4000                   129       14975       2439  \n",
       "After SMOTE N = 4000 p_class 0 = 0.5               130       14975       2439  \n",
       "After SMOTE N = 4000 p_class 0 = 0.55              129       14975       2439  \n",
       "After SMOTE N = 4000 p_class 0 = 0.6               127       14975       2439  \n",
       "After SMOTE N = 4000 p_class 0 = 0.65              130       14975       2439  \n",
       "After SMOTE N = 4000 p_class 0 = 0.7               128       14975       2439  \n",
       "After SMOTE N = 4000 p_class 0 = 0.75              128       14975       2439  \n",
       "After SMOTE N = 4000 p_class 0 = 0.8               131       14975       2439  \n",
       "After SMOTE N = 4000 p_class 0 = 0.85              129       14975       2439  \n",
       "After SMOTE N = 4000 p_class 0 = 0.9               130       14975       2439  \n",
       "After SMOTE N = 4000 p_class 0 = 0.95              134       14975       2439  \n",
       "After SMOTE N = 4000 p_class 0 = 1.0               135       14975       2439  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 4000</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.362</td>\n",
       "      <td>44</td>\n",
       "      <td>129</td>\n",
       "      <td>173</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.5</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.333</td>\n",
       "      <td>62</td>\n",
       "      <td>130</td>\n",
       "      <td>192</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.55</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.349</td>\n",
       "      <td>54</td>\n",
       "      <td>129</td>\n",
       "      <td>183</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.6</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.355</td>\n",
       "      <td>58</td>\n",
       "      <td>127</td>\n",
       "      <td>185</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.65</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.336</td>\n",
       "      <td>60</td>\n",
       "      <td>130</td>\n",
       "      <td>190</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.358</td>\n",
       "      <td>51</td>\n",
       "      <td>128</td>\n",
       "      <td>179</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.360</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>178</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.8</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.342</td>\n",
       "      <td>50</td>\n",
       "      <td>131</td>\n",
       "      <td>181</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.85</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.359</td>\n",
       "      <td>46</td>\n",
       "      <td>129</td>\n",
       "      <td>175</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.354</td>\n",
       "      <td>45</td>\n",
       "      <td>130</td>\n",
       "      <td>175</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.95</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.338</td>\n",
       "      <td>38</td>\n",
       "      <td>134</td>\n",
       "      <td>172</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1.0</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.328</td>\n",
       "      <td>41</td>\n",
       "      <td>135</td>\n",
       "      <td>176</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.926     0.327               47   \n",
       "After RANDOM mitigation N = 4000          0.929     0.362               44   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5      0.921     0.333               62   \n",
       "After SMOTE N = 4000 p_class 0 = 0.55     0.925     0.349               54   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6      0.924     0.355               58   \n",
       "After SMOTE N = 4000 p_class 0 = 0.65     0.922     0.336               60   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7      0.927     0.358               51   \n",
       "After SMOTE N = 4000 p_class 0 = 0.75     0.927     0.360               50   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8      0.926     0.342               50   \n",
       "After SMOTE N = 4000 p_class 0 = 0.85     0.928     0.359               46   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9      0.928     0.354               45   \n",
       "After SMOTE N = 4000 p_class 0 = 0.95     0.929     0.338               38   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0      0.928     0.328               41   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  134           181   \n",
       "After RANDOM mitigation N = 4000                   129           173   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5               130           192   \n",
       "After SMOTE N = 4000 p_class 0 = 0.55              129           183   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6               127           185   \n",
       "After SMOTE N = 4000 p_class 0 = 0.65              130           190   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7               128           179   \n",
       "After SMOTE N = 4000 p_class 0 = 0.75              128           178   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8               131           181   \n",
       "After SMOTE N = 4000 p_class 0 = 0.85              129           175   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9               130           175   \n",
       "After SMOTE N = 4000 p_class 0 = 0.95              134           172   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0               135           176   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.020           0.119   \n",
       "After RANDOM mitigation N = 4000                 0.018           0.119   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5             0.017           0.098   \n",
       "After SMOTE N = 4000 p_class 0 = 0.55            0.016           0.116   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6             0.020           0.154   \n",
       "After SMOTE N = 4000 p_class 0 = 0.65            0.014           0.120   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7             0.017           0.134   \n",
       "After SMOTE N = 4000 p_class 0 = 0.75            0.016           0.096   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8             0.017           0.118   \n",
       "After SMOTE N = 4000 p_class 0 = 0.85            0.017           0.137   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9             0.018           0.117   \n",
       "After SMOTE N = 4000 p_class 0 = 0.95            0.023           0.120   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0             0.018           0.096   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.098       0.084       0.067  \n",
       "After RANDOM mitigation N = 4000            0.092       0.080       0.064  \n",
       "After SMOTE N = 4000 p_class 0 = 0.5        0.088       0.079       0.068  \n",
       "After SMOTE N = 4000 p_class 0 = 0.55       0.090       0.075       0.061  \n",
       "After SMOTE N = 4000 p_class 0 = 0.6        0.115       0.094       0.075  \n",
       "After SMOTE N = 4000 p_class 0 = 0.65       0.093       0.080       0.065  \n",
       "After SMOTE N = 4000 p_class 0 = 0.7        0.083       0.072       0.058  \n",
       "After SMOTE N = 4000 p_class 0 = 0.75       0.074       0.065       0.053  \n",
       "After SMOTE N = 4000 p_class 0 = 0.8        0.088       0.076       0.062  \n",
       "After SMOTE N = 4000 p_class 0 = 0.85       0.077       0.067       0.055  \n",
       "After SMOTE N = 4000 p_class 0 = 0.9        0.078       0.066       0.055  \n",
       "After SMOTE N = 4000 p_class 0 = 0.95       0.086       0.072       0.058  \n",
       "After SMOTE N = 4000 p_class 0 = 1.0        0.077       0.066       0.054  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes=attributes\n",
    "                      \n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_4K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_4K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.753</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.725</td>\n",
       "      <td>45</td>\n",
       "      <td>129</td>\n",
       "      <td>15975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.725</td>\n",
       "      <td>59</td>\n",
       "      <td>129</td>\n",
       "      <td>15975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.55</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.713</td>\n",
       "      <td>57</td>\n",
       "      <td>127</td>\n",
       "      <td>15975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.736</td>\n",
       "      <td>62</td>\n",
       "      <td>131</td>\n",
       "      <td>15975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.65</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.725</td>\n",
       "      <td>60</td>\n",
       "      <td>129</td>\n",
       "      <td>15975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.736</td>\n",
       "      <td>54</td>\n",
       "      <td>131</td>\n",
       "      <td>15975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.75</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.747</td>\n",
       "      <td>48</td>\n",
       "      <td>133</td>\n",
       "      <td>15975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.736</td>\n",
       "      <td>46</td>\n",
       "      <td>131</td>\n",
       "      <td>15975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.85</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.736</td>\n",
       "      <td>45</td>\n",
       "      <td>131</td>\n",
       "      <td>15975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.730</td>\n",
       "      <td>48</td>\n",
       "      <td>130</td>\n",
       "      <td>15975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.95</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.747</td>\n",
       "      <td>51</td>\n",
       "      <td>133</td>\n",
       "      <td>15975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 1.0</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.758</td>\n",
       "      <td>40</td>\n",
       "      <td>135</td>\n",
       "      <td>15975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.926     0.327   \n",
       "After RANDOM mitigation N = 5000          0.929     0.360   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5      0.923     0.343   \n",
       "After SMOTE N = 5000 p_class 0 = 0.55     0.925     0.357   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6      0.921     0.328   \n",
       "After SMOTE N = 5000 p_class 0 = 0.65     0.923     0.341   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7      0.924     0.337   \n",
       "After SMOTE N = 5000 p_class 0 = 0.75     0.926     0.332   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8      0.927     0.347   \n",
       "After SMOTE N = 5000 p_class 0 = 0.85     0.928     0.348   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9      0.927     0.350   \n",
       "After SMOTE N = 5000 p_class 0 = 0.95     0.925     0.328   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0      0.928     0.330   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.021   \n",
       "After RANDOM mitigation N = 5000                     0.020   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                 0.026   \n",
       "After SMOTE N = 5000 p_class 0 = 0.55                0.025   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                 0.027   \n",
       "After SMOTE N = 5000 p_class 0 = 0.65                0.027   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                 0.024   \n",
       "After SMOTE N = 5000 p_class 0 = 0.75                0.021   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                 0.020   \n",
       "After SMOTE N = 5000 p_class 0 = 0.85                0.020   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                 0.021   \n",
       "After SMOTE N = 5000 p_class 0 = 0.95                0.023   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0                 0.018   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.753               47   \n",
       "After RANDOM mitigation N = 5000                     0.725               45   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                 0.725               59   \n",
       "After SMOTE N = 5000 p_class 0 = 0.55                0.713               57   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                 0.736               62   \n",
       "After SMOTE N = 5000 p_class 0 = 0.65                0.725               60   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                 0.736               54   \n",
       "After SMOTE N = 5000 p_class 0 = 0.75                0.747               48   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                 0.736               46   \n",
       "After SMOTE N = 5000 p_class 0 = 0.85                0.736               45   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                 0.730               48   \n",
       "After SMOTE N = 5000 p_class 0 = 0.95                0.747               51   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0                 0.758               40   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  134       10975       2439  \n",
       "After RANDOM mitigation N = 5000                   129       15975       2439  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5               129       15975       2439  \n",
       "After SMOTE N = 5000 p_class 0 = 0.55              127       15975       2439  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6               131       15975       2439  \n",
       "After SMOTE N = 5000 p_class 0 = 0.65              129       15975       2439  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7               131       15975       2439  \n",
       "After SMOTE N = 5000 p_class 0 = 0.75              133       15975       2439  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8               131       15975       2439  \n",
       "After SMOTE N = 5000 p_class 0 = 0.85              131       15975       2439  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9               130       15975       2439  \n",
       "After SMOTE N = 5000 p_class 0 = 0.95              133       15975       2439  \n",
       "After SMOTE N = 5000 p_class 0 = 1.0               135       15975       2439  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "                 \n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.360</td>\n",
       "      <td>45</td>\n",
       "      <td>129</td>\n",
       "      <td>174</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.343</td>\n",
       "      <td>59</td>\n",
       "      <td>129</td>\n",
       "      <td>188</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.55</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.357</td>\n",
       "      <td>57</td>\n",
       "      <td>127</td>\n",
       "      <td>184</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.328</td>\n",
       "      <td>62</td>\n",
       "      <td>131</td>\n",
       "      <td>193</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.65</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.341</td>\n",
       "      <td>60</td>\n",
       "      <td>129</td>\n",
       "      <td>189</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.337</td>\n",
       "      <td>54</td>\n",
       "      <td>131</td>\n",
       "      <td>185</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.75</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.332</td>\n",
       "      <td>48</td>\n",
       "      <td>133</td>\n",
       "      <td>181</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.347</td>\n",
       "      <td>46</td>\n",
       "      <td>131</td>\n",
       "      <td>177</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.85</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.348</td>\n",
       "      <td>45</td>\n",
       "      <td>131</td>\n",
       "      <td>176</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.350</td>\n",
       "      <td>48</td>\n",
       "      <td>130</td>\n",
       "      <td>178</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.95</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.328</td>\n",
       "      <td>51</td>\n",
       "      <td>133</td>\n",
       "      <td>184</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 1.0</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.330</td>\n",
       "      <td>40</td>\n",
       "      <td>135</td>\n",
       "      <td>175</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.926     0.327               47   \n",
       "After RANDOM mitigation N = 5000          0.929     0.360               45   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5      0.923     0.343               59   \n",
       "After SMOTE N = 5000 p_class 0 = 0.55     0.925     0.357               57   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6      0.921     0.328               62   \n",
       "After SMOTE N = 5000 p_class 0 = 0.65     0.923     0.341               60   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7      0.924     0.337               54   \n",
       "After SMOTE N = 5000 p_class 0 = 0.75     0.926     0.332               48   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8      0.927     0.347               46   \n",
       "After SMOTE N = 5000 p_class 0 = 0.85     0.928     0.348               45   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9      0.927     0.350               48   \n",
       "After SMOTE N = 5000 p_class 0 = 0.95     0.925     0.328               51   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0      0.928     0.330               40   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  134           181   \n",
       "After RANDOM mitigation N = 5000                   129           174   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5               129           188   \n",
       "After SMOTE N = 5000 p_class 0 = 0.55              127           184   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6               131           193   \n",
       "After SMOTE N = 5000 p_class 0 = 0.65              129           189   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7               131           185   \n",
       "After SMOTE N = 5000 p_class 0 = 0.75              133           181   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8               131           177   \n",
       "After SMOTE N = 5000 p_class 0 = 0.85              131           176   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9               130           178   \n",
       "After SMOTE N = 5000 p_class 0 = 0.95              133           184   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0               135           175   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.020           0.119   \n",
       "After RANDOM mitigation N = 5000                 0.018           0.119   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5             0.017           0.117   \n",
       "After SMOTE N = 5000 p_class 0 = 0.55            0.017           0.112   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6             0.016           0.133   \n",
       "After SMOTE N = 5000 p_class 0 = 0.65            0.013           0.113   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7             0.015           0.101   \n",
       "After SMOTE N = 5000 p_class 0 = 0.75            0.017           0.119   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8             0.014           0.069   \n",
       "After SMOTE N = 5000 p_class 0 = 0.85            0.015           0.085   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9             0.017           0.136   \n",
       "After SMOTE N = 5000 p_class 0 = 0.95            0.022           0.154   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0             0.020           0.100   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.098       0.084       0.067  \n",
       "After RANDOM mitigation N = 5000            0.092       0.080       0.064  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5        0.094       0.081       0.066  \n",
       "After SMOTE N = 5000 p_class 0 = 0.55       0.090       0.078       0.064  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6        0.097       0.086       0.071  \n",
       "After SMOTE N = 5000 p_class 0 = 0.65       0.089       0.076       0.063  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7        0.082       0.073       0.061  \n",
       "After SMOTE N = 5000 p_class 0 = 0.75       0.087       0.072       0.057  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8        0.061       0.056       0.048  \n",
       "After SMOTE N = 5000 p_class 0 = 0.85       0.070       0.062       0.051  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9        0.080       0.069       0.058  \n",
       "After SMOTE N = 5000 p_class 0 = 0.95       0.107       0.088       0.071  \n",
       "After SMOTE N = 5000 p_class 0 = 1.0        0.075       0.064       0.052  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes=attributes\n",
    "                          \n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_5K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_5K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.753</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.725</td>\n",
       "      <td>46</td>\n",
       "      <td>129</td>\n",
       "      <td>16975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.5</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.719</td>\n",
       "      <td>68</td>\n",
       "      <td>128</td>\n",
       "      <td>16975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.55</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.719</td>\n",
       "      <td>63</td>\n",
       "      <td>128</td>\n",
       "      <td>16975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.6</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.713</td>\n",
       "      <td>60</td>\n",
       "      <td>127</td>\n",
       "      <td>16975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.65</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.736</td>\n",
       "      <td>55</td>\n",
       "      <td>131</td>\n",
       "      <td>16975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.7</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.747</td>\n",
       "      <td>56</td>\n",
       "      <td>133</td>\n",
       "      <td>16975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.75</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.730</td>\n",
       "      <td>53</td>\n",
       "      <td>130</td>\n",
       "      <td>16975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.730</td>\n",
       "      <td>47</td>\n",
       "      <td>130</td>\n",
       "      <td>16975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.85</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.736</td>\n",
       "      <td>50</td>\n",
       "      <td>131</td>\n",
       "      <td>16975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.725</td>\n",
       "      <td>52</td>\n",
       "      <td>129</td>\n",
       "      <td>16975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.95</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.736</td>\n",
       "      <td>40</td>\n",
       "      <td>131</td>\n",
       "      <td>16975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 1.0</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.747</td>\n",
       "      <td>41</td>\n",
       "      <td>133</td>\n",
       "      <td>16975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.926     0.327   \n",
       "After RANDOM mitigation N = 6000          0.928     0.359   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5      0.920     0.338   \n",
       "After SMOTE N = 6000 p_class 0 = 0.55     0.922     0.344   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6      0.923     0.353   \n",
       "After SMOTE N = 6000 p_class 0 = 0.65     0.924     0.336   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7      0.923     0.323   \n",
       "After SMOTE N = 6000 p_class 0 = 0.75     0.925     0.344   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8      0.927     0.352   \n",
       "After SMOTE N = 6000 p_class 0 = 0.85     0.926     0.342   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9      0.926     0.351   \n",
       "After SMOTE N = 6000 p_class 0 = 0.95     0.930     0.355   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0      0.929     0.341   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.021   \n",
       "After RANDOM mitigation N = 6000                     0.020   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5                 0.030   \n",
       "After SMOTE N = 6000 p_class 0 = 0.55                0.028   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6                 0.027   \n",
       "After SMOTE N = 6000 p_class 0 = 0.65                0.024   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7                 0.025   \n",
       "After SMOTE N = 6000 p_class 0 = 0.75                0.023   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8                 0.021   \n",
       "After SMOTE N = 6000 p_class 0 = 0.85                0.022   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9                 0.023   \n",
       "After SMOTE N = 6000 p_class 0 = 0.95                0.018   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0                 0.018   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.753               47   \n",
       "After RANDOM mitigation N = 6000                     0.725               46   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5                 0.719               68   \n",
       "After SMOTE N = 6000 p_class 0 = 0.55                0.719               63   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6                 0.713               60   \n",
       "After SMOTE N = 6000 p_class 0 = 0.65                0.736               55   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7                 0.747               56   \n",
       "After SMOTE N = 6000 p_class 0 = 0.75                0.730               53   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8                 0.730               47   \n",
       "After SMOTE N = 6000 p_class 0 = 0.85                0.736               50   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9                 0.725               52   \n",
       "After SMOTE N = 6000 p_class 0 = 0.95                0.736               40   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0                 0.747               41   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  134       10975       2439  \n",
       "After RANDOM mitigation N = 6000                   129       16975       2439  \n",
       "After SMOTE N = 6000 p_class 0 = 0.5               128       16975       2439  \n",
       "After SMOTE N = 6000 p_class 0 = 0.55              128       16975       2439  \n",
       "After SMOTE N = 6000 p_class 0 = 0.6               127       16975       2439  \n",
       "After SMOTE N = 6000 p_class 0 = 0.65              131       16975       2439  \n",
       "After SMOTE N = 6000 p_class 0 = 0.7               133       16975       2439  \n",
       "After SMOTE N = 6000 p_class 0 = 0.75              130       16975       2439  \n",
       "After SMOTE N = 6000 p_class 0 = 0.8               130       16975       2439  \n",
       "After SMOTE N = 6000 p_class 0 = 0.85              131       16975       2439  \n",
       "After SMOTE N = 6000 p_class 0 = 0.9               129       16975       2439  \n",
       "After SMOTE N = 6000 p_class 0 = 0.95              131       16975       2439  \n",
       "After SMOTE N = 6000 p_class 0 = 1.0               133       16975       2439  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 6000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "                \n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.327</td>\n",
       "      <td>47</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.359</td>\n",
       "      <td>46</td>\n",
       "      <td>129</td>\n",
       "      <td>175</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.5</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.338</td>\n",
       "      <td>68</td>\n",
       "      <td>128</td>\n",
       "      <td>196</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.55</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.344</td>\n",
       "      <td>63</td>\n",
       "      <td>128</td>\n",
       "      <td>191</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.6</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.353</td>\n",
       "      <td>60</td>\n",
       "      <td>127</td>\n",
       "      <td>187</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.65</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.336</td>\n",
       "      <td>55</td>\n",
       "      <td>131</td>\n",
       "      <td>186</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.7</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.323</td>\n",
       "      <td>56</td>\n",
       "      <td>133</td>\n",
       "      <td>189</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.75</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.344</td>\n",
       "      <td>53</td>\n",
       "      <td>130</td>\n",
       "      <td>183</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.352</td>\n",
       "      <td>47</td>\n",
       "      <td>130</td>\n",
       "      <td>177</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.85</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.342</td>\n",
       "      <td>50</td>\n",
       "      <td>131</td>\n",
       "      <td>181</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.351</td>\n",
       "      <td>52</td>\n",
       "      <td>129</td>\n",
       "      <td>181</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.95</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.355</td>\n",
       "      <td>40</td>\n",
       "      <td>131</td>\n",
       "      <td>171</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 1.0</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.341</td>\n",
       "      <td>41</td>\n",
       "      <td>133</td>\n",
       "      <td>174</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.926     0.327               47   \n",
       "After RANDOM mitigation N = 6000          0.928     0.359               46   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5      0.920     0.338               68   \n",
       "After SMOTE N = 6000 p_class 0 = 0.55     0.922     0.344               63   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6      0.923     0.353               60   \n",
       "After SMOTE N = 6000 p_class 0 = 0.65     0.924     0.336               55   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7      0.923     0.323               56   \n",
       "After SMOTE N = 6000 p_class 0 = 0.75     0.925     0.344               53   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8      0.927     0.352               47   \n",
       "After SMOTE N = 6000 p_class 0 = 0.85     0.926     0.342               50   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9      0.926     0.351               52   \n",
       "After SMOTE N = 6000 p_class 0 = 0.95     0.930     0.355               40   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0      0.929     0.341               41   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  134           181   \n",
       "After RANDOM mitigation N = 6000                   129           175   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5               128           196   \n",
       "After SMOTE N = 6000 p_class 0 = 0.55              128           191   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6               127           187   \n",
       "After SMOTE N = 6000 p_class 0 = 0.65              131           186   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7               133           189   \n",
       "After SMOTE N = 6000 p_class 0 = 0.75              130           183   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8               130           177   \n",
       "After SMOTE N = 6000 p_class 0 = 0.85              131           181   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9               129           181   \n",
       "After SMOTE N = 6000 p_class 0 = 0.95              131           171   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0               133           174   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.020           0.119   \n",
       "After RANDOM mitigation N = 6000                 0.018           0.119   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5             0.018           0.166   \n",
       "After SMOTE N = 6000 p_class 0 = 0.55            0.019           0.132   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6             0.023           0.156   \n",
       "After SMOTE N = 6000 p_class 0 = 0.65            0.017           0.116   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7             0.020           0.155   \n",
       "After SMOTE N = 6000 p_class 0 = 0.75            0.015           0.097   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8             0.014           0.099   \n",
       "After SMOTE N = 6000 p_class 0 = 0.85            0.015           0.087   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9             0.022           0.114   \n",
       "After SMOTE N = 6000 p_class 0 = 0.95            0.018           0.093   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0             0.017           0.102   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.098       0.084       0.067  \n",
       "After RANDOM mitigation N = 6000            0.092       0.080       0.064  \n",
       "After SMOTE N = 6000 p_class 0 = 0.5        0.122       0.105       0.086  \n",
       "After SMOTE N = 6000 p_class 0 = 0.55       0.102       0.088       0.074  \n",
       "After SMOTE N = 6000 p_class 0 = 0.6        0.133       0.110       0.088  \n",
       "After SMOTE N = 6000 p_class 0 = 0.65       0.092       0.078       0.063  \n",
       "After SMOTE N = 6000 p_class 0 = 0.7        0.116       0.094       0.076  \n",
       "After SMOTE N = 6000 p_class 0 = 0.75       0.076       0.068       0.058  \n",
       "After SMOTE N = 6000 p_class 0 = 0.8        0.067       0.058       0.049  \n",
       "After SMOTE N = 6000 p_class 0 = 0.85       0.076       0.068       0.057  \n",
       "After SMOTE N = 6000 p_class 0 = 0.9        0.097       0.085       0.072  \n",
       "After SMOTE N = 6000 p_class 0 = 0.95       0.069       0.060       0.049  \n",
       "After SMOTE N = 6000 p_class 0 = 1.0        0.074       0.066       0.054  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes=attributes\n",
    "                          \n",
    "                     \n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_6K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_6K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati salvati in false_positives_K_compas.json\n",
      "‚úÖ Variabili salvate con successo in false_positives_K_compas.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"false_positives_K_compas.json\"\n",
    "\n",
    "# Controlla se il file esiste gi√† per evitare di sovrascrivere\n",
    "if os.path.exists(json_filename):\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        false_positives_data = json.load(f)\n",
    "else:\n",
    "    false_positives_data = {}\n",
    "\n",
    "# Lista dei diversi metrics_after_fp_SMOTE_XK\n",
    "metrics_dict = {\n",
    "    \"1K_run6\": metrics_after_fp_SMOTE_1K,\n",
    "    \"2K_run6\": metrics_after_fp_SMOTE_2K,\n",
    "    \"3K_run6\": metrics_after_fp_SMOTE_3K,\n",
    "    \"4K_run6\": metrics_after_fp_SMOTE_4K,\n",
    "    \"5K_run6\": metrics_after_fp_SMOTE_5K,\n",
    "    \"6K_run6\": metrics_after_fp_SMOTE_6K\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni dataset e salviamo i falsi positivi\n",
    "for J, metrics in metrics_dict.items():\n",
    "    false_positives_data[f\"N={J}\"] = metrics[\"False Positives\"].to_dict()\n",
    "\n",
    "# Salviamo il JSON aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(false_positives_data, f, indent=4)\n",
    "\n",
    "print(f\"Dati salvati in {json_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "#per i parametri # Nome del file JSON\n",
    "json_filename = \"false_positives_K_compas.json\"\n",
    "\n",
    "# Valori da salvare (sostituiscili con i tuoi valori reali)\n",
    "min_sup_run6 = min_sup\n",
    "percentage_run6 = percentage\n",
    "th_redundancy_run6 = pruning\n",
    "K_run6 = K\n",
    "L_run6 = filtered_instances  # Supponiamo sia la lunghezza di filtered_instances\n",
    "\n",
    "# 1Ô∏è‚É£ Caricare i dati esistenti (se il file esiste)\n",
    "try:\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        false_positives_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    false_positives_data = {}  # Se il file non esiste, inizializza un dizionario vuoto\n",
    "\n",
    "# 2Ô∏è‚É£ Aggiungere le nuove variabili sotto una chiave dedicata\n",
    "false_positives_data[\"run6_parameters\"] = {\n",
    "    \"min_sup\": min_sup_run6,\n",
    "    \"percentage\": percentage_run6,\n",
    "    \"th_redundancy\": th_redundancy_run6,\n",
    "    \"K\": percentage,\n",
    "    \"L\": L_run6\n",
    "}\n",
    "\n",
    "# 3Ô∏è‚É£ Salvare il file aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(false_positives_data, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ Variabili salvate con successo in\", json_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"false_positives_K_compas.json\"\n",
    "\n",
    "# Caricare i dati dal file JSON\n",
    "with open(json_filename, \"r\") as f:\n",
    "    false_positives_data = json.load(f)\n",
    "\n",
    "# Estrarre parametri dal JSON\n",
    "run6_params = false_positives_data.get(\"run6_parameters\", {})\n",
    "min_sup = run6_params.get(\"min_sup\", \"N/A\")\n",
    "percentage = run6_params.get(\"percentage\", \"N/A\")\n",
    "th_redundancy = run6_params.get(\"th_redundancy\", \"N/A\")\n",
    "L = run6_params.get(\"L\", \"N/A\")\n",
    "K = int((percentage / 100) * L)  # K rappresenta il numero di sottogruppi\n",
    "\n",
    "# Lista dei valori di p da 0.5 a 1.0 con step 0.05\n",
    "p_values = np.arange(0.5, 1.05, 0.05)\n",
    "\n",
    "# Definiamo i colori per ogni N\n",
    "colors = [\"blue\", \"red\", \"green\", \"orange\", \"brown\", \"pink\"]\n",
    "labels = [f\"N={k}K\" for k in range(1, 7)]\n",
    "\n",
    "# Creazione della figura\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig.suptitle(\"FALSE POSITIVE MITIGATION\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Disegniamo la linea tratteggiata \"Before Mitigation\"\n",
    "before_mitigation = false_positives_data.get(\"N=1K_run6\", {}).get(\"Before Mitigation\", None)\n",
    "if before_mitigation is not None:\n",
    "    ax.axhline(y=before_mitigation, color=\"purple\", linestyle=\"--\", linewidth=2, label=\"Before Mitigation\")\n",
    "\n",
    "# Aggiungere linee verticali per ogni valore di p\n",
    "for p in p_values:\n",
    "    ax.axvline(x=p, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Loop sui vari N (da 1K a 6K)\n",
    "legend_handles = []\n",
    "for i, n in enumerate(range(1, 7)):\n",
    "    N_key = f\"N={n}K_run6\"\n",
    "    if N_key not in false_positives_data:\n",
    "        continue\n",
    "    \n",
    "    data = false_positives_data[N_key]\n",
    "    \n",
    "    # Estrarre i valori di falsi positivi per ogni p\n",
    "    false_positives = [data.get(f\"After SMOTE N = {n*1000} p_class 0 = {round(p, 2)}\", None) for p in p_values]\n",
    "    \n",
    "    # Filtriamo solo i valori validi\n",
    "    p_values_filtered = [p for j, p in enumerate(p_values) if false_positives[j] is not None]\n",
    "    false_positives_filtered = [fp for fp in false_positives if fp is not None]\n",
    "    \n",
    "    # Plottiamo la linea corrispondente\n",
    "    line, = ax.plot(\n",
    "        p_values_filtered, false_positives_filtered, \n",
    "        marker=\"o\", linestyle=\"-\", color=colors[i], label=labels[i]\n",
    "    )\n",
    "    legend_handles.append(line)\n",
    "\n",
    "# Impostazioni asse\n",
    "ax.set_title(f\"Minsup = {min_sup}, pruning = {th_redundancy}, K% = {percentage}, subgroups: {K}/{L}\")\n",
    "ax.set_xlabel(\"p_class 0\")\n",
    "ax.set_ylabel(\"False Positives\")\n",
    "ax.grid()\n",
    "\n",
    "# Aggiungere la leggenda\n",
    "ax.legend(handles=legend_handles, loc=\"upper right\", fontsize=10, frameon=True, title=\"Legend\")\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
