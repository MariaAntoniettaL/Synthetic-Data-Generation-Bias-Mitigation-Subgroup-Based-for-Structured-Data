{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_compas import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import torch\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "from divexplorer.outcomes import get_false_negative_rate_outcome\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smote_nc = SMOTENC(categorical_features=categorical_features,random_state=seed)\\nX_to_SMOTE, y_to_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\ncount_1 = y_to_SMOTE.sum()\\ncount_0 = len(y_to_SMOTE)-count_1\\ncount_0, count_1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''smote_nc = SMOTENC(categorical_features=categorical_features,random_state=seed)\n",
    "X_to_SMOTE, y_to_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "count_1 = y_to_SMOTE.sum()\n",
    "count_0 = len(y_to_SMOTE)-count_1\n",
    "count_0, count_1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il CSV\n",
    "df = pd.read_csv(\"cox-violent-parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning = 0.00\n",
    "epsilon = pruning\n",
    "min_sup = 0.25\n",
    "percentage = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "VALIDATION SET ROWS:  2439\n",
      "HOLDOUT SET ROWS:  2440\n",
      "TEST SET ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) \n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0])\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "VALIDATION SET ROWS:  2439\n",
      "HOLDOUT SET ROWS:  2440\n",
      "TEST SET ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosit√† precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_no_Violent_Recidivist = df_train_enc.drop(columns = 'Violent_Recidivist')\n",
    "plt.figure(figsize=(4, 3))\n",
    "g = sns.heatmap(df_train_no_Violent_Recidivist.corr(),\n",
    "                annot = False,\n",
    "                cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.925     0.179                0.011   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.888               26              158   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       2439  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "X_train = df_train_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_train = df_train_enc['Violent_Recidivist']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_test = df_test_enc['Violent_Recidivist']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_val = df_val_enc['Violent_Recidivist']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_holdout = df_holdout_enc['Violent_Recidivist']\n",
    "\n",
    "classifier_train = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()\n",
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione √® giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  race  Recidivism_Risk  Risk_Level  Violent_Recidivism_Risk  \\\n",
       "10676    1     0                4           1                        2   \n",
       "13123    1     2                1           1                        1   \n",
       "2611     1     0                8           0                        6   \n",
       "7945     1     2                1           1                        1   \n",
       "5727     1     2                6           2                        6   \n",
       "\n",
       "       Violent_Risk_Level  Juvenile_Offenses  age_group  Prior_Offensesgroup  \\\n",
       "10676                   1                  0          3                    7   \n",
       "13123                   1                  0          3                    0   \n",
       "2611                    2                  2          2                    1   \n",
       "7945                    1                  0          5                    0   \n",
       "5727                    2                  0          1                    0   \n",
       "\n",
       "       y_val_true  y_pred  \n",
       "10676           0       0  \n",
       "13123           0       0  \n",
       "2611            0       0  \n",
       "7945            0       0  \n",
       "5727            0       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set, queste mi servono solo per il div explorer che ha bisogno di ground truth e predizioni\n",
    "y_pred_val = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Violent_Recidivist</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>fn</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>6-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>35-44</td>\n",
       "      <td>11-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>65-100</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex              race  Recidivism_Risk  Violent_Recidivist Risk_Level  \\\n",
       "10676  Male  African-American                4                   0        Low   \n",
       "13123  Male         Caucasian                1                   0        Low   \n",
       "2611   Male  African-American                8                   0       High   \n",
       "7945   Male         Caucasian                1                   0        Low   \n",
       "5727   Male         Caucasian                6                   0     Medium   \n",
       "\n",
       "       Violent_Recidivism_Risk Violent_Risk_Level  Juvenile_Offenses  \\\n",
       "10676                        2                Low                  0   \n",
       "13123                        1                Low                  0   \n",
       "2611                         6             Medium                  2   \n",
       "7945                         1                Low                  0   \n",
       "5727                         6             Medium                  0   \n",
       "\n",
       "      age_group Prior_Offensesgroup  fn  y_pred  accuracy  \n",
       "10676     45-54                6-10 NaN       0         1  \n",
       "13123     45-54                 0-5 NaN       0         1  \n",
       "2611      35-44               11-15 NaN       0         1  \n",
       "7945     65-100                 0-5 NaN       0         1  \n",
       "5727      25-34                 0-5 NaN       0         1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]\n",
    "\n",
    "df_val_class[\"fn\"] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature \"fn\" a df_val non encoded\n",
    "df_val[\"fn\"] = df_val_class[\"fn\"]\n",
    "\n",
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione √® giusta 0 se la predizione √® sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['accuracy'] = (df_val_class['y_val_true']==df_val_class['y_pred']).astype(int)\n",
    "df_val.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI CONDOTTA CON LA FEATURE FP (PASSATA A BOOLEAN OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Violent_Recidivist</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>fn</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>6-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>35-44</td>\n",
       "      <td>11-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>65-100</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>55-64</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>9</td>\n",
       "      <td>High</td>\n",
       "      <td>21</td>\n",
       "      <td>25-34</td>\n",
       "      <td>16-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>55-64</td>\n",
       "      <td>11-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2439 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sex              race  Recidivism_Risk  Violent_Recidivist  \\\n",
       "10676    Male  African-American                4                   0   \n",
       "13123    Male         Caucasian                1                   0   \n",
       "2611     Male  African-American                8                   0   \n",
       "7945     Male         Caucasian                1                   0   \n",
       "5727     Male         Caucasian                6                   0   \n",
       "...       ...               ...              ...                 ...   \n",
       "4183     Male         Caucasian                1                   0   \n",
       "9445     Male         Caucasian                8                   0   \n",
       "8674   Female         Caucasian                5                   0   \n",
       "6392     Male          Hispanic                1                   0   \n",
       "6524   Female         Caucasian                5                   0   \n",
       "\n",
       "      Risk_Level  Violent_Recidivism_Risk Violent_Risk_Level  \\\n",
       "10676        Low                        2                Low   \n",
       "13123        Low                        1                Low   \n",
       "2611        High                        6             Medium   \n",
       "7945         Low                        1                Low   \n",
       "5727      Medium                        6             Medium   \n",
       "...          ...                      ...                ...   \n",
       "4183         Low                        1                Low   \n",
       "9445        High                        9               High   \n",
       "8674      Medium                        4                Low   \n",
       "6392         Low                        1                Low   \n",
       "6524      Medium                        2                Low   \n",
       "\n",
       "       Juvenile_Offenses age_group Prior_Offensesgroup  fn  y_pred  accuracy  \n",
       "10676                  0     45-54                6-10 NaN       0         1  \n",
       "13123                  0     45-54                 0-5 NaN       0         1  \n",
       "2611                   2     35-44               11-15 NaN       0         1  \n",
       "7945                   0    65-100                 0-5 NaN       0         1  \n",
       "5727                   0     25-34                 0-5 NaN       0         1  \n",
       "...                  ...       ...                 ...  ..     ...       ...  \n",
       "4183                   0     55-64                 0-5 NaN       0         1  \n",
       "9445                  21     25-34               16-20 NaN       0         1  \n",
       "8674                   0     55-64               11-15 NaN       0         1  \n",
       "6392                   0     35-44                 0-5 NaN       0         1  \n",
       "6524                   0     35-44                 0-5 NaN       0         1  \n",
       "\n",
       "[2439 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['sex', 'race', 'Recidivism_Risk', 'Risk_Level', 'Violent_Recidivism_Risk', 'Violent_Risk_Level', 'Juvenile_Offenses', 'age_group', 'Prior_Offensesgroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_div</th>\n",
       "      <th>fn_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.439</td>\n",
       "      <td>(Juvenile_Offenses=0, Violent_Risk_Level=Low, Prior_Offensesgroup=0-5)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.112</td>\n",
       "      <td>3.041</td>\n",
       "      <td>3</td>\n",
       "      <td>1071.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.415</td>\n",
       "      <td>(Risk_Level=Low, Violent_Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.112</td>\n",
       "      <td>2.914</td>\n",
       "      <td>2</td>\n",
       "      <td>1011.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.399</td>\n",
       "      <td>(Juvenile_Offenses=0, Violent_Risk_Level=Low, Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.112</td>\n",
       "      <td>2.869</td>\n",
       "      <td>3</td>\n",
       "      <td>974.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.359</td>\n",
       "      <td>(Risk_Level=Low, Violent_Risk_Level=Low, Prior_Offensesgroup=0-5)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.112</td>\n",
       "      <td>2.622</td>\n",
       "      <td>3</td>\n",
       "      <td>876.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.349</td>\n",
       "      <td>(Juvenile_Offenses=0, Violent_Risk_Level=Low, Prior_Offensesgroup=0-5, Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.112</td>\n",
       "      <td>2.568</td>\n",
       "      <td>4</td>\n",
       "      <td>850.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.439   \n",
       "1    0.415   \n",
       "2    0.399   \n",
       "3    0.359   \n",
       "4    0.349   \n",
       "\n",
       "                                                                                  itemset  \\\n",
       "0                  (Juvenile_Offenses=0, Violent_Risk_Level=Low, Prior_Offensesgroup=0-5)   \n",
       "1                                                (Risk_Level=Low, Violent_Risk_Level=Low)   \n",
       "2                           (Juvenile_Offenses=0, Violent_Risk_Level=Low, Risk_Level=Low)   \n",
       "3                       (Risk_Level=Low, Violent_Risk_Level=Low, Prior_Offensesgroup=0-5)   \n",
       "4  (Juvenile_Offenses=0, Violent_Risk_Level=Low, Prior_Offensesgroup=0-5, Risk_Level=Low)   \n",
       "\n",
       "     fn  fn_div  fn_t  length  support_count  \n",
       "0 1.000   0.112 3.041       3       1071.000  \n",
       "1 1.000   0.112 2.914       2       1011.000  \n",
       "2 1.000   0.112 2.869       3        974.000  \n",
       "3 1.000   0.112 2.622       3        876.000  \n",
       "4 1.000   0.112 2.568       4        850.000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_diver = DivergenceExplorer(df_val)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "FP_fm = FP_fm.sort_values(by=[\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_div</th>\n",
       "      <th>fn_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.439</td>\n",
       "      <td>(Juvenile_Offenses=0, Violent_Risk_Level=Low, Prior_Offensesgroup=0-5)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.112</td>\n",
       "      <td>3.041</td>\n",
       "      <td>3</td>\n",
       "      <td>1071.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.415</td>\n",
       "      <td>(Risk_Level=Low, Violent_Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.112</td>\n",
       "      <td>2.914</td>\n",
       "      <td>2</td>\n",
       "      <td>1011.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.399</td>\n",
       "      <td>(Juvenile_Offenses=0, Violent_Risk_Level=Low, Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.112</td>\n",
       "      <td>2.869</td>\n",
       "      <td>3</td>\n",
       "      <td>974.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.359</td>\n",
       "      <td>(Risk_Level=Low, Violent_Risk_Level=Low, Prior_Offensesgroup=0-5)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.112</td>\n",
       "      <td>2.622</td>\n",
       "      <td>3</td>\n",
       "      <td>876.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.349</td>\n",
       "      <td>(Juvenile_Offenses=0, Violent_Risk_Level=Low, Prior_Offensesgroup=0-5, Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.112</td>\n",
       "      <td>2.568</td>\n",
       "      <td>4</td>\n",
       "      <td>850.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.439   \n",
       "1    0.415   \n",
       "2    0.399   \n",
       "3    0.359   \n",
       "4    0.349   \n",
       "\n",
       "                                                                                  itemset  \\\n",
       "0                  (Juvenile_Offenses=0, Violent_Risk_Level=Low, Prior_Offensesgroup=0-5)   \n",
       "1                                                (Risk_Level=Low, Violent_Risk_Level=Low)   \n",
       "2                           (Juvenile_Offenses=0, Violent_Risk_Level=Low, Risk_Level=Low)   \n",
       "3                       (Risk_Level=Low, Violent_Risk_Level=Low, Prior_Offensesgroup=0-5)   \n",
       "4  (Juvenile_Offenses=0, Violent_Risk_Level=Low, Prior_Offensesgroup=0-5, Risk_Level=Low)   \n",
       "\n",
       "     fn  fn_div  fn_t  length  support_count  \n",
       "0 1.000   0.112 3.041       3       1071.000  \n",
       "1 1.000   0.112 2.914       2       1011.000  \n",
       "2 1.000   0.112 2.869       3        974.000  \n",
       "3 1.000   0.112 2.622       3        876.000  \n",
       "4 1.000   0.112 2.568       4        850.000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp = df_pruned_fp = FP_fm\n",
    "df_pruned_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 52\n",
      "total problematic 48\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_fp)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_fp[(df_pruned_fp[\"fn_div\"] > 0) ])#& (df_pruned_fp[\"fn_t\"] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (52, 7)\n",
      "Dim pruned th_redundancy  (52, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_fp.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset_and_or li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "df_holdout_filtered_solo0 = df_holdout_filtered[df_holdout_filtered['Violent_Recidivist']==0]\n",
    "\n",
    "\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered_solo0, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "df_holdout_filtered = df_holdout_filtered_solo0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667\n"
     ]
    }
   ],
   "source": [
    "print(len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "TRAIN SET MITIGATED ROWS:  11642\n",
      "VALIDATION SET ROWS:  2439\n",
      "FILTERED DF holdout ROWS:  667\n",
      "TEST SET FILTERED ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['Violent_Recidivist']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "#cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667\n",
      "verifica : 667\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"Violent_Recidivist\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.843</td>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.848</td>\n",
       "      <td>21</td>\n",
       "      <td>151</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.925     0.179                0.011   \n",
       "After Mitigation(K=5, fp)     0.925     0.235                0.014   \n",
       "After RANDOM mitigation       0.929     0.239                0.009   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.888               26   \n",
       "After Mitigation(K=5, fp)                0.843               32   \n",
       "After RANDOM mitigation                  0.848               21   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      158       10975       2439  \n",
       "After Mitigation(K=5, fp)              150       11642       2439  \n",
       "After RANDOM mitigation                151       11642       2439  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE\n",
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.119</td>\n",
       "      <td>667.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.107</td>\n",
       "      <td>667.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.925     0.179             0.065   \n",
       "After Mitigation(K=5 fp)            0.925     0.235             0.091   \n",
       "After RANDOM Mitigation(K=5 fp)     0.929     0.239             0.084   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.112               0.112   \n",
       "After Mitigation(K=5 fp)           0.157               0.157   \n",
       "After RANDOM Mitigation(K=5 fp)    0.152               0.152   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.103               0.084   \n",
       "After Mitigation(K=5 fp)                      0.147               0.119   \n",
       "After RANDOM Mitigation(K=5 fp)               0.137               0.107   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)               667.000  \n",
       "After RANDOM Mitigation(K=5 fp)        667.000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class[\"fn\"] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature \"fn\" a df_val non encoded\n",
    "df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp = df_pruned_fp = FP_fm\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class[\"fn\"] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature \"fn\" a df_val non encoded\n",
    "df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp = df_pruned_fp = FP_fm\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline1  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fp_div_list_baseline1\n",
    "\n",
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class[\"fn\"] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature \"fn\" a df_val non encoded\n",
    "df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "#attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp = df_pruned_fp = FP_fm\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fp_div_list_random_per_confrontare_con_baseline1\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline1 = abs(sum(fp_div_list_baseline1) / len(fp_div_list_baseline1))\n",
    "media_fp_div_list_baseline1_primi10 = abs(sum(fp_div_list_baseline1[:10]) / len(fp_div_list_baseline1[:10]))\n",
    "media_fp_div_list_baseline1_primi20 = abs(sum(fp_div_list_baseline1[:20]) / len(fp_div_list_baseline1[:20]))\n",
    "media_fp_div_list_baseline1_primi40 = abs(sum(fp_div_list_baseline1[:40]) / len(fp_div_list_baseline1[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_baseline1 = max(abs(x) for x in fp_div_list_baseline1)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_fp_div_list_baseline1, fp_div_massimo_valore_assoluto_fp_div_baseline1,\n",
    "        media_fp_div_list_baseline1_primi10, media_fp_div_list_baseline1_primi20, media_fp_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGUE CODICE USANDO SMOTE \n",
    "DIVIDO IN TRAIN, TEST E VALIDATION -- ora uso quelli gia esistenti\n",
    "DIV EXPLORER SUL VALIDATION  -- gi√† fatto \n",
    "GENERO NUOVI DATI CON SMOTE a partire dai dati di divexplorer sul validation\n",
    "INSERISCO QUESTI NUOVI DATI NEL TRAIN SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p √® la probabilit√† che il campione simulato sia di classe 0 qui (perch√® voglio diminuire il numero di falsi positivi)\n",
    "- FISSO p VARIA N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 485\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = [\"fn\", 'y_pred', 'accuracy', \"Violent_Recidivist\"], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered[\"Violent_Recidivist\"]\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 1, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 437)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered[\"Violent_Recidivist\"].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = np.arange(0.5, 1.05, 0.05)\n",
    "p_values = np.round(p_values, 2).tolist()\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N come holdout filtered e targeted acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 667</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.848</td>\n",
       "      <td>21</td>\n",
       "      <td>151</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.5</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.871</td>\n",
       "      <td>20</td>\n",
       "      <td>155</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.876</td>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.882</td>\n",
       "      <td>21</td>\n",
       "      <td>157</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.888</td>\n",
       "      <td>21</td>\n",
       "      <td>158</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.876</td>\n",
       "      <td>21</td>\n",
       "      <td>156</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.882</td>\n",
       "      <td>20</td>\n",
       "      <td>157</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.8</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.871</td>\n",
       "      <td>25</td>\n",
       "      <td>155</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.85</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.888</td>\n",
       "      <td>22</td>\n",
       "      <td>158</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.9</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.882</td>\n",
       "      <td>22</td>\n",
       "      <td>157</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.95</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.888</td>\n",
       "      <td>22</td>\n",
       "      <td>158</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.876</td>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>11642</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.925     0.179                0.011   \n",
       "After RANDOM mitigation N = 667          0.929     0.239                0.009   \n",
       "After SMOTE N = 667 p_class 1 = 0.5      0.928     0.208                0.009   \n",
       "After SMOTE N = 667 p_class 1 = 0.55     0.927     0.197                0.010   \n",
       "After SMOTE N = 667 p_class 1 = 0.6      0.927     0.191                0.009   \n",
       "After SMOTE N = 667 p_class 1 = 0.65     0.927     0.183                0.009   \n",
       "After SMOTE N = 667 p_class 1 = 0.7      0.927     0.199                0.009   \n",
       "After SMOTE N = 667 p_class 1 = 0.75     0.927     0.192                0.009   \n",
       "After SMOTE N = 667 p_class 1 = 0.8      0.926     0.204                0.011   \n",
       "After SMOTE N = 667 p_class 1 = 0.85     0.926     0.182                0.010   \n",
       "After SMOTE N = 667 p_class 1 = 0.9      0.927     0.190                0.010   \n",
       "After SMOTE N = 667 p_class 1 = 0.95     0.926     0.182                0.010   \n",
       "After SMOTE N = 667 p_class 1 = 1.0      0.927     0.197                0.010   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.888               26   \n",
       "After RANDOM mitigation N = 667                     0.848               21   \n",
       "After SMOTE N = 667 p_class 1 = 0.5                 0.871               20   \n",
       "After SMOTE N = 667 p_class 1 = 0.55                0.876               23   \n",
       "After SMOTE N = 667 p_class 1 = 0.6                 0.882               21   \n",
       "After SMOTE N = 667 p_class 1 = 0.65                0.888               21   \n",
       "After SMOTE N = 667 p_class 1 = 0.7                 0.876               21   \n",
       "After SMOTE N = 667 p_class 1 = 0.75                0.882               20   \n",
       "After SMOTE N = 667 p_class 1 = 0.8                 0.871               25   \n",
       "After SMOTE N = 667 p_class 1 = 0.85                0.888               22   \n",
       "After SMOTE N = 667 p_class 1 = 0.9                 0.882               22   \n",
       "After SMOTE N = 667 p_class 1 = 0.95                0.888               22   \n",
       "After SMOTE N = 667 p_class 1 = 1.0                 0.876               23   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 158       10975       2439  \n",
       "After RANDOM mitigation N = 667                   151       11642       2439  \n",
       "After SMOTE N = 667 p_class 1 = 0.5               155       11642       2439  \n",
       "After SMOTE N = 667 p_class 1 = 0.55              156       11642       2439  \n",
       "After SMOTE N = 667 p_class 1 = 0.6               157       11642       2439  \n",
       "After SMOTE N = 667 p_class 1 = 0.65              158       11642       2439  \n",
       "After SMOTE N = 667 p_class 1 = 0.7               156       11642       2439  \n",
       "After SMOTE N = 667 p_class 1 = 0.75              157       11642       2439  \n",
       "After SMOTE N = 667 p_class 1 = 0.8               155       11642       2439  \n",
       "After SMOTE N = 667 p_class 1 = 0.85              158       11642       2439  \n",
       "After SMOTE N = 667 p_class 1 = 0.9               157       11642       2439  \n",
       "After SMOTE N = 667 p_class 1 = 0.95              158       11642       2439  \n",
       "After SMOTE N = 667 p_class 1 = 1.0               156       11642       2439  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>184</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 667</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.239</td>\n",
       "      <td>21</td>\n",
       "      <td>151</td>\n",
       "      <td>172</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.5</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.208</td>\n",
       "      <td>20</td>\n",
       "      <td>155</td>\n",
       "      <td>175</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.197</td>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>179</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.191</td>\n",
       "      <td>21</td>\n",
       "      <td>157</td>\n",
       "      <td>178</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.183</td>\n",
       "      <td>21</td>\n",
       "      <td>158</td>\n",
       "      <td>179</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.199</td>\n",
       "      <td>21</td>\n",
       "      <td>156</td>\n",
       "      <td>177</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.192</td>\n",
       "      <td>20</td>\n",
       "      <td>157</td>\n",
       "      <td>177</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.8</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.204</td>\n",
       "      <td>25</td>\n",
       "      <td>155</td>\n",
       "      <td>180</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.85</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.182</td>\n",
       "      <td>22</td>\n",
       "      <td>158</td>\n",
       "      <td>180</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.9</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.190</td>\n",
       "      <td>22</td>\n",
       "      <td>157</td>\n",
       "      <td>179</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 0.95</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.182</td>\n",
       "      <td>22</td>\n",
       "      <td>158</td>\n",
       "      <td>180</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 667 p_class 1 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.197</td>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>179</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.925     0.179               26   \n",
       "After RANDOM mitigation N = 667          0.929     0.239               21   \n",
       "After SMOTE N = 667 p_class 1 = 0.5      0.928     0.208               20   \n",
       "After SMOTE N = 667 p_class 1 = 0.55     0.927     0.197               23   \n",
       "After SMOTE N = 667 p_class 1 = 0.6      0.927     0.191               21   \n",
       "After SMOTE N = 667 p_class 1 = 0.65     0.927     0.183               21   \n",
       "After SMOTE N = 667 p_class 1 = 0.7      0.927     0.199               21   \n",
       "After SMOTE N = 667 p_class 1 = 0.75     0.927     0.192               20   \n",
       "After SMOTE N = 667 p_class 1 = 0.8      0.926     0.204               25   \n",
       "After SMOTE N = 667 p_class 1 = 0.85     0.926     0.182               22   \n",
       "After SMOTE N = 667 p_class 1 = 0.9      0.927     0.190               22   \n",
       "After SMOTE N = 667 p_class 1 = 0.95     0.926     0.182               22   \n",
       "After SMOTE N = 667 p_class 1 = 1.0      0.927     0.197               23   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 158           184   \n",
       "After RANDOM mitigation N = 667                   151           172   \n",
       "After SMOTE N = 667 p_class 1 = 0.5               155           175   \n",
       "After SMOTE N = 667 p_class 1 = 0.55              156           179   \n",
       "After SMOTE N = 667 p_class 1 = 0.6               157           178   \n",
       "After SMOTE N = 667 p_class 1 = 0.65              158           179   \n",
       "After SMOTE N = 667 p_class 1 = 0.7               156           177   \n",
       "After SMOTE N = 667 p_class 1 = 0.75              157           177   \n",
       "After SMOTE N = 667 p_class 1 = 0.8               155           180   \n",
       "After SMOTE N = 667 p_class 1 = 0.85              158           180   \n",
       "After SMOTE N = 667 p_class 1 = 0.9               157           179   \n",
       "After SMOTE N = 667 p_class 1 = 0.95              158           180   \n",
       "After SMOTE N = 667 p_class 1 = 1.0               156           179   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.065           0.112   \n",
       "After RANDOM mitigation N = 667                 0.084           0.152   \n",
       "After SMOTE N = 667 p_class 1 = 0.5             0.074           0.129   \n",
       "After SMOTE N = 667 p_class 1 = 0.55            0.071           0.124   \n",
       "After SMOTE N = 667 p_class 1 = 0.6             0.068           0.118   \n",
       "After SMOTE N = 667 p_class 1 = 0.65            0.064           0.112   \n",
       "After SMOTE N = 667 p_class 1 = 0.7             0.071           0.124   \n",
       "After SMOTE N = 667 p_class 1 = 0.75            0.069           0.118   \n",
       "After SMOTE N = 667 p_class 1 = 0.8             0.075           0.129   \n",
       "After SMOTE N = 667 p_class 1 = 0.85            0.065           0.112   \n",
       "After SMOTE N = 667 p_class 1 = 0.9             0.068           0.118   \n",
       "After SMOTE N = 667 p_class 1 = 0.95            0.064           0.112   \n",
       "After SMOTE N = 667 p_class 1 = 1.0             0.071           0.124   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.112       0.103       0.084  \n",
       "After RANDOM mitigation N = 667            0.152       0.137       0.107  \n",
       "After SMOTE N = 667 p_class 1 = 0.5        0.129       0.118       0.097  \n",
       "After SMOTE N = 667 p_class 1 = 0.55       0.124       0.114       0.092  \n",
       "After SMOTE N = 667 p_class 1 = 0.6        0.118       0.110       0.089  \n",
       "After SMOTE N = 667 p_class 1 = 0.65       0.112       0.103       0.083  \n",
       "After SMOTE N = 667 p_class 1 = 0.7        0.124       0.114       0.092  \n",
       "After SMOTE N = 667 p_class 1 = 0.75       0.118       0.112       0.091  \n",
       "After SMOTE N = 667 p_class 1 = 0.8        0.129       0.120       0.098  \n",
       "After SMOTE N = 667 p_class 1 = 0.85       0.112       0.106       0.085  \n",
       "After SMOTE N = 667 p_class 1 = 0.9        0.118       0.109       0.088  \n",
       "After SMOTE N = 667 p_class 1 = 0.95       0.112       0.104       0.082  \n",
       "After SMOTE N = 667 p_class 1 = 1.0        0.124       0.114       0.092  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_confronto = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_confronto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 500</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.882</td>\n",
       "      <td>15</td>\n",
       "      <td>157</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.854</td>\n",
       "      <td>26</td>\n",
       "      <td>152</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.55</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.871</td>\n",
       "      <td>31</td>\n",
       "      <td>155</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.876</td>\n",
       "      <td>28</td>\n",
       "      <td>156</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.65</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.888</td>\n",
       "      <td>30</td>\n",
       "      <td>158</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.848</td>\n",
       "      <td>27</td>\n",
       "      <td>151</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.75</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.893</td>\n",
       "      <td>30</td>\n",
       "      <td>159</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.8</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.882</td>\n",
       "      <td>30</td>\n",
       "      <td>157</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.85</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.899</td>\n",
       "      <td>29</td>\n",
       "      <td>160</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.9</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.882</td>\n",
       "      <td>32</td>\n",
       "      <td>157</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.95</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.865</td>\n",
       "      <td>21</td>\n",
       "      <td>154</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.882</td>\n",
       "      <td>21</td>\n",
       "      <td>157</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.925     0.179                0.011   \n",
       "After RANDOM mitigation N = 500          0.929     0.196                0.007   \n",
       "After SMOTE N = 500 p_class 1 = 0.5      0.927     0.226                0.011   \n",
       "After SMOTE N = 500 p_class 1 = 0.55     0.924     0.198                0.014   \n",
       "After SMOTE N = 500 p_class 1 = 0.6      0.925     0.193                0.012   \n",
       "After SMOTE N = 500 p_class 1 = 0.65     0.923     0.175                0.013   \n",
       "After SMOTE N = 500 p_class 1 = 0.7      0.927     0.233                0.012   \n",
       "After SMOTE N = 500 p_class 1 = 0.75     0.923     0.167                0.013   \n",
       "After SMOTE N = 500 p_class 1 = 0.8      0.923     0.183                0.013   \n",
       "After SMOTE N = 500 p_class 1 = 0.85     0.923     0.160                0.013   \n",
       "After SMOTE N = 500 p_class 1 = 0.9      0.923     0.182                0.014   \n",
       "After SMOTE N = 500 p_class 1 = 0.95     0.928     0.215                0.009   \n",
       "After SMOTE N = 500 p_class 1 = 1.0      0.927     0.191                0.009   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.888               26   \n",
       "After RANDOM mitigation N = 500                     0.882               15   \n",
       "After SMOTE N = 500 p_class 1 = 0.5                 0.854               26   \n",
       "After SMOTE N = 500 p_class 1 = 0.55                0.871               31   \n",
       "After SMOTE N = 500 p_class 1 = 0.6                 0.876               28   \n",
       "After SMOTE N = 500 p_class 1 = 0.65                0.888               30   \n",
       "After SMOTE N = 500 p_class 1 = 0.7                 0.848               27   \n",
       "After SMOTE N = 500 p_class 1 = 0.75                0.893               30   \n",
       "After SMOTE N = 500 p_class 1 = 0.8                 0.882               30   \n",
       "After SMOTE N = 500 p_class 1 = 0.85                0.899               29   \n",
       "After SMOTE N = 500 p_class 1 = 0.9                 0.882               32   \n",
       "After SMOTE N = 500 p_class 1 = 0.95                0.865               21   \n",
       "After SMOTE N = 500 p_class 1 = 1.0                 0.882               21   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 158       10975       2439  \n",
       "After RANDOM mitigation N = 500                   157       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.5               152       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.55              155       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.6               156       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.65              158       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.7               151       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.75              159       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.8               157       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.85              160       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.9               157       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.95              154       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 1.0               157       11475       2439  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 500\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>184</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 500</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.196</td>\n",
       "      <td>15</td>\n",
       "      <td>157</td>\n",
       "      <td>172</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.226</td>\n",
       "      <td>26</td>\n",
       "      <td>152</td>\n",
       "      <td>178</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.55</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.198</td>\n",
       "      <td>31</td>\n",
       "      <td>155</td>\n",
       "      <td>186</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.193</td>\n",
       "      <td>28</td>\n",
       "      <td>156</td>\n",
       "      <td>184</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.65</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.175</td>\n",
       "      <td>30</td>\n",
       "      <td>158</td>\n",
       "      <td>188</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.233</td>\n",
       "      <td>27</td>\n",
       "      <td>151</td>\n",
       "      <td>178</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.75</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.167</td>\n",
       "      <td>30</td>\n",
       "      <td>159</td>\n",
       "      <td>189</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.8</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.183</td>\n",
       "      <td>30</td>\n",
       "      <td>157</td>\n",
       "      <td>187</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.85</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.160</td>\n",
       "      <td>29</td>\n",
       "      <td>160</td>\n",
       "      <td>189</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.9</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.182</td>\n",
       "      <td>32</td>\n",
       "      <td>157</td>\n",
       "      <td>189</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.95</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.215</td>\n",
       "      <td>21</td>\n",
       "      <td>154</td>\n",
       "      <td>175</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.191</td>\n",
       "      <td>21</td>\n",
       "      <td>157</td>\n",
       "      <td>178</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.925     0.179               26   \n",
       "After RANDOM mitigation N = 500          0.929     0.196               15   \n",
       "After SMOTE N = 500 p_class 1 = 0.5      0.927     0.226               26   \n",
       "After SMOTE N = 500 p_class 1 = 0.55     0.924     0.198               31   \n",
       "After SMOTE N = 500 p_class 1 = 0.6      0.925     0.193               28   \n",
       "After SMOTE N = 500 p_class 1 = 0.65     0.923     0.175               30   \n",
       "After SMOTE N = 500 p_class 1 = 0.7      0.927     0.233               27   \n",
       "After SMOTE N = 500 p_class 1 = 0.75     0.923     0.167               30   \n",
       "After SMOTE N = 500 p_class 1 = 0.8      0.923     0.183               30   \n",
       "After SMOTE N = 500 p_class 1 = 0.85     0.923     0.160               29   \n",
       "After SMOTE N = 500 p_class 1 = 0.9      0.923     0.182               32   \n",
       "After SMOTE N = 500 p_class 1 = 0.95     0.928     0.215               21   \n",
       "After SMOTE N = 500 p_class 1 = 1.0      0.927     0.191               21   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 158           184   \n",
       "After RANDOM mitigation N = 500                   157           172   \n",
       "After SMOTE N = 500 p_class 1 = 0.5               152           178   \n",
       "After SMOTE N = 500 p_class 1 = 0.55              155           186   \n",
       "After SMOTE N = 500 p_class 1 = 0.6               156           184   \n",
       "After SMOTE N = 500 p_class 1 = 0.65              158           188   \n",
       "After SMOTE N = 500 p_class 1 = 0.7               151           178   \n",
       "After SMOTE N = 500 p_class 1 = 0.75              159           189   \n",
       "After SMOTE N = 500 p_class 1 = 0.8               157           187   \n",
       "After SMOTE N = 500 p_class 1 = 0.85              160           189   \n",
       "After SMOTE N = 500 p_class 1 = 0.9               157           189   \n",
       "After SMOTE N = 500 p_class 1 = 0.95              154           175   \n",
       "After SMOTE N = 500 p_class 1 = 1.0               157           178   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.065           0.112   \n",
       "After RANDOM mitigation N = 500                 0.084           0.152   \n",
       "After SMOTE N = 500 p_class 1 = 0.5             0.069           0.146   \n",
       "After SMOTE N = 500 p_class 1 = 0.55            0.076           0.129   \n",
       "After SMOTE N = 500 p_class 1 = 0.6             0.073           0.124   \n",
       "After SMOTE N = 500 p_class 1 = 0.65            0.066           0.112   \n",
       "After SMOTE N = 500 p_class 1 = 0.7             0.072           0.132   \n",
       "After SMOTE N = 500 p_class 1 = 0.75            0.062           0.107   \n",
       "After SMOTE N = 500 p_class 1 = 0.8             0.071           0.118   \n",
       "After SMOTE N = 500 p_class 1 = 0.85            0.060           0.101   \n",
       "After SMOTE N = 500 p_class 1 = 0.9             0.067           0.118   \n",
       "After SMOTE N = 500 p_class 1 = 0.95            0.078           0.135   \n",
       "After SMOTE N = 500 p_class 1 = 1.0             0.068           0.118   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.112       0.103       0.084  \n",
       "After RANDOM mitigation N = 500            0.152       0.137       0.107  \n",
       "After SMOTE N = 500 p_class 1 = 0.5        0.124       0.113       0.091  \n",
       "After SMOTE N = 500 p_class 1 = 0.55       0.129       0.118       0.098  \n",
       "After SMOTE N = 500 p_class 1 = 0.6        0.124       0.114       0.094  \n",
       "After SMOTE N = 500 p_class 1 = 0.65       0.112       0.105       0.086  \n",
       "After SMOTE N = 500 p_class 1 = 0.7        0.126       0.117       0.095  \n",
       "After SMOTE N = 500 p_class 1 = 0.75       0.107       0.099       0.080  \n",
       "After SMOTE N = 500 p_class 1 = 0.8        0.118       0.110       0.091  \n",
       "After SMOTE N = 500 p_class 1 = 0.85       0.101       0.095       0.077  \n",
       "After SMOTE N = 500 p_class 1 = 0.9        0.118       0.108       0.087  \n",
       "After SMOTE N = 500 p_class 1 = 0.95       0.135       0.122       0.101  \n",
       "After SMOTE N = 500 p_class 1 = 1.0        0.118       0.108       0.088  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.888</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.5</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>25</td>\n",
       "      <td>158</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.55</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.865</td>\n",
       "      <td>26</td>\n",
       "      <td>154</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.6</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.865</td>\n",
       "      <td>26</td>\n",
       "      <td>154</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.65</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.882</td>\n",
       "      <td>25</td>\n",
       "      <td>157</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.7</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.876</td>\n",
       "      <td>25</td>\n",
       "      <td>156</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.75</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.865</td>\n",
       "      <td>27</td>\n",
       "      <td>154</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.8</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.882</td>\n",
       "      <td>31</td>\n",
       "      <td>157</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.85</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.876</td>\n",
       "      <td>29</td>\n",
       "      <td>156</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.871</td>\n",
       "      <td>25</td>\n",
       "      <td>155</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.95</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.871</td>\n",
       "      <td>27</td>\n",
       "      <td>155</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 1.0</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.860</td>\n",
       "      <td>30</td>\n",
       "      <td>153</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.925     0.179   \n",
       "After RANDOM mitigation N = 1000          0.926     0.181   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5      0.925     0.179   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55     0.926     0.211   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6      0.926     0.211   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65     0.925     0.188   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7      0.926     0.196   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75     0.926     0.210   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8      0.923     0.183   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85     0.924     0.192   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9      0.926     0.204   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95     0.925     0.202   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0      0.925     0.215   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.011   \n",
       "After RANDOM mitigation N = 1000                     0.010   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5                 0.011   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55                0.011   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6                 0.011   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65                0.011   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7                 0.011   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75                0.012   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8                 0.014   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85                0.013   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9                 0.011   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95                0.012   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0                 0.013   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.888               26   \n",
       "After RANDOM mitigation N = 1000                     0.888               23   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5                 0.888               25   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55                0.865               26   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6                 0.865               26   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65                0.882               25   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7                 0.876               25   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75                0.865               27   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8                 0.882               31   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85                0.876               29   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9                 0.871               25   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95                0.871               27   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0                 0.860               30   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  158       10975       2439  \n",
       "After RANDOM mitigation N = 1000                   158       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.5               158       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.55              154       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.6               154       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.65              157       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.7               156       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.75              154       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.8               157       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.85              156       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.9               155       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.95              155       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 1.0               153       11975       2439  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>184</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.181</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>181</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.5</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>25</td>\n",
       "      <td>158</td>\n",
       "      <td>183</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.55</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.211</td>\n",
       "      <td>26</td>\n",
       "      <td>154</td>\n",
       "      <td>180</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.6</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.211</td>\n",
       "      <td>26</td>\n",
       "      <td>154</td>\n",
       "      <td>180</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.65</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.188</td>\n",
       "      <td>25</td>\n",
       "      <td>157</td>\n",
       "      <td>182</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.7</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.196</td>\n",
       "      <td>25</td>\n",
       "      <td>156</td>\n",
       "      <td>181</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.75</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.210</td>\n",
       "      <td>27</td>\n",
       "      <td>154</td>\n",
       "      <td>181</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.8</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.183</td>\n",
       "      <td>31</td>\n",
       "      <td>157</td>\n",
       "      <td>188</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.85</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.192</td>\n",
       "      <td>29</td>\n",
       "      <td>156</td>\n",
       "      <td>185</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.204</td>\n",
       "      <td>25</td>\n",
       "      <td>155</td>\n",
       "      <td>180</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.95</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.202</td>\n",
       "      <td>27</td>\n",
       "      <td>155</td>\n",
       "      <td>182</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 1.0</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.215</td>\n",
       "      <td>30</td>\n",
       "      <td>153</td>\n",
       "      <td>183</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.925     0.179               26   \n",
       "After RANDOM mitigation N = 1000          0.926     0.181               23   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5      0.925     0.179               25   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55     0.926     0.211               26   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6      0.926     0.211               26   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65     0.925     0.188               25   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7      0.926     0.196               25   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75     0.926     0.210               27   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8      0.923     0.183               31   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85     0.924     0.192               29   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9      0.926     0.204               25   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95     0.925     0.202               27   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0      0.925     0.215               30   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  158           184   \n",
       "After RANDOM mitigation N = 1000                   158           181   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5               158           183   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55              154           180   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6               154           180   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65              157           182   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7               156           181   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75              154           181   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8               157           188   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85              156           185   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9               155           180   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95              155           182   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0               153           183   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.065           0.112   \n",
       "After RANDOM mitigation N = 1000                 0.084           0.152   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5             0.063           0.112   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55            0.076           0.135   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6             0.077           0.135   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65            0.067           0.118   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7             0.071           0.124   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75            0.077           0.135   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8             0.067           0.118   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85            0.071           0.124   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9             0.075           0.129   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95            0.072           0.129   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0             0.080           0.140   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.112       0.103       0.084  \n",
       "After RANDOM mitigation N = 1000            0.152       0.137       0.107  \n",
       "After SMOTE N = 1000 p_class 1 = 0.5        0.112       0.103       0.082  \n",
       "After SMOTE N = 1000 p_class 1 = 0.55       0.135       0.121       0.099  \n",
       "After SMOTE N = 1000 p_class 1 = 0.6        0.135       0.123       0.100  \n",
       "After SMOTE N = 1000 p_class 1 = 0.65       0.118       0.108       0.088  \n",
       "After SMOTE N = 1000 p_class 1 = 0.7        0.124       0.114       0.092  \n",
       "After SMOTE N = 1000 p_class 1 = 0.75       0.135       0.121       0.100  \n",
       "After SMOTE N = 1000 p_class 1 = 0.8        0.118       0.108       0.088  \n",
       "After SMOTE N = 1000 p_class 1 = 0.85       0.124       0.114       0.093  \n",
       "After SMOTE N = 1000 p_class 1 = 0.9        0.129       0.119       0.098  \n",
       "After SMOTE N = 1000 p_class 1 = 0.95       0.129       0.117       0.094  \n",
       "After SMOTE N = 1000 p_class 1 = 1.0        0.140       0.127       0.104  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_1000 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1500</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.848</td>\n",
       "      <td>26</td>\n",
       "      <td>151</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.5</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.888</td>\n",
       "      <td>22</td>\n",
       "      <td>158</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.871</td>\n",
       "      <td>23</td>\n",
       "      <td>155</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.882</td>\n",
       "      <td>21</td>\n",
       "      <td>157</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.882</td>\n",
       "      <td>22</td>\n",
       "      <td>157</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.7</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.893</td>\n",
       "      <td>22</td>\n",
       "      <td>159</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.75</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>25</td>\n",
       "      <td>158</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.8</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.899</td>\n",
       "      <td>24</td>\n",
       "      <td>160</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.85</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.888</td>\n",
       "      <td>22</td>\n",
       "      <td>158</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.893</td>\n",
       "      <td>22</td>\n",
       "      <td>159</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.95</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>24</td>\n",
       "      <td>158</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 1.0</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.888</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.925     0.179   \n",
       "After RANDOM mitigation N = 1500          0.927     0.234   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5      0.926     0.182   \n",
       "After SMOTE N = 1500 p_class 1 = 0.55     0.927     0.205   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6      0.927     0.191   \n",
       "After SMOTE N = 1500 p_class 1 = 0.65     0.927     0.190   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7      0.926     0.174   \n",
       "After SMOTE N = 1500 p_class 1 = 0.75     0.925     0.179   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8      0.925     0.164   \n",
       "After SMOTE N = 1500 p_class 1 = 0.85     0.926     0.182   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9      0.926     0.174   \n",
       "After SMOTE N = 1500 p_class 1 = 0.95     0.925     0.180   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0      0.926     0.181   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.011   \n",
       "After RANDOM mitigation N = 1500                     0.011   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5                 0.010   \n",
       "After SMOTE N = 1500 p_class 1 = 0.55                0.010   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6                 0.009   \n",
       "After SMOTE N = 1500 p_class 1 = 0.65                0.010   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7                 0.010   \n",
       "After SMOTE N = 1500 p_class 1 = 0.75                0.011   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8                 0.011   \n",
       "After SMOTE N = 1500 p_class 1 = 0.85                0.010   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9                 0.010   \n",
       "After SMOTE N = 1500 p_class 1 = 0.95                0.011   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0                 0.010   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.888               26   \n",
       "After RANDOM mitigation N = 1500                     0.848               26   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5                 0.888               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.55                0.871               23   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6                 0.882               21   \n",
       "After SMOTE N = 1500 p_class 1 = 0.65                0.882               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7                 0.893               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.75                0.888               25   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8                 0.899               24   \n",
       "After SMOTE N = 1500 p_class 1 = 0.85                0.888               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9                 0.893               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.95                0.888               24   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0                 0.888               23   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  158       10975       2439  \n",
       "After RANDOM mitigation N = 1500                   151       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.5               158       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.55              155       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.6               157       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.65              157       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.7               159       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.75              158       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.8               160       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.85              158       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.9               159       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.95              158       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 1.0               158       12475       2439  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1500\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>184</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1500</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.234</td>\n",
       "      <td>26</td>\n",
       "      <td>151</td>\n",
       "      <td>177</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.5</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.182</td>\n",
       "      <td>22</td>\n",
       "      <td>158</td>\n",
       "      <td>180</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.205</td>\n",
       "      <td>23</td>\n",
       "      <td>155</td>\n",
       "      <td>178</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.191</td>\n",
       "      <td>21</td>\n",
       "      <td>157</td>\n",
       "      <td>178</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.190</td>\n",
       "      <td>22</td>\n",
       "      <td>157</td>\n",
       "      <td>179</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.7</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.174</td>\n",
       "      <td>22</td>\n",
       "      <td>159</td>\n",
       "      <td>181</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.75</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>25</td>\n",
       "      <td>158</td>\n",
       "      <td>183</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.8</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.164</td>\n",
       "      <td>24</td>\n",
       "      <td>160</td>\n",
       "      <td>184</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.85</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.182</td>\n",
       "      <td>22</td>\n",
       "      <td>158</td>\n",
       "      <td>180</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.174</td>\n",
       "      <td>22</td>\n",
       "      <td>159</td>\n",
       "      <td>181</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.95</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.180</td>\n",
       "      <td>24</td>\n",
       "      <td>158</td>\n",
       "      <td>182</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 1.0</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.181</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>181</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.925     0.179               26   \n",
       "After RANDOM mitigation N = 1500          0.927     0.234               26   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5      0.926     0.182               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.55     0.927     0.205               23   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6      0.927     0.191               21   \n",
       "After SMOTE N = 1500 p_class 1 = 0.65     0.927     0.190               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7      0.926     0.174               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.75     0.925     0.179               25   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8      0.925     0.164               24   \n",
       "After SMOTE N = 1500 p_class 1 = 0.85     0.926     0.182               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9      0.926     0.174               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.95     0.925     0.180               24   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0      0.926     0.181               23   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  158           184   \n",
       "After RANDOM mitigation N = 1500                   151           177   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5               158           180   \n",
       "After SMOTE N = 1500 p_class 1 = 0.55              155           178   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6               157           178   \n",
       "After SMOTE N = 1500 p_class 1 = 0.65              157           179   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7               159           181   \n",
       "After SMOTE N = 1500 p_class 1 = 0.75              158           183   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8               160           184   \n",
       "After SMOTE N = 1500 p_class 1 = 0.85              158           180   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9               159           181   \n",
       "After SMOTE N = 1500 p_class 1 = 0.95              158           182   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0               158           181   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.065           0.112   \n",
       "After RANDOM mitigation N = 1500                 0.084           0.152   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5             0.065           0.112   \n",
       "After SMOTE N = 1500 p_class 1 = 0.55            0.070           0.129   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6             0.069           0.118   \n",
       "After SMOTE N = 1500 p_class 1 = 0.65            0.070           0.118   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7             0.062           0.107   \n",
       "After SMOTE N = 1500 p_class 1 = 0.75            0.066           0.112   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8             0.058           0.101   \n",
       "After SMOTE N = 1500 p_class 1 = 0.85            0.065           0.112   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9             0.062           0.107   \n",
       "After SMOTE N = 1500 p_class 1 = 0.95            0.064           0.112   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0             0.067           0.112   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.112       0.103       0.084  \n",
       "After RANDOM mitigation N = 1500            0.152       0.137       0.107  \n",
       "After SMOTE N = 1500 p_class 1 = 0.5        0.112       0.105       0.085  \n",
       "After SMOTE N = 1500 p_class 1 = 0.55       0.129       0.113       0.091  \n",
       "After SMOTE N = 1500 p_class 1 = 0.6        0.118       0.110       0.090  \n",
       "After SMOTE N = 1500 p_class 1 = 0.65       0.118       0.110       0.091  \n",
       "After SMOTE N = 1500 p_class 1 = 0.7        0.107       0.100       0.081  \n",
       "After SMOTE N = 1500 p_class 1 = 0.75       0.112       0.106       0.086  \n",
       "After SMOTE N = 1500 p_class 1 = 0.8        0.101       0.095       0.075  \n",
       "After SMOTE N = 1500 p_class 1 = 0.85       0.112       0.105       0.084  \n",
       "After SMOTE N = 1500 p_class 1 = 0.9        0.107       0.100       0.081  \n",
       "After SMOTE N = 1500 p_class 1 = 0.95       0.112       0.105       0.083  \n",
       "After SMOTE N = 1500 p_class 1 = 1.0        0.112       0.106       0.086  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_1500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.865</td>\n",
       "      <td>27</td>\n",
       "      <td>154</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.5</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.55</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.893</td>\n",
       "      <td>25</td>\n",
       "      <td>159</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.6</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.876</td>\n",
       "      <td>24</td>\n",
       "      <td>156</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.65</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.899</td>\n",
       "      <td>23</td>\n",
       "      <td>160</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.7</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.854</td>\n",
       "      <td>34</td>\n",
       "      <td>152</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.75</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.888</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.8</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.865</td>\n",
       "      <td>30</td>\n",
       "      <td>154</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.85</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.882</td>\n",
       "      <td>26</td>\n",
       "      <td>157</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.9</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.871</td>\n",
       "      <td>36</td>\n",
       "      <td>155</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.95</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 1.0</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.876</td>\n",
       "      <td>28</td>\n",
       "      <td>156</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.925     0.179   \n",
       "After RANDOM mitigation N = 2000          0.926     0.210   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5      0.925     0.179   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55     0.925     0.171   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6      0.926     0.196   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65     0.925     0.164   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7      0.924     0.218   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75     0.926     0.181   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8      0.925     0.207   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85     0.925     0.187   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9      0.922     0.194   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95     0.925     0.179   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0      0.925     0.193   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.011   \n",
       "After RANDOM mitigation N = 2000                     0.012   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5                 0.011   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55                0.011   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6                 0.011   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65                0.010   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7                 0.015   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75                0.010   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8                 0.013   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85                0.011   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9                 0.016   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95                0.011   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0                 0.012   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.888               26   \n",
       "After RANDOM mitigation N = 2000                     0.865               27   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5                 0.888               26   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55                0.893               25   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6                 0.876               24   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65                0.899               23   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7                 0.854               34   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75                0.888               23   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8                 0.865               30   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85                0.882               26   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9                 0.871               36   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95                0.888               26   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0                 0.876               28   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  158       10975       2439  \n",
       "After RANDOM mitigation N = 2000                   154       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.5               158       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.55              159       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.6               156       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.65              160       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.7               152       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.75              158       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.8               154       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.85              157       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.9               155       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.95              158       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 1.0               156       12975       2439  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>184</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.210</td>\n",
       "      <td>27</td>\n",
       "      <td>154</td>\n",
       "      <td>181</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.5</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>184</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.55</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.171</td>\n",
       "      <td>25</td>\n",
       "      <td>159</td>\n",
       "      <td>184</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.6</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.196</td>\n",
       "      <td>24</td>\n",
       "      <td>156</td>\n",
       "      <td>180</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.65</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.164</td>\n",
       "      <td>23</td>\n",
       "      <td>160</td>\n",
       "      <td>183</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.7</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.218</td>\n",
       "      <td>34</td>\n",
       "      <td>152</td>\n",
       "      <td>186</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.75</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.181</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>181</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.8</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.207</td>\n",
       "      <td>30</td>\n",
       "      <td>154</td>\n",
       "      <td>184</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.85</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.187</td>\n",
       "      <td>26</td>\n",
       "      <td>157</td>\n",
       "      <td>183</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.9</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.194</td>\n",
       "      <td>36</td>\n",
       "      <td>155</td>\n",
       "      <td>191</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.95</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>184</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 1.0</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.193</td>\n",
       "      <td>28</td>\n",
       "      <td>156</td>\n",
       "      <td>184</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.925     0.179               26   \n",
       "After RANDOM mitigation N = 2000          0.926     0.210               27   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5      0.925     0.179               26   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55     0.925     0.171               25   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6      0.926     0.196               24   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65     0.925     0.164               23   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7      0.924     0.218               34   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75     0.926     0.181               23   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8      0.925     0.207               30   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85     0.925     0.187               26   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9      0.922     0.194               36   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95     0.925     0.179               26   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0      0.925     0.193               28   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  158           184   \n",
       "After RANDOM mitigation N = 2000                   154           181   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5               158           184   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55              159           184   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6               156           180   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65              160           183   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7               152           186   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75              158           181   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8               154           184   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85              157           183   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9               155           191   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95              158           184   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0               156           184   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.065           0.112   \n",
       "After RANDOM mitigation N = 2000                 0.084           0.152   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5             0.068           0.112   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55            0.062           0.107   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6             0.074           0.124   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65            0.060           0.101   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7             0.083           0.146   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75            0.068           0.112   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8             0.077           0.135   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85            0.071           0.118   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9             0.077           0.129   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95            0.068           0.112   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0             0.075           0.124   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.112       0.103       0.084  \n",
       "After RANDOM mitigation N = 2000            0.152       0.137       0.107  \n",
       "After SMOTE N = 2000 p_class 1 = 0.5        0.112       0.106       0.088  \n",
       "After SMOTE N = 2000 p_class 1 = 0.55       0.107       0.100       0.081  \n",
       "After SMOTE N = 2000 p_class 1 = 0.6        0.124       0.116       0.096  \n",
       "After SMOTE N = 2000 p_class 1 = 0.65       0.101       0.095       0.077  \n",
       "After SMOTE N = 2000 p_class 1 = 0.7        0.146       0.136       0.109  \n",
       "After SMOTE N = 2000 p_class 1 = 0.75       0.112       0.106       0.088  \n",
       "After SMOTE N = 2000 p_class 1 = 0.8        0.135       0.124       0.100  \n",
       "After SMOTE N = 2000 p_class 1 = 0.85       0.118       0.110       0.092  \n",
       "After SMOTE N = 2000 p_class 1 = 0.9        0.129       0.121       0.099  \n",
       "After SMOTE N = 2000 p_class 1 = 0.95       0.112       0.105       0.087  \n",
       "After SMOTE N = 2000 p_class 1 = 1.0        0.124       0.115       0.096  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_2000 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2500</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.871</td>\n",
       "      <td>25</td>\n",
       "      <td>155</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.5</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.871</td>\n",
       "      <td>30</td>\n",
       "      <td>155</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.55</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.871</td>\n",
       "      <td>27</td>\n",
       "      <td>155</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.871</td>\n",
       "      <td>28</td>\n",
       "      <td>155</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.65</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.860</td>\n",
       "      <td>28</td>\n",
       "      <td>153</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.7</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.876</td>\n",
       "      <td>28</td>\n",
       "      <td>156</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.75</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.871</td>\n",
       "      <td>29</td>\n",
       "      <td>155</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.8</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.893</td>\n",
       "      <td>23</td>\n",
       "      <td>159</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.85</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.876</td>\n",
       "      <td>28</td>\n",
       "      <td>156</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.9</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.871</td>\n",
       "      <td>30</td>\n",
       "      <td>155</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.95</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.882</td>\n",
       "      <td>33</td>\n",
       "      <td>157</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 1.0</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.888</td>\n",
       "      <td>29</td>\n",
       "      <td>158</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.925     0.179   \n",
       "After RANDOM mitigation N = 2500          0.926     0.204   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5      0.924     0.199   \n",
       "After SMOTE N = 2500 p_class 1 = 0.55     0.925     0.202   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6      0.925     0.201   \n",
       "After SMOTE N = 2500 p_class 1 = 0.65     0.926     0.216   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7      0.925     0.193   \n",
       "After SMOTE N = 2500 p_class 1 = 0.75     0.925     0.200   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8      0.925     0.173   \n",
       "After SMOTE N = 2500 p_class 1 = 0.85     0.925     0.193   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9      0.924     0.199   \n",
       "After SMOTE N = 2500 p_class 1 = 0.95     0.922     0.181   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0      0.923     0.176   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.011   \n",
       "After RANDOM mitigation N = 2500                     0.011   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5                 0.013   \n",
       "After SMOTE N = 2500 p_class 1 = 0.55                0.012   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6                 0.012   \n",
       "After SMOTE N = 2500 p_class 1 = 0.65                0.012   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7                 0.012   \n",
       "After SMOTE N = 2500 p_class 1 = 0.75                0.013   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8                 0.010   \n",
       "After SMOTE N = 2500 p_class 1 = 0.85                0.012   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9                 0.013   \n",
       "After SMOTE N = 2500 p_class 1 = 0.95                0.015   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0                 0.013   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.888               26   \n",
       "After RANDOM mitigation N = 2500                     0.871               25   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5                 0.871               30   \n",
       "After SMOTE N = 2500 p_class 1 = 0.55                0.871               27   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6                 0.871               28   \n",
       "After SMOTE N = 2500 p_class 1 = 0.65                0.860               28   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7                 0.876               28   \n",
       "After SMOTE N = 2500 p_class 1 = 0.75                0.871               29   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8                 0.893               23   \n",
       "After SMOTE N = 2500 p_class 1 = 0.85                0.876               28   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9                 0.871               30   \n",
       "After SMOTE N = 2500 p_class 1 = 0.95                0.882               33   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0                 0.888               29   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  158       10975       2439  \n",
       "After RANDOM mitigation N = 2500                   155       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.5               155       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.55              155       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.6               155       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.65              153       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.7               156       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.75              155       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.8               159       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.85              156       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.9               155       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.95              157       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 1.0               158       13475       2439  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2500\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>184</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2500</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.204</td>\n",
       "      <td>25</td>\n",
       "      <td>155</td>\n",
       "      <td>180</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.5</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.199</td>\n",
       "      <td>30</td>\n",
       "      <td>155</td>\n",
       "      <td>185</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.55</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.202</td>\n",
       "      <td>27</td>\n",
       "      <td>155</td>\n",
       "      <td>182</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.201</td>\n",
       "      <td>28</td>\n",
       "      <td>155</td>\n",
       "      <td>183</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.65</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.216</td>\n",
       "      <td>28</td>\n",
       "      <td>153</td>\n",
       "      <td>181</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.7</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.193</td>\n",
       "      <td>28</td>\n",
       "      <td>156</td>\n",
       "      <td>184</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.75</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.200</td>\n",
       "      <td>29</td>\n",
       "      <td>155</td>\n",
       "      <td>184</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.8</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.173</td>\n",
       "      <td>23</td>\n",
       "      <td>159</td>\n",
       "      <td>182</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.85</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.193</td>\n",
       "      <td>28</td>\n",
       "      <td>156</td>\n",
       "      <td>184</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.9</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.199</td>\n",
       "      <td>30</td>\n",
       "      <td>155</td>\n",
       "      <td>185</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.95</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.181</td>\n",
       "      <td>33</td>\n",
       "      <td>157</td>\n",
       "      <td>190</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 1.0</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.176</td>\n",
       "      <td>29</td>\n",
       "      <td>158</td>\n",
       "      <td>187</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.925     0.179               26   \n",
       "After RANDOM mitigation N = 2500          0.926     0.204               25   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5      0.924     0.199               30   \n",
       "After SMOTE N = 2500 p_class 1 = 0.55     0.925     0.202               27   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6      0.925     0.201               28   \n",
       "After SMOTE N = 2500 p_class 1 = 0.65     0.926     0.216               28   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7      0.925     0.193               28   \n",
       "After SMOTE N = 2500 p_class 1 = 0.75     0.925     0.200               29   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8      0.925     0.173               23   \n",
       "After SMOTE N = 2500 p_class 1 = 0.85     0.925     0.193               28   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9      0.924     0.199               30   \n",
       "After SMOTE N = 2500 p_class 1 = 0.95     0.922     0.181               33   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0      0.923     0.176               29   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  158           184   \n",
       "After RANDOM mitigation N = 2500                   155           180   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5               155           185   \n",
       "After SMOTE N = 2500 p_class 1 = 0.55              155           182   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6               155           183   \n",
       "After SMOTE N = 2500 p_class 1 = 0.65              153           181   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7               156           184   \n",
       "After SMOTE N = 2500 p_class 1 = 0.75              155           184   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8               159           182   \n",
       "After SMOTE N = 2500 p_class 1 = 0.85              156           184   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9               155           185   \n",
       "After SMOTE N = 2500 p_class 1 = 0.95              157           190   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0               158           187   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.065           0.112   \n",
       "After RANDOM mitigation N = 2500                 0.084           0.152   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5             0.077           0.129   \n",
       "After SMOTE N = 2500 p_class 1 = 0.55            0.078           0.129   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6             0.076           0.129   \n",
       "After SMOTE N = 2500 p_class 1 = 0.65            0.084           0.140   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7             0.074           0.124   \n",
       "After SMOTE N = 2500 p_class 1 = 0.75            0.077           0.129   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8             0.065           0.107   \n",
       "After SMOTE N = 2500 p_class 1 = 0.85            0.075           0.124   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9             0.080           0.129   \n",
       "After SMOTE N = 2500 p_class 1 = 0.95            0.070           0.118   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0             0.069           0.112   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.112       0.103       0.084  \n",
       "After RANDOM mitigation N = 2500            0.152       0.137       0.107  \n",
       "After SMOTE N = 2500 p_class 1 = 0.5        0.129       0.121       0.099  \n",
       "After SMOTE N = 2500 p_class 1 = 0.55       0.129       0.121       0.100  \n",
       "After SMOTE N = 2500 p_class 1 = 0.6        0.129       0.121       0.099  \n",
       "After SMOTE N = 2500 p_class 1 = 0.65       0.140       0.131       0.108  \n",
       "After SMOTE N = 2500 p_class 1 = 0.7        0.124       0.117       0.095  \n",
       "After SMOTE N = 2500 p_class 1 = 0.75       0.129       0.121       0.099  \n",
       "After SMOTE N = 2500 p_class 1 = 0.8        0.107       0.105       0.084  \n",
       "After SMOTE N = 2500 p_class 1 = 0.85       0.124       0.120       0.097  \n",
       "After SMOTE N = 2500 p_class 1 = 0.9        0.129       0.126       0.103  \n",
       "After SMOTE N = 2500 p_class 1 = 0.95       0.118       0.111       0.090  \n",
       "After SMOTE N = 2500 p_class 1 = 1.0        0.112       0.111       0.088  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_2500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2500\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3000</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.876</td>\n",
       "      <td>25</td>\n",
       "      <td>156</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.888</td>\n",
       "      <td>21</td>\n",
       "      <td>158</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.55</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.888</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.6</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.888</td>\n",
       "      <td>28</td>\n",
       "      <td>158</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.65</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.888</td>\n",
       "      <td>29</td>\n",
       "      <td>158</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.7</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.888</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.75</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.882</td>\n",
       "      <td>27</td>\n",
       "      <td>157</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.8</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.893</td>\n",
       "      <td>28</td>\n",
       "      <td>159</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.85</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.893</td>\n",
       "      <td>31</td>\n",
       "      <td>159</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.9</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.888</td>\n",
       "      <td>29</td>\n",
       "      <td>158</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.95</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.893</td>\n",
       "      <td>29</td>\n",
       "      <td>159</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 1.0</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.888</td>\n",
       "      <td>30</td>\n",
       "      <td>158</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.925     0.179   \n",
       "After RANDOM mitigation N = 3000          0.926     0.196   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5      0.927     0.183   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55     0.926     0.181   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6      0.924     0.177   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65     0.923     0.176   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7      0.925     0.179   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75     0.925     0.186   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8      0.923     0.169   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85     0.922     0.167   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9      0.923     0.176   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95     0.923     0.168   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0      0.923     0.175   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.011   \n",
       "After RANDOM mitigation N = 3000                     0.011   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5                 0.009   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55                0.010   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6                 0.012   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65                0.013   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7                 0.011   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75                0.012   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8                 0.012   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85                0.014   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9                 0.013   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95                0.013   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0                 0.013   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.888               26   \n",
       "After RANDOM mitigation N = 3000                     0.876               25   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5                 0.888               21   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55                0.888               23   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6                 0.888               28   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65                0.888               29   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7                 0.888               26   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75                0.882               27   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8                 0.893               28   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85                0.893               31   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9                 0.888               29   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95                0.893               29   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0                 0.888               30   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  158       10975       2439  \n",
       "After RANDOM mitigation N = 3000                   156       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.5               158       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.55              158       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.6               158       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.65              158       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.7               158       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.75              157       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.8               159       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.85              159       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.9               158       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.95              159       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 1.0               158       13975       2439  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>184</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3000</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.196</td>\n",
       "      <td>25</td>\n",
       "      <td>156</td>\n",
       "      <td>181</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.183</td>\n",
       "      <td>21</td>\n",
       "      <td>158</td>\n",
       "      <td>179</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.55</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.181</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>181</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.6</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.177</td>\n",
       "      <td>28</td>\n",
       "      <td>158</td>\n",
       "      <td>186</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.65</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.176</td>\n",
       "      <td>29</td>\n",
       "      <td>158</td>\n",
       "      <td>187</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.7</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.179</td>\n",
       "      <td>26</td>\n",
       "      <td>158</td>\n",
       "      <td>184</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.75</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.186</td>\n",
       "      <td>27</td>\n",
       "      <td>157</td>\n",
       "      <td>184</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.8</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.169</td>\n",
       "      <td>28</td>\n",
       "      <td>159</td>\n",
       "      <td>187</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.85</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.167</td>\n",
       "      <td>31</td>\n",
       "      <td>159</td>\n",
       "      <td>190</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.9</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.176</td>\n",
       "      <td>29</td>\n",
       "      <td>158</td>\n",
       "      <td>187</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.95</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.168</td>\n",
       "      <td>29</td>\n",
       "      <td>159</td>\n",
       "      <td>188</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 1.0</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.175</td>\n",
       "      <td>30</td>\n",
       "      <td>158</td>\n",
       "      <td>188</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.925     0.179               26   \n",
       "After RANDOM mitigation N = 3000          0.926     0.196               25   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5      0.927     0.183               21   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55     0.926     0.181               23   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6      0.924     0.177               28   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65     0.923     0.176               29   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7      0.925     0.179               26   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75     0.925     0.186               27   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8      0.923     0.169               28   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85     0.922     0.167               31   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9      0.923     0.176               29   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95     0.923     0.168               29   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0      0.923     0.175               30   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  158           184   \n",
       "After RANDOM mitigation N = 3000                   156           181   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5               158           179   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55              158           181   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6               158           186   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65              158           187   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7               158           184   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75              157           184   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8               159           187   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85              159           190   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9               158           187   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95              159           188   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0               158           188   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.065           0.112   \n",
       "After RANDOM mitigation N = 3000                 0.084           0.152   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5             0.067           0.112   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55            0.068           0.112   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6             0.069           0.112   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65            0.068           0.112   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7             0.071           0.112   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75            0.071           0.118   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8             0.067           0.107   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85            0.064           0.107   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9             0.069           0.112   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95            0.066           0.107   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0             0.071           0.112   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.112       0.103       0.084  \n",
       "After RANDOM mitigation N = 3000            0.152       0.137       0.107  \n",
       "After SMOTE N = 3000 p_class 1 = 0.5        0.112       0.104       0.085  \n",
       "After SMOTE N = 3000 p_class 1 = 0.55       0.112       0.105       0.087  \n",
       "After SMOTE N = 3000 p_class 1 = 0.6        0.112       0.107       0.087  \n",
       "After SMOTE N = 3000 p_class 1 = 0.65       0.112       0.105       0.087  \n",
       "After SMOTE N = 3000 p_class 1 = 0.7        0.112       0.109       0.089  \n",
       "After SMOTE N = 3000 p_class 1 = 0.75       0.118       0.109       0.091  \n",
       "After SMOTE N = 3000 p_class 1 = 0.8        0.107       0.105       0.085  \n",
       "After SMOTE N = 3000 p_class 1 = 0.85       0.107       0.103       0.082  \n",
       "After SMOTE N = 3000 p_class 1 = 0.9        0.112       0.107       0.087  \n",
       "After SMOTE N = 3000 p_class 1 = 0.95       0.107       0.103       0.083  \n",
       "After SMOTE N = 3000 p_class 1 = 1.0        0.112       0.111       0.091  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_3000 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_3000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati salvati in false_negatives_K_compas.json\n",
      "‚úÖ Variabili salvate con successo in false_negatives_K_compas.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"false_negatives_K_compas.json\"\n",
    "\n",
    "# Controlla se il file esiste gi√† per evitare di sovrascrivere\n",
    "if os.path.exists(json_filename):\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        false_negatives_data = json.load(f)\n",
    "else:\n",
    "    false_negatives_data = {}\n",
    "\n",
    "# Lista dei diversi metrics_after_fp_SMOTE_XK\n",
    "metrics_dict = {\n",
    "    \"500_run6\": metrics_after_fp_SMOTE_500,\n",
    "    \"1000_run6\": metrics_after_fp_SMOTE_1000,\n",
    "    \"1500_run6\": metrics_after_fp_SMOTE_1500,\n",
    "    \"2000_run6\": metrics_after_fp_SMOTE_2000,\n",
    "    \"2500_run6\": metrics_after_fp_SMOTE_2500,\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni dataset e salviamo i falsi positivi\n",
    "for J, metrics in metrics_dict.items():\n",
    "    false_negatives_data[f\"N={J}\"] = metrics[\"False Negatives\"].to_dict()\n",
    "\n",
    "# Salviamo il JSON aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(false_negatives_data, f, indent=4)\n",
    "\n",
    "print(f\"Dati salvati in {json_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "#per i parametri # Nome del file JSON\n",
    "json_filename = \"false_negatives_K_compas.json\"\n",
    "\n",
    "# Valori da salvare (sostituiscili con i tuoi valori reali)\n",
    "min_sup_run6 = min_sup\n",
    "percentage_run6 = percentage\n",
    "th_redundancy_run6 = pruning\n",
    "K_run6 = K\n",
    "L_run6 = filtered_instances  # Supponiamo sia la lunghezza di filtered_instances\n",
    "\n",
    "# 1Ô∏è‚É£ Caricare i dati esistenti (se il file esiste)\n",
    "try:\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        false_negatives_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    false_negatives_data = {}  # Se il file non esiste, inizializza un dizionario vuoto\n",
    "\n",
    "# 2Ô∏è‚É£ Aggiungere le nuove variabili sotto una chiave dedicata\n",
    "false_negatives_data[\"run6_parameters\"] = {\n",
    "    \"min_sup\": min_sup_run6,\n",
    "    \"percentage\": percentage_run6,\n",
    "    \"th_redundancy\": th_redundancy_run6,\n",
    "    \"K\": percentage,\n",
    "    \"L\": L_run6\n",
    "}\n",
    "\n",
    "# 3Ô∏è‚É£ Salvare il file aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(false_negatives_data, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ Variabili salvate con successo in\", json_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"false_negatives_K_compas.json\"\n",
    "\n",
    "# Caricare i dati dal file JSON\n",
    "with open(json_filename, \"r\") as f:\n",
    "    false_negatives_data = json.load(f)\n",
    "\n",
    "# Estrarre parametri dal JSON\n",
    "run6_params = false_negatives_data.get(\"run6_parameters\", {})\n",
    "min_sup = run6_params.get(\"min_sup\", \"N/A\")\n",
    "percentage = run6_params.get(\"percentage\", \"N/A\")\n",
    "th_redundancy = run6_params.get(\"th_redundancy\", \"N/A\")\n",
    "L = run6_params.get(\"L\", \"N/A\")\n",
    "K = int((percentage / 100) * L)  # K rappresenta il numero di sottogruppi\n",
    "\n",
    "# Lista dei valori di p da 0.5 a 1.0 con step 0.05\n",
    "p_values = np.arange(0.5, 1.05, 0.05)\n",
    "\n",
    "# Definiamo i colori per ogni N\n",
    "colors = [\"blue\", \"red\", \"orange\", \"pink\", \"green\"]\n",
    "labels = [f\"N={n}K\" for n in range(500, 2501, 500)]\n",
    "\n",
    "# Creazione della figura\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig.suptitle(\"FALSE NEGATIVE MITIGATION\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Disegniamo la linea tratteggiata \"Before Mitigation\"\n",
    "before_mitigation = false_negatives_data.get(\"N=500_run6\", {}).get(\"Before Mitigation\", None)\n",
    "if before_mitigation is not None:\n",
    "    ax.axhline(y=before_mitigation, color=\"purple\", linestyle=\"--\", linewidth=2, label=\"Before Mitigation\")\n",
    "\n",
    "# Aggiungere linee verticali per ogni valore di p\n",
    "for p in p_values:\n",
    "    ax.axvline(x=p, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Inizializziamo la lista per la legenda\n",
    "legend_handles = []\n",
    "\n",
    "# Loop sui vari N (da 500 a 2500)\n",
    "for i, n in enumerate(range(500, 2501, 500)):  # da 500 a 2500 con passo 500\n",
    "    N_key = f\"N={n}_run6\"\n",
    "    if N_key not in false_negatives_data:\n",
    "        continue\n",
    "    \n",
    "    data = false_negatives_data[N_key]\n",
    "    \n",
    "    # Estrarre i valori di falsi positivi per ogni p\n",
    "    false_negatives = [\n",
    "        data.get(f\"After SMOTE N = {n} p_class 1 = {round(p, 2)}\", None) \n",
    "        for p in p_values\n",
    "    ]\n",
    "    \n",
    "    # Filtriamo solo i valori validi\n",
    "    p_values_filtered = [p for j, p in enumerate(p_values) if false_negatives[j] is not None]\n",
    "    false_negatives_filtered = [fp for fp in false_negatives if fp is not None]\n",
    "    \n",
    "    # Se ci sono dati validi, plottiamo la linea\n",
    "    if false_negatives_filtered:\n",
    "        line, = ax.plot(\n",
    "            p_values_filtered, false_negatives_filtered, \n",
    "            marker=\"o\", linestyle=\"-\", color=colors[i], label=labels[i]\n",
    "        )\n",
    "        legend_handles.append(line)\n",
    "\n",
    "# Impostazioni asse\n",
    "ax.set_title(f\"Minsup = {min_sup}, pruning = {th_redundancy}, K% = {percentage}, subgroups: {K}/{L}\")\n",
    "ax.set_xlabel(\"p_class 0\")\n",
    "ax.set_ylabel(\"False Negatives\")\n",
    "ax.grid()\n",
    "\n",
    "# Aggiungere la leggenda\n",
    "#ax.legend(handles=legend_handles, loc=\"upper right\", fontsize=10, frameon=True, title=\"Legend\")\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
