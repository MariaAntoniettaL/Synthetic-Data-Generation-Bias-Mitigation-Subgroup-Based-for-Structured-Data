{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_compas import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import torch\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "from divexplorer.outcomes import get_false_negative_rate_outcome\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smote_nc = SMOTENC(categorical_features=categorical_features,random_state=seed)\\nX_to_SMOTE, y_to_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\ncount_1 = y_to_SMOTE.sum()\\ncount_0 = len(y_to_SMOTE)-count_1\\ncount_0, count_1'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''smote_nc = SMOTENC(categorical_features=categorical_features,random_state=seed)\n",
    "X_to_SMOTE, y_to_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "count_1 = y_to_SMOTE.sum()\n",
    "count_0 = len(y_to_SMOTE)-count_1\n",
    "count_0, count_1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il CSV\n",
    "df = pd.read_csv(\"cox-violent-parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning = 0.00\n",
    "epsilon = pruning\n",
    "min_sup = 0.45\n",
    "percentage = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "VALIDATION SET ROWS:  2439\n",
      "HOLDOUT SET ROWS:  2440\n",
      "TEST SET ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) \n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0])\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "VALIDATION SET ROWS:  2439\n",
      "HOLDOUT SET ROWS:  2440\n",
      "TEST SET ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosit√† precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_no_Violent_Recidivist = df_train_enc.drop(columns = 'Violent_Recidivist')\n",
    "plt.figure(figsize=(4, 3))\n",
    "g = sns.heatmap(df_train_no_Violent_Recidivist.corr(),\n",
    "                annot = False,\n",
    "                cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.927     0.032                0.002   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.983                4              175   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       2439  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "X_train = df_train_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_train = df_train_enc['Violent_Recidivist']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_test = df_test_enc['Violent_Recidivist']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_val = df_val_enc['Violent_Recidivist']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_holdout = df_holdout_enc['Violent_Recidivist']\n",
    "\n",
    "classifier_train = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()\n",
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione √® giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  race  Recidivism_Risk  Risk_Level  Violent_Recidivism_Risk  \\\n",
       "10676    1     0                4           1                        2   \n",
       "13123    1     2                1           1                        1   \n",
       "2611     1     0                8           0                        6   \n",
       "7945     1     2                1           1                        1   \n",
       "5727     1     2                6           2                        6   \n",
       "\n",
       "       Violent_Risk_Level  Juvenile_Offenses  age_group  Prior_Offensesgroup  \\\n",
       "10676                   1                  0          3                    7   \n",
       "13123                   1                  0          3                    0   \n",
       "2611                    2                  2          2                    1   \n",
       "7945                    1                  0          5                    0   \n",
       "5727                    2                  0          1                    0   \n",
       "\n",
       "       y_val_true  y_pred  \n",
       "10676           0       0  \n",
       "13123           0       0  \n",
       "2611            0       0  \n",
       "7945            0       0  \n",
       "5727            0       0  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set, queste mi servono solo per il div explorer che ha bisogno di ground truth e predizioni\n",
    "y_pred_val = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Violent_Recidivist</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>fn</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>6-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>35-44</td>\n",
       "      <td>11-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>65-100</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex              race  Recidivism_Risk  Violent_Recidivist Risk_Level  \\\n",
       "10676  Male  African-American                4                   0        Low   \n",
       "13123  Male         Caucasian                1                   0        Low   \n",
       "2611   Male  African-American                8                   0       High   \n",
       "7945   Male         Caucasian                1                   0        Low   \n",
       "5727   Male         Caucasian                6                   0     Medium   \n",
       "\n",
       "       Violent_Recidivism_Risk Violent_Risk_Level  Juvenile_Offenses  \\\n",
       "10676                        2                Low                  0   \n",
       "13123                        1                Low                  0   \n",
       "2611                         6             Medium                  2   \n",
       "7945                         1                Low                  0   \n",
       "5727                         6             Medium                  0   \n",
       "\n",
       "      age_group Prior_Offensesgroup  fn  y_pred  accuracy  \n",
       "10676     45-54                6-10 NaN       0         1  \n",
       "13123     45-54                 0-5 NaN       0         1  \n",
       "2611      35-44               11-15 NaN       0         1  \n",
       "7945     65-100                 0-5 NaN       0         1  \n",
       "5727      25-34                 0-5 NaN       0         1  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]\n",
    "\n",
    "df_val_class[\"fn\"] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature \"fn\" a df_val non encoded\n",
    "df_val[\"fn\"] = df_val_class[\"fn\"]\n",
    "\n",
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione √® giusta 0 se la predizione √® sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['accuracy'] = (df_val_class['y_val_true']==df_val_class['y_pred']).astype(int)\n",
    "df_val.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI CONDOTTA CON LA FEATURE FP (PASSATA A BOOLEAN OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Violent_Recidivist</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>fn</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>6-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>35-44</td>\n",
       "      <td>11-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>65-100</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>55-64</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>9</td>\n",
       "      <td>High</td>\n",
       "      <td>21</td>\n",
       "      <td>25-34</td>\n",
       "      <td>16-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>55-64</td>\n",
       "      <td>11-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2439 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sex              race  Recidivism_Risk  Violent_Recidivist  \\\n",
       "10676    Male  African-American                4                   0   \n",
       "13123    Male         Caucasian                1                   0   \n",
       "2611     Male  African-American                8                   0   \n",
       "7945     Male         Caucasian                1                   0   \n",
       "5727     Male         Caucasian                6                   0   \n",
       "...       ...               ...              ...                 ...   \n",
       "4183     Male         Caucasian                1                   0   \n",
       "9445     Male         Caucasian                8                   0   \n",
       "8674   Female         Caucasian                5                   0   \n",
       "6392     Male          Hispanic                1                   0   \n",
       "6524   Female         Caucasian                5                   0   \n",
       "\n",
       "      Risk_Level  Violent_Recidivism_Risk Violent_Risk_Level  \\\n",
       "10676        Low                        2                Low   \n",
       "13123        Low                        1                Low   \n",
       "2611        High                        6             Medium   \n",
       "7945         Low                        1                Low   \n",
       "5727      Medium                        6             Medium   \n",
       "...          ...                      ...                ...   \n",
       "4183         Low                        1                Low   \n",
       "9445        High                        9               High   \n",
       "8674      Medium                        4                Low   \n",
       "6392         Low                        1                Low   \n",
       "6524      Medium                        2                Low   \n",
       "\n",
       "       Juvenile_Offenses age_group Prior_Offensesgroup  fn  y_pred  accuracy  \n",
       "10676                  0     45-54                6-10 NaN       0         1  \n",
       "13123                  0     45-54                 0-5 NaN       0         1  \n",
       "2611                   2     35-44               11-15 NaN       0         1  \n",
       "7945                   0    65-100                 0-5 NaN       0         1  \n",
       "5727                   0     25-34                 0-5 NaN       0         1  \n",
       "...                  ...       ...                 ...  ..     ...       ...  \n",
       "4183                   0     55-64                 0-5 NaN       0         1  \n",
       "9445                  21     25-34               16-20 NaN       0         1  \n",
       "8674                   0     55-64               11-15 NaN       0         1  \n",
       "6392                   0     35-44                 0-5 NaN       0         1  \n",
       "6524                   0     35-44                 0-5 NaN       0         1  \n",
       "\n",
       "[2439 rows x 13 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['sex', 'race', 'Recidivism_Risk', 'Risk_Level', 'Violent_Recidivism_Risk', 'Violent_Risk_Level', 'Juvenile_Offenses', 'age_group', 'Prior_Offensesgroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_div</th>\n",
       "      <th>fn_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.454</td>\n",
       "      <td>(Prior_Offensesgroup=0-5, Violent_Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.425</td>\n",
       "      <td>2</td>\n",
       "      <td>1107.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.462</td>\n",
       "      <td>(Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.390</td>\n",
       "      <td>1</td>\n",
       "      <td>1126.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.468</td>\n",
       "      <td>(sex=Male, Violent_Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.332</td>\n",
       "      <td>2</td>\n",
       "      <td>1141.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.847</td>\n",
       "      <td>(Juvenile_Offenses=0)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.309</td>\n",
       "      <td>1</td>\n",
       "      <td>2065.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.569</td>\n",
       "      <td>(Juvenile_Offenses=0, Violent_Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.244</td>\n",
       "      <td>2</td>\n",
       "      <td>1389.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support                                            itemset    fn  fn_div  \\\n",
       "0    0.454  (Prior_Offensesgroup=0-5, Violent_Risk_Level=Low) 1.000   0.006   \n",
       "1    0.462                                   (Risk_Level=Low) 1.000   0.006   \n",
       "2    0.468                 (sex=Male, Violent_Risk_Level=Low) 1.000   0.006   \n",
       "3    0.847                              (Juvenile_Offenses=0) 1.000   0.006   \n",
       "4    0.569      (Juvenile_Offenses=0, Violent_Risk_Level=Low) 1.000   0.006   \n",
       "\n",
       "   fn_t  length  support_count  \n",
       "0 0.425       2       1107.000  \n",
       "1 0.390       1       1126.000  \n",
       "2 0.332       2       1141.000  \n",
       "3 0.309       1       2065.000  \n",
       "4 0.244       2       1389.000  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_diver = DivergenceExplorer(df_val)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "FP_fm = FP_fm.sort_values(by=[\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_div</th>\n",
       "      <th>fn_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.454</td>\n",
       "      <td>(Prior_Offensesgroup=0-5, Violent_Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.425</td>\n",
       "      <td>2</td>\n",
       "      <td>1107.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.462</td>\n",
       "      <td>(Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.390</td>\n",
       "      <td>1</td>\n",
       "      <td>1126.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.468</td>\n",
       "      <td>(sex=Male, Violent_Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.332</td>\n",
       "      <td>2</td>\n",
       "      <td>1141.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.847</td>\n",
       "      <td>(Juvenile_Offenses=0)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.309</td>\n",
       "      <td>1</td>\n",
       "      <td>2065.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.569</td>\n",
       "      <td>(Juvenile_Offenses=0, Violent_Risk_Level=Low)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.244</td>\n",
       "      <td>2</td>\n",
       "      <td>1389.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support                                            itemset    fn  fn_div  \\\n",
       "0    0.454  (Prior_Offensesgroup=0-5, Violent_Risk_Level=Low) 1.000   0.006   \n",
       "1    0.462                                   (Risk_Level=Low) 1.000   0.006   \n",
       "2    0.468                 (sex=Male, Violent_Risk_Level=Low) 1.000   0.006   \n",
       "3    0.847                              (Juvenile_Offenses=0) 1.000   0.006   \n",
       "4    0.569      (Juvenile_Offenses=0, Violent_Risk_Level=Low) 1.000   0.006   \n",
       "\n",
       "   fn_t  length  support_count  \n",
       "0 0.425       2       1107.000  \n",
       "1 0.390       1       1126.000  \n",
       "2 0.332       2       1141.000  \n",
       "3 0.309       1       2065.000  \n",
       "4 0.244       2       1389.000  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp = df_pruned_fp = FP_fm\n",
    "df_pruned_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 15\n",
      "total problematic 13\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_fp)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_fp[(df_pruned_fp[\"fn_div\"] > 0) ])#& (df_pruned_fp[\"fn_t\"] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (15, 7)\n",
      "Dim pruned th_redundancy  (15, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_fp.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset_and_or li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "df_holdout_filtered_solo0 = df_holdout_filtered[df_holdout_filtered['Violent_Recidivist']==0]\n",
    "\n",
    "\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered_solo0, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "df_holdout_filtered = df_holdout_filtered_solo0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646\n"
     ]
    }
   ],
   "source": [
    "print(len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "TRAIN SET MITIGATED ROWS:  11621\n",
      "VALIDATION SET ROWS:  2439\n",
      "FILTERED DF holdout ROWS:  646\n",
      "TEST SET FILTERED ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['Violent_Recidivist']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "#cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646\n",
      "verifica : 646\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"Violent_Recidivist\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.927     0.032                0.002   \n",
       "After Mitigation(K=5, fp)     0.927     0.043                0.002   \n",
       "After RANDOM mitigation       0.927     0.053                0.002   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.983                4   \n",
       "After Mitigation(K=5, fp)                0.978                4   \n",
       "After RANDOM mitigation                  0.972                5   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      175       10975       2439  \n",
       "After Mitigation(K=5, fp)              174       11621       2439  \n",
       "After RANDOM mitigation                173       11621       2439  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE\n",
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>646.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>646.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.927     0.032             0.011   \n",
       "After Mitigation(K=5 fp)            0.927     0.043             0.014   \n",
       "After RANDOM Mitigation(K=5 fp)     0.927     0.053             0.018   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.017               0.015   \n",
       "After Mitigation(K=5 fp)           0.022               0.020   \n",
       "After RANDOM Mitigation(K=5 fp)    0.028               0.022   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.011               0.011   \n",
       "After Mitigation(K=5 fp)                      0.014               0.014   \n",
       "After RANDOM Mitigation(K=5 fp)               0.018               0.018   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)               646.000  \n",
       "After RANDOM Mitigation(K=5 fp)        646.000  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class[\"fn\"] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature \"fn\" a df_val non encoded\n",
    "df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp = df_pruned_fp = FP_fm\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class[\"fn\"] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature \"fn\" a df_val non encoded\n",
    "df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp = df_pruned_fp = FP_fm\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline1  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fp_div_list_baseline1\n",
    "\n",
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class[\"fn\"] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature \"fn\" a df_val non encoded\n",
    "df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "#attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "df_pruned_fp = FP_fm\n",
    "df_pruned_fp = df_pruned_fp = FP_fm\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fp_div_list_random_per_confrontare_con_baseline1\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline1 = abs(sum(fp_div_list_baseline1) / len(fp_div_list_baseline1))\n",
    "media_fp_div_list_baseline1_primi10 = abs(sum(fp_div_list_baseline1[:10]) / len(fp_div_list_baseline1[:10]))\n",
    "media_fp_div_list_baseline1_primi20 = abs(sum(fp_div_list_baseline1[:20]) / len(fp_div_list_baseline1[:20]))\n",
    "media_fp_div_list_baseline1_primi40 = abs(sum(fp_div_list_baseline1[:40]) / len(fp_div_list_baseline1[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_baseline1 = max(abs(x) for x in fp_div_list_baseline1)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_fp_div_list_baseline1, fp_div_massimo_valore_assoluto_fp_div_baseline1,\n",
    "        media_fp_div_list_baseline1_primi10, media_fp_div_list_baseline1_primi20, media_fp_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGUE CODICE USANDO SMOTE \n",
    "DIVIDO IN TRAIN, TEST E VALIDATION -- ora uso quelli gia esistenti\n",
    "DIV EXPLORER SUL VALIDATION  -- gi√† fatto \n",
    "GENERO NUOVI DATI CON SMOTE a partire dai dati di divexplorer sul validation\n",
    "INSERISCO QUESTI NUOVI DATI NEL TRAIN SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p √® la probabilit√† che il campione simulato sia di classe 0 qui (perch√® voglio diminuire il numero di falsi positivi)\n",
    "- FISSO p VARIA N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 996\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = [\"fn\", 'y_pred', 'accuracy', \"Violent_Recidivist\"], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered[\"Violent_Recidivist\"]\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 1, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 882)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered[\"Violent_Recidivist\"].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = np.arange(0.5, 1.05, 0.05)\n",
    "p_values = np.round(p_values, 2).tolist()\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N come holdout filtered e targeted acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 646</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.972</td>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.85</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.9</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.983</td>\n",
       "      <td>9</td>\n",
       "      <td>175</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.95</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.983</td>\n",
       "      <td>16</td>\n",
       "      <td>175</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 1.0</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.989</td>\n",
       "      <td>14</td>\n",
       "      <td>176</td>\n",
       "      <td>11621</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.927     0.032                0.002   \n",
       "After RANDOM mitigation N = 646          0.927     0.053                0.002   \n",
       "After SMOTE N = 646 p_class 1 = 0.5      0.927     0.032                0.002   \n",
       "After SMOTE N = 646 p_class 1 = 0.55     0.927     0.043                0.002   \n",
       "After SMOTE N = 646 p_class 1 = 0.6      0.927     0.043                0.001   \n",
       "After SMOTE N = 646 p_class 1 = 0.65     0.927     0.053                0.003   \n",
       "After SMOTE N = 646 p_class 1 = 0.7      0.927     0.043                0.002   \n",
       "After SMOTE N = 646 p_class 1 = 0.75     0.927     0.043                0.002   \n",
       "After SMOTE N = 646 p_class 1 = 0.8      0.927     0.043                0.001   \n",
       "After SMOTE N = 646 p_class 1 = 0.85     0.927     0.032                0.002   \n",
       "After SMOTE N = 646 p_class 1 = 0.9      0.925     0.032                0.004   \n",
       "After SMOTE N = 646 p_class 1 = 0.95     0.922     0.030                0.007   \n",
       "After SMOTE N = 646 p_class 1 = 1.0      0.922     0.021                0.006   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.983                4   \n",
       "After RANDOM mitigation N = 646                     0.972                5   \n",
       "After SMOTE N = 646 p_class 1 = 0.5                 0.983                4   \n",
       "After SMOTE N = 646 p_class 1 = 0.55                0.978                4   \n",
       "After SMOTE N = 646 p_class 1 = 0.6                 0.978                3   \n",
       "After SMOTE N = 646 p_class 1 = 0.65                0.972                6   \n",
       "After SMOTE N = 646 p_class 1 = 0.7                 0.978                4   \n",
       "After SMOTE N = 646 p_class 1 = 0.75                0.978                5   \n",
       "After SMOTE N = 646 p_class 1 = 0.8                 0.978                3   \n",
       "After SMOTE N = 646 p_class 1 = 0.85                0.983                4   \n",
       "After SMOTE N = 646 p_class 1 = 0.9                 0.983                9   \n",
       "After SMOTE N = 646 p_class 1 = 0.95                0.983               16   \n",
       "After SMOTE N = 646 p_class 1 = 1.0                 0.989               14   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 175       10975       2439  \n",
       "After RANDOM mitigation N = 646                   173       11621       2439  \n",
       "After SMOTE N = 646 p_class 1 = 0.5               175       11621       2439  \n",
       "After SMOTE N = 646 p_class 1 = 0.55              174       11621       2439  \n",
       "After SMOTE N = 646 p_class 1 = 0.6               174       11621       2439  \n",
       "After SMOTE N = 646 p_class 1 = 0.65              173       11621       2439  \n",
       "After SMOTE N = 646 p_class 1 = 0.7               174       11621       2439  \n",
       "After SMOTE N = 646 p_class 1 = 0.75              174       11621       2439  \n",
       "After SMOTE N = 646 p_class 1 = 0.8               174       11621       2439  \n",
       "After SMOTE N = 646 p_class 1 = 0.85              175       11621       2439  \n",
       "After SMOTE N = 646 p_class 1 = 0.9               175       11621       2439  \n",
       "After SMOTE N = 646 p_class 1 = 0.95              175       11621       2439  \n",
       "After SMOTE N = 646 p_class 1 = 1.0               176       11621       2439  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 646</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "      <td>178</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>179</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.85</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.9</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.032</td>\n",
       "      <td>9</td>\n",
       "      <td>175</td>\n",
       "      <td>184</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 0.95</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.030</td>\n",
       "      <td>16</td>\n",
       "      <td>175</td>\n",
       "      <td>191</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 646 p_class 1 = 1.0</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.021</td>\n",
       "      <td>14</td>\n",
       "      <td>176</td>\n",
       "      <td>190</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.927     0.032                4   \n",
       "After RANDOM mitigation N = 646          0.927     0.053                5   \n",
       "After SMOTE N = 646 p_class 1 = 0.5      0.927     0.032                4   \n",
       "After SMOTE N = 646 p_class 1 = 0.55     0.927     0.043                4   \n",
       "After SMOTE N = 646 p_class 1 = 0.6      0.927     0.043                3   \n",
       "After SMOTE N = 646 p_class 1 = 0.65     0.927     0.053                6   \n",
       "After SMOTE N = 646 p_class 1 = 0.7      0.927     0.043                4   \n",
       "After SMOTE N = 646 p_class 1 = 0.75     0.927     0.043                5   \n",
       "After SMOTE N = 646 p_class 1 = 0.8      0.927     0.043                3   \n",
       "After SMOTE N = 646 p_class 1 = 0.85     0.927     0.032                4   \n",
       "After SMOTE N = 646 p_class 1 = 0.9      0.925     0.032                9   \n",
       "After SMOTE N = 646 p_class 1 = 0.95     0.922     0.030               16   \n",
       "After SMOTE N = 646 p_class 1 = 1.0      0.922     0.021               14   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 175           179   \n",
       "After RANDOM mitigation N = 646                   173           178   \n",
       "After SMOTE N = 646 p_class 1 = 0.5               175           179   \n",
       "After SMOTE N = 646 p_class 1 = 0.55              174           178   \n",
       "After SMOTE N = 646 p_class 1 = 0.6               174           177   \n",
       "After SMOTE N = 646 p_class 1 = 0.65              173           179   \n",
       "After SMOTE N = 646 p_class 1 = 0.7               174           178   \n",
       "After SMOTE N = 646 p_class 1 = 0.75              174           179   \n",
       "After SMOTE N = 646 p_class 1 = 0.8               174           177   \n",
       "After SMOTE N = 646 p_class 1 = 0.85              175           179   \n",
       "After SMOTE N = 646 p_class 1 = 0.9               175           184   \n",
       "After SMOTE N = 646 p_class 1 = 0.95              175           191   \n",
       "After SMOTE N = 646 p_class 1 = 1.0               176           190   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.011           0.017   \n",
       "After RANDOM mitigation N = 646                 0.018           0.028   \n",
       "After SMOTE N = 646 p_class 1 = 0.5             0.011           0.017   \n",
       "After SMOTE N = 646 p_class 1 = 0.55            0.014           0.022   \n",
       "After SMOTE N = 646 p_class 1 = 0.6             0.014           0.022   \n",
       "After SMOTE N = 646 p_class 1 = 0.65            0.013           0.028   \n",
       "After SMOTE N = 646 p_class 1 = 0.7             0.014           0.022   \n",
       "After SMOTE N = 646 p_class 1 = 0.75            0.014           0.022   \n",
       "After SMOTE N = 646 p_class 1 = 0.8             0.010           0.022   \n",
       "After SMOTE N = 646 p_class 1 = 0.85            0.010           0.017   \n",
       "After SMOTE N = 646 p_class 1 = 0.9             0.011           0.017   \n",
       "After SMOTE N = 646 p_class 1 = 0.95            0.011           0.017   \n",
       "After SMOTE N = 646 p_class 1 = 1.0             0.008           0.011   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.015       0.011       0.011  \n",
       "After RANDOM mitigation N = 646            0.022       0.018       0.018  \n",
       "After SMOTE N = 646 p_class 1 = 0.5        0.015       0.011       0.011  \n",
       "After SMOTE N = 646 p_class 1 = 0.55       0.020       0.014       0.014  \n",
       "After SMOTE N = 646 p_class 1 = 0.6        0.020       0.014       0.014  \n",
       "After SMOTE N = 646 p_class 1 = 0.65       0.018       0.013       0.013  \n",
       "After SMOTE N = 646 p_class 1 = 0.7        0.020       0.014       0.014  \n",
       "After SMOTE N = 646 p_class 1 = 0.75       0.020       0.014       0.014  \n",
       "After SMOTE N = 646 p_class 1 = 0.8        0.013       0.010       0.010  \n",
       "After SMOTE N = 646 p_class 1 = 0.85       0.015       0.010       0.010  \n",
       "After SMOTE N = 646 p_class 1 = 0.9        0.015       0.011       0.011  \n",
       "After SMOTE N = 646 p_class 1 = 0.95       0.015       0.011       0.011  \n",
       "After SMOTE N = 646 p_class 1 = 1.0        0.010       0.008       0.008  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_confronto = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_confronto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 500</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.966</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.8</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.85</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.9</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.978</td>\n",
       "      <td>8</td>\n",
       "      <td>174</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.95</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.983</td>\n",
       "      <td>11</td>\n",
       "      <td>175</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 1.0</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.989</td>\n",
       "      <td>12</td>\n",
       "      <td>176</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.927     0.032                0.002   \n",
       "After RANDOM mitigation N = 500          0.926     0.032                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 0.5      0.927     0.053                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 0.55     0.927     0.043                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 0.6      0.927     0.063                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 0.65     0.927     0.043                0.001   \n",
       "After SMOTE N = 500 p_class 1 = 0.7      0.927     0.043                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 0.75     0.927     0.032                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 0.8      0.926     0.032                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 0.85     0.927     0.043                0.001   \n",
       "After SMOTE N = 500 p_class 1 = 0.9      0.925     0.042                0.004   \n",
       "After SMOTE N = 500 p_class 1 = 0.95     0.924     0.031                0.005   \n",
       "After SMOTE N = 500 p_class 1 = 1.0      0.923     0.021                0.005   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.983                4   \n",
       "After RANDOM mitigation N = 500                     0.983                5   \n",
       "After SMOTE N = 500 p_class 1 = 0.5                 0.972                4   \n",
       "After SMOTE N = 500 p_class 1 = 0.55                0.978                4   \n",
       "After SMOTE N = 500 p_class 1 = 0.6                 0.966                5   \n",
       "After SMOTE N = 500 p_class 1 = 0.65                0.978                3   \n",
       "After SMOTE N = 500 p_class 1 = 0.7                 0.978                5   \n",
       "After SMOTE N = 500 p_class 1 = 0.75                0.983                4   \n",
       "After SMOTE N = 500 p_class 1 = 0.8                 0.983                5   \n",
       "After SMOTE N = 500 p_class 1 = 0.85                0.978                3   \n",
       "After SMOTE N = 500 p_class 1 = 0.9                 0.978                8   \n",
       "After SMOTE N = 500 p_class 1 = 0.95                0.983               11   \n",
       "After SMOTE N = 500 p_class 1 = 1.0                 0.989               12   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 175       10975       2439  \n",
       "After RANDOM mitigation N = 500                   175       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.5               173       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.55              174       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.6               172       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.65              174       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.7               174       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.75              175       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.8               175       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.85              174       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.9               174       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.95              175       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 1.0               176       11475       2439  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 500\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 500</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.032</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>180</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.063</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>177</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>179</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.8</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.032</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>180</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.85</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.9</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.042</td>\n",
       "      <td>8</td>\n",
       "      <td>174</td>\n",
       "      <td>182</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.95</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.031</td>\n",
       "      <td>11</td>\n",
       "      <td>175</td>\n",
       "      <td>186</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 1.0</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.021</td>\n",
       "      <td>12</td>\n",
       "      <td>176</td>\n",
       "      <td>188</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.927     0.032                4   \n",
       "After RANDOM mitigation N = 500          0.926     0.032                5   \n",
       "After SMOTE N = 500 p_class 1 = 0.5      0.927     0.053                4   \n",
       "After SMOTE N = 500 p_class 1 = 0.55     0.927     0.043                4   \n",
       "After SMOTE N = 500 p_class 1 = 0.6      0.927     0.063                5   \n",
       "After SMOTE N = 500 p_class 1 = 0.65     0.927     0.043                3   \n",
       "After SMOTE N = 500 p_class 1 = 0.7      0.927     0.043                5   \n",
       "After SMOTE N = 500 p_class 1 = 0.75     0.927     0.032                4   \n",
       "After SMOTE N = 500 p_class 1 = 0.8      0.926     0.032                5   \n",
       "After SMOTE N = 500 p_class 1 = 0.85     0.927     0.043                3   \n",
       "After SMOTE N = 500 p_class 1 = 0.9      0.925     0.042                8   \n",
       "After SMOTE N = 500 p_class 1 = 0.95     0.924     0.031               11   \n",
       "After SMOTE N = 500 p_class 1 = 1.0      0.923     0.021               12   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 175           179   \n",
       "After RANDOM mitigation N = 500                   175           180   \n",
       "After SMOTE N = 500 p_class 1 = 0.5               173           177   \n",
       "After SMOTE N = 500 p_class 1 = 0.55              174           178   \n",
       "After SMOTE N = 500 p_class 1 = 0.6               172           177   \n",
       "After SMOTE N = 500 p_class 1 = 0.65              174           177   \n",
       "After SMOTE N = 500 p_class 1 = 0.7               174           179   \n",
       "After SMOTE N = 500 p_class 1 = 0.75              175           179   \n",
       "After SMOTE N = 500 p_class 1 = 0.8               175           180   \n",
       "After SMOTE N = 500 p_class 1 = 0.85              174           177   \n",
       "After SMOTE N = 500 p_class 1 = 0.9               174           182   \n",
       "After SMOTE N = 500 p_class 1 = 0.95              175           186   \n",
       "After SMOTE N = 500 p_class 1 = 1.0               176           188   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.011           0.017   \n",
       "After RANDOM mitigation N = 500                 0.018           0.028   \n",
       "After SMOTE N = 500 p_class 1 = 0.5             0.013           0.028   \n",
       "After SMOTE N = 500 p_class 1 = 0.55            0.014           0.022   \n",
       "After SMOTE N = 500 p_class 1 = 0.6             0.015           0.034   \n",
       "After SMOTE N = 500 p_class 1 = 0.65            0.014           0.022   \n",
       "After SMOTE N = 500 p_class 1 = 0.7             0.014           0.022   \n",
       "After SMOTE N = 500 p_class 1 = 0.75            0.011           0.017   \n",
       "After SMOTE N = 500 p_class 1 = 0.8             0.011           0.017   \n",
       "After SMOTE N = 500 p_class 1 = 0.85            0.014           0.022   \n",
       "After SMOTE N = 500 p_class 1 = 0.9             0.014           0.022   \n",
       "After SMOTE N = 500 p_class 1 = 0.95            0.011           0.017   \n",
       "After SMOTE N = 500 p_class 1 = 1.0             0.008           0.011   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.015       0.011       0.011  \n",
       "After RANDOM mitigation N = 500            0.022       0.018       0.018  \n",
       "After SMOTE N = 500 p_class 1 = 0.5        0.018       0.013       0.013  \n",
       "After SMOTE N = 500 p_class 1 = 0.55       0.020       0.014       0.014  \n",
       "After SMOTE N = 500 p_class 1 = 0.6        0.021       0.015       0.015  \n",
       "After SMOTE N = 500 p_class 1 = 0.65       0.020       0.014       0.014  \n",
       "After SMOTE N = 500 p_class 1 = 0.7        0.020       0.014       0.014  \n",
       "After SMOTE N = 500 p_class 1 = 0.75       0.015       0.011       0.011  \n",
       "After SMOTE N = 500 p_class 1 = 0.8        0.015       0.011       0.011  \n",
       "After SMOTE N = 500 p_class 1 = 0.85       0.020       0.014       0.014  \n",
       "After SMOTE N = 500 p_class 1 = 0.9        0.020       0.014       0.014  \n",
       "After SMOTE N = 500 p_class 1 = 0.95       0.015       0.011       0.011  \n",
       "After SMOTE N = 500 p_class 1 = 1.0        0.010       0.008       0.008  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.55</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.978</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.7</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.978</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.8</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.989</td>\n",
       "      <td>10</td>\n",
       "      <td>176</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.85</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.978</td>\n",
       "      <td>14</td>\n",
       "      <td>174</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.9</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.978</td>\n",
       "      <td>18</td>\n",
       "      <td>174</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.95</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.989</td>\n",
       "      <td>20</td>\n",
       "      <td>176</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 1.0</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.983</td>\n",
       "      <td>24</td>\n",
       "      <td>175</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.927     0.032   \n",
       "After RANDOM mitigation N = 1000          0.928     0.054   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5      0.927     0.032   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55     0.928     0.054   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6      0.927     0.033   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65     0.927     0.043   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7      0.926     0.043   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75     0.927     0.043   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8      0.924     0.021   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85     0.923     0.041   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9      0.921     0.040   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95     0.920     0.020   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0      0.918     0.029   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.002   \n",
       "After RANDOM mitigation N = 1000                     0.001   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5                 0.002   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55                0.001   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6                 0.001   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65                0.001   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7                 0.003   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75                0.002   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8                 0.004   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85                0.006   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9                 0.008   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95                0.009   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0                 0.011   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.983                4   \n",
       "After RANDOM mitigation N = 1000                     0.972                3   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5                 0.983                4   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55                0.972                2   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6                 0.983                2   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65                0.978                3   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7                 0.978                6   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75                0.978                4   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8                 0.989               10   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85                0.978               14   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9                 0.978               18   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95                0.989               20   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0                 0.983               24   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  175       10975       2439  \n",
       "After RANDOM mitigation N = 1000                   173       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.5               175       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.55              173       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.6               175       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.65              174       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.7               174       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.75              174       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.8               176       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.85              174       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.9               174       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.95              176       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 1.0               175       11975       2439  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.55</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>177</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.7</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>180</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.75</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.8</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.021</td>\n",
       "      <td>10</td>\n",
       "      <td>176</td>\n",
       "      <td>186</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.85</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.041</td>\n",
       "      <td>14</td>\n",
       "      <td>174</td>\n",
       "      <td>188</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.9</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.040</td>\n",
       "      <td>18</td>\n",
       "      <td>174</td>\n",
       "      <td>192</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.95</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.020</td>\n",
       "      <td>20</td>\n",
       "      <td>176</td>\n",
       "      <td>196</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 1.0</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.029</td>\n",
       "      <td>24</td>\n",
       "      <td>175</td>\n",
       "      <td>199</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.927     0.032                4   \n",
       "After RANDOM mitigation N = 1000          0.928     0.054                3   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5      0.927     0.032                4   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55     0.928     0.054                2   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6      0.927     0.033                2   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65     0.927     0.043                3   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7      0.926     0.043                6   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75     0.927     0.043                4   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8      0.924     0.021               10   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85     0.923     0.041               14   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9      0.921     0.040               18   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95     0.920     0.020               20   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0      0.918     0.029               24   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  175           179   \n",
       "After RANDOM mitigation N = 1000                   173           176   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5               175           179   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55              173           175   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6               175           177   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65              174           177   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7               174           180   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75              174           178   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8               176           186   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85              174           188   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9               174           192   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95              176           196   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0               175           199   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.011           0.017   \n",
       "After RANDOM mitigation N = 1000                 0.018           0.028   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5             0.011           0.017   \n",
       "After SMOTE N = 1000 p_class 1 = 0.55            0.017           0.028   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6             0.011           0.017   \n",
       "After SMOTE N = 1000 p_class 1 = 0.65            0.014           0.022   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7             0.014           0.022   \n",
       "After SMOTE N = 1000 p_class 1 = 0.75            0.010           0.022   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8             0.008           0.011   \n",
       "After SMOTE N = 1000 p_class 1 = 0.85            0.014           0.022   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9             0.014           0.022   \n",
       "After SMOTE N = 1000 p_class 1 = 0.95            0.008           0.011   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0             0.011           0.017   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.015       0.011       0.011  \n",
       "After RANDOM mitigation N = 1000            0.022       0.018       0.018  \n",
       "After SMOTE N = 1000 p_class 1 = 0.5        0.015       0.011       0.011  \n",
       "After SMOTE N = 1000 p_class 1 = 0.55       0.025       0.017       0.017  \n",
       "After SMOTE N = 1000 p_class 1 = 0.6        0.015       0.011       0.011  \n",
       "After SMOTE N = 1000 p_class 1 = 0.65       0.020       0.014       0.014  \n",
       "After SMOTE N = 1000 p_class 1 = 0.7        0.020       0.014       0.014  \n",
       "After SMOTE N = 1000 p_class 1 = 0.75       0.013       0.010       0.010  \n",
       "After SMOTE N = 1000 p_class 1 = 0.8        0.010       0.008       0.008  \n",
       "After SMOTE N = 1000 p_class 1 = 0.85       0.020       0.014       0.014  \n",
       "After SMOTE N = 1000 p_class 1 = 0.9        0.020       0.014       0.014  \n",
       "After SMOTE N = 1000 p_class 1 = 0.95       0.010       0.008       0.008  \n",
       "After SMOTE N = 1000 p_class 1 = 1.0        0.015       0.011       0.011  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_1000 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1500</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.6</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.978</td>\n",
       "      <td>7</td>\n",
       "      <td>174</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.65</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.978</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.7</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.983</td>\n",
       "      <td>11</td>\n",
       "      <td>175</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.75</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.978</td>\n",
       "      <td>10</td>\n",
       "      <td>174</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.8</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.972</td>\n",
       "      <td>14</td>\n",
       "      <td>173</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.85</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.966</td>\n",
       "      <td>22</td>\n",
       "      <td>172</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.9</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.989</td>\n",
       "      <td>24</td>\n",
       "      <td>176</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.95</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.972</td>\n",
       "      <td>34</td>\n",
       "      <td>173</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 1.0</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.978</td>\n",
       "      <td>35</td>\n",
       "      <td>174</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.927     0.032   \n",
       "After RANDOM mitigation N = 1500          0.928     0.054   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5      0.927     0.033   \n",
       "After SMOTE N = 1500 p_class 1 = 0.55     0.927     0.033   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6      0.926     0.042   \n",
       "After SMOTE N = 1500 p_class 1 = 0.65     0.926     0.043   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7      0.924     0.031   \n",
       "After SMOTE N = 1500 p_class 1 = 0.75     0.925     0.042   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8      0.923     0.051   \n",
       "After SMOTE N = 1500 p_class 1 = 0.85     0.920     0.058   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9      0.918     0.020   \n",
       "After SMOTE N = 1500 p_class 1 = 0.95     0.915     0.046   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0      0.914     0.037   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.002   \n",
       "After RANDOM mitigation N = 1500                     0.001   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5                 0.001   \n",
       "After SMOTE N = 1500 p_class 1 = 0.55                0.001   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6                 0.003   \n",
       "After SMOTE N = 1500 p_class 1 = 0.65                0.003   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7                 0.005   \n",
       "After SMOTE N = 1500 p_class 1 = 0.75                0.004   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8                 0.006   \n",
       "After SMOTE N = 1500 p_class 1 = 0.85                0.010   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9                 0.011   \n",
       "After SMOTE N = 1500 p_class 1 = 0.95                0.015   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0                 0.015   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.983                4   \n",
       "After RANDOM mitigation N = 1500                     0.972                2   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5                 0.983                2   \n",
       "After SMOTE N = 1500 p_class 1 = 0.55                0.983                2   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6                 0.978                7   \n",
       "After SMOTE N = 1500 p_class 1 = 0.65                0.978                6   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7                 0.983               11   \n",
       "After SMOTE N = 1500 p_class 1 = 0.75                0.978               10   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8                 0.972               14   \n",
       "After SMOTE N = 1500 p_class 1 = 0.85                0.966               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9                 0.989               24   \n",
       "After SMOTE N = 1500 p_class 1 = 0.95                0.972               34   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0                 0.978               35   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  175       10975       2439  \n",
       "After RANDOM mitigation N = 1500                   173       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.5               175       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.55              175       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.6               174       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.65              174       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.7               175       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.75              174       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.8               173       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.85              172       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.9               176       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.95              173       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 1.0               174       12475       2439  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1500\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1500</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>177</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>177</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.6</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.042</td>\n",
       "      <td>7</td>\n",
       "      <td>174</td>\n",
       "      <td>181</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.65</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>180</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.7</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.031</td>\n",
       "      <td>11</td>\n",
       "      <td>175</td>\n",
       "      <td>186</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.75</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.042</td>\n",
       "      <td>10</td>\n",
       "      <td>174</td>\n",
       "      <td>184</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.8</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.051</td>\n",
       "      <td>14</td>\n",
       "      <td>173</td>\n",
       "      <td>187</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.85</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.058</td>\n",
       "      <td>22</td>\n",
       "      <td>172</td>\n",
       "      <td>194</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.9</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.020</td>\n",
       "      <td>24</td>\n",
       "      <td>176</td>\n",
       "      <td>200</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.95</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.046</td>\n",
       "      <td>34</td>\n",
       "      <td>173</td>\n",
       "      <td>207</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 1.0</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.037</td>\n",
       "      <td>35</td>\n",
       "      <td>174</td>\n",
       "      <td>209</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.927     0.032                4   \n",
       "After RANDOM mitigation N = 1500          0.928     0.054                2   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5      0.927     0.033                2   \n",
       "After SMOTE N = 1500 p_class 1 = 0.55     0.927     0.033                2   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6      0.926     0.042                7   \n",
       "After SMOTE N = 1500 p_class 1 = 0.65     0.926     0.043                6   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7      0.924     0.031               11   \n",
       "After SMOTE N = 1500 p_class 1 = 0.75     0.925     0.042               10   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8      0.923     0.051               14   \n",
       "After SMOTE N = 1500 p_class 1 = 0.85     0.920     0.058               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9      0.918     0.020               24   \n",
       "After SMOTE N = 1500 p_class 1 = 0.95     0.915     0.046               34   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0      0.914     0.037               35   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  175           179   \n",
       "After RANDOM mitigation N = 1500                   173           175   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5               175           177   \n",
       "After SMOTE N = 1500 p_class 1 = 0.55              175           177   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6               174           181   \n",
       "After SMOTE N = 1500 p_class 1 = 0.65              174           180   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7               175           186   \n",
       "After SMOTE N = 1500 p_class 1 = 0.75              174           184   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8               173           187   \n",
       "After SMOTE N = 1500 p_class 1 = 0.85              172           194   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9               176           200   \n",
       "After SMOTE N = 1500 p_class 1 = 0.95              173           207   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0               174           209   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.011           0.017   \n",
       "After RANDOM mitigation N = 1500                 0.018           0.028   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5             0.010           0.017   \n",
       "After SMOTE N = 1500 p_class 1 = 0.55            0.011           0.017   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6             0.014           0.022   \n",
       "After SMOTE N = 1500 p_class 1 = 0.65            0.014           0.022   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7             0.011           0.017   \n",
       "After SMOTE N = 1500 p_class 1 = 0.75            0.014           0.022   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8             0.017           0.028   \n",
       "After SMOTE N = 1500 p_class 1 = 0.85            0.021           0.034   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9             0.008           0.011   \n",
       "After SMOTE N = 1500 p_class 1 = 0.95            0.018           0.028   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0             0.015           0.022   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.015       0.011       0.011  \n",
       "After RANDOM mitigation N = 1500            0.022       0.018       0.018  \n",
       "After SMOTE N = 1500 p_class 1 = 0.5        0.015       0.010       0.010  \n",
       "After SMOTE N = 1500 p_class 1 = 0.55       0.015       0.011       0.011  \n",
       "After SMOTE N = 1500 p_class 1 = 0.6        0.020       0.014       0.014  \n",
       "After SMOTE N = 1500 p_class 1 = 0.65       0.020       0.014       0.014  \n",
       "After SMOTE N = 1500 p_class 1 = 0.7        0.015       0.011       0.011  \n",
       "After SMOTE N = 1500 p_class 1 = 0.75       0.019       0.014       0.014  \n",
       "After SMOTE N = 1500 p_class 1 = 0.8        0.023       0.017       0.017  \n",
       "After SMOTE N = 1500 p_class 1 = 0.85       0.028       0.021       0.021  \n",
       "After SMOTE N = 1500 p_class 1 = 0.9        0.010       0.008       0.008  \n",
       "After SMOTE N = 1500 p_class 1 = 0.95       0.023       0.018       0.018  \n",
       "After SMOTE N = 1500 p_class 1 = 1.0        0.019       0.015       0.015  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_1500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.5</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.989</td>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.65</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.978</td>\n",
       "      <td>8</td>\n",
       "      <td>174</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.7</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.983</td>\n",
       "      <td>10</td>\n",
       "      <td>175</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.75</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.978</td>\n",
       "      <td>11</td>\n",
       "      <td>174</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.8</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.972</td>\n",
       "      <td>19</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.85</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.983</td>\n",
       "      <td>30</td>\n",
       "      <td>175</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.9</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.972</td>\n",
       "      <td>27</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.95</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.978</td>\n",
       "      <td>37</td>\n",
       "      <td>174</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 1.0</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.978</td>\n",
       "      <td>41</td>\n",
       "      <td>174</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.927     0.032   \n",
       "After RANDOM mitigation N = 2000          0.927     0.053   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5      0.928     0.054   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55     0.927     0.022   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6      0.927     0.043   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65     0.925     0.042   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7      0.924     0.031   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75     0.924     0.041   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8      0.921     0.050   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85     0.916     0.028   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9      0.918     0.048   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95     0.913     0.037   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0      0.912     0.036   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.002   \n",
       "After RANDOM mitigation N = 2000                     0.002   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5                 0.001   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55                0.001   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6                 0.002   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65                0.004   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7                 0.004   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75                0.005   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8                 0.008   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85                0.013   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9                 0.012   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95                0.016   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0                 0.018   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.983                4   \n",
       "After RANDOM mitigation N = 2000                     0.972                4   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5                 0.972                2   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55                0.989                3   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6                 0.978                5   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65                0.978                8   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7                 0.983               10   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75                0.978               11   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8                 0.972               19   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85                0.983               30   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9                 0.972               27   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95                0.978               37   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0                 0.978               41   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  175       10975       2439  \n",
       "After RANDOM mitigation N = 2000                   173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.5               173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.55              176       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.6               174       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.65              174       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.7               175       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.75              174       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.8               173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.85              175       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.9               173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.95              174       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 1.0               174       12975       2439  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.5</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.022</td>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>179</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.65</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.042</td>\n",
       "      <td>8</td>\n",
       "      <td>174</td>\n",
       "      <td>182</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.7</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.031</td>\n",
       "      <td>10</td>\n",
       "      <td>175</td>\n",
       "      <td>185</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.75</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.041</td>\n",
       "      <td>11</td>\n",
       "      <td>174</td>\n",
       "      <td>185</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.8</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.050</td>\n",
       "      <td>19</td>\n",
       "      <td>173</td>\n",
       "      <td>192</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.85</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.028</td>\n",
       "      <td>30</td>\n",
       "      <td>175</td>\n",
       "      <td>205</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.9</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.048</td>\n",
       "      <td>27</td>\n",
       "      <td>173</td>\n",
       "      <td>200</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.95</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.037</td>\n",
       "      <td>37</td>\n",
       "      <td>174</td>\n",
       "      <td>211</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 1.0</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.036</td>\n",
       "      <td>41</td>\n",
       "      <td>174</td>\n",
       "      <td>215</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.927     0.032                4   \n",
       "After RANDOM mitigation N = 2000          0.927     0.053                4   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5      0.928     0.054                2   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55     0.927     0.022                3   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6      0.927     0.043                5   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65     0.925     0.042                8   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7      0.924     0.031               10   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75     0.924     0.041               11   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8      0.921     0.050               19   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85     0.916     0.028               30   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9      0.918     0.048               27   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95     0.913     0.037               37   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0      0.912     0.036               41   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  175           179   \n",
       "After RANDOM mitigation N = 2000                   173           177   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5               173           175   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55              176           179   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6               174           179   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65              174           182   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7               175           185   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75              174           185   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8               173           192   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85              175           205   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9               173           200   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95              174           211   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0               174           215   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.011           0.017   \n",
       "After RANDOM mitigation N = 2000                 0.018           0.028   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5             0.013           0.028   \n",
       "After SMOTE N = 2000 p_class 1 = 0.55            0.008           0.011   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6             0.014           0.022   \n",
       "After SMOTE N = 2000 p_class 1 = 0.65            0.014           0.022   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7             0.011           0.017   \n",
       "After SMOTE N = 2000 p_class 1 = 0.75            0.014           0.022   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8             0.018           0.028   \n",
       "After SMOTE N = 2000 p_class 1 = 0.85            0.011           0.017   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9             0.018           0.028   \n",
       "After SMOTE N = 2000 p_class 1 = 0.95            0.015           0.022   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0             0.015           0.022   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.015       0.011       0.011  \n",
       "After RANDOM mitigation N = 2000            0.022       0.018       0.018  \n",
       "After SMOTE N = 2000 p_class 1 = 0.5        0.018       0.013       0.013  \n",
       "After SMOTE N = 2000 p_class 1 = 0.55       0.010       0.008       0.008  \n",
       "After SMOTE N = 2000 p_class 1 = 0.6        0.020       0.014       0.014  \n",
       "After SMOTE N = 2000 p_class 1 = 0.65       0.020       0.014       0.014  \n",
       "After SMOTE N = 2000 p_class 1 = 0.7        0.015       0.011       0.011  \n",
       "After SMOTE N = 2000 p_class 1 = 0.75       0.020       0.014       0.014  \n",
       "After SMOTE N = 2000 p_class 1 = 0.8        0.025       0.018       0.018  \n",
       "After SMOTE N = 2000 p_class 1 = 0.85       0.015       0.011       0.011  \n",
       "After SMOTE N = 2000 p_class 1 = 0.9        0.023       0.018       0.018  \n",
       "After SMOTE N = 2000 p_class 1 = 0.95       0.020       0.015       0.015  \n",
       "After SMOTE N = 2000 p_class 1 = 1.0        0.020       0.015       0.015  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_2000 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2500</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.7</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.983</td>\n",
       "      <td>14</td>\n",
       "      <td>175</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.75</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.983</td>\n",
       "      <td>17</td>\n",
       "      <td>175</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.8</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.966</td>\n",
       "      <td>20</td>\n",
       "      <td>172</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.85</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.966</td>\n",
       "      <td>26</td>\n",
       "      <td>172</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.9</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.972</td>\n",
       "      <td>40</td>\n",
       "      <td>173</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.95</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.966</td>\n",
       "      <td>52</td>\n",
       "      <td>172</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 1.0</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.972</td>\n",
       "      <td>54</td>\n",
       "      <td>173</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.927     0.032   \n",
       "After RANDOM mitigation N = 2500          0.927     0.033   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5      0.927     0.043   \n",
       "After SMOTE N = 2500 p_class 1 = 0.55     0.927     0.043   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6      0.927     0.043   \n",
       "After SMOTE N = 2500 p_class 1 = 0.65     0.927     0.043   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7      0.923     0.031   \n",
       "After SMOTE N = 2500 p_class 1 = 0.75     0.921     0.030   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8      0.921     0.059   \n",
       "After SMOTE N = 2500 p_class 1 = 0.85     0.919     0.057   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9      0.913     0.045   \n",
       "After SMOTE N = 2500 p_class 1 = 0.95     0.908     0.051   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0      0.907     0.042   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.002   \n",
       "After RANDOM mitigation N = 2500                     0.001   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5                 0.002   \n",
       "After SMOTE N = 2500 p_class 1 = 0.55                0.002   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6                 0.002   \n",
       "After SMOTE N = 2500 p_class 1 = 0.65                0.002   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7                 0.006   \n",
       "After SMOTE N = 2500 p_class 1 = 0.75                0.008   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8                 0.009   \n",
       "After SMOTE N = 2500 p_class 1 = 0.85                0.011   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9                 0.018   \n",
       "After SMOTE N = 2500 p_class 1 = 0.95                0.023   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0                 0.024   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.983                4   \n",
       "After RANDOM mitigation N = 2500                     0.983                3   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5                 0.978                4   \n",
       "After SMOTE N = 2500 p_class 1 = 0.55                0.978                5   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6                 0.978                5   \n",
       "After SMOTE N = 2500 p_class 1 = 0.65                0.978                5   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7                 0.983               14   \n",
       "After SMOTE N = 2500 p_class 1 = 0.75                0.983               17   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8                 0.966               20   \n",
       "After SMOTE N = 2500 p_class 1 = 0.85                0.966               26   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9                 0.972               40   \n",
       "After SMOTE N = 2500 p_class 1 = 0.95                0.966               52   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0                 0.972               54   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  175       10975       2439  \n",
       "After RANDOM mitigation N = 2500                   175       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.5               174       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.55              174       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.6               174       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.65              174       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.7               175       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.75              175       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.8               172       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.85              172       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.9               173       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.95              172       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 1.0               173       13475       2439  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2500\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2500</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.55</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>179</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>179</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.65</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>179</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.7</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.031</td>\n",
       "      <td>14</td>\n",
       "      <td>175</td>\n",
       "      <td>189</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.75</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.030</td>\n",
       "      <td>17</td>\n",
       "      <td>175</td>\n",
       "      <td>192</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.8</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.059</td>\n",
       "      <td>20</td>\n",
       "      <td>172</td>\n",
       "      <td>192</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.85</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.057</td>\n",
       "      <td>26</td>\n",
       "      <td>172</td>\n",
       "      <td>198</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.9</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.045</td>\n",
       "      <td>40</td>\n",
       "      <td>173</td>\n",
       "      <td>213</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.95</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.051</td>\n",
       "      <td>52</td>\n",
       "      <td>172</td>\n",
       "      <td>224</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 1.0</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.042</td>\n",
       "      <td>54</td>\n",
       "      <td>173</td>\n",
       "      <td>227</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.927     0.032                4   \n",
       "After RANDOM mitigation N = 2500          0.927     0.033                3   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5      0.927     0.043                4   \n",
       "After SMOTE N = 2500 p_class 1 = 0.55     0.927     0.043                5   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6      0.927     0.043                5   \n",
       "After SMOTE N = 2500 p_class 1 = 0.65     0.927     0.043                5   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7      0.923     0.031               14   \n",
       "After SMOTE N = 2500 p_class 1 = 0.75     0.921     0.030               17   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8      0.921     0.059               20   \n",
       "After SMOTE N = 2500 p_class 1 = 0.85     0.919     0.057               26   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9      0.913     0.045               40   \n",
       "After SMOTE N = 2500 p_class 1 = 0.95     0.908     0.051               52   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0      0.907     0.042               54   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  175           179   \n",
       "After RANDOM mitigation N = 2500                   175           178   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5               174           178   \n",
       "After SMOTE N = 2500 p_class 1 = 0.55              174           179   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6               174           179   \n",
       "After SMOTE N = 2500 p_class 1 = 0.65              174           179   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7               175           189   \n",
       "After SMOTE N = 2500 p_class 1 = 0.75              175           192   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8               172           192   \n",
       "After SMOTE N = 2500 p_class 1 = 0.85              172           198   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9               173           213   \n",
       "After SMOTE N = 2500 p_class 1 = 0.95              172           224   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0               173           227   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.011           0.017   \n",
       "After RANDOM mitigation N = 2500                 0.018           0.028   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5             0.014           0.022   \n",
       "After SMOTE N = 2500 p_class 1 = 0.55            0.014           0.022   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6             0.014           0.022   \n",
       "After SMOTE N = 2500 p_class 1 = 0.65            0.014           0.022   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7             0.011           0.017   \n",
       "After SMOTE N = 2500 p_class 1 = 0.75            0.011           0.017   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8             0.021           0.034   \n",
       "After SMOTE N = 2500 p_class 1 = 0.85            0.021           0.034   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9             0.018           0.028   \n",
       "After SMOTE N = 2500 p_class 1 = 0.95            0.021           0.034   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0             0.018           0.028   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.015       0.011       0.011  \n",
       "After RANDOM mitigation N = 2500            0.022       0.018       0.018  \n",
       "After SMOTE N = 2500 p_class 1 = 0.5        0.020       0.014       0.014  \n",
       "After SMOTE N = 2500 p_class 1 = 0.55       0.020       0.014       0.014  \n",
       "After SMOTE N = 2500 p_class 1 = 0.6        0.020       0.014       0.014  \n",
       "After SMOTE N = 2500 p_class 1 = 0.65       0.020       0.014       0.014  \n",
       "After SMOTE N = 2500 p_class 1 = 0.7        0.015       0.011       0.011  \n",
       "After SMOTE N = 2500 p_class 1 = 0.75       0.015       0.011       0.011  \n",
       "After SMOTE N = 2500 p_class 1 = 0.8        0.028       0.021       0.021  \n",
       "After SMOTE N = 2500 p_class 1 = 0.85       0.028       0.021       0.021  \n",
       "After SMOTE N = 2500 p_class 1 = 0.9        0.023       0.018       0.018  \n",
       "After SMOTE N = 2500 p_class 1 = 0.95       0.028       0.021       0.021  \n",
       "After SMOTE N = 2500 p_class 1 = 1.0        0.023       0.018       0.018  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_2500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2500\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3000</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.55</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.978</td>\n",
       "      <td>7</td>\n",
       "      <td>174</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.6</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.978</td>\n",
       "      <td>11</td>\n",
       "      <td>174</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.65</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.978</td>\n",
       "      <td>15</td>\n",
       "      <td>174</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.7</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.978</td>\n",
       "      <td>21</td>\n",
       "      <td>174</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.75</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.972</td>\n",
       "      <td>21</td>\n",
       "      <td>173</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.8</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.972</td>\n",
       "      <td>29</td>\n",
       "      <td>173</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.85</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.966</td>\n",
       "      <td>42</td>\n",
       "      <td>172</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.9</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.972</td>\n",
       "      <td>41</td>\n",
       "      <td>173</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.95</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.972</td>\n",
       "      <td>50</td>\n",
       "      <td>173</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 1.0</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.966</td>\n",
       "      <td>66</td>\n",
       "      <td>172</td>\n",
       "      <td>13975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.927     0.032   \n",
       "After RANDOM mitigation N = 3000          0.927     0.053   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5      0.927     0.032   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55     0.926     0.042   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6      0.924     0.041   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65     0.923     0.041   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7      0.920     0.039   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75     0.920     0.049   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8      0.917     0.047   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85     0.912     0.053   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9      0.912     0.045   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95     0.909     0.043   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0      0.902     0.048   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.002   \n",
       "After RANDOM mitigation N = 3000                     0.002   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5                 0.002   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55                0.003   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6                 0.005   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65                0.007   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7                 0.009   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75                0.009   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8                 0.013   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85                0.019   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9                 0.018   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95                0.022   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0                 0.029   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.983                4   \n",
       "After RANDOM mitigation N = 3000                     0.972                4   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5                 0.983                4   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55                0.978                7   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6                 0.978               11   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65                0.978               15   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7                 0.978               21   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75                0.972               21   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8                 0.972               29   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85                0.966               42   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9                 0.972               41   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95                0.972               50   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0                 0.966               66   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  175       10975       2439  \n",
       "After RANDOM mitigation N = 3000                   173       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.5               175       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.55              174       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.6               174       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.65              174       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.7               174       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.75              173       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.8               173       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.85              172       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.9               173       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 0.95              173       13975       2439  \n",
       "After SMOTE N = 3000 p_class 1 = 1.0               172       13975       2439  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {1: count_1 + int(N * p), 0: count_0 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class[\"fn\"] = get_false_negative_rate_outcome(df_test_class[\"y_test_true\"], df_test_class[\"y_pred\"])\n",
    "    \n",
    "    df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = attributes\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp = FP_fm\n",
    "    \n",
    "    fp_div_results[p] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote[\"Violent_Recidivist\"]\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3000</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.55</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.042</td>\n",
       "      <td>7</td>\n",
       "      <td>174</td>\n",
       "      <td>181</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.6</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.041</td>\n",
       "      <td>11</td>\n",
       "      <td>174</td>\n",
       "      <td>185</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.65</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.041</td>\n",
       "      <td>15</td>\n",
       "      <td>174</td>\n",
       "      <td>189</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.7</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.039</td>\n",
       "      <td>21</td>\n",
       "      <td>174</td>\n",
       "      <td>195</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.75</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.049</td>\n",
       "      <td>21</td>\n",
       "      <td>173</td>\n",
       "      <td>194</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.8</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.047</td>\n",
       "      <td>29</td>\n",
       "      <td>173</td>\n",
       "      <td>202</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.85</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.053</td>\n",
       "      <td>42</td>\n",
       "      <td>172</td>\n",
       "      <td>214</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.9</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.045</td>\n",
       "      <td>41</td>\n",
       "      <td>173</td>\n",
       "      <td>214</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.95</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.043</td>\n",
       "      <td>50</td>\n",
       "      <td>173</td>\n",
       "      <td>223</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 1.0</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.048</td>\n",
       "      <td>66</td>\n",
       "      <td>172</td>\n",
       "      <td>238</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.927     0.032                4   \n",
       "After RANDOM mitigation N = 3000          0.927     0.053                4   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5      0.927     0.032                4   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55     0.926     0.042                7   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6      0.924     0.041               11   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65     0.923     0.041               15   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7      0.920     0.039               21   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75     0.920     0.049               21   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8      0.917     0.047               29   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85     0.912     0.053               42   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9      0.912     0.045               41   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95     0.909     0.043               50   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0      0.902     0.048               66   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  175           179   \n",
       "After RANDOM mitigation N = 3000                   173           177   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5               175           179   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55              174           181   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6               174           185   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65              174           189   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7               174           195   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75              173           194   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8               173           202   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85              172           214   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9               173           214   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95              173           223   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0               172           238   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.011           0.017   \n",
       "After RANDOM mitigation N = 3000                 0.018           0.028   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5             0.011           0.017   \n",
       "After SMOTE N = 3000 p_class 1 = 0.55            0.014           0.022   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6             0.014           0.022   \n",
       "After SMOTE N = 3000 p_class 1 = 0.65            0.014           0.022   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7             0.014           0.022   \n",
       "After SMOTE N = 3000 p_class 1 = 0.75            0.017           0.028   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8             0.018           0.028   \n",
       "After SMOTE N = 3000 p_class 1 = 0.85            0.021           0.034   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9             0.018           0.028   \n",
       "After SMOTE N = 3000 p_class 1 = 0.95            0.018           0.028   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0             0.022           0.034   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.015       0.011       0.011  \n",
       "After RANDOM mitigation N = 3000            0.022       0.018       0.018  \n",
       "After SMOTE N = 3000 p_class 1 = 0.5        0.015       0.011       0.011  \n",
       "After SMOTE N = 3000 p_class 1 = 0.55       0.020       0.014       0.014  \n",
       "After SMOTE N = 3000 p_class 1 = 0.6        0.020       0.014       0.014  \n",
       "After SMOTE N = 3000 p_class 1 = 0.65       0.020       0.014       0.014  \n",
       "After SMOTE N = 3000 p_class 1 = 0.7        0.020       0.014       0.014  \n",
       "After SMOTE N = 3000 p_class 1 = 0.75       0.023       0.017       0.017  \n",
       "After SMOTE N = 3000 p_class 1 = 0.8        0.023       0.018       0.018  \n",
       "After SMOTE N = 3000 p_class 1 = 0.85       0.028       0.021       0.021  \n",
       "After SMOTE N = 3000 p_class 1 = 0.9        0.023       0.018       0.018  \n",
       "After SMOTE N = 3000 p_class 1 = 0.95       0.023       0.018       0.018  \n",
       "After SMOTE N = 3000 p_class 1 = 1.0        0.027       0.022       0.022  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class[\"fn\"] = get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test[\"fn\"] = df_test_class[\"fn\"]\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = attributes\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\"fn\"])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, \"fn\")\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fn_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_3000 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_3000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati salvati in false_negatives_K_compas.json\n",
      "‚úÖ Variabili salvate con successo in false_negatives_K_compas.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"false_negatives_K_compas.json\"\n",
    "\n",
    "# Controlla se il file esiste gi√† per evitare di sovrascrivere\n",
    "if os.path.exists(json_filename):\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        false_negatives_data = json.load(f)\n",
    "else:\n",
    "    false_negatives_data = {}\n",
    "\n",
    "# Lista dei diversi metrics_after_fp_SMOTE_XK\n",
    "metrics_dict = {\n",
    "    \"500_run6\": metrics_after_fp_SMOTE_500,\n",
    "    \"1000_run6\": metrics_after_fp_SMOTE_1000,\n",
    "    \"1500_run6\": metrics_after_fp_SMOTE_1500,\n",
    "    \"2000_run6\": metrics_after_fp_SMOTE_2000,\n",
    "    \"2500_run6\": metrics_after_fp_SMOTE_2500,\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni dataset e salviamo i falsi positivi\n",
    "for J, metrics in metrics_dict.items():\n",
    "    false_negatives_data[f\"N={J}\"] = metrics[\"False Negatives\"].to_dict()\n",
    "\n",
    "# Salviamo il JSON aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(false_negatives_data, f, indent=4)\n",
    "\n",
    "print(f\"Dati salvati in {json_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "#per i parametri # Nome del file JSON\n",
    "json_filename = \"false_negatives_K_compas.json\"\n",
    "\n",
    "# Valori da salvare (sostituiscili con i tuoi valori reali)\n",
    "min_sup_run6 = min_sup\n",
    "percentage_run6 = percentage\n",
    "th_redundancy_run6 = pruning\n",
    "K_run6 = K\n",
    "L_run6 = filtered_instances  # Supponiamo sia la lunghezza di filtered_instances\n",
    "\n",
    "# 1Ô∏è‚É£ Caricare i dati esistenti (se il file esiste)\n",
    "try:\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        false_negatives_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    false_negatives_data = {}  # Se il file non esiste, inizializza un dizionario vuoto\n",
    "\n",
    "# 2Ô∏è‚É£ Aggiungere le nuove variabili sotto una chiave dedicata\n",
    "false_negatives_data[\"run6_parameters\"] = {\n",
    "    \"min_sup\": min_sup_run6,\n",
    "    \"percentage\": percentage_run6,\n",
    "    \"th_redundancy\": th_redundancy_run6,\n",
    "    \"K\": percentage,\n",
    "    \"L\": L_run6\n",
    "}\n",
    "\n",
    "# 3Ô∏è‚É£ Salvare il file aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(false_negatives_data, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ Variabili salvate con successo in\", json_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA18AAAJJCAYAAABVvo1bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOydd3gUVReH3930RhottITem0FApEoHBQQFxU8BRRALTWxgwY6AioioqBQVK1JUQAWkiXQIHaTXhBJI77vz/XGzm91kN9lstue+z5Mns1PunJ09U87c3z1HpSiKgkQikUgkEolEIpFI7Ira2QZIJBKJRCKRSCQSSXlABl8SiUQikUgkEolE4gBk8CWRSCQSiUQikUgkDkAGXxKJRCKRSCQSiUTiAGTwJZFIJBKJRCKRSCQOQAZfEolEIpFIJBKJROIAZPAlkUgkEolEIpFIJA5ABl8SiUQikUgkEolE4gBk8CWRSCQSiUQikUgkDkAGXxKJRCKRSCQSiUTiAGTwJZFIXJZNmzahUqlK/Bs5cmSRbZs1a2a0TlRUFHl5eSb3c+7cOaN1p0+fbpF9ly5dYuLEiTRt2pSgoCD8/PyoWrUqzZs3Z9iwYbz77rvcunXLaJuuXbta9J3OnTtnkQ2F27v//vuLrDNlyhSjdQyZPn26RfYsXrzY5P4TExOZOXMmvXr1olq1avj7++Pn50dUVBSdO3fmueeeY+vWrSiKYvY73H333Ub78vPz4+bNm/rlhX8fS/9Mbav7bWfMmGE0f9euXWbtGzVqlH49X19frl+/DkBMTIzFdlhC4fZ8fX1JSEgosl5eXh41a9Ysdj+Ff1edP1lzHE1ta+qcA9BqtaxcuZKHHnqIBg0aEBoaio+PD2FhYbRo0YJHHnmEr7/+mtTUVLPHYdmyZUVsmDdvntE6lp5HpnzYcNuYmBiTNuTl5bF06VLuvfdeatWqRUBAAEFBQdSpU4cHH3yQ1atXm7W/8H4/+eSTIuu0adNGv7xr165m25JIJJ6HDL4kEonHsXv3bo4cOWI0LyEhgT/++MNm+9i3bx/NmjXjo48+4ujRo2RkZJCTk8PVq1c5fPgwP/30E1OnTuX8+fM226cl/PLLL+zbt88h+1qwYAHR0dG88MILrFu3jvj4eLKzs8nJySEhIYGtW7cye/ZsOnfuzNWrV022Yep3ycnJ4bvvvrOr7Q8//DBqdcEt8JtvvjG5XmZmJr/88ov+c//+/alUqZJdbdORm5vLZ599VmT+8uXLuXTpkkNsKA1Hjx7ltttu49577+W7777j5MmTpKSkkJeXR3JyMocOHeKbb75hxIgRJgMSHYsWLSoyz1zwbw9OnTpFbGws//vf/1i5ciUXL14kKyuLjIwMzp49yw8//MDdd99Njx499IF4cbz99ttkZGQ4wHKJROIOeDvbAIlEIrGUYcOG0aZNmyLzmzVrZvTZ3IPa4sWLufvuu21iy5NPPklycjIAQUFBDBs2jDp16pCbm8vJkyfZunUrFy9eLLaN8PBwpk6danJZRESEVXYpisK0adNYu3atVdtPnTqV8PDwIvNvv/12o8+zZs3i+eef139WqVR069aN9u3bExwczM2bN4mLi+Off/4hKyvL7P6++eYbNBpNkfmLFy/m6aefBsSxmDVrltHyPXv28OOPP+o/P/HEE9StW9eyLwlUr16dnj178ueffwLwww8/8MEHH+Dj42O03ooVK4x6acz1+NSpU4dx48ZZvH9L+fzzz5k6dSq+vr76eXPnzrW6vcLH8fTp00YBnqlzzBJfPH78OJ07dyYxMVE/r3bt2vTr14/q1auTlZXFf//9x9atW7l8+bLZdhISEvS/iSF79+7l8OHD+nN93LhxRc7l5557Tj/dpk0bhg0bZrS8sA+b4tq1a3Tv3p0LFy7o53Xq1Inu3buTm5vL6tWriYuLA2DDhg3069ePrVu34u/vb7bN+Ph4Pv74Y1544YUS9y+RSMoBikQikbgoGzduVAD936JFi0rcJisrSwkPD9dv06BBA/20r6+vcuPGjSLbnD171mg/r732WrH7SE5ONlp/8eLFJtfbtWuXcv36daN5Xbp00W8XHR1d4vcpCcP2DP+2bNmiX+fZZ581WmbIa6+9ZrTs7NmzJe7z6NGjipeXl36byMhIZdu2bSbXTU1NVebPn68kJSWZXN6kSROTvxWgHDp0yKwNixYtMlp348aNJtcr7rf94YcfjJatWrWqyPZ9+vTRL69cubKSm5urXxYdHa1f1qVLF7O2Wophe2q1Wj/9zTff6NfZu3evfr7hb2Dt71qac8xwvREjRhgt69Chg9HyadOmKXl5eUXa0Gq1yqZNm5R169aZ3MfMmTP1bQQHByvVqlXTf3722WfN2laSfYYUdw4+/vjjRu28+eabRss1Go3y6KOPGq0zY8YMs3bo/sLDw43OgdjYWJv6jkQicR+k7FAikXgUq1atMhpntWTJEn1vhq3kbIXHjh0+fNhk783tt99OxYoVy7w/S6lUqRJeXl4AvPTSS3bbz9y5c42+72effUaHDh1MrhscHMy4ceMIDQ0tsmzXrl0cPXpU//mjjz4ykvSZkp/ZkkGDBhEWFqb/XFh6mJCQwLp16/SfH3roIby9HSMYueuuuwgODgbg448/1s//6KOP9NP33HOPQ2wpiZ07d/Lvv//qP/fv35+33npL74uGqFQqunTpQo8ePUy2ZdhrPWDAAKPeq2+//dbsuE1bkJWVZeQDtWvX5sUXXzRaR61WM3PmTP1vA5iUhuqoWrUqALdu3SrS6yiRSMonUnYokUjchj/++IMbN24UmT9s2DBq1qwJGD+83XbbbbRv354ePXroZXiLFy/mmWeeKZMdERERREdH68dzzZ49m0WLFnHnnXfSunVr7rjjDrp27Yqfn1+x7aSkpDB79uwi82vWrFlEMmUJtWrVon///ixevJht27axevVq+vfvX6o2vvjiC5OywylTpuinN2zYoJ8ODw9n8ODBpbYVjH+rypUr07NnT+677z4+/fRTAJYuXcp7771nt4DHz8+PBx54QP/w/Ntvv5GUlKQPyL777jujINOc5BDg4sWLJn/LZs2a0adPn1LbFhoaqh8btWvXLnbs2EGdOnX0UssuXbrQsmVLVq5cWeq2bY2hPwCMHj3aqnYKB+MPPPAAVapU4cMPPwTg6tWrrF271m5B5+7du40ksoMGDTLpe5GRkfTo0UN/7M+dO8elS5eoUaNGkXWHDRvG6tWrOXXqFHPmzGH8+PFUrlzZLvZLJBL3QAZfEonEbfjxxx+NxvnoaNOmDTVr1iQ+Pp6//vpLP//BBx/U/9cFX/v27ePQoUM0b968TLZ8+OGHDBkyRJ/FLzExkV9//ZVff/0VEA/PkydPZtq0aSZ7AEC8DTccp6KjS5cuVgVfILLcfffdd+Tk5PDyyy/Tr1+/Um3/zjvvmJxvGHwZjtmpX7++UeKK48eP07hx4yLbjxgxwijYys7O5ocfftB/vv/++/Hy8uLBBx/UB1/2ftgGkclQF3xlZ2fz008/MWbMGMC4J6x169a0aNHCbDtnzpwx+VuOGDHCquAL4JlnnmH+/PkoisLcuXNp1KgR2dnZAIwfP56DBw9a1a6tKTyGq2HDhkaf27dvz86dO4tspxTKgGnoH+Hh4fTu3RtfX1/q1q3L6dOn9evYyx/i4+ONPkdHR5tdt/Cy+Ph4k8GXt7c3b7zxBsOHDyc9PZ23337bqPdSIpGUP6TsUCKReAyGyRtUKpU+gBk0aJDRgHhbyNnuvfde/v77b+666y6j4ENHcnIyr732Gm+++WaZ91UaoqOjGTt2LABxcXEmg1VbUppU6oYUloc+8MADAHTs2NHoIdbe0sO2bdvSpEkT/WddwHX48GF9YgUQQZqjadiwoT5wW7ZsmT7denR0NAMHDnS4PZZijU8UDsYHDx6sTzJi+CLi999/N0rq4Q488MADtGzZEhASRcNkHhKJpPwhgy+JROI2LFq0CEVRivzp6uQYvjnv0KGDXooYEhJiJL9bunSpTcaOdO3alQ0bNnDz5k3Wrl3L9OnTi2SK00mmTBEdHW3y+2zatKlMdk2bNo2goCAAXn311VJ917Nnz5q0yZDq1avrp0+ePGm0vHLlysyaNYtZs2YRGBhodj+GQVXNmjW58847AeOgGWD16tV2f9geMWKEfnrbtm2cPXuWr7/+Wj/P19eX4cOHF9tGly5dTB63sqZIHz9+PCDSzuvSmj/11FNme1OdgaE/AJw4ccLo8/jx45k1axZdunQx28bKlStNBuNQ0IMNYtzm0qVLy2qySaKioow+F1cmovCywtsaolKpeOuttwBhv6V1BCUSiWcigy+JROIR7Ny5k2PHjuk/b9u2zajQqWGtpmvXrrFmzRqb7Ts0NJQ+ffrw2muvsXv3bh599FH9spSUFLM1ruxFlSpVmDBhAiCCI1v3fnXv3l0/ffPmTb3UEsR4uClTpjBlyhQCAgJMbn/lyhWjRBYXL15ErVbrf6v3339fv8yeD9s6Hn74YX0wowuYDBOz3H333URGRtrVBnP07t3bSMYXGBho9Zgqe2HoD1C01MPw4cOZMmWKyTIR5rbp2bOn3h8KS4TtVfOrTZs2Rj3kK1euNJlI5+bNm0bj3GJiYkxKDg25++679Ulpvv76a9n7JZGUY2TwJZFIPILSPpCV9QFuxIgR7N271+Qyw0xoarWakJCQMu3LGp577jl94oyEhASbtv30008b9bw88cQTRhK9kjBX28sc9i6wGxUVRe/evfWfZ8+ebTSOyRmSQx0qlUrf+wXwv//9z2RCFGfSrl072rdvr/+8cuVK3nvvvSI9puYoHIyXxP79++0y3i0gIICHH35Y//ns2bPMnDnTaB1FUXjhhReMar898cQTFrWvG0+p0WgsKs4skUg8E5lwQyKRuD1ZWVlG40Vq165N27Zti6x36NAhfTa133//nRs3bphMBb9gwQJ+//13k/vas2cPIN5ef/3119StW5eOHTtSp04dVCoVBw4cYPny5fr1O3fubFZ+Zy7bIUDfvn1p2rSpmW9cMmFhYTz//POlTjlvLtuhYda+pk2b8uabb+oLRCckJNCmTRv69u1LbGwsPj4+nD17lpSUFJP7KJzlsFu3bkXWOXPmDLt37wYKHraLS3hRVkaOHKnvDc3IyNDPr1q1qkUJM8xlOwTjbJzW2latWjVABDquyFdffcWdd95JUlISAC+++CLffPMNvXv3plKlSty8edNsZsavv/7aKBi/5557ipwzWq2Wn3/+Wf950aJFxUp6reWtt97izz//1PdMTZ06lT///JO77rpLX2R5//79+vXbtGljFBwXR5cuXejdu7fJItISiaQc4aB6YhKJRFJqLC0A+/333xut9+2335pcb8OGDUbrzZkzR1GUooV4i/vTYcm6ERERRQoFmyuKXPjPkoLShduLjY01Wpaenq5UrVrV7HdQlKLFeM39mSpa+9FHHyl+fn4WbT958mRFURRl+/btRvPfeustk9/r1KlTRutNnDjRaLktiiwbkpWVpURERBSxu7jCvoZFkYv7M2dbce0NGTKkxPUL/3bFLbN3kWVFUZS4uDilUaNGFp8bOgy3qV+/vtn9d+rUSb9e4YLXltino6RC5ydPnlRatGhR4ne46667lGvXrhV7nAr7z549exSVSmW0jiyyLJGUL6TsUCKRuD2GPSmhoaFm605169aNmJgYk9uVln379jFr1iz69+9P48aNiYyMxMvLi5CQEFq3bs3zzz/PkSNHaNasmdX7KCuBgYG8/PLLdmt//PjxnD17lunTp9OxY0cqVaqEt7c3AQEB1KpVi549ezJ9+nT27dunH8dleMzVarVRsgtD6tatS+fOnfWfly5dSm5urt2+i5+fn1FiBx3F1faSGNOyZUsOHjzI0qVLGTJkCNHR0QQEBODj40NkZCS33347TzzxBMuXL+fKlSsA7Nixg+PHj+vbKE7iabjs2rVrrF692i7fo169euzdu5dvvvmGgQMHUr16dfz8/AgICCAmJoZhw4bx22+/sX79eqOi4JYQGxvLkCFD7GK3RCJxD1SKYqEoWyKRSCQSiUQikUgkViN7viQSiUQikUgkEonEAcjgSyKRSCQSiUQikUgcgAy+JBKJRCKRSCQSicQByOBLIpFIJBKJRCKRSByADL4kEolEIpFIJBKJxAHI4EsikUgkEolEIpFIHIAMviQSiUQikUgkEonEAcjgSyKRSCQSiUQikUgcgAy+JBKJRCKRSCQSicQByOBLIpFIJBKJRCKRSByADL4kEolEIpFIJBKJxAHI4EsikUgkEolEIpFIHIAMviQSiUQikUgkEonEAcjgSyKRSCQSiUQikUgcgAy+JBKJRCKRSCQSicQByOBLIpFIJBKJRCKRSByADL4kEolEIpFIJBKJxAHI4EsikUgkEolEIpFIHIAMviQSiUQikUgkEonEAcjgSyKRSCQSiUQikUgcgAy+JBKJRCKRSCQSicQByOBLIpFIJBKJRCKRSByADL4kEg9DpVIxffp0Z5shKQdIX5OUJxYvXoxKpWLPnj3ONkUikbgxMviSSFwQ3U1epVLxzz//FFmuKAo1a9ZEpVJx9913O8FC9+PYsWP06dOH4OBgIiIiePjhh7l+/Xqp2zl9+jT+/v4mH8IMf7fCfwkJCbb6KhI78Ouvv3Lbbbfh7+9PrVq1eO2118jLy7NoW61Wy8yZM6lduzb+/v60aNGC77//3mpbzp07h0qlYvbs2UbzFUVh7NixRkFvUlISDz30EOHh4dSpU4evvvqqSHt79uwhMDCQs2fPWm2TtRw/fpznn3+eVq1aERISQlRUFP379zcZwEyfPt3kuePv7+9wuyW25Z133qF9+/ZUqlQJf39/6tevz8SJE4u9BsfGxvLkk08CcOLECSZNmkSHDh30199z586Z3G7SpEncdtttREREEBgYSOPGjZk+fTppaWn2+GoSSanxdrYBEonEPP7+/nz33Xd07NjRaP7mzZu5dOkSfn5+RbbJzMzE21ue2oZcunSJzp07ExoayjvvvENaWhqzZ8/m0KFD7Nq1C19fX4vbmjRpEt7e3mRnZ5td54033qB27dpG88LCwqw132XxFF9bu3YtgwYNomvXrnz88cccOnSIt956i2vXrvHpp5+WuP20adOYMWMGjz/+OLfffjurVq1i+PDhqFQqHnjgAZvYqCgKTz75JAsWLOCVV17RB19Tpkxh06ZNvP7665w6dYrHH3+cxo0b06FDB/1248ePZ+LEiUV80hF8+eWXfPXVVwwZMoQnn3yS5ORkPv/8c9q3b88ff/xBjx49imzz6aefEhwcrP/s5eXlSJMldmDv3r20atWKBx54gJCQEI4dO8YXX3zB6tWriYuLIygoyGj9+Ph49u/fzxtvvAHA9u3bmTt3Lk2aNKFx48bExcWZ3dfu3bvp1KkTo0aNwt/fn/379zNjxgzWr1/Pli1bUKtlv4PEySgSicTlWLRokQIogwcPVipWrKjk5uYaLX/88ceV2NhYJTo6Wunfv7+TrHQfxo0bpwQEBCjnz5/Xz1u3bp0CKJ9//rnF7fzxxx+Kr6+v8vLLLyuAsnv3bqPlut+t8HxnodFolMzMTGeb4fI0adJEadmypdF5Nm3aNEWlUinHjh0rdttLly4pPj4+ylNPPaWfp9VqlU6dOik1atRQ8vLySm3P2bNnFUCZNWuWft5TTz2lAMq0adOM1q1SpYqyZMkS/ecuXbooL774ov7zN998o1SrVk1JTU0ttR22YM+ePUX2fePGDaVSpUrKnXfeaTT/tddeUwDl+vXrjjTRYhx1fqelpdm1fVdh2bJlCqB8//33RZZ99dVXSkBAgJKRkaEoiqIkJiYqKSkpiqIoyqxZsxRAOXv2rMX7mj17tgIo27dvt4ntEklZkOG/ROLCPPjggyQmJrJu3Tr9vJycHJYtW8bw4cNNblN4HI5OynPq1ClGjhxJWFgYoaGhjBo1ioyMDKNt161bR8eOHQkLCyM4OJiGDRsydepU/XKdrK6w3GPTpk2oVCo2bdqkn9e1a1eaNWvG3r176dChAwEBAdSuXZvPPvvM+gNiJb/88gt33303tWrV0s/r0aMHDRo04KeffrKojdzcXCZMmMCECROoW7duieunpqai0WistlmH7vc7fvw4Q4cOpUKFCkRGRjJhwgSysrKM1lWpVDz99NMsXbqUpk2b4ufnxx9//GHy94ECedvixYv180aOHElwcDCXL19m0KBBBAcHU6lSJaZMmVLk+5TF1zIzMxk/fjwVK1YkJCSEAQMGcPnyZYePIzt69ChHjx5lzJgxRr14Tz75JIqisGzZsmK3X7VqFbm5uXp5FIjjMm7cOC5dusT27dvLbOOECRP45JNPeOmll3jrrbeMlmVmZhIeHq7/HBERoT/W6enpvPjii7z77rtGPUmOJDY2tsi+IyMj6dSpE8eOHTO5jaIopKSkoChKmfefkJDAqFGjqFGjBn5+fkRFRTFw4ECja5g5n4uJiWHkyJFF5mdkZDB27FgiIyOpUKECjzzyCLdu3TJaR6vVMn36dKpVq0ZgYCDdunXj6NGjRdrUXVM3b97Mk08+SeXKlalRo4Z++fz58/XncrVq1XjqqadISkqyyM6uXbvStWtX/WfddeDHH39k6tSpVK1alaCgIAYMGMDFixeNtj158iRDhgyhatWq+Pv7U6NGDR544AGSk5P169y4cYPjx48XObctJSYmBqDI9wFYvXo13bp1IyAgABB+HRISYtV+StqXROJo3F8vIpF4MDExMdxxxx18//339O3bFxASqeTkZB544AHmzp1rcVtDhw6ldu3avPvuu+zbt48vv/ySypUr89577wFw5MgR7r77blq0aMEbb7yBn58fp06dYtu2bVbbf+vWLfr168fQoUN58MEH+emnnxg3bhy+vr48+uijxW6bnJxMbm5uifvw9/cv9sHy8uXLXLt2jTZt2hRZ1rZtW9asWVPyFwHmzJnDrVu3ePnll1m+fHmx63br1o20tDR8fX3p3bs377//PvXr17doP+YYOnQoMTExvPvuu+zYsYO5c+dy69Ytvv76a6P1/v77b3766SeefvppKlasSExMTKkfODQaDb1796Zdu3bMnj2b9evX8/7771O3bl3GjRtnka3F+RqIIO+nn37i4Ycfpn379mzevJn+/ftbbOONGzcsWi8kJMSkPFfH/v37AYr4R7Vq1ahRo4Z+eXHbBwUF0bhxY6P5bdu21S8vLBsuDZMmTWLu3Lm88MILvPPOO0WW33777XzwwQc0atSIM2fO8Mcff/DFF18AYpxN9erVefjhh0u1z9zcXKOH7OKIiIiwSsaVkJBAxYoVTS6rU6cOaWlpBAUFMWjQIN5//32qVKlS6n0ADBkyhCNHjvDMM88QExPDtWvXWLduHRcuXNA/kJeWp59+mrCwMKZPn86JEyf49NNPOX/+vD64AXjppZeYOXMm99xzD7179+bAgQP07t27yAsTHU8++SSVKlXi1VdfJT09HRAvM15//XV69OjBuHHj9PvavXs327Ztw8fHxyr73377bVQqFS+88ALXrl1jzpw59OjRg7i4OAICAsjJyaF3795kZ2fzzDPPULVqVS5fvszvv/9OUlISoaGhAMybN4/XX3+djRs3GgV55lAUhcTERPLy8jh58iQvvvgiXl5eRbbNzc1l/fr1Jv3dUvLy8khKSiInJ4fDhw/z8ssvExISoj8vJRKn4tyON4lEYgpDecu8efOUkJAQvfzi/vvvV7p166YoimJSdggor732mv6zTsrz6KOPGq137733KpGRkfrPH374YYmSH51dheUeGzduVABl48aN+nldunRRAOX999/Xz8vOzlZatWqlVK5cWcnJySn2GOi2L+lvxIgRxbaze/duBVC+/vrrIsuee+45BVCysrKKbSM+Pl4JCQnRSxTNyY9+/PFHZeTIkcqSJUuUFStWKC+//LISGBioVKxYUblw4UKx+zCH7vcbMGCA0fwnn3xSAZQDBw7o5wGKWq1Wjhw5YrSuqd9HUQrkbYsWLdLPGzFihAIob7zxhtG6rVu3VmJjY43mWetre/fuVQBl4sSJRuuNHDmySJvmsMQ3Cn83U+gkTKZ+n9tvv11p3759sdv3799fqVOnTpH56enpCmAkAbQU3e8SHR2tAMpzzz1ndt2DBw8qNWrU0H/fIUOGKBqNRjlz5owSEBBglcxK5y+W/JVG+qVjy5YtikqlUl555RWj+XPmzFGefvppZenSpcqyZcuUCRMmKN7e3kr9+vWV5OTkUu/n1q1bReSbpjDnc9HR0UbXF915Hxsba3T9mjlzpgIoq1atUhRFURISEhRvb29l0KBBRu1Nnz69yDVL12bHjh2NJKrXrl1TfH19lV69eikajUY/f968eQqgLFy40KydOrp06aJ06dJF/1n3u1avXl0v4VMURfnpp58UQPnoo48URVGU/fv3K4Dy888/mz5g+ejO98LXFXPEx8cb+U6NGjWUH3/8sch6GzZsKNa3LJEdbt++3WhfDRs2tNhOicTeyJ4vicTFGTp0KBMnTuT333+nT58+/P7776Xq8dLxxBNPGH3u1KkTK1asICUlhQoVKugTQqxatYpRo0bZZFCyt7c3Y8eO1X/29fVl7NixjBs3jr1799K+fXuz277//vtFpDymqFatWrHLMzMzAUz2fuiyqGVmZhbbO/LCCy9Qp04dRo8eXey+hg4dytChQ/WfBw0aRO/evencuTNvv/12mSSXTz31lNHnZ555hvnz57NmzRpatGihn9+lSxeaNGli9X50mPKXb775xuptDX3tjz/+ADCS6oH4ToYSyOIwlOIWR9OmTYtdXpJ/pKSklLh9Sb5lLVevXgWgQYMGZtdp3rw5J0+e5PDhw4SFhVGvXj0Ann32WYYMGUL79u1Zvnw5r7/+OikpKYwaNYpXXnlF30NjipYtW1p8fKtWrVqKbwTXrl1j+PDh1K5dm+eff95o2YQJE4w+DxkyhLZt2/LQQw8xf/58XnzxxVLtKyAgAF9fXzZt2sRjjz1mJM8sC2PGjDHqdRo3bhxTp05lzZo1DBgwgA0bNpCXl2fSv81Jah9//HGjxCLr168nJyeHiRMnGl2LH3/8caZOncrq1asZNWqUVfY/8sgjRhK+++67j6ioKNasWcP48eP1PVt//vkn/fr1IzAw0GQ706dPL5VEOCIignXr1pGVlcX+/ftZvny5yQyEa9asoUmTJlb3TAI0adKEdevWkZ6ezr///sv69etltkOJyyCDL4nExalUqRI9evTgu+++IyMjA41Gw3333VfqdgzHOwH6B5Fbt25RoUIFhg0bxpdffsno0aN58cUX6d69O4MHD+a+++6zOhCrVq1akSxWugfJc+fOFRt8xcbGWrXPwujGDJjKTqiTAOnWMcWOHTv45ptv2LBhg1XHoWPHjrRr147169eXeltDCssW69ati1qtLjL+zhYZ7fz9/alUqZLRvPDwcIuCYSjZ186fP49arS5iqy5wsARTWfKsoST/KM43dNtb61sl8cILL7BmzRrGjh1LWFiY2fPe39/fSDb5999/89dff3HixAlOnDjBAw88wOeff05MTAwPPvggNWvWLPbBPTw83GbH15D09HTuvvtuUlNT+eeffywahzZ8+HCeffZZ1q9fX+rgy8/Pj/fee49nn32WKlWq0L59e+6++24eeeSRUgeNhhQ+F4ODg4mKitKfi+fPnweK+nNERITZALDwuaBro2HDhkbzfX19qVOnjn65LexXqVTUq1dPb3/t2rWZPHkyH3zwAUuXLqVTp04MGDCA//3vf/rAzBp8fX31fnX33XfTvXt37rzzTipXrmxUMmX16tXcc889Vu8HoEKFCvp9DRw4kO+++46BAweyb98+WrZsWaa2JZKyIhNuSCRuwPDhw1m7di2fffYZffv2tSptubl0zUr+oPaAgAC2bNnC+vXrefjhhzl48CDDhg2jZ8+e+kQL5t6W2yKxRGFu3rxJQkJCiX8ljU2JiooCROriwsTHxxMREVFsr9fzzz9Pp06dqF27NufOnePcuXP68Ubx8fFcuHChxO9Ss2ZNbt68WeJ6pcHcb2HqYb+0v1tZU3uX5Gu2wBLfSEhIKLHnqST/KKlnNSoqioSEhCLfTddeSdsXR3BwMGvXrqVRo0Y89NBD/PXXXyVuo9FomDBhAi+++CLVq1fnp59+okOHDowaNYpu3boxduxYli5dWmwbOTk5Fh9fS8/9nJwcBg8ezMGDB1m1ahXNmjWzaDso2/kzceJE/vvvP9599138/f155ZVXaNy4cYlj+cA+1zVzlCVIt8d1+f333+fgwYNMnTpVnxynadOmXLp0yeo2C9OhQweioqKM/PHs2bMcP36cfv362Ww/AIMHDwbghx9+sGm7Eok1yOBLInED7r33XtRqNTt27DCb5dAWqNVqunfvzgcffMDRo0d5++23+fvvv9m4cSNQ0INROIGDubewV65c0Q8e1/Hff/8BlCgpGTx4MFFRUSX+FZYqFaZ69epUqlTJZFHXXbt20apVq2K3v3DhAlu2bKF27dr6v+eeew6AAQMGGEn+zHHmzJkiPUml5eTJk0afT506hVartUiaU9rfzd5ER0ej1WqLFP09deqUxW1Y4htRUVH8+OOPxbaj+/0L+8eVK1e4dOlSif7RqlUrMjIyimTu27lzp1H71hIZGclff/1FVFQUgwcPLjF74qeffkpqaipTpkwBxPcwDACrVavG5cuXi23j33//tfj4Fs6SZwqtVssjjzzChg0b+O677+jSpYsF31ygKArnzp0r0/lTt25dnn32Wf766y8OHz5MTk4O77//vn55eHh4kXMjJyfHZEAORc/FtLQ04uPj9edidHQ0UNSfExMTLe491rVx4sSJInadPXtWv9yc/WD+/C5sv6IonDp1qsi1pHnz5rz88sts2bKFrVu3cvnyZZtnq83KyjJ6gbZ69WpCQ0PLlKTGFNnZ2Wi1WosTyUgk9kTKDiUSNyA4OJhPP/2Uc+fOlVmOYY6bN28SERFhNE/34KiTVelSrG/ZskW/TKPRsGDBApNt5uXl8fnnnzN58mRAPDh8/vnnVKpUqURZoa3GfIEYO7JkyRIuXrxIzZo1AdiwYQP//fcfkyZN0q+Xm5vL6dOnCQ0N1feILFiwoEgq5b///puPP/6Y2bNn06hRI/3869evF3lIXLNmDXv37mX8+PEl2lkcn3zyCb169dJ//vjjjwH0WTCLIzo6Gi8vL7Zs2cKgQYP08+fPn18mm6yld+/eTJs2jfnz5/Phhx/q5+u+kyXYasxX06ZNadSoEQsWLGDs2LH6XrtPP/0UlUplJPVLTk4mPj6eqKgovfxq4MCBTJo0ifnz5zNv3jxAPMx+9tlnVK9eXV/suCxUr15dXwaif//+bN68mebNmxdZ7+bNm7z22mt89tln+jFnVapU0QeCAMeOHStRcmfrMV/PPPMMP/74I59//rm+B8IUps6fTz/9lOvXr9OnTx+L7DEkIyMDtVqtPxYgrmEhISFGUtG6deuyZcsWo20XLFhgtudowYIFjBo1Sj/u69NPPyUvL09/Lnbv3h1vb28+/fRTevbsqd9O5x+W0KNHD3x9fZk7dy59+vTR92599dVXJCcnG2UGrVu3Llu3biUnJ0dfMP7333/n4sWL1KlTp0jbX3/9NS+99JJ+3NeyZcuIj4/nhRdeACAlJYXAwECj0gvNmzdHrVYbHbcbN25w48YNatWqZXZcGAi5qUqlKrLOL7/8wq1bt4wks2vWrKFXr15WF29PSkoiKCioSCbIL7/8Eiia1VQicQYy+JJI3IQRI0bYtf033niDLVu20L9/f6Kjo7l27Rrz58+nRo0a+reQTZs2pX379rz00kv6YO2HH34gLy/PZJvVqlXjvffe49y5czRo0IAff/yRuLg4FixYUGKaZFuN+QKYOnUqP//8M926dWPChAmkpaUxa9YsmjdvbjT25fLlyzRu3JgRI0boEz8YBjw6dG+Zu3TpYnQz79ChA61bt6ZNmzaEhoayb98+Fi5cSM2aNY3qpYFItb5kyRLOnj1rUe/V2bNnGTBgAH369GH79u18++23DB8+3KLxC6Ghodx///18/PHHqFQq6taty++//861a9dK3NYexMbGMmTIEObMmUNiYqI+1byuV7S4ZBA6bDkmadasWQwYMIBevXrxwAMPcPjwYebNm8fo0aONUsivWLGCUaNGsWjRIn1dpRo1ajBx4kRmzZpFbm4ut99+OytXrmTr1q0sXbrUSIK5ePHiIttbSv369fnzzz/p2rUrvXv35p9//inyYP3KK6/QvHlz7r//fv28IUOG8MYbbzBu3Diio6P5/PPP+eCDD4rdly3HfM2ZM4f58+dzxx13EBgYyLfffmu0/N5779WPC42OjmbYsGE0b94cf39//vnnH3744QdatWpllLgHRA2rzZs3Fytl/e+//+jevTtDhw6lSZMmeHt7s2LFCq5evcoDDzygX2/06NE88cQTDBkyhJ49e3LgwAH+/PNPs6nwc3Jy9O2eOHGC+fPn07FjRwYMGACIgHfChAm8//77+nP2wIEDrF27looVK1rk35UqVeKll17i9ddfp0+fPgwYMEC/r9tvv53//e9/RvYvW7aMPn36MHToUE6fPs23335rth5hREQEHTt2ZNSoUVy9epU5c+ZQr149Hn/8cUC8XHr66ae5//77adCgAXl5eXzzzTd4eXkxZMgQfTuWppo/efIkPXr0YNiwYTRq1Ai1Ws2ePXv49ttviYmJ0asXMjMz2bhxo8neteTkZP3LGV35k3nz5hEWFkZYWBhPP/00IGqZjR8/nvvuu4/69euTk5PD1q1bWb58OW3atDE6bhKJ03BipkWJRGIGc6nMC1OaVPOFU8gXThu/YcMGZeDAgUq1atUUX19fpVq1asqDDz6o/Pfff0bbnT59WunRo4fi5+enVKlSRZk6daqybt06k6nmmzZtquzZs0e54447FH9/fyU6OlqZN29e6Q+IDTh8+LDSq1cvJTAwUAkLC1MeeughJSEhwWgdXYrvktLXm/t9pk2bprRq1UoJDQ1VfHx8lFq1ainjxo0rsh9FUZQhQ4YoAQEByq1bt4rdl+73O3r0qHLfffcpISEhSnh4uPL0008rmZmZRusCylNPPWWynevXrytDhgxRAgMDlfDwcGXs2LHK4cOHTaaaDwoKMmtH4f1Z42uKIlKxP/XUU0pERIQSHBysDBo0SDlx4oQCKDNmzCj2mNiDFStWKK1atVL8/PyUGjVqKC+//HKRcgi671E4fb1Go1HeeecdJTo6WvH19VWaNm2qfPvtt0X28fHHHyuA8scffxRri84PTaVI37p1qxIQEKDUrl1buXz5sn7+wYMHFV9fX2X//v1Ftlm8eLESExOjREZGKpMnTzZKaW5vdKULzP0Z+sTo0aOVJk2aKCEhIYqPj49Sr1495YUXXjBKi64jNjZWqVq1arH7vnHjhvLUU08pjRo1UoKCgpTQ0FClXbt2yk8//WS0nkajUV544QWlYsWKSmBgoNK7d2/l1KlTZlPNb968WRkzZowSHh6uBAcHKw899JCSmJho1GZeXp7yyiuvKFWrVlUCAgKUu+66Szl27JgSGRmpPPHEE0XaNHetnzdvntKoUSPFx8dHqVKlijJu3DiT14z3339fqV69uuLn56fceeedyp49e8ymmv/++++Vl156SalcubISEBCg9O/fXzl//rx+vTNnziiPPvqoUrduXcXf31+JiIhQunXrpqxfv95on5ammr9+/boyZswY/e/g6+ur1K9fX5k4caLRteL3339XVCqVcvXq1SJt6M4JU3/R0dH69U6dOqU88sgjSp06dZSAgADF399fadq0qfLaa68paWlpxdopkTgKlaLYcAS0RCKR5NO1a1du3LjB4cOHnW2KS1KlShUeeeQRZs2aVex6ukKr169fN/sm3lOIi4ujdevWfPvttzz00EPONsfmDB06lHPnzrFr1y5nm+LWpKamEhERwZw5c4qUYHBlkpKSCA8P56233mLatGkO3/+mTZvo1q0bP//8s1UZc+3Nk08+yZ49e+T5IfF4pOxQIpFIHMyRI0fIzMzUj7Eoj2RmZhbJ8DZnzhzUajWdO3d2klX2Q1EUNm3aVER2Jyk9W7ZsoXr16nqZnCtizr+BYiV65ZlWrVrZbUyzROJKyOBLIpFIHEzTpk1LLN7r6cycOZO9e/fSrVs3vL29Wbt2LWvXrmXMmDH6pCiehEqlctoYO0+jf//+RgknXJEff/yRxYsX069fP4KDg/nnn3/4/vvv6dWrF3feeaezzXNJxowZ42wTJBKHIIMviUQikTicDh06sG7dOt58803S0tKoVasW06dPd4ocSyKxNS1atMDb25uZM2eSkpKiT8Lx1ltvOds0iUTiZOSYL4lEIpFIJBKJRCJxALLIskQikUgkEolEIpE4ABl8SSQSiUQikUgkEokDkGO+rESr1XLlyhVCQkIsKpgokUgkEolEIpFIPBNFUUhNTaVatWqo1eb7t2TwZSVXrlzxyIxcEolEIpFIJBKJxDouXrxIjRo1zC6XwZeVhISEAOIAV6hQwWl2aLVaLl26xI4dOxg4cCB+fn5Os8XV0Gq1JCQkAFC1atVi30KUJ6TPmEb6i3mkz5hG+ox5pM+YRvqMeaTPmEb6jHlczWdSUlKoWbOmPkYwhwy+rEQnNaxQoYJTgy+NRsPVq1fJy8sjJCQEf39/p9niamg0GuLi4gCoX78+Xl5ezjXIRZA+YxrpL+aRPmMa6TPmkT5jGukz5pE+YxrpM+ZxVZ8paTiSDJ8lEolEIpFIJBKJxAHI4EsikUgkEolEIpFIHIAMviQSiUQikUgkEonEAcjgSyKRSCQSiUQikUgcgAy+JBKJRCKRSCQSicQByOBLIpFIJBKJRCKRSByATDXv5qjVapo2bcqNGzdk7YdCqNVqmjdvrp+WCKTPmEb6i3mkz5hG+ox5pM+YRvqMeaTPmEb6jHnc1Wdk8OXmqFQqIiMj8ff3L7GuQHlDd2wkxkifMY30F/NInzGN9BnzSJ8xjfQZ80ifMY30GfO4q8+4T5gokUgkEolEIpFIJG6M7Plyc7RaLVevXiUjIwOtVutsc1wKrVbLtWvXAKhcubJbdUnbE+kzppH+Yh7pM6aRPmMe6TOmkT5jHukzppE+Yx539RkZfLk5iqJw4sQJkpOTURTF2ea4FIqicPz4cQAqVarkZGtcB+kzppH+Yh7pM6aRPmMe6TOmkT5jHukzppE+Yx539RkZPkskEolEIpFIJBKJA5DBl0QikUgkEolEIpE4ABl8STwXRSEMLyrjDUmp4EZd0hKJROLWaDSExcVRb/du1Fu2gEbjbIskro5WQ1hOHPW8d6O+vgW00mcA/blUecMG2LRJnksGaDQQFxfG7t312LJF7TaHxqnB15YtW7jnnnuoVq0aKpWKlStXGi1XqVQm/2bNmmW03urVq2nXrh0BAQGEh4czaNCgYverKAqvvvoqUVFRBAQE0KNHD06ePGnjbydxKtdvod59hFaqAJqo/PE6fAp2HITrt5xtmUQikXg2y5ejrluX2ClT6LFwIb69e0NMDCxf7mzLJK7KxeWof69L7K0p9AhciO/W3vBrDFws5z6Tfy61mjSJJm+9hVePHvJcymf5cqhbV82UKbEsXNiD3r193ebQODX4Sk9Pp2XLlnzyyScml8fHxxv9LVy4EJVKxZAhQ/Tr/PLLLzz88MOMGjWKAwcOsG3bNoYPH17sfmfOnMncuXP57LPP2LlzJ0FBQfTu3ZusrCybfj+Jk7h+C46ehpxc4/k5uWK+DMAkEonEPixfDvfdB5cuGc+/fFnMd4cnI4ljubgctt4HmYV8JuOymF9eAzB5LpnF3Q+NU7Md9u3bl759+5pdXrVqVaPPq1atolu3btSpUweAvLw8JkyYwKxZs3jsscf06zVp0sRsm4qiMGfOHF5++WUGDhwIwNdff02VKlVYuXIlDzzwQFm+ksTZKAqcugCA2XJ7py9AxTBwo4J8EolE4vJoNDBhAihK0euvoohr7sSJMHAgeHk5wUCJy6HVwN4JgAmfQQFUsHciVB8I6nLkM/JcMovBoaHwk567HBq3STV/9epVVq9ezZIlS/Tz9u3bx+XLl1Gr1bRu3ZqEhARatWrFrFmzaNasmcl2zp49S0JCAj169NDPCw0NpV27dmzfvt1s8JWdnU12drb+c0pKCgC5ubnk5uaa3MYRKIpC/fr1uX79OhqNxqm2uAKq5DS8C/d4FSY7l7zEJJTQYMcY5WJInzGNoig0aNAAAI1G41Y1Q+yN9BnTSJ8xRrV5M96FX0Uboihw8SJ5GzeidOniOMNcCOkzxqiubcY7oxifQYGMi+TFb0SpXH58Rp5L5tm8WcWlS+bDl/xDw8aNeXTp4tix/pbeG90m+FqyZAkhISEMHjxYP+/MmTMATJ8+nQ8++ICYmBjef/99unbtyn///UdERESRdhISEgCoUqWK0fwqVarol5ni3Xff5fXXXy8y/6+//iIwMNCq72RLAgICWL9+vbPNcDrVfQJoE1T0dy9M3K7dXM7NdIBFrov0GUlpkT4jKY7qW7bQxoL14tau5XJ6ut3tkbg+1fMs9Jkda7nsXX58Rp5L5tmypTpYcHTWro0jPf2y/Q0yICMjw6L13Cb4WrhwIQ899BD+/v76ebo3RtOmTdOPA1u0aBE1atTg559/ZuzYsTbb/0svvcTkyZP1n1NSUqhZsya9evWiQoUKNtuPNeTm5rJu3Tp69uyJj4+PU21xNqrkNDhyusT1WrW9nZbltOcLpM9ISo/0GUlJqIKC4IMPSlyvVd++tCxnb+slplFdC4LNFvhM+760LE89X/JcMktQkMqSQ0Pfvq3o0qWl/Q0yQKeKKwm3CL62bt3KiRMn+PHHH43mR0VFAcZjvPz8/KhTpw4XLlww2ZZuHNnVq1f12+s+t2rVyqwNfn5++Pn5FZnv4+Pj1AcRRVG4fv06mZmZeHt7y4eiyDDw9SmabMMQPx+8I8PK7Zgv6TOm0R0XgEqVKqEqp/5hCukzppE+U4hu3aBGjaKj4HWoVFCjBt7durnuYAw7I32mEFHdILCGSK6BKYmYCgJr4B3VrXyN+dKdS5cvmy+TU7NmuTyXunWD4GBISzO9PP8yQ7du3g4/NJbeG92iztdXX31FbGwsLVsaR7CxsbH4+flx4sQJ/bzc3FzOnTtHdHS0ybZq165N1apV2bBhg35eSkoKO3fu5I477rDPF7AjWq2WY8eOkZSUVO6144A46+rVKn6durXKbeAF0mfModVqOXr0KEePHpXHpRDSZ0wjfaYQXl7w0UfFrzNnTrl7WDRE+kwh1F4QK3ymaIiRf5+OnVO+Ai8oOJeKq0/6/PPl8lzaudMw8DI+PrpHO1e/zDg1+EpLSyMuLo64uDhAJMOIi4sz6rVKSUnh559/ZvTo0UW2r1ChAk888QSvvfYaf/31FydOnGDcuHEA3H///fr1GjVqxIoVKwBRO2zixIm89dZb/Prrrxw6dIhHHnmEatWqlVgfTOImVAqHcBNSUG8vaFJXLJdIJBKJ7Rk0CCIji84PCoJly8Bg3LZEAkDNwXD7p0Wz+gXWgE7LxPLyyODBcO+9RefrVFg//FDuCi5nZsKoUWK6SxfRw2VIjRrucZlxquxwz549dOvWTf9ZN6ZqxIgRLF68GIAffvgBRVF48MEHTbYxa9YsvL29efjhh8nMzKRdu3b8/fffhIcXPGCfOHGC5ORk/efnn3+e9PR0xowZQ1JSEh07duSPP/4wGk8mcXPyZYdnlWxC8KKiyhvCQmTgJZFIJPZkxw5ITEQJCWH/tGkomzYR+8cf4oHxnnucbZ3EVQkSipUsdUW8NbfwVmmg61oIa+pkw5yIosCBAwCcHTGCzJo1adi1K161a0OrVrBtm+gdM8hH4Om8/DL89x9UqwYrVkBQkJaPP47j6NFbDBvWme7dfV26x0uHU4Ovrl27ohTXpQqMGTOGMWPGmF3u4+PD7NmzmT17ttl1Cu9DpVLxxhtv8MYbb5TOYIl7kKeBdJHJMJ48EtFQEW+4mSLeErnDmSmRSCTuyE8/AaAMHMitNm04FRzMbXv3orp+HTZuhF69nGygxCVJPiL++TRBkxNPNe+TkLirfAdf+/bBmTMogYFcHDYMbUAADTt1Es8w778PY8bAtGnQrx80auRsa+3OP//Ahx+K6S++gPBw8UjXqlUSQUGn6Ny5o9s83rnFmC+JpFSkirSrip8POSikoUXx9wWtFhKTS9hYIpFIJFah1cLPPwOg3Hef+O/lhUYn6c8PzCSSIuQHX+neMVzV1Bbzbmx3okEugO5FRv/+aAMCjJeNHi1eZGRlCR2eh8sP09PF11QUePRREW+6MzL4kngeKWIkphISpJ+lVMyXG16/5QyLJBKJxPP591+4cgVCQ6FnT/1sbX4pGJYvB1mgW2KKJMPgq46YV56DL0UpCL4MchjoUangyy+hQgUh9bUk97obM3UqnDolxnR5wleVwZfE80jJLzhoFHyFiYmbSR7/hkgikUicgq5na9CggqQAgLZjR6hcGW7dAoNMwxIJAIoWUo4CkOYdTYKu5yv5COSUU7XKnj1w7pxIVNOnj+l1atYUaf0AXnkFjh51lHUOZfNmmDtXTH/5pXi34+7I4MvNUalUNGzYkNDQUFkvBMTbovyeL0KDadSoEY0aNUIVHAgBfqBVyr30UPqMaVQqVYG/yONihPQZ00ifMUCjEWnGAIYONfYZb2/IlyGWd+mh9BkTpF+AvHQUtQ81G3fDr0JNlKA6gAKJO51tnXPQnSf33IMqKMi8z4wcKTR42dliOi/P0ZbalbQ0ITMEePxx6N3beLm73ptk8OXmqNVqqlSpQmBgIGq1/DnJzBYJN9Qq1CFBVK1alapVq6L28irIdHj9pnNtdDLSZ0yjVqsL/EUeFyOkz5hG+owB27ZBfDyEhUGPHkV9ZuhQsd6KFZCT41RTnYn0GRPkj/dShTSkSlQNAgMDUSLbi2XlUXpoIDnk/vuL9xmVChYsEN1Bu3fDrFmOt9eOvPginDkDtWqBqbx67npvch9LJRJL0PV6BQdB4ROxUoT4n5gsAjSJRCKR2Abdw+K994Kvb9HlHTtC1aqQlATr1zvUNImLkx98EVqQ2VAffF3/1wkGOZldu+DCBSE57Nu35PWrVy/Q5b32Ghw+bF/7HMTff8Mnn4jpr74Sw9s8BRl8uTmKopCYmEhWVlaJafvLBbrgq0KQ/tgkJiaKYxMUIKSHiiLGfpVTpM+Ypoi/SPRInzGN9Jl8NBr45Rcxnd/DVcRnvLwKpIf5GRHLI9JnTJAffCmhTfQ+o41oJ5Yl7hRjwsoTuvNjwAAICLDMZx5+WNTRy80V8kM3T2yTmlogN3ziCejRw/R67npvksGXm6PVajly5Ai3bt1Cqy1nFyhT6JJthAaj1Wo5dOgQhw4dEsdGpSro/bpWfrMeSp8xTRF/keiRPmMa6TP5/PMPJCSIwjvduwNmfEZKD6XPmCI/+NJWaKL3GU1IE/AOgtxkSD7mZAMdiKHkMP98schnVCr4/HNxDu7dC++95yCD7cPzz8P58xATAzNnml/PXe9NMviSeA55efriylQINr2ObtzXTSk9lEgkEptgKDn08TG/3p13QlQUJCfDunWOsU3i2ijaguCqQpOC+WpviGwrpsvTuK+dO+HiRQgONp/l0BxRUfDxx2L6jTfgwAHb2+cA1q2Dzz4T0wsXQkiIc+2xBzL4kngOul4vf1/wNfMAEBQAgf7i7VJiksNMk0gkEo+kUJbDYlGrZdZDiTHp50CTAWpfCK5rvKziHeL/jXI07kt3XgwcCP7+pd9++HBR6sFN5YcpKfDYY2L66aehWzfn2mMvZPAl8Rx0wZe5Xi/Ilx7KgssSiURiE7ZsgWvXICIC7rqr5PV1AdrKlSI9tqR8k19cmQoNRW+XIfrgq5z0fGm1BeO9SnqRYQ6VSnQbRUZCXBy8847NzHMEzz4rOv7q1IEZM5xtjf2QwZfEc9An2ygm+IKCcV83kz2uJoZEIpE4FN2b+sGDi5cc6ujQAapVE6+4//rLvrZJXB8TmQ716DIephyH7HJQImbHDrh0SaT169XL+naqVClIE/jWW7B/v23sszN//CGKKAMsWiSSPXoqMviSeAaKYtDzVcIZG+hvID0s3wWXJRKJxGry8opkOSwRtRruv19MS+mhpLjgy78ihDQQ0+Wh2LLufBgwwDrJoSFDh8KQIeIcHTHC5RPcJCXB6NFiesIE6NzZqebYHRl8STyDjCwx9kCthuDA4tc1lB5eKwdv0yQSicQebN4M168LiVNpBmfoArVVqyAryz62SdyD4oIvKJAeenq9L1tIDg1RqWD+fKhYEQ4dgjffLHubdmTyZLh8GerVczulpFXI4MvNUalU1KtXjwoVKqBSqZxtjvPQSQ5DAsVFB3Fs6tevT/369YseG5308FZKuZMeSp8xTbH+Us6RPmOacu8zujf1Q4aAt/F4nWJ9pn17qFFDFPP5808HGesalHufMUSrgZT8TIehTU37THkZ9/Xvv3DliknJodU+U7myCMAA3n1XpKB3QVavFjJDlQoWL4bAEt6fG+Ku9yYZfLk5arWaatWqERQUhFpdjn9OE8k21Go11atXp3r16kWPjWHWwxtJjrPTBZA+Y5pi/aWcI33GNOXaZ/LyYPlyMW3iTX2xPlOOpYfl2mcKk34WNFmg9oPguqZ9plIH8T9xpwjWPBXdeTBoEPj5GS0qk8/cfz8MGyaUQSNGuFySm1u34PHHxfSkSaIaRWlw13uT+1gqkRSHpck2DNH1fsmshxKJRFI6Nm2CGzeErKlLl9JvrwvYfv0VMjNtaprETUg+Kv5XaARqL9PrVGgC3iGQl1YgUfQ0tFrLyzVYw7x5ohfsyBF4/XXbt18GJk6E+Hho0EDkBikvyODLzVEUhaSkJLKzs1EUxdnmOIfcPDHmC4ySbeiOTVJSkuljoxv3dStFtFFOkD5jmhL9pRwjfcY05dpnipEcggU+064d1KwJaWnlSnpYrn2mMIXGe5n0GbUXVGwnpj213te2bSICCQ2Fnj2LLC6zz1SsWFC1+L33YNeuMhpsG379Fb7+WnSEL1kCAQGlb8Nd700y+HJztFotBw8e5ObNm2i1Wmeb4xx0ksMAP6Piylqtlri4OOLi4kwfm6AA8VfOCi5LnzFNif5SjpE+Y5py6zO5ucVKDsECn1GpyqX0sNz6jCl0wVeYCL7M+oynj/vS+f+994Kvb5HFNvGZe+8VBZi1WiE/dHKim8REGDtWTE+ZIoaBWoO73ptk8CVxf6yRHOrQF1yWWQ8lEonEIjZuFE9PlSuXLSe0lB6Wb0rKdKijYv64L08MvjQa+0oODZk7F6pWhePH4bXX7LuvEhg/HhISoHFjl1NCOgQZfEncH33wZUVFPn3Ww9RyJT2USCQSqylBcmgxbdtCrVqQng5r19rGNol7oNWI4slgQfCVLztMPQlZN+xrl6P55x8RhYSHQ/fu9t1XZCR8/rmYnj0btjsnmF2xAr77TsgNFy8ue0kzd0QGXxL3RlEgtWimQ4sJ9C+QHpazrIcSiURSaiyQHFqMSlXQRjmSHkqAtDMi06GXPwTVLn5d33Co0FhMe1rvl2GWQxOSQ5szYAA8/LCQH44c6fAe5xs34IknxPQLL4j3L+URGXxJ3Jv0TNBowUstgihrkNJDiUQisYwNG0R+6CpVoFOnsrenC75++w0yMsrensQ90EkOKzQ2n+nQEE8c9+VIyaEhH30EUVHw33/w8suO2y/w9NNw7Ro0bep05aNTkcGXxL3RJdsICdIXVy41hgWXpfRQIpFIzKN7U3/ffeBlwUNzSbRpAzExIvBas6bs7UncA0vHe+mo5IHjvrZsEZGIIySHhoSHwxdfiOkPPxTZFh3Azz/Djz+Ky8aSJUXKmZUrZPAlcW/KkmxDR6A/BOf3mt2QNb8kEonEJDk5YsAG2O5NvZQelk9KG3zper4Sd4HWQ16S6vx98GDw8Sl+XVvTvz+MGiWGXIwcafde52vX4MknxfRLL0FsrF135/LI4MvNUalU1K5dm5CQEFTW9vy4M8Uk21CpVNSpU4c6deqUfGzKUcHlcu8zZiiVv5QzpM+Yptz5zIYNkJQkMqbdeWexq5bKZ3TB1+rVIvmGB1PufMYcJoKvYn2mQiPwCQNNBiQddJyd9iIvz+Kxk3bzmQ8+gBo14NQpmDrVdu0WQlFE4HXjBrRoAa+8Yru23fXeJIMvN0etVlOzZk2Cg4NRq8vZz5mbC5nZYtpEz5daraZWrVrUqlWr5GNjVHA518aGuhbl2meKoVT+Us6QPmOacuczpZAclspnbrsNatcuF9LDcuczptDmFWQ6DCsIvor1GZXaoNiyB0gPdZLDyEjo1q3YVe3mM2Fh8OWXYvqjj2DzZtu1bcBPP8Evv4jEqIsX2zaviLvem9zHUomkMLrxXoH+4FOGdMcAAf4QHCimZdZDiUQiMcYekkMdUnpYvkg7Ddoc8AqAoBjLt/Okel/OlBwa0rs3jB4tph991OY9zwkJBXLDl1+G1q1t2rzbIoMvN0dRFFJTU8nJyUFRFGeb41hKqO+lKAopKSmkpKRYdmx0vV/XPDvrYbn2mWIotb+UI6TPmKZc+cy6dZCcLLKklSA5BCt8xlB6mJZWRmNdl3LlM+YwzHSoKngMLdFnPCXjYV6e6AoCi15k2N1n3n8fataEM2fgxRdt1qyiiLTyN29Cq1b2UTa6671JBl9ujlarZf/+/SQmJqLVap1tjmNJLr6+l1arZd++fezbt8+yY6Mb95WUCjmeKz0s1z5TDKX2l3KE9BnTlCuf0b2pv/9+UR21BErtM61bQ926ou7Q6tVlNNZ1KVc+Y44k08k2SvSZiu0AlagRlnnV/nbai02bxACoihWha9cSV7e7z1SoAAsXiul582DjRps0+913sGqV6NhbvNg+HXzuem+SwZfEPSlrcWVTBPhJ6aFEIpEUJjsbVq4U0/aqRySlh+UHXc9XmIWZDnX4VICwZmLanXu/DCWH3mUcMmErevSAsWPF9KOPQmpqmZqLj4dnnhHTr74KLVuW0T4PQwZfEvckLVNUaPfyEmO+bIUsuCyRSCTG/PUXpKRA9epwxx32248u+FqzpswPfxIXprRp5g1xd+lhbq7FWQ4dzqxZEB0N587B889b3YyiiDju1i2RUv6FF2xnoqcggy+Je2I43suW6UXLifRQIpFILKaUkkOradkS6teHrCz4/Xf77UfiPLS5kHpCTJcp+PrXdjY5ko0bITERKlWCLl2cbY0xISEF8sPPPoP1661q5ptv4LffRFZDe8kN3R0ZfEnckxKSbVhNgB+E6KSHnl/zSyKRSIolK0sM3AD7v6mX0kPPJ/W0CMC8AiEouvTb64Kvm3tAk2Nb2xyBzq+HDHEdyaEhd90FTz0lph97TPR4l4LLl2H8eDE9fTo0a2Zb8zwFGXxJ3JMUG4/3MqQcFVyWSCSSYvnrLyEBrFED2rWz//50wdfatVJ66InoJYdNjDIdWkxIA/CNAE0WJB2wrW32JjfXfuUabMmMGaLu3oULMGWKxZspCowZI5Ki3n47PPecHW10c2TwJXE/cnIhS1dc2cY9X1Aw7ktKDyUSSXnHUZJDHc2bQ4MGIsnHb7/Zf38Sx1KW8V4gekfdddzX33+LvOuVK0Pnzs62xjzBwbBokZj+4gv480+LNlu8WAzX9PMT067YsecqyODLzVGpVERHRxMcHIzKlmOfXBmd5DDQv9izW6VSERMTQ0xMTOmOjb8fhOQHdR7Y+1UufcYCrPaXcoD0GdN4vM9kZlotObTaZzxceujxPlMSxQRfFvuMLvi67mbjvnT+fN99IlmYhTjFZ7p0KdAPjh4turOK4eJFmDhRTL/5JjRpYl/zdLjrvUkGX26OWq0mOjqakJAQ1I54K+kKWCg5VKvV+gtWqY+NB2c9LJc+YwFl8hcPR/qMaTzeZ/78UxQ8rlWr1JLDMvmMofSwlGNOXB2P95mSKCb4sthn3LHnKyfHasmh03zmnXegXj24dAkmTza7mqKI+CwlBdq3L3ZVm+Ou9yb3sVQi0aFPtmGH8V46dMFXchpku+GgXolEIikrhpJDR75VbtYMGjUSD6y//uq4/UrsizYXUv8T06Wt8WVIZFsxXizjAmRcsY1t9mbDBpF7vWpV6NjR2dZYRlCQkB+qVCIL4po1Jlf78ksxNNTfX8gNS9GpV26RwZeboygK6enp5ObmoiiKs82xP1otpGaI6dDix3vpjk16enrpj42h9NDDCi6XO5+xkDL5i4cjfcY0Hu0zmZkFgY8VyQHK5DMeLD30aJ8pidSTIgDzDobAWkUWW+wzPsEQ1kJMu0vvl2GWw1JGJ071mY4dC/SEjz8uAkgDzp+HZ58V02+/DQ0bOtY8d703yeDLzdFqtezdu5cbN26g1WqdbY79Sc8vruztBQHFF1fWarXs3r2b3bt3W3dsKnum9LDc+YyFlNlfPBjpM6bxaJ9ZuxbS00XR1dtvL/XmZfYZXfD155+QlFT67V0Uj/aZkjDKdFi0J7VUPuNO9b7KIDkEF/CZt94SSXCuXCkIxBByw8ceE0lJ77wTJkxwvGnuem9yavC1ZcsW7rnnHqpVq4ZKpWLlypVGy1Uqlcm/WbNm6dfRDUA0/JsxY0ax++3atWuRbZ544gl7fEWJrUm2U3FlU1SMKNinlB5KJJLyhO5N/dChjpUc6mjaVIzal9JDzyGpjJkODXGncV/r1omEFVFRIkpxNwIDhZ5QrYavv9ZnIf38c6GmDAgQ6kQpN7QcpwZf6enptGzZkk8++cTk8vj4eKO/hQsXolKpGDJkiNF6b7zxhtF6zzzzTIn7fvzxx422mTlzpk2+k8TO2LO+V2H8fQtS2Xtg1kOJRCIxSUZGQZr3++93nh0eKj0st5Q1zbwhFTuI/zf3gia77O3ZEyuzHLoUd9xRoC8cM4bz+2/qS4C9+y7Ur+8809wRp2bh79u3L3379jW7vGrVqkafV61aRbdu3ahTp47R/JCQkCLrlkRgYGCpt5G4AI5ItmFIpQgR8F2/BTWqOGafEolE4kzWrhUBWEwMtGnjPDvuvx+mTxej+ZOSICzMebZIyo4tg6/gOuBXCbKvw639ULF92du0B9nZVpdrcDneeEO8lDl+nP/6jic9/Vs6dQIL+jskhXCbEmhXr15l9erVLFmypMiyGTNm8Oabb1KrVi2GDx/OpEmT8C6hutvSpUv59ttvqVq1Kvfccw+vvPIKgYGBZtfPzs4mO7vg7UpKfvrb3NxccnOdV4hXo9Hoda65ubl4uetbFUvIycUnOwcFyAvwFdXii0Gj0aDRaABxbKzSA4eF4AOQkkZuWgb4+ZS+DRejXPlMKbCJv3go0mdM46k+4/XDD6gBzZAhaPPyrGrDJj5Tvz7eTZqgOnqUvF9+QXnkEatscSU81WdKRJuDd+pJVEBuUAOT9+/S+oxXZDvUV35Hc3Ur2tBYe1hdZlRr1+KdnIxSrRp5t99e4nOLKVzGZ7y8UH35JepOnel5dSlDfYfw+oK70Wgg3zyH42r3JkvjAbcJvpYsWUJISAiDBw82mj9+/Hhuu+02IiIi+Pfff3nppZeIj4/ngw8+MNvW8OHDiY6Oplq1ahw8eJAXXniBEydOsHz5crPbvPvuu7z++utF5v/111/FBm32RqvVcvXqVQDWr1/vVnUOSkuUjz9tgyJJ0eSyyYKK64bHJiUlxepj0zG4IpHefhzf+i9nctKtasOVKE8+Uxps5S+eiPQZ03iiz3hlZdHnt99QA1ujokg2k166JGzlMw1atqTx0aPc+PRTdlasaFUbroQn+owlhGjPc5eSRy4BrNl4EFSHiqxTWp+pnxNOEyDh8Er2nGpgD7PLzG0ffURN4Mxtt3H4jz+sasOVfCY+PpBU9RSe08zkC6/RbNs9hxMnKjjNHle7N2VkZFi0nkpxkdyMKpWKFStWMGjQIJPLGzVqRM+ePfn444+LbWfhwoWMHTuWtLQ0/Pz8LNr333//Tffu3Tl16hR169Y1uY6pnq+aNWty48YNKlRwnuNpNBq2bt3K6dOneeihh/D3Lz4DoDujPncFryvX0VSJRFu3RonrazQatm3bBsCdd95p9RsRdfx1vM5eQRsSiKa5+wuby5PPlAZb+YsnIn3GNJ7oM6ply/AePhylTh3yjh2zOtmGzXzm2DF8WrZE8fYm7/JlCA+3rh0XwRN9xhJUF3/Ce8f/0Ea0RdP9H5PrlNZnVNe34r2pO0pAdfLuPmsPs8tGVhbeNWqgSkkhb/NmlDvusKoZV/EZrRZ69PBi1z+5HA+MpXbGEbRDh6L59lun2AOud29KSUmhYsWKJCcnFxsbuEXP19atWzlx4gQ//vhjieu2a9eOvLw8zp07R0MLCw60a9cOoNjgy8/Pz2Qw5+Pjg4+P86RoXl5e1KpVi4SEBHx9fZ1qi91JE28UvMJC8LLge3p5eRETEwOAr6+v9W9EqlSEs1dQp2ag1igiEYcbU658phTYzF88EOkzpvFIn8lXgKiGDsXH1/prnc18pkULaN4c1aFD+KxeDaNGWW2TK+CRPmMJaScAUIc1Q23GF0rtM5Xbg8obVeZlfHISIKimra0uG2vXQkoK1KiBd8eOIlugFbiKz3z0EfzzDwQF+eG7dDEMaY/6p59Q33+/SCbiBFzt3mTp/t3irP/qq6+IjY2lZcuWJa4bFxeHWq2mcuXKFrcfFxcHQFRUlLUmOg21Wk2dOnWoUKGCZ1/EDYsrW5hsQ61WU7duXerWrVu2Y+PnC6H5+7zh/jW/yo3PlBKb+YsHIn3GNB7nM2lpsHq1mC5jcgCb+owHZT30OJ+xFAuSbZTaZ7wDITz/udAV630ZZjksw2/tCj5z8iS89JKYnj0bqg9sAy++KGY8+SRcv+4Uu9z13uRUS9PS0oiLi9MHP2fPniUuLo4LFy7o10lJSeHnn39m9OjRRbbfvn07c+bM4cCBA5w5c4alS5cyadIk/ve//xGeL024fPkyjRo1YteuXQCcPn2aN998k71793Lu3Dl+/fVXHnnkETp37kyLFi3s/6Ul1pGWISr6+XhDgGVyUptSKb/m1zWZcl4ikXgoq1dDZibUqwetWjnbmgJ06e7Xr4fEROfaIrEOW2Y6NMRV631lZnpMlkONRnQ4Z2ZCjx4wdmz+gldegebNReD11FNOtdHdcGrwtWfPHlq3bk3r1q0BmDx5Mq1bt+bVV1/Vr/PDDz+gKAoPPvhgke39/Pz44Ycf6NKlC02bNuXtt99m0qRJLFiwQL9Obm4uJ06c0A+C8/X1Zf369fTq1YtGjRrx7LPPMmTIEH7T1TRxMxRFISsri7y8PFxk+J59SCl9cWXdscnKyir7sakYJv6npkOWi9cUKYFy4zOlxKb+4mFInzGNx/mMDQsr29RnGjaEli0hLw9WrixbW07G43zGEjTZkHpKTIeZD76s8hldvS9XC77+/FP0JNesCflDW6zF2T7z0UewbRuEhMCXXxpcGvz8RPFlb2/4+Wen9Ey7673JqWO+unbtWuLBGjNmDGPGjDG57LbbbmPHjh3Fbh8TE2O0j5o1a7J58+bSG+uiaLVadu3axfXr1z07Za0VxZW1Wq3ePzp16lS2Qao66WFymqj5VdN9a8SVG58pJTb1Fw9D+oxpPMpn0tJAl9nQBoWVbe4zQ4fCgQPiAe+xx8renpPwKJ+xlNT/QNGATwUIqG52Nat8RtfzdWs/5GWCd4ANDLYBukDk/vvLJDkE5/rMiRMwbZqYfv99iI4utMJtt4kVXn9dyA+7dIEqjquJ6q73JvcRSErKN8kGPV/OQic9vC6lhxKJxMP4/XfIyoL69UUvk6uhCwg3bJDSQ3cjyUByWMYe1SIERYN/VdDmws29tm3bWjIzRTFicGvJoUYDI0eKy0KvXmBi9I9g6lRxzUhMhHHjxBARSbHI4Evi+mTlQE5+4boQZwZf+SmOPUB6KJFIJEbYUHJoF+rXF+PQNBpYscLZ1khKg73Ge4HwVVcb9/XHH6InuVYtaNvW2dZYzQcfwI4dUKFCIblhYXx9YckSIT9csQK+/96hdrojMviSuD668V7BgeBMiYavD4SFiGnZ+yWRSDyF1NQCyaErv6n3oKyH5Qp7Bl8AlVxs3Jerv8iwgKNHRT4NgDlzxNC1YmnZEnT5Gp5+GuLj7Wme2yODL4nrk+ICkkMdut6v6+6fcl4ikUgAIZHKzhaJLZo3d7Y15tFJD//+22mprSVWYO/gy7Dny9mSt4wMt5cc5uUJuWF2NvTrJ6Yt4sUXxRiwW7dESkRn/xYujAy+JK6PFck27EZFnfQwAzKl9FAikXgA7vKmvl498XAnpYfugyYL0vIzHdor+IqIBbUPZCVA+jn77MNS1q6F9HSIiYE2bZxri5XMmgW7d0NoKCxYUIpLgo+PyH7o4yMC0G+/taeZbo0MviSujVYranyBawRfRtJD2fslkUjcnJQU8cAI7vGmXkoP3YuUE6BowScMAqLssw8vfwgXJYucLj00zHLoyi8yzHD4MEyfLqbnzoXq5pNTmqZ584IGxo+HK1dsaJ3nIIMvN0elUlGtWjUCAwNRueGJXiKp6QXFlf19S7Wp7thUq1bNtsfGzbMeerzPWInd/MUDkD5jGo/wmV9/hZwcaNwYmtquZ8JuPqOTHm7cCNeu2a5dB+ERPlMadJLDsJIzHZbJZ1yh3ld6usgaCjZ9keEon8nNFRLDnBy45x54+GErG3r+edHrl5QEY8bYVX7orvcmGXy5OWq1mnr16hEaGoq6jLUkXBJDyWEpTyy1Wk2DBg1o0KCBbY+NruByWgZkZtmuXQfh8T5jJXbzFw9A+oxpPMJn7PSm3m4+U6eOeLDTamH5ctu16yA8wmdKQynGe5XJZ1wh4+GaNWLMV+3aEBtrs2Yd5TPvvQd790J4OHz+eRkuB97eIvuhry+sXi2m7YS73pvcx1JJ+cSVkm3okFkPJRKJJ5CcDH/+KabdQXKoQ0oP3Qd7J9vQoS+2HAd56fbdlzncZeykCQ4ehDfeENMffwxRZVWINmlS0OCECXDpUhkb9Cxk8OXmKIpCTk4OGo0GxdMyyyhKmZJt6I5NTk6O7Y9NZfeVHnq0z5QBu/qLmyN9xjRu7zM6yWGTJjaVHIKdfUYnPdy8Ga5etW3bdsbtfaa0JFkefJXJZ4JqQkB1UDSQuMcKQ8tIerro5QGbv8iwt8/k5sKIEeL/oEEwfLiNGn72WWjXTowrHT3aLvJDd703yeDLzdFqtezYsYNr166h1WqdbY5tyc4vrqxSWVVcWavV8u+///Lvv//a/ti4sfTQo32mDNjVX9wc6TOmcXufMXxTb2Ps6jMxMXD77W4pPXR7nykNeZmQdlpMWxB8ldlnnFnva/VqyMyEunWhdWubNm1vn3nnHYiLg8hI+OwzG3baeXuL7Id+fqKH/auvbNRwAe56b5LBl8R10RdXDgAvF3NVHx8IryCm3bD3SyKRlHOSkgokh7qeJHdCSg9dn5TjgAK+EeBfxf7704/7+tf++yqMm0oO9++Ht94S0598AlVs/TM1agRvvy2mJ0+GCxdsvAP3xMWeaCUSA5JdqL6XKWTBZYlE4q6sWiV0Rs2aCdmhu2EoPUxIcK4tEtPox3s1cUxA4qxiy2lpdpMc2pOcHCE3zMuDIUPsaPrEidChA6SmwmOPyeLLyOBL4srok224aPClK7iclgkZ7iU9lEgk5Rw7Sg4dQnS0GE+iKPDLL862RmIKRyXb0BHeGtS+kH2jQO7oCH7/HbKyRBHwli0dt98y8uabcOgQVKwI8+fbMT728oJFi8DfH9avF5Wbyzky+JK4JhoNpGeKaVfKdGiIj7eB9FD2fkkkEjfh1i346y8x7Y6SQx1SeujaODr48vKDiDZi2pHjvtxQcrh3L7z7rpiePx8qV7bzDhs0KNjhlClw7pydd+jayOBL4pqkZog3mr4+4Fe64soOxc0LLkskknLIypVCa9SihRiT4a7cd5/4v3UrXLniXFskRXF08AUF0sPrDhr3lZoq6nuB2/QiZ2cLuaFGA8OGOfD9y/jx0KmTkGk+9phImFNOkcGXxDUxlBy68pukimHCvvRMyMh0tjUSiURSMoaFld2ZWrXgjjuk9NAVycuAtLNi2hnBl6N6vn77TUQzDRqIlxluwOuvw5Ejordr3jwH7lithoULITAQ/v5bpFYsp8jgy81RqVRUqVKFgIAAVK4cpJQWfX0v6yWHKpWKqlWrUrVqVfsdGx9vCHevgsse6zNlxCH+4qZInzGNW/pMYqIYdwF2Db4c5jNuJj10S5+xBl2mQ79I8LdM02YTn9EFX8mHIDfVujZKgwMkh7b0mV274L33xPRnn4nxXg6lXj2YMUNMP/ccnDlTpubc9d4kgy83R61W07BhQ8LCwlCrPeTnVBSbJNtQq9U0atSIRo0a2ffYuJn00CN9xgY4zF/cEOkzpnFLn9FJDlu2hIYN7bYbh/mMTnr4zz9w+bL99mMj3NJnrMFQcmjhQ7FNfCawGgRFg6KFxN3WtWEpKSnwxx9i2o6SQ1v5TFYWjBwp1H7Dh8O999rOxlLx1FPQpQtkZMCoUWWSH7rrvcl9LJWUH7KyITcvv7hyoLOtKZnIsALpYbqUHkokEhfm55/FfzcZn1IiNWqINNYgpYeuhDPGe+lwVL0vneSwUSNRssHFee01OHYMqlaFuXOdaIhOfhgUBFu2iAJj5QwZfLk5iqKg0WjQarUonlI7QSc5DA4UJ6mV6I6NRqOx77Exynro+r1fHukzNsBh/uKGSJ8xjdv5jIMkh+Bgn3Ej6aHb+Yy1JJU++LKZzzhq3JeDshzawme2b4fZs8X0559DZKQNDbSGOnVg1iwx/cILcOqUVc24671JBl9ujlarZdu2bVy9ehWtp2SO0UkOQ8tW30ur1bJ161a2bt1q/2PjRgWXPdJnbIBD/cXNkD5jGrfzmRUrRIqz1q2hfn277sqhPqOTHm7bBpcu2XdfZcTtfMZarOj5spnPVMzvCb2xw34FfZOTHSI5hLL7TGZmgdzw4YdhwADb22gVY8dC9+4FBmo0pW7CXe9NMviSuB768V4uWt/LFLqshxlZUnookUhcE3cvrGyO6tWhY0cxvWyZc22RQF46pDsh06GO8JbgFQA5NyH1P/vs49dfIScHGjeGpk74jqXg5Zfhv/8gKgo++sjZ1higVsNXX0FwsHhx4lQtpGORwZfEtdBoIE1XXLlsPV8OxVsWXJZIJC7M9esivTO4f4p5U7iR9NDjST4m/vtVAv9Kjt+/2qeg2LK96n25yYuMbdvgww/F9BdfQHi4c+0pQnQ0vP++mJ46FU6ccK49DkIGXxLXQjfey8/XtYsrm6KyQdZDN9IeSySScoBOchgbC3XrOtsa2zNkiFAfbN8OFy4425ryjTOTbeiw57ivpCT4808x7cIvMjIyhJpPUURSwf79nW2RGR5/HHr2FOkYR42ySn7obsjgS+JauKPkUEdkaIH0MCPL2dZIJBJJAZ5SWNkc1apBp05iWkoPnYsrBF+VdOO+7BB8rVoFublCbujCksOpU0Uei+rV4YMPnG1NMahUQn5YoYJ4eaLrqvNgZPAlcS30xZXdSHKow9sbIkLF9DUpPZRIJC7CtWuwcaOY9tTgC6T00FXQBV9hLtDzlXwEcpJt27YbSA63bCkY3/XllxAW5lRzSqZmzYII8eWXRU58D0YGXxLXwai4shv2fIFB1kMpPZRIJC7C8uUi1VmbNiLFs6eikx7u3AnnzzvbmvKLK/R8+VeG4DqAAok7bdfurVuwbp2YdtEXGenpQr0HMHo09OnjXHss5tFHhbHZ2UIvmZfnbIvshgy+3ByVSkXFihXx9/dHZcc6Ew4hMxvyNKBWiRpfZUSlUlGpUiUqVarkuGOjK7ic6bpZDz3KZ2yIU/zFTZA+Yxq38RknFFZ2is9UrQqdO4tpF5Ueuo3PWEtuGqTnB76lDL5s7jP2GPelkxw2by4yHTqA0vrMiy/CmTOiM0mXy8ItUKlEVpDQUNi1yyLj3fXeJIMvN0etVtOkSRPCw8NRl6EgsUug6/UKDipTcWUdarWapk2b0rRpU8cdG2+vAumhixZc9iifsSFO8Rc3QfqMadzCZ65ehU2bxLQD39Q7zWdcXHroFj5TFpKPiv/+VcCvdJV8be4zFe0w7ssJksPS+MzGjTBvnpheuFAMo3IratQo0Eu++iocOVLs6u56b3IfSyWej7tLDnUYFlyW0kOJROJMdJLDtm0hJsbZ1tifwYPFy7tdu+DcOWdbU/7QSw6bONcOMOj52gGKDQrw3rzp0pLD1FSh3ANRv7hHD+faYzWPPCJSM+bkwIgRoqfRw5DBl8R10CXbCHXDZBuG6KWH2S4rPZRIJOUEN0gOYFOqVoUuXcS0Tm4pcRyuMN5LR1hz8A6C3OSC2mNlYeVKMQ6pRQto2LDs7dmY558X7xuio2HWLGdbUwZUKliwQGQJ2bsXZs50tkU2RwZfbo5Go2HLli3Ex8ejcefaCHl5BYGKjTIdajQaNm3axKZNmxx7bLy9RNp5cMmCyx7jMzbGaf7iBkifMY3L+0xCAmzeLKbvu8+hu3aqz7iw9NDlfaaslCH4srnPqL0h4nYxbQvpoZNeZFjiM+vXw2efiemFCyEkxIEG2oNq1eDjj8X066/DwYMmV3PXe5MMviSuga7Xy98XfH2ca4stqCQLLkskEifzyy/i+tOunXgdXl7QSQ/37BGZBySOQzfmyxV6vsB29b4SE0WEAy4nOUxJgcceE9NPPQV33eVce2zGQw/BwIFCdjhypEfJD2XwJXEN3Lm+lykiQ0XWxsxsSJPSQ4lE4gTKm+RQR+XK0K2bmJbSQ8eRmwoZF8S0qwRftsp4uGIFaDTQqhU0aFBms2zJlClw4QLUrg0zZjjbGhuiUonuvIgI2L8f3n3X2RbZDBl8SVwDfbINDwm+vLwgIkxMu6D0UCKReDhXrsDWrWLawZJDl8CFpYceiz7TYVXwi3CuLToi24v/Kccguwz3Yhd9kfHnnyI7O8CiRRDsIY9QeqpWLUjf+OabEBfnVHNshQy+JM5HUQx6vtw806EhsuCyRCJxFjrJ4R13QK1azrbG8dx7r3gJtm8fnD7tbGvKB66UbEOHf0UIqS+mrS22fOMG/P23mHYhyWFysiiiDDB+fEGeGY/jgQeElDgvT2Q/zMlxtkVlRgZfEueTkSW689VqCApwtjW2IzJUfKesbEjLcLY1EomkPOGEwsouRaVKUnroaFwx+IKy1/vSSQ5vuw3q1bOdXWVk8mS4dEmY9M47zrbGjqhU8OmnULGiSLzx9tvOtqjMyOBL4nx0ksOQQJsUV3YZvAyzHrpmwWWJROKBXL4M//wjpsuj5FCHlB46Fl3wFeZqwVf+uK/r/1q3vQtKDtesEVkNVSohNwzyINGQSSpXhvnzxfTbb4sebTfGg550yycqlYqIiAj8/PxQqVTONsc67JRsQ3dsIiIinHdsXLDgskf4jB1wCX9xUaTPmMZlfUYnObzzTqhRwykmuITP6KSH+/fDyZPOsaEQLusztqCMPV928xld8JW4E7SlTEd+/brTJYeFfebWLXj8cbFs4kTo2NEpZjme++8XfxqNkB9mZ7vGdcYKZPDl5qjVapo1a0ZERARqd+01slOyDbVaTYsWLWjRooXzjk2ETnqY4zLSQ4/wGTvgEv7iokifMY3L+owLvKl3CZ+pWBG6dxfTLiI9dFmfKSs5yZBxSUxbGXzZzWdCm4J3COSlFQSIlrJ8OWi1EBsLderYzqZSUNhnJk4U+XQaNIC33nKKSc7jk0+EpPjwYXjjDde4zliB+1gqMU1uDup1c2l+aAHqdXMh180GIubmiTFfYPtkG1oNXN0E574X/0v7xssWGEoPr7lI1kONBtXmzVTfsgXV5s3iLZJEUgya3Gy27PyEs0nL2bLzEzS52c42ySXIydUwZ+Umnvn8e+as3EROrgucS5cuwbZtQo80ZIjTzNBoYPNmFVu2VGfzZpXzLjOuJj1UFEhKgWuJ4r+LKCLKjC7TYUA18A1zqilFUHtBxXZiurTjvlzgRYZGA5s2wfffi7FdX38t3ukuXgyBgU4zyzlUqiTGfwG89x7s2OGWzzNODb62bNnCPffcQ7Vq1VCpVKxcudJouUqlMvk3a9Ys/ToxMTFFls8oodBBVlYWTz31FJGRkQQHBzNkyBCuXr1qj69oX35+Hr4IxCtpCnXqrMEraQp8ESjmuwup+ZLDAD/bFle+uBx+jYEN3eDf4eL/rzFivqNxpYLLy5dDTAzePXvS5oMP8O7ZE2JixHyJxATL179MzOwa9NgwiUnnvqbHhknEzK7B8vUvO9s0p/L8ouUETo1h0oFuzEsYzqQD3QicGsPzi5x8Li1bJv7feSdUr+4UE/IvM/Ts6c0HH7ShZ09v511mBg0Cb284cABOnHCCAQZcvwU7DsKB/+DYWfF/x0HPGBPsqsk2dOjrfZVi3NfVqyLqAadJDnXnUrduMHw4TJsm5t9zj0hkWi4ZMgQefFAEWp06ueXzjFODr/T0dFq2bMknn3xicnl8fLzR38KFC1GpVAwp9DbvjTfeMFrvmWeeKXa/kyZN4rfffuPnn39m8+bNXLlyhcGDB9vsezmEn5+HnFkooYWi/AoayJnlPgFYsh0khxeXw9b7UHQSCB0Zl2HrfY4PwCIqiNdU2TkFwaYzWL4c7rsP5VKh43L5shiU7wYXLHui0WjYsmULW7ZsQeMmb8/szfL1L3Pftre5lHPDaP7lnBvct+3tchuAPb9oObPO34cmyPhc0gRdZtb5+5wbgDn5TX3+ZYZLl4xfNDntMhMZCT16iGlnSg+v34Kjp1Fyco3n5+TC0dPuH4DZIPjSaDRs27aNhIQE21+DrSm2rJMc3n67qGDsYMydSwC//lrOb9m9e4v/eXnG893kecbbmTvv27cvffv2Nbu8atWqRp9XrVpFt27dqFNIdxsSElJkXXMkJyfz1Vdf8d1333HXXXcBsGjRIho3bsyOHTto3759Kb+FE8jNgesfQKhQlhihBhQgZTYcCgMvp/7EJZPUCoiA9G1w1AY3RkULR2cACkWHXiqACvZOhOoDhRTBEXh5QWSYSLpx/ZZzCklrNDBhAigmjouiCEeaOBEGDhT2llO0Wq2zTXAZNLnZTNj9Oab6anXzHt0xh/98A1G7+nXGhuRptMw+OQN8FYqcTCoFFBWzD08k7N2BeDv4XAq5dYFx27ejqFR8enUIaTMdunu0WpgxQ9fBb3xwnHqZGToU/vhDBKYvO+GFgaLAqQtAUZfRc/oCVAwzcVN3E2zU86XRaFDsoRCpmP9sl3oSsm6I+l8l4cQXGQa3bMx5Tbm9ZWs05s9jN3mecZs75tWrV1m9ejVLliwpsmzGjBm8+eab1KpVi+HDhzNp0iS8vU1/tb1795Kbm0sP3ZswoFGjRtSqVYvt27ebDb6ys7PJzi4Y55CSkgLAvEbz8Ff7F2t71VZVuX+FcZf1z/f+TEJcQrHbAbSd0JZ2E9sV2JGaze7+D9HtmWLeCqmAAAUOTSuxfeeihqgNImA8/QbkOSIblQIZF/mp6zNcOlOPiPoRPPTXQ0ZrrHpkFRe2XiixpVaPtqLTK52M5n1c+2OT69ZrE8mASU1JiTvPl11+ZsDiAUR3idYvP7/5PL+O/NWib/DMWeOe3a1vbiVuYVyx29TIPsXQG5fMr6AocPEiP1V9hkt+ReuYdJzWkdajW+s/p8WnsajDIovsHf7HcCIbRuo/H/n+CH9P/bvE7YKqBPHojkeN5q15cg2n15ZcMLXJsCZ0n9HdaN5nzT4jNz3XzBagqBVyWuVQr189ctvn6gOx+H3xLBuyrMR9Aow5OAa/ED/9551zdrLro10lbmfra8SCFgsssve+X+4j6rYo/eeTq0/yx9N/AKDqd4hL1W+Y2xSAZE06L2109euMHfArZplKQalwkWkLtsK5ro6yCIBJCD/donTiqberOXTflpB/meGZqj9Rz6/gemTva4SfNoMn8MLr0CEWVXmBWz5VrLpG6Ogzrw/1+9fXfy7pGlGjcShDX25ZfKPZufzUayGXjiWbXOyK1whDxkzbSXAofP/IQeIvfIBPkA9PHH7CaJ0NL27g6I9Hze5LUStkt8rGu7I3uQ/l4mXw4Lyw/ULSr5asHLnrnbto+mBBAJh4IpHv+nwHwIhnqxBZ5Sor7nmRs8eaFNl21L+jCI7KfzmakID35s2ogC9mJ5E65wOz+7THc8Sp7BpcumE+6NOdSxs35tGliwhW7f0cAVCrUy0Gfj3QaN7SXku5ebLkMe22eo5Qbd6Md2EFjyEGzzO3arV06HNEljarxHbBjYKvJUuWEBISUkQeOH78eG677TYiIiL4999/eemll4iPj+eDD0yfKAkJCfj6+hIWFmY0v0qVKiQkmL+Ivfvuu7z++utF5qfGp5JL8RdrTbCGNWvWGM27fOoyGZdLzn53eO9hEtckFrSVoaG6quSLLUByYjWSqzTUf865lkPa4bQSt1N5qQjvEm40L/1YOtnxJQ+y963kS3Bz456dpG1JaLOL9ij4h1anUfVgNLlZHNoYRFDDDvhVK3iq0aRpSN5l+kZUmLAOYaj91QRqr1JRa/7irsMr7xqpl6uQq84t8ttcOH6B1MupJbZx/MBxUtcYr2duu0PX0+k9tiEVKvpToYIX2//ZzpH0gqxLKftTLNonUNSXDlwucVsvrlnUtteNa6RSpcj8A7sPEF8tXv8550aOxfZu2riJgNMFxbMTdyVatG1WVlaR73r26FmLtj158CTZa4z9NeliEtrMYnq2vIC6cPniZdauXavPnJR+PN3i7/rXn3/hFVjwwBC/N96ibW19jbDU3n82/UNQQkGim6R/k/TbqoOSLGrj9qC6BPvWIv14Ka4RzQpdI/41fY0oTFCjIPyiDK4R6aW8RvgVKO2zLmaRcark4+sV6EVou1D95/+u3+Kyd1yJ20UGH6RezaoE1jMeEX9zo2WJd0JahuATUTAONvdmLqkHiv9dR7AYgLj6PehWo+DBL+NUBlkXS34o8An3IaRViNG85J3JaDJKloAF1gsk2TeCo0dL7lG4dsOLKhR8F3tfI1KBM9SmPqeIubabC3Sx7hqRz+5/d3NSVfCysKRrhFfDELPLjNbTas2244rXCB1+gZkEh4oX0ufjgsjOTEUdoC56bz1Ywr01/xqsDlOzfv16o+x1iecTyU0sOTDet2sf50PP6z9nXsjU7/PCsWpEVrlKxYgTHLxcs8i269etx7eiLwAxa9bQUlG4RHWuXPUBzNttj+eIa1jWY7N2bRzp6ZcB+z9HgPhehbe9evoqWZdLvr7Y6jmi+pYttLFgG68b10hUEh36HJGFhwVfCxcu5KGHHsLf37iXafLkyfrpFi1a4Ovry9ixY3n33Xfx8yvu9WTpeOmll4z2lZKSQs2aNQmJCim556teVfr162c0L/2LdBLSSg6imsU2o12/Qj1fc4v2/plC4/cYUfe+ov98cvVJ/p5R9I1VYXyCfHhiTqE3Vjs3cPT3koOaun3r0u9V4++69j3Tb6ya3xVFI+DyiUz+/u1h7rrjLmLuNX5jteLV70rcJ8CoqeKNleraZtjcs8T1Nd6VCakeQkTdiCK/zaofVnHheslvrBq1bESnfsZvrE5XN/825cz+mzS+szKt7okmrGMz456voPNcr369xH0CRezduncrWXuLP+E12ZWh+E4MsV7FyoT4FX1QaHl7S1r3M35jdbH6RYvs7dqtq/Fb7eQjJK1MKnG7oCpBRb7rmt/XcPp8yW+s6reoT/d+xm+sLtS8UHLPV0gO1WtWp2/fvvq3rvFV40mobtkLj169exn3fP23k4x/Sn44svU14lz1cxbZ27FrR+O32spJEquLhzRVehiEldzGu+2fpnO7p8Rb7d0WXiPGGX/XhUssfKt9r4m32p9YeI34yOCtNrD/y/388/0/JW4XUT+Ch8YVvNWe++sWphzuUcwWgju9Epkw8oqJt9qW9aIOmD2A6C4Fv414q22+Nygk7yYtrx5CQcWTG0bypIEUv2xvtf+27K325I6k1K9Dz5Ivv1SuqDG6zjjiGnE6PZb6Sado7n2M/VXutuoaoeP2DrdTv59Bz1cJ1wiNhSmwNWo1IdVNB2queI3QUS1a3FxSk0LxjaiEL+I5orC9G7Zs4OixEnq+QrJR+6rp0aOH0fNeQnQC6f4lXyNua3sbTfsZXyOuVL8CwPUb9YD9xDSLJ2Rb0ePco2cP/TXCK/8F/qkKsYSEFB882+M5onK2xqJ7dt++rejSRfSq2vs5AqBWo1pFtr015xY3tSVfI2z1HKEKCgIzHSyGaCpWJrJWpEOfI3y0PhBvdrEelWIXcW3pUalUrFixgkGDBhVZtnXrVjp37kxcXBwtWxbfdX/kyBGaNWvG8ePHadiwYZHlf//9N927d+fWrVtGvV/R0dFMnDiRSZMmWWRvSkoKoaGhJCcnU6FCBYu2sRm5OSKrYQWN6ZQpWiDFCx7PAB9fx9pWGo6fhauJUCsKatsoK5dWI7IaZlwGk6NVVBBYAwacddyYLx03bsGR0+DnC+2aO1bbr9GILECXL5vPuFizJpw967IaaXuj0WjYunUrAJ06dTKSvJRHNLnZVJ1ZhRt5pnuWVEANv4qcffYSXj62e9Hl6uTkagiYGoM26LIY41UYRYVXeg0y3jmLr48Dfej992HKFOjaFTZudNx+DSjpMqNSiZrPTrnM3LoFVapAbi4cOQJNisrO7IaiiKyGhZNtGOLnA+1auOeYr1MLYNdYqNoL7vrT6mY0Gg2bNm3i5MmTjBw5ssjL9jKTdATWNAOvQLg/GdRm+h/i40WmUEWB8+ehVi3b2mEBGo24JcebeZB36rnkbFz4QmNpbOAWdb6++uorYmNjSwy8AOLi4lCr1VSuXNnk8tjYWHx8fNiwYYN+3okTJ7hw4QJ3uEveTh9fqDQZVCK/hBFaxFNRpcmuHXiBQXFlG9b3UntB7EeA6ZQboEDsHMcHXiAKLnvlZz1McXDWQy8v+Oij4lPdv/tuObyKS8yRlhaPYvIFRsHw7zm3PV6uAi8AXx8v7kgS1xiUQteY/MM1uckcxwZe4PQsh1BwmQFQmQhMFUW8sHbKZSY8HHr1EtOOznqoUkG9Eh7g69Zyz8ALRFADrptmXkdoY/AJBU0GJB0yv94vvwhnbd/eKYEXiHMkJkb3yfhc0rnJnDnl9JZtcKFRCp8zbnJwnBp8paWlERcXR1xcHABnz54lLi6OCxcKumpTUlL4+eefGT16dJHtt2/fzpw5czhw4ABnzpxh6dKlTJo0if/973+Eh4sxS5cvX6ZRo0bs2iUGvYeGhvLYY48xefJkNm7cyN69exk1ahR33HGHe2Q61HH/TPB9TvRwGXIL8JkilrsyubmQma+ltXX2v5qDodMyCDDRm6byhpCiPaIOQa0WWQ9BZD50NIMHQ+vWRefrLlD/lCzB8nTCwsKKjActrzy7bCSJeSlU8Qmjum+k0bIaflVY1vQ9Boc2c5J1zuPgQdi1ZDD8tAxVmvE1RpUbzHPRy5g5ysGlS86dg127xDXGyWVTBg8WpcbMlRi7bpkqyj44s+BypXCoEml6WcNosdxd0WU6DCt78BUWFoavr51eHKvUBVkPi6v35QIvMn76CbZvF6d04b6EGjXEOeZuFZJsirkLjbscHMWJbNy4UUGE9EZ/I0aM0K/z+eefKwEBAUpSUlKR7ffu3au0a9dOCQ0NVfz9/ZXGjRsr77zzjpKVlaVf5+zZswqgbNy4UT8vMzNTefLJJ5Xw8HAlMDBQuffee5X4+PhS2Z6cnKwASnJycqm/t03JyVbyVs9WTr/eW9G29FEUFYqyc6dzbbKEG7cUZdNuRdl5yH770OQpSsJGRTn7naLE/60of/dTlKUoytpYRdHk2G+/xXH9lvje/8Ypilbr2H0nJiqKt7eigJK7cKGye/JkJXfdOkVZt05RxHs+RfnrL8faJHFJ1mx6R2E6imq6Stmy4xMlLydLWb/1Q+XDxY8o67d+qOQdXCn8eON2Rbm0x9nmOoycHEVp1UqcKoMGKUpWdp7y4YqNSq8Pn1aYjhL7WaxzDJs5UxjVrZtz9m+CvDxFWbcuV5k8ebeybl2u8uGHwsSgIEU5fdpJRt26pSi+vsKQw4cdv/99R8V58995Rbl6Q1F2HBSfr1xzvC22ZHmUuLde317mpnJycpSVK1cqOTl2ukcfnC5s3faQ6eWXLimKSiV85MIF+9hQAgkJihIZKUx47TVxLm3cqCjffSf+5+U5xSzXJC9PyV23ruB5xskHx9LYwKnBlzvjMsGXUnCx0gwbJs7WZ591tkklc+aiuOkcP+O4faZfVpSfwsSF99BbjtuvIRqNomzdJ757Uopj9/3VV8I/WrYseoN76imxrGZNRXEBn5Y4j5uJJ5Vq70QqTEeZuLC3fn4Rn9n8jfDjv5crSk6Gk6x1LNOni9MkMlI8IOk4d+ucwnQU7ze8lQxnHIs2bYRhn37q+H0Xg6HPaDSK0rmzMLNLF3EpdAr33COMePVVx+43M0ucL5t2K0pWtph3/or4HHfcsbbYkuyb4p66FEXJKfu9w+7B15U/ha2r6phe/tFHwj86dLDP/ktAq1WUe+/V36qV7GynmOFW2N1nSoGlsYFbjPmSWIb2vvvExE8/FT+2xxXQjXlyZMHhwGrQZq6YPvw63DrouH3rUKtFIU0QBZcdSXFSihkzoE4dUTjk2Wcda5fEpZj08yiu5CRSP6Aab9//tfkVW/cAbRKoa8Le5Q6zz1nExcFbb4npefNE7gYdtUJrERUcRZ42jz1X9jjWsDNnYM8el5AcFodaDYsWQWAgbN4Mn3ziJEMMpYeOvE/qrvehwSLpEhRIDZNSi0/G4croxnsF1gQfBycfs4bIdoAK0s5A5tWiy50sOfz+e1ixAry9YckSsJcCU+JcZPDl5mg0GrZv387Vq1fJ69EDgoPFA/TOnc42zTyK4pDgS6PRsG3bNrZt24ZGk1+nJuZ/UH0AaHNhx0jx39HobrjXbznu5p+YCOvXA6AZPFjvM/rjEhwsnowAvvwS/ii5JIGnYdJfyhm/b3yTJQn/oELFoq6vEhgsBhsYXmf0xyakKlTNP3+y6sIlBwcdDiQnB0aMgLw8GDIEhg0T83U+8++//9K+hhhLsv3Sdscap0se0a1b0cEhTsSUz9SpAzPzhyO/+CKcOuUEwwYMAD8/OH4cDh923H7zgy9tZFjBdcbXB4Lz68DdSHKcLbYk2XbJNkxeZ2yNb2iBrTcKnauXLsG2bWJa9zLbgcTHw9NPi+lXXwVdjjl5bzKPQ3zGDsjgywPIzc1Fq9WCvz8MzK/R4owBxZaSlglarUj0EGjjVLKFyM3NJTfXIMBSqaDt5+AbAbf2w5F37bp/k4RXEN89J7cg46O9WbFCpGdt3Rrq1y/wGUM6d4YJE8T06NGQlOQY21yIIv5Sjrh54z/G7JgDwOToPtzZdqzRcpM+07gvqI6LRDb/XYbcTAdZ61jeeksk2qhYEebPN05Kp/OZ9tVF8PXvxWIG8tsDXfDlxOQA5jDlM+PGiTgxIwNGjRK3AodSoQL07i2mHZX1MCsbUsULR6VimPF1Rv8yzglJmGyBDYMvMHOdsTUV8zNbFw6+fvlF/O/Y0XzGGDuhKDB2rKiIcNtt4uWEIeX53lQSDvEZGyODL09DdwP++Wcn3NUsxDDFvDNS6wZUhTbzxPThN+FWnGP37wzpoaVSinfegXr1RP0Mg6LiEs9nwrJRxOfcpGFAdd68rxi5YWFu6wXaW+BVHfb+Yj8DncTeveK0ABF4metcuqOGeKDbfmk7iqN6tE+fFgZ6ecG99zpmn2VErYaFC0Vn+z//wNy5TjDC0dJDveQwBHx9jJdVihD/3VV6aOPgyyGYC76cKDn89lv47Tfw8YHFi8V/iecigy9Po1cvCAkR3ec7djjbGtPYo75XaYl+QKSkV/Jg+wjQ5Dh2/46UHl6/Dn//Labvv7/4dQMDxZVfpRIyxNWr7WubxCVYuf5Vvr36L2rULL5rOgHBFS3fOLgyVMt/0ZNVHy64sOS5lGRnC7mhRiOex4o7fW6Lug0ftQ/X0q9xNumsYwzU9dzcdRdUquSYfdqAmBiYNUtMv/QS/Pefgw245x4hPTxxAg4VU+/JVuh6tSqbSCcf4AchOumhg8cB2wJ3DL4qdRD/b+4uGHpw8SL8+6+49w0Z4lBzLl+G8ePF9PTp0Ly5Q3cvcQIy+PI0DKWHji4kaSnOSLZRGJUK2swHv0hIOghH3nLs/g2lh8l2lh7qJIe33QZ165a8/p13wqRJYvrxx4UOQuKxJF4/zhO7RE/wlJi+tG9TtKZiiTTsDapjoPKCUwmQm2FjK53D66/DkSOit6ukBBH+3v7cFnUb4EDpoQvUI7KWsWOhRw/IyoKRI8UlymFUqAB9+4ppe0v0M7MhNf98qGimlpeu9+uam11rsxMhKz9pRWgT59pSGkIaiKEHmqwC5cuyZeJ/x45QrZrDTFEUGDNGqPzbtIHnn3fYriVORAZfnogrSw9zcoX+HZzb8wUQUEUEYABH3oGb+xy3byPpoZ21/taMCXnrLWjQQIwAnjjRLmZJXINnlj3K1dxbNA6owetDSyE3LExsH9DeFPLDPe6f/XD3bnjvPTH92WdivFdJ6KWHFx2QdOPkSdi/X7zEGTTI/vuzMSqVyO0TEiKKyc6Z42ADHCU91PVmhZmQHOrQKSGS3Ux6qOv1CooGHye+TC0tKpVBseX8c9VJLzKWLIE1a0RWwyVLRJZDiecjgy9PpFcv8Wbv8mVxV3MldJLDQH/XuMpED4Va94OiyZcfZjtu37q3nfaUHpZGcmhIQIC4E6jV8PXX8Ouv9rFP4lR+WTeN769txwsvlvR4C/+ACOsbC6oEuhfG2Q3gvItde0pBVpaQG2q1MHy45cOpOtQUciaHZDzUvVTp3t2yyNAFiY6GDz4Q09OmiQSEDuPuu4VS5ORJOHDAfvvRvVyrVMy55e8HIfkvIx1dgqQsuKPkUEfFfOnhje1w/rwYpuFgyeGlSwU5rt58E5q4UeehpGzI4MsDCAkJwcdwdKafX8GbUFfLeuhgyWFISAghISHFr9TmE/CrBMmH4fAbDrELgPAQ8PaC3DzxxtMeLF8uniDbtBF5nvMp4jOmaN8epkwR02PHinT1Ho5F/uIhXL96mHG7Rc/vC3X6c/ttI4pd3yKfadgL1MdApYbTNyDbQdk8bcxrr8GxY1C1askJIQx95o6aoufr4NWDpOXY+bu7geTQEp957DGRfFA3vi4vz2HGQb9+Ytpe90kjyWGYwa5NXGfcMethku2DL4uuM7bAMOmGTnLYuTNERdl/34j3raNHQ0oKtGtXcnnN8nRvKi0O8xkbIoMvN8fLy4vWrVtTsWJFvLy8Cha4qvRQn2zD/sGXl5cXsbGxxMbGGh+bwvhXgts/FdNHZ0DibrvbBuRLDw0Sb9gDEw9oZn3GFK+/Do0bQ0JCwYhgD8Vif/EQnvrlMa7nJtEssBav3rek2HVL5TOx/UCbCF5RsHel7Qx2EDt2wOzZYvrzzyEy0vy6hX2mRoUa1KhQA42iYfdlO15HTpwQvTXe3i4rObTUZ3TywwoVYNcueP99Bxppb+mhLpAykByavc7opYdpkO3gBFDWYuOer1JdZ8pKZFvxkij9PKz+Vsxz4IuMr76CP/8U78oXLxbqYXOUt3tTaXCoz9gQGXx5Kj17QmioGLOjKxrobLTagreAzh7vVZhaQ0QGREUrii9rshyzX3tmPbx6FTZtEtOlkRwa4u8v7gxqNXz3nUjeIXF7fvrzRX6+vgsvvFjc6238AsJs13hgJNTIlxTnNIBzLnL9sYDMTJH8QauFhx8W9XhLi2HKebuhkxz26FF8dOgm1KhRMObr1Vfh6FEH7bh/fyGxPn1ajJ+zNbqXasVJDnUYSg/dpeCyO8sOfYIhND+tYFqcuMcNHuyQXV+4UFDJ5e23oVEjh+xW4kLI4MtT8fUtGKjgKtLD9Pziyt72L65sFW3mgX8VSD4Kh6Y7Zp9hBtLDJBtLD3WSw7ZtRW5na2nbFl54QUw/8QTcuGET8yTO4Wr8AZ7cI3p6p9a9h9iW/7P9Tup3L5AfnrkJ2XaS1dqYV14RnUpRUfDRR9a14ZBxXy5cWNlaRo4UKsCcHAfKD4ODC6SHts4OnJkFaUUlh8VS2Y2kh1nXIfu6mA5t7FxbrEWXcr4+0KWL0BnbGUURUtvUVOjQQeazKq/I4MvN0Wg07Nq1i2vXrqEpnKtX19uxbJmD8/iawcHFlTUaDTt27GDHjh1Fj40p/CKh7edi+tgsuOGAOmn2lB7qgu5CvV7F+ow5XnsNmjaFa9fg6adta6eLUGp/cUMUjYZxy0eTmJdCi6BoXi5BbqjDKp+J7Q/aG0J+uGel9UY7iG3bCpI/fPEFhJvJCm6IKZ8xzHhol2LLx4/DwYOiCquLSg6h9D6jUsGCBRAWBnv2wMyZ9rcRsJ/0UHc9D69glOWw2OtMxfweMneQHuozHdYGb9soWay6zpQF3biv+jjsRcaCBbB+vRCVLFpUvNxQR3m4N1mLw33GRsjgywPIysoy7XQ9eog7WUIC/POPw+0qghPqe2VlZZGVVQoJYY2BEPO/AvlhXqbdbNOjkx7esKH0MCEBNm8W0yYkh2Z9xhx+fiL7oZcX/Pij69aQKyOl9hc344e/XmDFjT14q7xY0nsGvv4VLN621D4TGAE1fcV0XmM4u7WU1jqOjAzR86IoMGqUUKNZSmGfaR3VGj8vPxIzEzl586TtjdWdez17WhYhOpHS+kz16gUJTqZPd0z9Y7308MwZ2GfDciP6LIdFfyOz1xl/3wJJvqtnPdRLDm2boq/U15mykFlD/K8NDCrFSW8lZ88WJNZ4911RzcVSPP3eVBYc6jM2QgZfnoyh9NAVHpaTHZdso0zEfgT+VSHlBBx8xf77CwsRA+dtKT1cvlw8SbZrJ/I524LYWHjpJTH95JOiF0ziNiRc2c/T+xYA8HLdgbRq/oD9d1rvLvA6JqbPpkBWiv33aQVTp8KpU+LhX9f7ZS2+Xr7EVosF7FTvyw2yHJaF//0P7rkHcnOF/DDX3mWvgoJE2nmwnUQ/IwvS8l/cmSusbA7DEiSujDuP99Lx+y5IAXwA78t23ZVWK+SG6enQqZPH56+SlIAMvjwd3Q3a2dLD7JwCGUWIiyXbKIxfBLQVD6kc/wCu/2vf/anVUClMTNtK62+vB7RXXoEWLcS4ryeftG9xUonNUDQanlj+ODfzUmkVVJup95WhmHJpib0bNNfBqwrsXeW4/VrIli0FvS1ffinEAmWlQw07jfs6ehQOHxaSw4EDbdu2i6BSiSyT4eEiB8aMGQ7Yqa2lh4aSQ59S1rPU9ZSluLj0MDk/K4o7B18//Qy6zukb9q3N99lnsHEjBAbCwoXiti8pv8if39Pp3l3cxa5eha1OlP3oJIdBASLBhKtT4x6oPQJQ8uWHGfbdn/5tZ1LZb/7x8eKJEuC++8rWVmF8fUX2Q29v+OUX10nmIimWpX8+x6rEvfiovFnSewY+fg58ARIQDtEBYjqvMZze7Lh9l0B6upAZ6mru9Oljm3Z19b5sHnzpFAy9etkmSnRRoqJg3jwx/cYbEBdn5x326yeeis+dEwPOyoolhZXN4edboA5x5d4vXc9XmJsGX6dPw969cCp//LkdX7KeOQPPPSem33sP6tWz264kboIMvjwdH5+C9KnOfFB2YH0vmxE7BwKqQepJODDNvvsKCxFvSPPy4FYZpVm//CKeJu+4A2rVso19hrRuDS+/LKaffFKML5O4LFcu7eaZ/V8A8Fq9wbRo7gS5Wt2u4J0vP7yQDlnJjrfBBC++KB6Mata0bX0pXdKNQ1cPkZJtQ6mlh0sODXnwQaGaz8sT4/Fy7NkJFBgotI5Q9vtkRpbI7KtSWZ7lsDCuXnA56xpk3wBUUMFNMx3qXmSE3Cb+26nnS6sVL3gyMqBrV3HLlEhk8FUe0N2of/nFQfl7TWCY6dBd8A2Ddl+K6RMfwTU79hyqVLbLeuiIB7SpU6FVK7h5U6Sfl/JDl0TRaBizYgxJeWnEBtfhhfsXO8+Y2IGguQbqyrDnV+fZkc/GjQW9K199JYr82oqokCiiQ6NRUNh1eZdtGj1yRMgOfX2tK0DmZqhU8OmnoozZgQOiHpJdsZX00LCwcmklhzr00sN0yHJB6aGu1yu4NngHOtcWa9HdJ7uMBJUXZF6G9Is23828eUKIEhQkrjNSbigBGXx5BIGBgXh7F3OR79ZN3MGuXSuQozkSo+LKju35CgwMJDCwDDeHan2hzqMI+eEoyEu3mW1FMMx6qNVa18blywWZLYuRHJboMyXh4yPkhz4+sGqVKMDsAZTZX1yMr9dOYvXNOHxVPizuOwtvnwCr2yqzz/hXgJgQMa1pDKc2Wt9WGUlLg0cfFdNjx4rEgdZizmf09b5slXRD97DYu7fbSA7L6jNVqsAnn4jpd96xbTLCIvTtK56QL1yAXWUImHUvzyqblxyWeJ3x84XQ/HvlDRfs/UqyX7KNMl9nLOHkSTGg0MsL7n0AwluJ+Tbu/Tp1SvSuA8yaBXXqWN+Wp92bbIlDfMbGyODLzfHy8qJNmzZUqlQJL3MFI5wtPUzLEG8SfbwhwM9hu/Xy8qJt27a0bdvW/LGxhNs+gMAakHYa4l6ynYGF0UsPNdZnPdRJDu+8E2rUMLmKRT5jCS1bwquviulnnhFjzdwYm/mLi3Dp4g4mxC0E4PUGQ2jWZLDVbdnMZ+p0KpAfXsyCTOeMaXn+eTG8JzpaPBRZS3E+o6/3ZYtxX4ridpJDW/nM0KHiPZJOfpidbTsbjQgIKLv0MD2zQHIYGWZyFYuvM7rxYtdccNyXnTId2uw6UxI6yWH37lCxYkG9rxu2G/el0Qh/zcwUuxk71vq2PO3eZEsc5jM2RgZf5QVdrSdnSA91ksMQxxRXtjm+odDuKzH938dwdZN99mML6aGZwsp244UXRAr6W7fE3UXKD10CRaPh8RVjSdak0zakHlOGLHS2SQW0GQSaBFBXgr2/O3z369cLORuIrGMhIfbZj2HSDa1iZU+2jiNHRHFlP79yITk0RKWC+fOhUiVR9+vNN+24M11g+/PP1l3LypLlsDC68WKp6ZBlr4jTStw9zbwu+NL93vrgy3Y9X3PnisLtwcFSbigpinSH8oJOenjjBmza5Nh96zIdhrpRso3CRPWCemPE9I5RkJtmn/2URXp46ZK42oPtsxyaQyc/9PWF336Db75xzH4lxbJw9Xj+uHUQP5Uvi/u9Xya5oc3xC4E64aKQuaYxnNzgsF2npIhaOwBPPQV33WW/fbWs0pIA7wCSspI4ceNE2RrTvVTp08e2g9PchEqVCgLmGTNsk5DQJH36iKflixdh587Sb19MYeVSYyg9dKWsh4ri3sHXf/+J9JleXjBokJinC75u7QdN2QsZnzghhkWDSORjq1KbEs9BBl9ujkajYc+ePVy/fr34Ct/e3jBkiJh2dMFlJyXb0Gg07Nq1i127dtmm+nnr2RAUDennIO6FsrdnirJID3/5Rfzv2FFUizWDxT5jKc2awfTpYnr8eDHuzA2xub84iQvn/2HywSUAvNnofho3KntPic19JuZO8M0PSC7lQkZi2du0gOeeE0N6ate2Tf2o4nzGx8uH26vfDpRRemgoOXRUj7YNsLXPDBkCw4YJOdeIEXaSHwYEFPQsllZ6mJ4pMh2WkOWwVNcZVyy4nHUVcm6CSg0VGtm0aZtfZ0yhe/7p0UO8kAYIigH/qqDNhZt7y9S8RiOyG2ZlibGkjz9eNnNFm55xb7IHDvEZOyCDLw8gIyODPEukhM7IepiVA9m5YtoJxZUzMjLIyLBRjS6fkAL54cn5kGCHN/YqlfVphksxJsRin7GU556D22+H5GRxt3FT+aFN/cUJKBoNo1c9SYomnfYh9Zl871c2a9vmPhN7L2jiQV0R9q6xXbtm+OsvWJBfO33RItHBYQuK8xn9uK+yJN04dEi8SvfzKxiT5CbY2mfmzYPKlUXSR937HptjKD0sjfrAUHJYwuB/i68zunuBK0kPdb1eQXXA2/Y96ja/zhTG1H1SpSro/Spjva8PP4Tt20UH9Vdf2W6khbvfm+yJ3X3GDsjgqzzRpYvQbyQmijzLjkDX6xUcKLr53Z2q3aH+ODG941HItWENHx26t503kiy/+V+8CP/+K670uh5OR+LtLeSHfn6wdq2YljicL35/inW3DuGv9mVx/zl4+TguwU2p8QuGupFCfqhtDP+ts9uukpML5Ibjx4tLoSPQBV//XirDA53uYbFv33IpOTSkYkX47DMxPXOmdcrAEundWwwEvHQJduywfDvdy7JishyWGl8fCM0flOgqvV/uXFz5+HE4eFDcr3SSQx02GPd17FhBCcwPPhD1AyUSU8jgqzxhKD10VNZDd6zvVRKtZgqZQsYF2P+c7dsPDRY33TyN5QWXly0T/zt1gmrVbG+TJTRpUjAafuJEERBKHMa5s5t59tDXALzTaBgNG/ZzskUWEN0BfP8T05e1kHHDLruZPFk8S9erJ1KWOwpd0o2j14+SlJVU+gbcMMuhvbn3XnjoIfFeSpdNzqb4+8PAgWLa0vukoeQwMtS29lR2sYLL7jzeSyc57NkTIgoFyYbBlxXKDcNsnH36FJSykEhMIYOv8obuBr58OeTm2n9/umQbDq7vZVd8gqH9IjF9agHE/2Xb9q3JeugqD2iTJ0P79iKzwejRbis/dDe0mlwe+/Up0jSZ3FmhIeMHfeFskywn9l7QXAF1JOxZa/Pm16wRWQ1VKiE3DHLge6DKQZWpG14XgJ2XrOimOXBA1CTy94e777axde7L3LlQtaroyNBVu7AppZUe6gKjiJIlh6VGdy9IzYBMF5AeunPwVdx9MiIW1D6QlQDp50vd9OzZojxcaCh88YV7JnaWOA4ZfJU3OncWovmbN+Hvv+27L61W1PgCzwq+AKp0hQbPiOmdoyEn2bbt67MeJpV88z9/XshjnCU5NMTLS0gO/f3FIJsvv3SuPeWEz399kr+TjhCg9mPR3R+5ttywMH5BUK8yKBpQGsOJP23W9K1bBQPeJ04UuWgcjWHK+VKje1js189+OfHdkIgI+PxzMf3++0JxbVN69RISzytXSm5cUQpeklWyoeRQh6+PSMQEzu/9UhS7Fli2K0ePwuHDIkOvrmfTEO8ACG8tpktZ7+vIEXjtNTH90UdmS2xKJHpk8FXe8PIqSENub+lhanpBcWV/X/vuyxm0eheC60LGRdj/rG3b1kkPNRZID3WSwy5dxOtgZ9OwIbz9tph+9lkRHErsxpkzG3ju8FIAZjR+kPr1ezvZIiuo1R78TorpKypIu2aTZidNEs/PDRrAW2/ZpMlSox/3dbGUEYKUHBbLgAHwyCPiMI0cCTbNReDnZ7n00EhyGGZDIwxwlayHmfGQm5Sf6bChc20pLTrJYa9eEG6mFIAV475yc0X2zZwc0Tn9yCNltFNSLpDBlwfg7+9fusreunTFK1aIK4a9MJQcOqkP3t/fH39/f/s07h2ULz9Uwemv4IoNJVNGWQ9LuOFakYa61D5TWiZMgDvvhNRUkenATeSHdvUXO6DV5PLor8+Qrs2kc2hjnr53gd32ZXefaTMYNJdBHQH7yt779dtvsGSJKG66eDEEBpbdRFOU5DMdanYAYOflnaUrthwXB6dPi/Tn/fuX0UrnYG+fmTNHDHE9ebIg0YHN0AW8y5YVrz7QXZ8jQsHbsu9a6uuMLnV9WgZklr0OldXoJIfB9cDLPtdJu/lM4cLKprAi+Jo5E/buhbAw0Rtrr0cdd7s3ORK735vsgAy+3BwvLy/atm1L5cqVLXe+Tp2gShWhydlgxwKnTk624eXlRfv27Wnfvr39TszKnaDhBDG9czTkJNmubUukh+fOCaG5Wg2DB1vUrFU+U1q8vMQAm4AA4WM6jZAL4xB/sTGfrBzL5uRjBKkDWDTgY9RePnbZj0N8xicQ6lcDJU/ID4//YXVTN2/CmPya6M8+C3fcYSMbC2GJzzSr3IwgnyBSslM4ev2o5Y3rXqr072+7vPgOxBE+Ex4uxteACMS2brVh4z17igE88fEFxesLoyilLqxs1XXGSHroxN4v/XivJnZp3m4+c+SI+PPxKajjZoqK4kUJt+IgL73EZg8ehNdfF9Mff2y/XFfueG9yFA65N9kBGXyVRwylh/YquKwonplswxQt34aQ+pB5BfZNsl27FQykhzfNSA9dTXJoSP368O67YnrKFDh71rn2eBinTv3Fi0e/B+C9psOpU6e7ky2yATVvB//TYjreC1KvWtXMhAmQkACNGsEbb9jQPivwVnvTtnpboBTSQzctrOwM+vUTRW0VRWSYSy/5mdky/PwK0pGbkx6mZ4okGPaUHOqo7ALSQ3dNtqF7zundW3RRmSOoJgRUF+NPE/cU22RurpC75uYKhepDD9nMWkk5QAZf5RVd17u9pIfZOZCTK25KTiiu7FC8Awvkh2cWw+XfbdOuJQWXXX1MyDPPiJ7W9HTxZFSaoqUSs2g1uYz6bQIZ2iy6hTZh3MBPnW2S7YgdDJpLoA6H/aWv/bVyJXz7bYHc0BWUOvpiy5Ym3di3D86ccWvJoSP54AOR5ODUKZg61YYNG0oPNZqiy3WBUKTlkkOrcQXpYXJ+z607BV+lHTtpofTw3Xdh/36R/OWzz2R2Q0npkMGXm6PRaNi/fz83btxAY+rmYI4774SoKEhKgvXrbW+YvrhyAHg5x800Gg179+5l7969pTs21lDpTmg0WUzvGgPZNspKpRtonZhUNHA5exZ27y6V5BDK4DPWoFYL+WFgIGzaBJ+6bpDgUH8pI3OXj+aflOMEewWwcOB8u8kNdTjUZ3wCoGGNfPlhIzi22uJNb9yAsWPF9PPPQ7t2drIxH0t9Rjfua/tFC4Mv3cPi3Xc7Nje+DXGkz4SFFSRWnTsXNm+2UcM9eojGExLgn3+MlxlJDi3Pcmj1dcbHB8Lzi2w7o/dLUeze82UXnzlyRFQ/9vUtXnKow4LgKy6uoKTlvHn2F524073J0Tj03mRDZPDlAaSmppJb2ppd9s566CKSw9TUVFJTUx2zsxZvigxQmfGwd4Jt2qwQBH4+oNHCzULp7HVSim7dRPmAUmCVz1hL3bpiVDKIJ+LTpx2zXytwqL9YyX//reWl4z8AMLvZw8TU7uKQ/TrUZ6q3gYB8P0nwh9R4izZ75hm4dg2aNoXp0+1nniGW+Ez7Gu0BOJF4gsSMxOIb9KAsh470md69C8oKjBoFaWk2aNTXV1R1hqL3SZ3kUF36wspWX2dKUkLYk8wrkJsMKi+7Zjq0uc/ofrc+fcQYvpKolD/uy0yx5Zwckd0wL0+883zgAduZWhzucG9yFg69N9kIGXyVZ3Q39pUrRVl2W6JPtuHh470M8Q6A9otFGt5z38KlVWVvU6WCima0/u70gDZuHHTtKvJBjxol5YdWosnNZuTqiWRpc+gR1owx98x3tkn247YhoPk/e+cd3sSV9eF3JPdubIwBG9MxvYaaEEghgTRaki+bzYaEkLKbnk3vvfeymwrsbnaTUFJIJYRQQm+mY7oNNrgX3G1pvj+uxpa7ykgzsud9Hj++SKOZw/jozj33/u45J8AUCdt/a9VnliyBL76oKzUXqKNSZzEhMfSN6QvAxpMbWz5461aRSCckRGxoMnCY116Dbt2EKODBB1U6aXPSw2ylsHKkcDpvoBRcLrGlt/cmyqpXeG8w6+jL1RKuTGREDwdTAFTmQEnjicLnnhOJNmJjhZDDkBsauIIRfLVnxo8X6XmKiuBX5/dWNIvFIh4OoFmmQ82IHQv97xftzbdAZSuz3I4QZ3vg5hWKFTAQq0fbtomHvjIzq2dMJvjsMyGhWrtWpIYycJq3vr6JDcUHCTeH8MkV/0DyoexOTuMfBP2ShPyQZDjwY7OH5uSI+B7goYdg1CjvmOgMDu/7UgaLl13mufz4bZSICPj0U9H+4ANYuVKFk55/vkirmJ0Na9aI1zxdWLk5/P3spIdeXv3yxWQbu3dDaqqYibnsMsc+Yw6EDiNFu4H0cPt2eOEF0f7gA6cFJwYGtRjBV3vGZKrLpKWm9PBMmXg4BfhDYBssrtwag58SqXgrsmDrHe6fLzxU3EeLFQps0kNFcnjeedCxo/vX8AY9eoipaYCHHxbFeQwc5sCB73n0gPievjH4epK6n62xRV6g6wgIOSraWSFQlNHkYX/7mwjABg+Gxx/3on1OULvvq6XgS5Ydq0dk0CwXXAC33iraN94oSg26hb9/Y+lhSRlUVIpnqJOSQ7fRquCyLwZfyt9r6lQRmTtKE/u+KiuF3NBiEcMmIwmpgTsYwVd7R+lBvv0WKlSSMdhLDtvjmrw5yCY/NEPa/yB9iXvna6rgsq+mob7lFjE6Ki8X8kMf2iCrJTXV5Vz/4z1UylVcFD2EuZe2o5XDEbPBmg6mCEhZ1Uh++NVXIl7x89Of3NAeZeVrc8Zmaqw1TR+0ZQukpYkV4qlTvWhd2+KVV6B7d3Er779fhRMqgfDSpWKzj31hZW+vPsdGiWdCaTmUlXvvuoU+FnzZT2Q4+5yMtdv3ZeOZZ2DPHjHX+f77Ktlo0G4xgq/2zrhx0LUrFBfD8uXqnLM22UY7kxzaE3MWDLBtOthyG1TkuHc++4LLhw6JHLe+Ijm0R5JEWrLwcFG49O23tbbIJ3h96Vw2nzlMpDmUT2Z82Lblhg3xC4B+PUGuBvrBvrpSDllZ8Ne/ivajj8KIEdqY6AgDOg4gPCCckqoS9mTvafoge8lhcLD3jGtjhIcLlTOI+u5uq+rPO0/kFFekh4rkT5GEexN/P4j2csFlWYZiH0szv2sXHDzonORQQVn5KtwF1WfYsgVeekm89I9/+I7YxEC/aBp8rVmzhssuu4wuXbogSRLffPNNvfclSWry59VXX210rsrKSoYNG4YkSaSkpLR43UmTJjU6562KTsEH8ff3x2Ry8U9pLz1Uo+CyLOsq2Ya/vz/+/p5Nw90sg56AyEFi4+7W2907lyI9tFphpW3fwfnni12/LuCWz7hLUhK8/rpoP/ooHDigjR1NoKm/NMO+/d/yRKoopv3m0BtISByriR2a+kyXYRBiK9KdEwZFJ5Flsc8rLw+GDlW5vpMTOOozZpOZMQki932TKefbUJZDBS19ZvJkIUcFmDtXzC+6jL9/XTmPFSuhoko8Ozu4Jjl0u5/xtvSw7CRUF4PkB+F9PXop1XxG+S5NmyaicWcI6QIh3UC2UnVqC3PmiEfvNdfArFnum+YKenw26QVNn00uoqm1paWlDB06lPebWcM9depUvZ/PPvsMSZKY1YT3P/DAA3Tp0sXha8+bN6/euV9RUmH7GGazmXHjxtGpUyfMrs6GKw96NaSHFZVQXWMrrqztZnGz2cyECROYMGGC6/fGLQMCYdxCIT9M/wrS3NhXZy89LLNlpnRxgKaKz7jLTTfBlCnC33QiP9TcX5pAyA3vo0quZlqHYcyZ9pYmdujCZ0bMBmuaTX64mi/+Z+Xrr4XccOFCkRXc2zjrM+MTWtj3tWkTnDgBYWEiLbaPowefeekl6NlT3Nb77nPzZEp/W25LaR3jmuRQlX4mJqpOeljqBelhbabDPmD23BdNNZ9RYyLDtvr1++IN7NsHnTpplydKj88mvaCHfsYVNA2+pk6dynPPPceMZqRT8fHx9X6+/fZbJk+eTM+ePesd99NPP7F8+XJeUzbzO0BISEi9c0c4sxmzrTFmDCQmip3Jv/zi3rkUyWFYiJgZbO90GAEDbVPyW/8K5Vmun0uZ7ew/WOwJmT7dbfM0Q5EfRkTAxo3wxhtaW6RLXlk8h60lR4jyC+Oj9iY3bIhfACT3AbkK6Efl9mUAPPGEWPnyBcYltpDxUBksXn65ITlUibAwUeMdRHfz889unGzyZIiJgTG2/UDezHLYkHpZD72w+uVryTZSUuDwYQgKEoXKXcFW78tyej0g5KsxMSrZZ9Du8XP3BBaLhd27d5OUlER0tOf0z1lZWfzwww8sXLiw0evz5s3jm2++IcSJtLyff/45//nPf4iPj+eyyy7j8ccfb/HzlZWVVNrVwiq2aRiqq6s1L+6mXN8dO0yzZmF+6y2sX3yBxY3aMqbCYsyAJSwYq48VvfMY/R7E78Q3SEW7sW6+Fcu4L11LRBLkj195GVJwCNa5t2CJiAAX77EaPuM28fFIr7+O37x5yI8/Ts2UKTBggHb26Izd+5fy1KGlALw19EbiOg3X9O+lC5+J7Y8pfRHmir5cPy2S5fvTuO++Lq5+DbzOiDixKe1w/mEyCjOIC7XlqrZa8Vu0CAmomTkT2Vf+Q62gB58ZNw7uuMPEu++auekmmR07aoiKcu1cpptuxty5K3JNNTXhIS73v2ogdYjAL78IOTufmq6e3YRkLtiNCbCEJ3v8ua7KeOZ//8MMWKdOxRIY6NLfqTL4LMKAMb028qc/WZg2zeoz/Ux7Qw/9jIKjNjgdfN19990MHjyYuXPnYrFYOPfcc1m/fj0hISF8//33TJo0ydlTOsTChQsJDw9npqK7BmRZZs6cOdx6662MGjWK48ePO3SuP/3pTyQlJdGlSxd27drFgw8+SGpqKkuXLm32My+++CJPP/10o9eXL1/uVNCnNrIsk5+fX2uL5GJ2weguXZgIWL/5hp+//hqriynDzg3rSJRfANsOp3Jq/06XzqEW9vemQ4cOLt8bNYiw3MC53I8p4xu2L3uEDL9zXDrPxeu2EHjJdIpGj2PNj83XPWoJtXxGFWJjGTNyJPHbtlFy5ZWsfeklZI1Wd/TkL1ZrBc8eeZhquYZLoocSWT2JH138e6uBnnzmj9W9eHLyccIiuvPJ7b/z6/IozbKquuIzCYEJnKw8yQfffcDoyNEARB84wMSTJ6kODuZnqxWrhn9rtdCTz5x9tpnFiyeRkRHGNddkcscdKS6dZ9SgYXQFrOvX8lNhJrKf8/PXavUzfpLE1IjOmMorWPvzcs40l0FTBSaWryca2H6kksw0z/mmKj4jy1zwr38RCmzr1YtMF79L/1nYm39dHkRMeD5XT/2UH3/s5NJ51EBPzya9oad+BqCsrMyh45zuORYvXsyf//xnAJYtW8axY8c4cOAA//73v3n00UdZt26ds6d0iM8++4xrr72WoKCg2tfeffddzpw5w8MPP+zUuW6++eba9uDBg+ncuTPnn38+R44coVevXk1+5uGHH+bee++t/XdxcTGJiYlMmTJFU8mixWJh7dq1HDlyhPPPP7/e/XGKqVOR33sPv/R0pkoSsiurXxYLfptEFq/hE89heKC2m0MtFkutP+pBKy3vK4S9zzBSns/Q8+6CoHjnTnDgAP4PPASXTCcqsQfTRg90ac+Baj6jFsOGIQ8bRvShQ1yybx/WBx/UxAw9+cuLX13DjtJjRPuF88H0D+ncWds0fnrxmcxMmDPHjwPrQvnu5SJCQgZxaed0rAOdzGamEq74zIXyhczfOZ/q+GqmTRb9rOm33wAwz5jBxb4sJ7ZDLz6jEBcncd55Mr/9lsQdd3Rl2jTZuRPIMn7b9kNVNeZff2bayL8jX3ih03ao2s/sPwYFxZw7YAjWbk4+TxxFlvH75s9ghWGTrmVYhOfUCar4zPbt+GdlIQcHM+zRRxkW6nzW5Q0bJJZ8Y+bOQaM4J/kPpo0xI3d3XRHkLnp6NukNvfUzxQ5m9nE6+MrNzSU+XnzJf/zxR6688kr69u3LjTfeyNseShu9du1aUlNT+fLLL+u9vnLlSjZs2EBgg1WaUaNGce211zaSKDbHmDEiA9Xhw4ebDb4CAwMbXQe0z0BjMplqs7y4bctVV8Frr+G3dKlr9aNKbBt/AwPwD9M22QaIe6N0Uv7+/tp3WIMfg8xlSAU78N9xB5zztXMz9t98AwcPQEE+UnQH/IvLIM75fQeq+owadO8O77wD11+P+ZlnME+fDoMGed0MvfhLyu4vePbINwC8N+JmunUbo4kd9ujBZ2RZZK8rLITT1kHIoV8glfXGXNABc0kGRHf3uk2u+MyEbhOYv3M+mzM3i/totcISUQvQ9H//h0nr76NK6MFn7Jk0Ce65R2wvve02P/buBad2ShSXQFW1kLBtWi+eky5MUqraz3SKgYJizPlFmHsmeGYFuDQNakrA5I9/9AAwee7vqIrP2BRM0qWX4u+CvrSsTOSDkmUoDhwP/IFf/iboM9d5W1RCL88mPaK3fsbR6zudEaFTp07s27cPi8XCzz//zIW2mZ+ysjKPOcSnn37KyJEjGdpgV/U777zDzp07SUlJISUlpVaW8+WXX/L88887fH4lNX3nzp1Vs9knUQKuZctED+QsRn2vljH5i+yHJn84+S0c/9y5zysb8iVbZkBvpRn2BtddJ2qxVFfDnDma7qXQkqqKYub88jA1soUZsaO4ZsrLWpukGxYuhB9+EFkNFy4E04jZYD0GpjDYuaFR8WW9oiTd2JyxmWpLNWzYIJb0IiJEBlADj/Hcc9C3L5w6BXfd5eSHlf7WDFRVwtdfa99PxUSKgKusQvx4AqW4cnhfjwZequBOYWUbjz4qSml26QKTZtnqfeU2kSDHwMANnA6+brjhBq666ioGDRqEJElccMEFAGzatInk5GSnzlVSUlIbOAEcO3aMlJQU0tPTa48pLi5m0aJF3HTTTY0+361bNwYNGlT707evqD/Rq1cvEhISAMjIyCA5OZnNmzcDcOTIEZ599lm2bdvG8ePH+e677/jLX/7CxIkTGTJkiLO3o21x1lmiBlNpKfz0k/Of11F9L90SNRgGPSnaW++AskzHPrd/P+zZI+rNjBouXssv0kWKdlWQJJFOKjoatm2Dl9tn0PH84jnsLD1OjF8E/5j5SfvObmjHyZN1g+Vnn7XlZTH7wcBBIFeC1Ad2f6OliQ6THJtMVFAU5TXl7MraVTepcsUVoiCsgccIDrYF7ib497/hu+8c/KAs1wVfA/pAXBzk58PKlR6z1SH8/OpqjWXne+YatZkOfSAZ0rZtcOwYhIS4tCq5di0oAq5PPoHQJFvwVbQXqopUNNSgveN08PXUU0/xySefcPPNN7Nu3bpaKZ7ZbOahhx5y6lxbt25l+PDhDB8uBpP33nsvw4cP54knnqg95osvvkCWZa655hpnTQVE5pHU1NTaTXABAQGsWLGCKVOmkJyczH333cesWbNYtmyZS+dvU0hSXU0MZwsuy7Kx8uUoAx6EDiOhuhA23yLuXWsof48pU6BLJwgKFDP9eW3ogdC5c10hlWeegZ3aJmzxNtt3fs4LR8Vo8P1Rt9Kps4/kT/cwsgzz5okiuWPGNKjXFNcfwk+Kdn4M5B/VxEZnMEkmxiaIQtkbTqyv+263kcLKemfs2DofuuUWUaS7VYpLobIKzCaRYl6pNaoEzlqi1H/MKXDsWeIsxfvEb19IM6/8PS69VJRjcYLSUlFyUpZFUe6pU4HgThDWE5Ahb7Pq5hq0X1wqxDR79mzuueceYmNja1+7/vrrueKKK5w6z6RJk5BludHPggULao+5+eabKSsrIzKy9Ury3bt3R5Zlhg0b1ug1JQtjYmIiq1evJi8vj4qKCg4dOsQrr7zSvut82aMMAJyVHpZXQk0NmCRR48ugeUx+MHYhmAIg83s49q/WP2NfMNK+4HKOh2Y7teJPfxL1y9qZ/LCyvJA5vz5KjWxhdsezuGrKS1qbpBs++0zUZwoMhAULmsgxM2wWWI+CKRR2bvIJ+eG4BFu9rx3fCQ1cZCS4kLzBwDWeeQaSk+H0abjzTgc+oKx6xUSJZTPlOfn111BV5SkzHUMpuFxe4ZmCy4rsUO/Bl5uFlR9+GI4cESVPX3/d7o1YRXq43n0bDQxsOB18WSwWnn32Wbp27UpYWBhHj4qZxscff5xPP/1UdQMNWsdsNquXXnPkSOjRQwRezqRoVSSHYaG6Kq5svxlTV0QNhMG20gXb7oKyk80fu3ev+AkIEAVYoS7RRn4R1DgvPVTVZ9REkuCf/xTVLFNS4IUXvHp5rfzl2cVz2F2aRkf/KD6Y9Zku/zZa+Ex6ukiSAPD882LA3NgwPxg4BOQKMPWBXV971UZXfEYJvtZnbhIvTJ/eJiWHeu1ngoLq5If//W9tjoamkWXItU1yKYWVzzkHOnWCggKwZap0BlX7GT9znfRQ7X3AstXrK18u+8yWLZCWJla8pk516qOrVtWJLj75RMyF1BKrj31fuh3L6AC99jMt4fRf8vnnn2fBggW88sorBAQE1L4+aNAgPvnkE1WNM2gds9nMhAkTiI+PVyfhib300BlJRe1+L/1IDs1mMxMnTmTixIn6zA7U/+8QMxqqi2DTvOYlI4os6aKLqK0OGhoMwYFglSG/0KnLqu4zatOpE7z/vmg/9xzs2OGVy2rlL1t3/IuXjn4PwD/O+isdO3k/02NraOEzsiyyjp05A+PHw913t3BwXDJE2PZPFsRB3mFvmOiyz4xJGIOExHHzGU6H0SYlh3rvZ0aPBqWqxW23QW5uMwcWl0JltZAcdrApZMxmmD1btJ2UHnqkn7FXQqgpPSxNh5pSkWgjvLd6520Gt3xG+TtcdpnY8+UgJSVCbghw881N5LypDb42imBUA3Q/ltEQvfczzeF08PWvf/2Ljz76iGuvvbbef3To0KEcOHBAVeMMNEIZCHz/vRBCO4Ky3yvSSLbhMCY/GLsATIFw6mc4Or/xMc1JKSSpbhY2uw1lPVS46iqxr6KmBq6/Xntpj4eoLC/k+hWPYcHC1XFjmHWh41la2zoffwy//ipWKebPd6Ck3bBZYD0CpmDYtRWs+k1GExEYwaDQHgBs6BcCtsRVBt7lySdh4EDIzobbb2/mIEXarUgOFXQpPaxUV3qoJNsI76fvTIduSA4ffBCOHxe5xl57rYkDooaAOURMkhYbY1wDdXA6+MrIyKB378YzIFarlep2sj+jzTN8OPTqBeXlIrdza9RY6jp8I9Ohc0T2h6HPifb2e8RMoz1794pMh4GBdZJDBWW200Xpoa6RJPjgA4iNhd27RYq7NshTi65jX9kJ4vyjeG/WZ1qboxuOH69LivDiiyI9eKuYzDB4OFjLwdQbdnpXfugs43JFMdANE3sKSbGB17HfR/jll03kmbLPcqhMdilMmCCSBBUViVkCLfEzi7TzoO4+4CIf2e+1aROcOAFhYXDxxQ5/7LffxGMG4NNPITy8iYNMfkKhApBj7PsyUAeng68BAwawdu3aRq8vXry4NmuhgfewWq3s2bOH/Px8rGptNJekuhoZjkgqFMlhUAAE6Gd2zGq1smvXLnbt2qXevfEE/e4R0obqYth0U33ZiHL/L7pI1AGyJzQYgoPE8XmFDl/OIz7jCeLi6p6ML74IW7d69HLe9pdN2z7llWNiX+U/R99ObJx+Uzl702esVpFtrKREbK1xKCGCQmxfiMoS7cJOkHvQIzYquOwzFgvjNoh9nuu76vg76Aa+0s+MGiWSLQD89a9iFawWpbCy2VwnOVQwm13KeuixfkYJDtXMeujl4Mtln1Hu/+WXi3oCDlBcDDfeKNq33Qbnn9/CwRrv+/KZsYwG+Eo/0xCng68nnniC22+/nZdffhmr1crSpUuZN28ezz//fL0U8QbeQZZl8vPzqaysRFZT660s3f/wgxgFtURtinl9rXop9yY/P1/de6M2JrOQH5qD4PSvcORj8bp9wcimpBT1sh46Lj30mM94giuvhKuvFvXM5syBykqPXcqb/lJeksuc357CipVrO41nxgX6Xtnzps/885+ifFJIiMh06PQe86EzwHpYyA937/Co/NBln1m7lvF7iwHYWn6EKkvbk9X6Uj/z+OMwZIjY9/XXv9rFLkq/GhvVtCMq/fK33zrcN3msn4mJFNmGyyuhRCXpoRJ8RXkn+HLJZ6xWWLxYtJ0orHz//SKhT/fu8MorrRyscfDlM2MZDfClfsYep4OvK664gmXLlrFixQpCQ0N54okn2L9/P8uWLeNCI1Vu22HYMOjdGyoqxN6vljCKK7tPRF8Yasvst/0+KDkuiiofOCC0MZdd1vTn2rL0UOG998Qq2N698PTTWlujCk8svp4D5SeJD+jAO7Ob2OvXTjl6VAyKQNTZbkLh3jomMwwZZZMf9oKUJaraqApffUWfPIixBFJpqSTldIrWFrVrAgKE/NDPD5YsERLE+pLD6KY/qCfpodkMHaJEWw3poWyFov2irWfZoQuSw+XL4aOPRHv+fPHRFlGCr+L9UNUG91gbeB2X8laec845/Prrr2RnZ1NWVsYff/zBlEYpYgx8GkcLLssynDGKK6tC3zuh49lQUwKb5sJXX4rXp05tLDlUCA2GEOelhz5FbKxYDgExIt/s28Uu12/5iNfTfgLgozF30SHWkQ1NbR+rVciAyspg0iSxAuEyMb0h2qYfK+4C2TraKF9TA0uWIAFjY0Qh7fUnjL0kWjN8ODz6qGj/7W+Qd8xOchjdTP9rMjkn0fc0ahZcLj0OljJRjzKsl9umeQzlvl9xhcjO0wpFRSKLKsAdd4i+plWCYiG8j2jnbnTJTAMDe5wOvm666SZWrVrlAVMMdIcSfP34o8j33BRlFWLFxWQSgYCB65jMMHY+mIMhayUctckPW8re1JYLLtszY4YowGy1iuyHFRVaW+QSZSXZzPn9aWRk/hI/gcvOM6TaCu+/D6tXizI9n36qQrnAITNAPgRSEOzdBZYaVex0mzVrxMaiDh0YN/QSADac1LaGkIHgkUeE6CM/HzZ+14rkUMFeeqh1vxQTKWytqISSMvfOpRRXjkgWSSf0iNXasjS/Ce67TyyU9eolthI7jE7qfRm0DZx+vOXk5HDxxReTmJjI/fffT0pKigfMMtAFQ4aINGMtSQ8VyWF4iK6KK/ss4b1h2MuifX42JATApZe2/Bllo3V+sZhVb6u88w7Exwsppo/uL31s0fUcKs+kS0AMb125QGtzdMPhw3U1l159FXr2VOGkJhMMGQPWUjD11I/8UJmpnzmT8UnnALDhhDGg0wOK/DAwUGZEt2ayHDZk3Djo2lVkcFi+3OM2tohZxYLLvpDpcMMGyMgQyhAH1Fc//SQmdiRJyA1DnRHrGMGXgYo4PVr+9ttvOXXqFI8//jhbtmxh5MiRDBw4kBdeeIHjx497wEQDzXCk4LJOk234NH3/BqXdIAj4ewSEtfKEsJce5hZ6w0JtiImBDz8U7ddfFw9eH2Ltpg94K/0XAD4edw/RHTxftNQXsFpFkdPycpFx7JZbVDx5h57QIU+0zyRA9n4VT+4CNskhAFddxVldz8IkmThRfIKTxSe1tc0AgKFD4aNXS+gcU01hiZlTlU3lH7dDb9LDOJUKLvtC8OWE5LCwsE5ueNddIpOqU8SOF79zN+m6hqCBb+DSUkV0dDQ333wzq1atIi0tjTlz5vDvf/+7yfpfBj6OEnz99JOY2WuIkWzDA0jwsQQVQMdcOPhB6x+xTzPclrn8crjuOjFinzNHjNh9gNIzp7lx1XPIyNzQ+RymTXpUa5N0wzvvwB9/iE3vqsgNGzJ4uk1+GAh792grP1y1SqTUi4mByZMJCwhjSKchgLH6pSeunSIk3EvXRHHLrabWYxh76aHWfVIHRXpY5Z70UO/Bl5OSw3vugcxM6NMHnnelln3kQPALh5ozdffGwMBF3HrMVVdXs3XrVjZt2sTx48fp1KmTWnYZOIjZbGbixIl07twZs9ms/gUGDYLkZJFGd9my+u9V14g9X6DLZBtms5lJkyYxadIkz9wbT5GSAlvSYLGtZlrKg3DmcMufUfZ9FRSLv0sLeNxnPM3bb4sMYwcPwmOPqXZaT/rLI4uu53DFKRICYnlj9kJVz+0NPOUzBw/W1Vh6/XVISlLt1HWYTDB0HFhLwNQDdixW7dRO+4wyUz9rlkitB4xLEHKmtrbvy2f7GVnGnCcmsZau7cCyZfDvf7fymTFjIDFRlGX55ZcWD/X4c8lsV3A528V9wFaLyOwHXg2+nPKZdevg1CmIjIRWMm1//72Qk0qS+B0S4oJxJnNdsWUvSw99dizjBXy1n3Ep+Pr999+ZN28enTp1Ys6cOURERPD9999z8qQhm2hztFRwWclyGByoq+LKPo9yn0Mug07niYxTG28QqX+boz1kPVSIjoaPbclI3nxTLJvomNUb3uWdE2IvyCfj/05Uhx4aW6QPlNJtFRVi7DRvngcvFt0dYgpFuyQRsvZ48GLNUF0NS5eKtt1M/fhEIWdqa8GXz1J4Rkxg+Zk553IhObzzTrG1qFlMJpg9W7T1ID10t+By6TGwVIjak2FqbMD0AMp9nj5dlGNphvx8uPlm0b73Xhg/3o1rGvu+DFTC6eCra9euTJs2jdzcXD766COysrL47LPPOP/885EkyRM2GmiNMlD4+WeRp1XBkByqT73CylfDmE/BLwxy/oDUd1r+bHuRHgJcconYKCTL4neZm5m9PERJcSY3rBEal3ldJnHRuQ9qbJF+ePNNsW0vIqJuE7xHGXQ5yAeF/HDfAbBUe/iCDVi1CvLyROmEc8+tfVlZ+dp+ajsVNb6ZxbNNUVtYOZr7/m7irLPEY2/evFbiGOU5uWyZDqSHESIgrKyqmyR1hiL7TIc6XE2wWOr2TrZSWPmuu8QCWb9+8Ky7tew7Kvu+jODLwD2cDr6eeuopTp06xddff83s2bMJbGHGwcDzWK1W9u3bR0FBAVZrCysj7jBwIPTvD1VV8N13da8X67u+l9VqZe/evezdu9dz90ZtduyAI0cgOFgEGGHdYfhr4r2dj0DxweY/66D00Cs+4w3eeAMSEkSqvEcecft0nvCXhxZdz7GKLLoFduQ1H85uqLbPHDhQpxh9802h2PI4JhMMO9smP+wO292XHzrlM01IDgF6RvekY0hHqixVbD+13W2b9IJP9jOyDLl1hZX9/JTsh2Lb84IFLXx2zBjo1k1ID3/+udnDvPJcMpshJkq0XZmMK9onfkcMUM0kR3DYZxyUHH77LfznP+Krv2CBeKy6RexY8fvMQajIdfNkjuOTYxkv4ZP9DC4EX/PmzSMqKsoDphi4gizL5ObmUlFRgexuUcXmaKrgsizrfuVLlmVycnLIycnx3L1RG2WAdumldXlwe98M8ReApVzID5vLtBQaLH5akR56xWe8QVQUfPKJaL/9tigS5QZq+8vKdW/y/skVAHx69oNERHliQ5N3UNNnampEqbbKSlE//IYbVDLSEaK6Qaxt9b40CU7tcut0DvtMM5JDAEmSGJdo2/fVhpJu+GQ/Uys59IMoITkcMACeeUa8fffdokZUk7Qk0bfDa88ldwouKytfUd5NtuGwzyj3d8YMUR+gCfLy6jKn3n8/jB2rgoEB0WI1ECDPe8WWfXIs4yV8sp/BweBr5syZFNsy3c2cObPFH4M2ivJQ+eUXkbO1tBwsVjAbxZVVQ5brHir2AzRJsskPwyF3PaS+1fw5lAeuqxutfY2LLqrLH3zjjWLWWQecKTrJjWtfAuDWrudxwdn3aWyRfnj9ddi8WUxaf/SRF+SGDRl4GZAKUgAcOAQ1VZ6/5sqVYvNJXBxMnNjo7fEJxr4vXaCsEnWMqpd28777xOC9uFh0N82O8eylh1pLoZWsh65ID/Wc6dBigcW2VesWshzecQdkZYng+amnVLy+se/LQAUcCr4iIyNr93NFREQQGRnZ7I9BG2XgQPGjSA8VyWF4qAajpzbKtm1w7JhIxTRtWv33QrvByDdFe+ejUHSg6XMo+76UGdz2wOuvC93a0aPw0ENaWwPA/Yv+QlplNt0DO/HKlb6X3dBT7N1bVx/77beFatTrmEww7FywFoMpSRX5Yas0IzlUqF35OrnBp2Zv2xT1JIf1CyubzUK2FhQk6igrC+6NOOsskbKztFToFLXEbILYKNF2RnpotUCx7fmix+Br7VoRVUVHi8KATbBkCfzvf/X/bqqh1PvKWa/iSQ3aG42fAk0wf/782vaCFkXPBm2aq66CJ58UA4nRtgqFOpUc+iTKAO2yy5rOhdvzRkhfDKd+ho1z4MJ1jTdDhwSJlcjScjGQ6NzR42ZrTkQEfPaZ0P6//74Y4E6erJk5v659lQ8zfgfgs4kPER6pRYShP2pqRHbDqiqhqv3LXzQ0JjIBOm6HvAgo6wGZKdBlmGeuVVUFX38t2s3M1I/qMgo/kx+ZZzJJL0onyYclqj6LMmHlXyc5tKdfP1Ef6r77RNa8KVOaKI2gSPRffVX057Nmecf25ugYLVQQOQXQM8GxidKSo3WZDkN1mJm1FclhTg7cdptoP/igiIdVRVn5ytsM1howOTSMNjCoh9N7vs477zwKCwsbvV5cXMx5552nhk0GekWRHi5fLpI6gG6TbfgczUkO7ZEkGPMx+EdC3iY48HrTx7WnrIcKF1xQJ/C/8UY4c0YTM4oL05i77lUAbk+4gMnj79bEDj3yyiuwdauYsP7wQx0smA+4FCE/9IfUo56TH/72GxQUQKdOcM45TR4S4h/C0E5DAUN6qBk5Nql2bFSzznnXXTBhglA3z53bjPxQ6b+//16sgGlJh0ixAlZZVadWaY3aTIf99ZfpsKamLsthM8/J228XAdigQXWr7KoS2V88gy1lULjbAxcwaA84HXytWrWKqqrGD6mKigrWrl2rilEGOqV/fxg8GIJDoMqWptlY+VKHLVsgLU0k2Zg6tfnjQhJg5FuivevxuqxU9tTLeujldNpa8uqrYir6+HF44AFNTLhv0fWcqMyhZ1A8L13VWmXW9sPu3XX7Lt55B7p00dQcgckEwyeDtQhM3TwnP1QmVWbPFjqoZqit99WGkm74DFYr5BSKdgPJoT1mM8yfL7Lm/fabmERoxMiR0KOH2PP1448eMddhTCa7rIcO7gPW836vNWsgOxs6dIAmJvu/+kr8KHJDjyTjlkwQM0a0jX1fBi7icPC1a9cudu0SmaH27dtX++9du3axY8cOPv30U7p27eoxQw10wpVXwoBBoh0cJCQaBu5jLzlsLR9uj+uhyyVgrYIN1wvpgz0hQRBmO0duoeqm6pbwcCE/BPjnP2HFCq9e/ufVL/JJpsi4OP/cRwkNj/fq9fVKdbXIblhdDVdcAddeq7VFdkR0gU62mkxlPSFD5VTvVVXwzTei3UJyAKir92WsfGlA4RmxqtKM5NCePn3gxRdF++9/F9t06+Fg1kOv4WzBZT0HX/aSQ3//em9lZcFf/yrajzwiYmCPUVvvy9j3ZeAaDo+chw0bhiRJSJLUpLwwODiYd999V1XjDFrHZDIxYcIEiouLMZmcXsh0niuvhLRM0Q7Sd+BlMpk4xybz8cq9cZV6hZVbHqAB4uE++iP4YSDkb4X9r8DABnWuOnaAkgzxwG2w78vrPuNNzjsP/vY3sfdr7lyx5BIR4dBH3fGXwvyj3LReyEDv6jaFiWNvd85uneOOz7z4oihf16GDiIk1lxs2JHka5PwXpGRITYO4AeDv2A79Vn1mxQqRHTY+XujVWkBJurHj9A7Kq8sJ9vftLLI+1c/YFVZ2xEHvuEOo39auFSrn336rlxxR9OOvvAI//CCkh6F18nyvP5c6RIiloKpqUR4msuXgUsvgq0WfqalptlyDLIvAKy8PhgypqyHoMbyc8dBnxjIa4FP9jB0OW3rs2DGOHDmCLMts3ryZY8eO1f5kZGRQXFzMjTfe6ElbDZpAkiTMZjMmk6k2I6VHSU6GMbZZn9RmMu7pBOXemM1m79wbV9m8GdLTISwMLr7Ysc+EdIFR74j27qcaa8/tpYdV9aWHXvcZb/PSS9Czp7inf/+7wx9zx1/uXTyHjKo8egd15oUr257c0FWfSUmBZ58V7fffFzGI7jCZYMT5Qn5oToTtSxz+aKs+46DkECApMonOYZ2psdawNXOrM/8DXeIz/YzVWq+wsiOYTEJ+GBICq1bBP/7R4IARI0QfVF4uAjA7vP5cMjmR9dBaU5fp0Ms1vqAVn1m9WmzmiolplFDpyy9FXObnBwsXNlv6Sz1ixgCSSE5Ske3hi/nQWEYDfKafaYDDwVdSUhLdu3fHarUyatQokpKSan86d+6MuZUHi0EbQZahVx/R/naptra0FZQB2uWXty45tKf7n6Hr5WCthg1zxG+F4CAIs2VMbE/SQxBBrCI//PhjUZvOg/zw+3PMP7UWCYkFk58gJCzOo9fzFaqqRHbDmhqYOROuvlpri1ogvDPEV4h2eS/IUCH4qax0WHIIDYotG9JD71F4BmosDkkO7enVC15+WbQfeACOHLF7U8l6CPqQHsY6WHC55IiQs5tDILS7V0xzGOU+zpxZT3J4+rQQOwA8/jgMG+YFWwIiIXKAaBv7vgxcwOU1un379vHzzz/z3Xff1fsx8C5Wq5XU1FQKCwuxWq2ev2BpOZj9RLqnr74Q6/w6xWq1cuDAAQ4cOOCde+MKVqtzkkN7JAlGfwgBHaBgO+x9qf77yixug43WXvcZLTj3XLjzTtGeO1dIv1rBFX8pyD/MvI2i/to93S5mwuhbXbVY17jiM88/Dzt3QmysWBnQ/aRk/0tAOgCSH6SehOryVj/Sos/8+isUFUHnzq1KDhXa0r4vn+lncuxWvZx00r/+FSZNErk1brhBdOe1KP35Dz/UK/6uyXOpofSwOWolh/1FYgkv06zPNJPlUJbh1ltF/fLhw+Hhh71orBfrffnEWEYjfKafaYDT366jR48ydOhQBg0axCWXXML06dOZPn06M2bMYMaMGZ6w0aAFZFkmKyuL8vJy7xTnVDruk2liB70ys6tDZFnm9OnTnD59Wr+FSzdtghMnRLKIiy5y/vPB8TDqPdHe8wwUpNS9Z19w2U566HWf0YoXXoDevSEjQxTmaQVX/OWur+ZwqiqfvsFdeO7Kf7lrsW5x1me2bxfBF8AHH0CcrywGDr8QrAVgToBtra/st+gzykz9lVc22BDUPErwtf7Eep//bvpEP1NPcth8lsPmMJnEIntoqNj/VW/b+7Bhov+pqBBp521o8lxyVHpYqG2yjWZ95vffxURvbKyIdm18/jl8+61YCFuwoFEODs/ixX1fPjGW0Qif6GeawOng66677qJHjx5kZ2cTEhLC3r17WbNmDaNGjWLVqlUeMNFAVxTZgq9Q24Z0PUgqfBnl/l1xBQQ5tsm/EUn/B4kzQa4R8kOLrRREcCCEK9LDdlTzSyE0VGzMkCTxW+W0z9+tfIp/Z63DhImF5z1NcFisquf3VSorRXZDi0VMUiuJ33yC8E7Q2SLaFb0hfbNr56moEKNCcGpFe2SXkfib/MkuzeZYYcM0egaqU2AnOYx0rWxKjx7w2mui/fDDcOiQ7Q29SQ87OiA91GumQ+X+zZolNnYBmZki8QnAk0+KRBteRQm+8rfWl/wbGDiA08HXhg0beOaZZ4iNjcVkMmEymTj77LN58cUXuVOR+Ri0XZRCjcNsPd1vv0Furnb2+DLuSA7tkSQY9QEExkDhTtj7Qt177bHgsj1nnw133y3a8+aJYrcqkJdzgFs2iWnuv3efythRN6ly3rbAs8/Cnj1itev997W2xgWSLwZpP0hmOHwKqsucP8fy5VBcDF27wrhxDn8syC+IEZ1HAEa9L6+gSLJdkBzac8stos57ebmQH1ps8Xttv/7jj5oVfq8l2k56WNSM9FCPwVd1daMsh7Is7nlhoUgp/+CDGtgV0RcCosFSDgU7NTDAwJdxOviyWCyEh4tNqbGxsWRmirTjSUlJpKamqmudgb6oqoaKStFO7iMyOlks8PXX2trlq2zYICRxEREwZYp75wruJAIwgL3PQ76tXpEy29lAetiueO456NtXTJUqgZib3LnkRk5X5dM/OIGnr2q7ckNn2bJFJJsEsc8r1lcXA0dcBNZ8MHeFrS4kFnJBcqhgLz008CBWa10yIhckh/ZIEnzyiVCPr1sHb79te2PIENH3VFbCsmVuXcNt6kkPmyi4bK2GM7YxnJ6Cr5UrxaauuDiYOBGAf/1LKDkDAkR2Qz8tqt5IJjvpofFdNXAOp4OvQYMGsXOniPLHjBnDK6+8wrp163jmmWfo2bOn6gYa6Ahl1SskSPR2eiok6Ysoq15XXAGBge6fL+kq6HalkB9unAOWSgiykx6219WvkBCxIcBkEk9tNxMDLV3xGP/N2oAJEwvOf4agYPcGbm2FigqR3dBigWuuEUnJfJawOOhik2ZV9oG0jY5/trzcJcmhgpHx0EsUFAtnDfB3WXJoT1ISvC5K/fHoo3DgAL5VcPnMYRGA+YVCaDfv29Yc9lkO/fw4eRLuuku89PTTMFDLONHL9b4M2g5OB1+PPfZYbUaRZ555hmPHjnHOOefw448/8s4776huoIGOUJJtRNgeVMpDZeVKUX/DwHHUkhw2ZNT7ENhR1P3aYyuwVPvAbWK2s70wbhzcd59o33KLmEl1gdzsfdy2WWjpHuxxCaNH3qCWhT7PU0/Bvn3QqVODxAO+Sr+L6uSHR7KhstSxz/3yi8hul5AAY8Y4fdnxiSKL2q6sXZRWOXhNA+dxI8thc9x0kxAxVFTYyQ+V/v3nn4UUVUuiw8HPDNU1UNRABqlIDiMGaJLpsEmqq+uUNVddhSwL9XhREYwe7VQZR89gBF8GLuL0N+yiiy5ipm1Ks3fv3hw4cIDc3Fyys7M577zzVDfQQEc0DL569RKCa6u1TpNt4Bjr1wsZXGQkXHiheucN6ghn2Sp+7nsJ8rbWSQ+LStqv9BDgmWdEkfDTp+vS0DvJ7UtuJLu6kIEhiTzZhrMbOsumTfDqq6L94YeiDmqbYNRUsOaBuQtsc1BerUyquCA5BEiISCAhIgGLbGFL5hanP2/gAPUkh44VVnYERX4YEQEbN8IbbwCDB0O/fjqUHjZQQhTtE7+V+lV64LffxD5dm+Rw/nwRwwYGCjGDJnJDe2JGi0C1NA3KMjU2xsCXUGV6o0OHDj5VWbotYTKZGDt2LHFxcZhceNA7jNUKZ2wbzyNC617XUzanBphMJsaPH8/48eM9e29cQblf06erIzm0p9sskQFRtsDG68EfCLf9zXIKvOczeiMoSGwQMJlEjuIGexVb85dFyx/my+xNmDGzcMrzBAZHeclw7WnJZ8rLhdzQaoU//1moaNsMIbHQ1fb/reoLafX3djTymfLyOlmrGyvabWHfl677GXvJYYT7kkN7EhPhTVH6j8cfh33762c91Py51Jz0UAfJNhr5jPKcnD2b9Awz99wj/vncc9C/v2Zm1uEfDpGDRduDq1+a+4yO0XU/0wJOWzpjxgxmzpzZ6GfWrFlce+21PPnkk0biDS8iSRIBAQGYzWbPBsCl5WJ05WcWe74UFOnhqlWQne2567uAcm8CAgL0NTlgscDixaKtpuTQnlHvQVAnMZu5+6l6BZe95jN6ZPRoeOAB0b711nqZOlvyl+ys3fx1q1hRfLjnpYwcep3XTNYDLfnME0+I/S2dO9slGmhL9L0QTPvFDPeRPKisyxTXyGd+/llIDrt1c0lyqNAWii3rup/xgOTQnhtugKlTxWLXnDlQM7NOeigVF2v7XIqykx4W2kkPdRB81fMZO8mhfOVV3HSTUG2OG0dtEKYLvCA91O1YRgfoup9pAaeDr8jISFauXMn27duRJAlJktixYwcrV66kpqaGL7/8kqFDh7Ju3TpP2GugFbWSw9D6D6sePeCsswzpoTOsWwenTkFUlMhP7AkCY2D0h6K9/xUwp4l2UQlUVnnmmr7CU0+JXdrZ2XD77a0eLlss/HXxXHKrixgSmsTjhtywlvXr65IMfPQRdGiruUdGTgNrLpg7tyw/tM9y6MZAQNn3tfHkRp8qHOoTqJjlsDkkCT7+WKjKt2yBV38cKJZqqqrcTvjjNiYTxNrV/AJbpsODoh2lj0yH0m+/iVzy8fF8cuBsfv1ViBfmzxcZ83WDse/LwAWcDr7i4+P505/+xNGjR1myZAlLlizhyJEj/PnPf6ZXr17s37+f66+/ngc1KbzQ/rBarRw+fJiioqLaRCgeQcl02JREQ6fSQ6vVysGDBzl48KBn742zKPdpxgyRK9dTJFwB3f8MshW2z4HwYACs2fne8Rm9omwYMJvhyy9rVyGb85evVjzCktwt+ElmFlz4AgFBERoZrh1N9TNlZWJWX5bF70sv1dREzxISAwn+ol3dH47/ATTwmZKSuj09bq5oD+88nEBzILlluRzOP+zWubTCa88mZ8m3lxyGtn68i3TtCkoOsqeelsieZKtR9eWX2j+XFCVErk16eOaQLdNhGIRol+nQ3mck297J4otmc+/9Itp64QWxfU5XdBQTJeRvExmGPYBuxzI6QLf9TCs4HXx9+umn3H333fW0lSaTiTvuuIOPPvoISZK4/fbb2bNnj6qGGjSNLMtkZmZSVlbm2RnShsk27FGkh6tXi2QGOkG5N5mZmfqZPfaG5NCekW9DUDwUH4AqsX9Eyi3wjs/omVGj4OGHRfu22yA7u0l/OZ25o1Zu+FivKxg+9E9aWawpTfUzjz0Ghw6JQaayx6VN0+d8MO8X7aOFUHmmvs/89BOUloqc42ed5dalAswBjOwyEvDdfV9eezY5i0qFlR3huuvgssvEgtftq23PyeXLyT54UNvnUlS4yFahSA9rJYcDPH5PWkLxmYqiIky2iYwndl9FSQmcfbbLeZI8S1gvCIwFayUU7PDIJXQ5ltEJuu1nWsHp4KumpoYDBw40ev3AgQNYbGXdg4KCfEp7adAKlVVQYZOqhTcxU5iUJPY3GNLD1lm7FrKyIDoazj/f89cL7ACjPxLt448DIBWXEojx/eTxx0Umstxc+OtfG9W9kS0Wbl06j/yaMwwL7cEjsw25ocLatfDWW6L98cdCQdsuGHkpWHPAHA9bv6n3lmRfOkKF519b2PelOyxWyCsUbQ9JDu2RJJH9MzoaFu0bSHbcQKTqamL++MPj124Rkwk6Rol2Tj4Uar/fy56EAweQiooojezMO9snEBysQ7mhgiQZ0kMDp3E6+LruuuuYO3cub775Jn/88Qd//PEHb775JnPnzuUvf/kLAKtXr2agppXvDFRFkRyGBouNuk2hp0KSekYZoM2YAf7+3rlmwmXQ43qwZkGNSIYTJ3np2nomIKAuX/GSJXWDZxv//eV+vs3bhr/kx4KLXsQ/0HMSJV+itFQkFJBlmDtXJBZoNwRHQ6It4VBNfzi2FgBTeTnSDz+I15W+0E2UfV9G8KUiBUUiAAsM8Kjk0J7Onevq3v0zV/hG3KpVXrl2i9RmPSyEQiXNvD7Gbb22bQPgX6WzkTHx0kvQu7fGRrWEEXwZOInTwdebb77J3XffzSuvvMLEiROZOHEir7zyCvfccw9vvPEGAFOmTOGLL75Q3ViDxlisFlIKU9hSvoU16WuwWC3qX6QlyaHC7Nni95o1IpmEDqiqtrB462HeXrmFt75ZRVW1B+6NM3hbcmjPyLcguAuUfI9FtnCscBtFplX8seUDLNWe0an7BCNGwKOPAmC9+3aO/bGA7evfY/6Ht3H79o8BeKL3dIYOvlpLKzXHUmUhd/FhpC/SeePydRw7YiExsS7ZRrui9+Ra+aEpvZS+6WsYvmcZ0gXJ0KO7kLSqgLLytSd7D8WVGhfnbSt4OMthc/zpT6KqyBdWEXxFbdlCwaurSXlrFZYqjZ5LUeHg7wc1NVBqW/XXOPiyVFko+PIA3bcK+d7/amYxcaJDeZG0Jda278tTwZcsE4WZOPyETNSH5HUex1JDQs0xJkQVYE5fD5YarS1yCEl2QyRZbKvWHhHh2gb0NWvW8Oqrr7Jt2zZOnTrF119/zfTp0+uMa6ZzfOWVV7j//vvrvVZZWcmYMWPYuXMnO3bsYNiwYc1et6Kigvvuu48vvviCyspKLrroIj744AM6derksO3FxcVERkZSVFTk8v/fXZbuX8pdP93FyTMna19LiEjg7YvfZmb/mepdaMcBEYD16w7xsc0fN26cqCz57rua95YPzF/KG/vuwhJWd2/MJQncO+BtXrlBxXvjDL//DuedJ1LCnT7tvZUvhcyfWLr8Se46ncbJyrqyAAkBsbx91i3MvOA579qjF6qq+Oqhs7mv4zFOVuXWe6tnYCcO3HOkXa96bXxgKd3euIsulrrv0gkSWHfl2/zfVxp9l7SmogjWbwZzgwK9VVlQfhguv0uVy3R/qztpRWn8et2vXNDTQ5lRPYTFYmHVqlUcOnSIOXPmEBQU1PqHPGqQFdanCHn88GTV63u1RlYW3Nt9KfMrriaAugFipjmB9HvfZuwrGnyXDh6HU7lQ+i0UPgdXpENoovftoPl+Zu+8t7n4I533MzWlsChS1NZU+x7mFCAfTkeqqq57LcAfendTtUC4T3LgJ+RMCclsNy615kJnGZK1kWQ4Ghu4VJGspqaGFStW8L///a82QMrMzKSkpKSVT9antLSUoUOH8v777zf5/qlTp+r9fPbZZ0iSxKxZsxod+8ADD9ClSxeHrnvPPfewbNkyFi1axOrVq8nMzGTmTJ1/uRuwdP9SZn81u17gBZBRnMHsr2azdL9Ke6+sVjjTQqZDe3SS9fCB+Ut5NW02ltD698YSmsGrabN5YL5G+9KU+zJzpvcDL2DpvnXMTttSL/ACyKjKZfa651m64jGv26QHPv7gVv4vckujwAvgWGUWC/5xhwZW6YONDyxl9KuzibfU/y51JYOrFs1m4wPtdI/n8gVgimr8un9HiBgP36lT8Gxcom3f1wlDzuQ2BUXieRYY0PTeZQ9z7PWl/LtiNv7Un5mPt2Qw+lWNvkuK9DDoXPCPhpAE79tAy/3MlI99oJ/xC4WooaKt5upXTgHsOwL2gReIf+87UreS2x458BOcjgVTg72bUgfx+oGftLHLQfyc/UBaWhoXX3wx6enpVFZWcuGFFxIeHs7LL79MZWUl//znPx0+19SpU5nawoaB+Pj4ev/+9ttvmTx5Mj179qz3+k8//cTy5ctZsmQJP/3U8g0vKiri008/5b///S/nnXceAPPnz6d///5s3LiRsWPHOmy/VlisFu76+S5kGi9aKq/d+O2NHMw7iElys+J3RSVk5oDZJGrctCTV6FsIEwDrWvjpMdBgRbDGYuW1Qy9BgEyjnBKSDDK8duhGotYcxM/sxWroVisc/be4PxOAda9479qA1VLDSxvfbMJjqH3txo1vcTDnsE9ViXcXi8XCyyU/NHlfFJ4tX0aPac/hhwfLAugQ2WplxC8vISE3+iqZbD1N/9duxBp1EJNf+/EZrDUwcijim9PgzkgmUdohuBdUVUJAoFuXGp8wni/2fGHs+1KDbG0khyDkdN3euAta+C4lv3ojv+86iOTF/leSJCbcOQa/oChKz5zNlkte9dq1FVrrZ6xIJL5xN5bnrsAcoMeMGzZix0HBdhF8JamwrUCW4XA60HgoU0vqcSgr1zRDpSZYrXAqBCSQGo5xlT74FNCnBsxOhzlewWmr7rrrLkaNGsXOnTuJiYmpfX3GjBnMmzdPVePsycrK4ocffmDhwoWNXp83bx7ffPMNISEhrZ5n27ZtVFdXc4Fdcdvk5GS6devGhg0bmg2+Kisrqays2xujSC6rq6uprq5u8jOeYnXaak4Wn2zxmKLKIh7+7WF1L3zIgWMutP3e/Ly613aGlsY7EsiBRTz6u8r3xhFssnDSPoE071++NYospTx88EutzdAVMnCiKhe/6H8x6b+OfAHaDxIQKRfBoxp8l7Tk8hEwbkrz70smCIjHsvLfWM+/3q1LndVZpKzfeHIjlVWV7k+meRFZlhk+fDiFhYVYLBavPyfrYbHil1eIBNRERyB72ZZd765hpKX5Z7YERFHE5F80+C5NfRAGzyZUHsKkn/RXn9WETFfLCba9u4ohd07U2pxmkTqMxo/3seasw6KCf0lFJfg1XPFqiMUCxzPdvpZPYmph9VoygdQRy9E/sHaf4D2bwOF+zunga+3ataxfv56ABsVhu3fvTkZGhrOnc5iFCxcSHh5eTx4oyzJz5szh1ltvZdSoURw/frzV85w+fZqAgACiGuRG7tSpE6dbqFH14osv8vTTTzd6ffny5Q4FfWqypmCNQ8cNCB1ApwDH97E1RaxfICEmM4WWaootrTtV+MmTRB86RGVkJFkjRrh1bVc4mFNAhl9Kq8d1rRlGXy/qpTukphKWmUlJly7ka1AlsqQqnS2lR1o97uzwfnQLbD868vSKfP4oOdjqcQfi46mIH+oFi/RDTNFJzirf2OpxR7oOw79v+/GZ2IGdcKTHz007xMYff3TrWjVyDQFSAAUVBXz89cckBmmzH8cd/Pz8WLFihaY2dPYPYnRoDKWWGlasXeX1659ZuYeRDhy3JXgseZHelf6NLkuhA7OxJFzIiq6HkC3eLVTraD+zf+VGTvZ2bmuLNwmxVoi55/wd/PzDN1gl95QSXf2DGRXaejmE3JoKyjyRaE3HRFFChANj27QDu9i9r8gLFtVRVlbm0HFOB19Wq7W2npc9J0+eJDw83NnTOcxnn33GtddeW2/T7rvvvsuZM2d4+GHPzxY9/PDD3HvvvbX/Li4uJjExkSlTpng94UZoWihvpL3R6nFvT3+bc5POdetaflv3IVVVUzOwF3KkAxuUMzLw79EDKKL6qc9EBVYv8s53a/j7ntY3pt8z7DXuvNxLs2g1Nfh164aUCzU/f4Zsk7t6kzWb3ueC3+5p9binRt/KxDF/84JF+mDpx4/wR8lrrR4X3WsM56e/4AWL9MOud9bA31v/LhXe85quZ6TVxvTbwtYPAmKT+jDt/GluX290/mj+OPEHgb0CmTbU/fN5k+rqan799VcuvPBC/DXY56pgTj0OeUUEJXZmWndHwiB12XU4DByIw03PPsf5Xv4u+f08GCx5mINiOH/7B8jR3h3PONrP9D9vLEOm6bifkWXkZU9gqsxi6pg4ZCUDootIRSWwt/UJ06ihA4l0ZGzWhjAdXwcOLPglJQ8h0csrX4oqrjWcDr6mTJnCW2+9xUcficKtkiRRUlLCk08+ybRpnnkwrF27ltTUVL78sr4kauXKlWzYsIHAwPo6s1GjRnHttdc2kiiC2EdWVVVFYWFhvdWvrKysRnvM7AkMDGx0HQB/f3+vP1Qm95xMQkQCGcUZTe77kpBIiEhgcs/JmE1uaKQrq2o3evpFRzhW4bB7d5gwAdatw//bb+EudbJ+Ocodl0/i/vUJyOEZYo9XQ2QJc2kCd1w+CX9/L+nHV68WhXxjY/E7/3xRV8rLTBpzGwlrnyejKrfJ/U0SkBAYy6Qxt2HWcJDkbWbMeZqEtxe0fF8CYpkx52lNB49aMOyOSWQ+mEC8JQNTE3fHisQpcwLD7piE2VvfJT1w3nWwZgX4dRTylobIMlRnYT7vOlW+SxO6TeCPE3+wOXMz80Z5TtqvNlarlaNHj1JcXIzZbNbu+2OxQMEZAMzxsZr0b7r9LlkqoeQwmFZC2JX4FRRDXEzrn1MR3d4bV+g4Dk5+g1/hFujs3sQ3MVEiq2FL0sNAf/xiotrfnq+eZ8OJ5WCKbaYPtoKch7nnhZi9vOfL0X7OaQH566+/zrp16xgwYAAVFRX86U9/qpUcvvzyy04b6giffvopI0eOZOjQ+rKfd955h507d5KSkkJKSgo/2iQeX375Jc8/3/Seo5EjR+Lv789vv/1W+1pqairp6emMGzfOI/arjdlk5u2LRTYtqcFWTOXfb138lnuBF9TV9woLca60vIZZD3/+yYz8ky3TmNygQ7L9+94BbxHgzU5cuQ+zZmkSeAGY/QN5+6xbgCbykNh+vzXqFsz+7iUI8DUCQkJ4IvgyoPn78njwZQR4WVqsB8wBZtLvFd8la4O7o/z7xL1v6XsTvCcICISyw4CELDeQaMmyGAhVHnE72YaCUu/L15JuyLLMyZMnKS0txY2KNu6Tb8tyGBQgnmUaoNvvUnGqSI9ebfOt3EJxr7yIbu+NKyirXTnr3T+XJInMnNB8Qqhe3dpf4AWQvxkKX6PpPtgKSNAZ3SbbABeCr4SEBHbu3MkjjzzCPffcw/Dhw3nppZfYsWMHcXFxTp2rpKSkNnACOHbsGCkpKaSnp9ceU1xczKJFi7jpppsafb5bt24MGjSo9qdv374A9OrVi4QEoZvOyMggOTmZzZs3AxAZGcncuXO59957+f3339m2bRs33HAD48aN84lMhwoz+89k8VWL6RpeX9aXEJHA4qsWq1Pnq0hJMe9kWt5Zs0SHsH49nDjhvh0OkpcHt9wC7J/J6OOLMZfWvzemkgTuT1rs3Tpf1dWw1JYm19uFlRsw84LnWDzhUboG1K/VlhAYy+IJj7bbOl/z7v6MtwJuaHxfAmL5MPIG5t39mUaWac/YV2ay+f7FnDbX/y6dMiew+f7F2tQm0gOX3wXF66Emp/7rsk3vH5oMZY1LF7iCkm5+b85eCisKVTlnu6I2y2EHTQequvwuFe0Tv0OstoLLFijwfkFvXd4bV4i1TeDnbnC/EHJ2fl2ZH/8GQUSgPwzo1T7rfNWUw8YboOJ3sCwEa3799+U8iM/VrM6Xo7gUFvr5+fHnP//Z7Ytv3bqVyZMn1/5b2VN1/fXXs2DBAgC++OILZFnmmmuuceka1dXVpKam1tsE9+abb2IymZg1a1a9Isu+xsz+M7m096W8+9277Evfx9WXXM35vc93f8VLQVn5crYYZdeucPbZsHYtLF4M97S+10gN7rxT1C7u3x9W/3MmMpdy/3v/Yvl6K4d29GXGqHN45TUvz579/ruICuPiYKL2evWZFzzHpWc/whffPcmpwhOM7D+ayWP/1u5WvBqyP/0zsj4p48lbHyGi80m6RvVgxpyn2+WKV0PGvjKTqqcv5ct751O4P40Rl0xmxF3n0dUXZqI9yeV3Ya0o4/QXbxBkKScqoQfmCTNg8zowd4FtP8E517l9mbjQOHpF9+JIwRE2ndzERb0vUsH4doLFIla+QBcDVeW7tPj+f2HNKKDX2SMYdsck7b5LRXvF78j+0CFalJXJKRCSNy/TJvqZDiNB8oOK01CaBmHdXTtPVTUcsi1CJHXGmtCJ3X9sIACJfoMHYe4Q2T5XvAB2PQZnDkJwFzjnWayEcPj3f1NVkEPyiDH497pQ1yteCg5buGaNYxn2JjoxwJw0aVKrcoSbb76Zm2++2aHzde/evdH5mnotKCiI999/v9nizr6E2WRmWNQwQnNCmdhtonqBl9UKJbaA1dngC8Qqz9q1QnLnheBr6VL473/BZIIFCyAoCCwWM7NH9WZIRBi3fD2KH7OgtBRCvVlfUweSw4aY/QPpGnMxZfmHOPusOe0+8KqpgSVLoLomhLCkGxgxqoBzzjkHszNS2zaOOcBM7OzeFBySGTznHN+QAHkD/0AOdT8bgHPOOUfIs3vFwTELWPtD6nLo10JaegcZlziOIwVH2HBygxF8OUOeIjkM1Exy2BDluwQwTOt+pjb4GihWBjNz6qSHGtR79Pl+xi8YoodD/hax+uVK8CXLcChNPJhCg6FbZ5BlChGJ7vpFhbffwCv7DzjwpmiP/hgCosFi4aRfDw4V1tCn23j8fSDwAieCr0mTJjX7nmRzBEmSqKmpafY4Ax/iTJnoBPz9hFbeWWbNEktRGzdCejp066a+jTZyc+G220T7wQdh9Oj67/fpU0KvXjJHjkj88IMX1X86khwaNM/q1ZCTAzExMsOHF2ptjoGvkzQWMv8DVckiI1dCDoR2dOuU4xLG8Z9d//G5fV+ak6NdYWWfwD74igyrS/BQUKzJ6leboON4W/C1Hrq7oNjKzhcBsCRBcg8RBDeRYbzdUVMq5IbI0PNG6OpbmV8b4vDURkFBQZM/GRkZ3H///QQGBpKcnOxJWw28ib3k0JWHVufOdTK7xYvVs6sJbr8dsrNh4EB48snG70sSzJ4tVj+9mgPkt9+goAA6dYJzzvHihQ2cQfGJmTNlzGYNEwMYtB1GzABLBpg6wLaf3T6dknRj48mNWBtuMDdoGosF8gtFO671ekntDkuFyHQIIviSpDppphK0GjiP/b4vZ6msgsM2uWG3zrpZrdUFKY8Ifw1JgBGtl1rSOw4HX5GRkfV+wsPDWbRoEaNHj+Z///sf77//Prt27fKkrQbepDb4ckOj54Wsh4sWwZdfCrXPwoXQRDUAAK68Ugyqf/gBSrxVp1H5f8+e7Vy2SAOvoUgOoS5ANzBwm8BQ6B0vMsnJ/eGAewHY4E6DCfUPpbiymH05+1Qyso2TVwRWGYIDhXzLoD7FqSIznH8UBHcWrynBlwZZD9sMSvBVsBNqHCu4C9jJDS0i6OrWfOmjdkfWajj4jmiP/gQCIrW1RwVcEkcuXbqURx55hJycHB5++GHuuOOOJmtgGXgek8nEyJEjKSgowKSWRluWoVjJdOhG8b6ZM+GOO2DTJjh+XNQAU5HsbPjrX0X7kUdgZIPamSaTibPOOguA4GATffrAoUPw/ffwf/+nqimNqaqCr78WbZ1JDj3iMz6Kkg+lY0eYPNlEVZXwl/Z+Xxpi+EzT2Pcxje5LtzFCfliZDKfM0DULwju5dB0/kx+ju47m9+O/s+HEBgbFDXLXdI+juc/k2LKg6Uxy2KLPeBNFchg1sO7+RNhJD/OLITbKqyZp7jNqEJIokkGUZ0L+VohzMA9Cdr6YMJAk6Ne93p473fiMFlSXwKYbRbvXPOhSf8+rr/qMU5auXr2asWPHct111zFz5kyOHj3K3//+dyPw0hBJkggNDcXf3792753bKMWVJQnC3Vj5io/3mPRQlkXglZsLQ4bAY481Pka5N6GhoZhMEldeKV73ivTwt9+gsFDcgwnerbDeGh7xGR+lTnII/v51/tLe70tDDJ9pGvs+psn7MnIWWE6CKRp2/OrWtRTp4fqTKtQQ8gKa+kyNRQxkQSSS0BGt+oy3sN/vpVBPepjf+DMepk30M5LkfL0ve7lhUmO5oW58RgtSHoKSoxDSDUa81uhtX/UZh4OvadOmceGFFzJs2DCOHDnCCy+8QGSk7y/9GTSBsuoVFgxmN2cSPCQ9/PJLIRfz8xPZDQMcyAmimPLjj3DmjKrmNMaQHOoeIx+KgcfxD4a+XUGuATkZ9v/o8qmUel8bThhJN1olr1DM0BmSw+ZpKviCumA1r9CQHrqKM/u+ZBkO2ssNO3vWNl/i9Eo4ZMtKPvZT8I/Q1h4VcXhk/fPPQrP+5ZdfMmDAADp06NDkj4F3sVqtpKWlcebMGaxqdZSu1vdqipkzxfL5li1w7Jj750PU8vrb30T7scdg+PCmj7NarRw/fpzjx49jtVoZMgT69oXKSiE99Bg6lhyCh3zGB/n9d8jPryvB1tBfDOowfKZpHPKZhLMg6Ihonw6AM6ddutbYhLEApOalkl/u/VUJZ9HUZ2qzHGpbWLkpdNPPFDYTfEWECumhxVpXI81LtJl+xpliy1l54j4r2Q2b8Ffd+Iw3qT5TJzfsfSvEX9DkYb7qMw7v+Zo/f74n7TBwEVmWSUtLo6SkpNWaaQ6jZvDVqRNMmgQrV4rsGA884NbpZBluvVUMmocNE3u9mj9W5vjx4wAkJiZiMolY6LnnxMKUi3W7W+fXX6GoSGR81JnkEDzkMz5IwxJsFkt9fzGow/CZpmnYxzTLyJnwx89gSoQdK2Din52+VmxILH1j+nIw7yAbT25kWh99p1rWzGdq9FVYuSEO+4wnqSmHEtuEQMPgS5EeZmSLIDbWe/ewzfQzHUaAKQAqc4RkLrxX08dVVsHhE6LdvUuzq7S68Blvs+MBUag6tDsMf6XZw3zVZxwOvq6//npP2mGgFyxWKCkXbXcyHdpz1VUi+PrqK7eDr//+F779Fvz9RXZDf3/nTXnuOfjpJyguhghPrGIro/orr9SkUKVB6xiSQwOv4h8MfbvBoWogGfb9AAMucfo04xLGcTDvIOtPrNd98KUZiuQwJMiQHDZH8QFAhoAOENREEpiOHUTwlVcoxgTubj9ob5gDocNIsfKVu77p4EuWIfW4KIkQHgqJRnbDWk79Cof/KdpjPwP/cG3t8QDGN8qgPmdKRacQ4A+BLhRXbgpFerhtGxw96vJpTp0SyRMBnnhCJNpwlkGDIDlZSA+XLXPZlOaprIRvvhFtY1SvW4wSbAZep+tICLatNmQFQXGm06dQkm4YxZZbwCis3Dr2+72aukcRoeL5b7FCgXelh22G1vZ9nc4VxawlCZK7G76qUF0Mm+aKdt/bodNkbe3xEEbwZVAfd4srN0XHjnDeeaK9aJFLp5BluOUWMWAeORIefNA1UyTJw+XHli8XS2pdu8K4cR64gIEaGPlQDDRhxCywpIMpEnb87nRCg/GJIova5ozNWKwWT1jo29TU2EkOjT3ozdJcsg0Fo+Cy+7QUfFVUwhGb3LBHVwgxVmhr2X4flJ2AsJ4w7CWtrfEYRvBlUJ/a+l4qSQ4V3Ix4/v1vsVIVECCyGzorN2zKlJ9/FluzVMWQHOoenedDMWjL+AdBck+R/ZB+sP8Hpz4+oOMAwgPCKakqYU/2Hs/Y6MvkFRmSQ0doLfiC+gWXLb6TyEA3KMFX4S5Rq0qhVm5oFeOsBNdq/7VJMn+BI5+I9tj54KfyOFRHGKNDgzpkWd1kG/bMmCGWGLZvh8OHnfpoRgbceadoP/WUkA66w8CB0L+/GIR/951756pHRYXYkAbGqF7HrFghSrDpNB+KQVunyzAIscmvs0Oh6KTDHzWbzIxJGAPA+hO+Ue/Lq2TbFVY2aB77AsvNEW6THlq9n/WwTRDSVdSmkq2Qt7nu9VO5UHgGTBL0azq7YbukqrBObtjvLseLU/soLgdfVVVVpKamUlNTo6Y9BlpSUQXVNbbiyiGtH+8MsbEuSQ9lGebNEytUZ50F99+vjjkekR4uXy4KiCUkwJgxKp7YQE3ssxwakkMDTRgxG6xpYIqAlNVOyQ+NfV/NUFMj9tCAITlsiZoyKLGVfWlp5UvjgsttgobSw4pKOKrIDRPECq2BYPu9UJ4BYb1h6AtaW+NxnA6+ysrKmDt3LiEhIQwcOJD0dFGV+4477uCll9quPlOvmEwmhg8fTkxMDCZ3ZW7KqldYiGckcy5EPAsWiMyEgYGi7edwfk5xb0aMGMGIESMa3ZsrrxS/f/lFrIKogo9IDlX1GR+jpXwoLflLe6c9+0xLuOwzfgGQ3BvkaqAf7HM8+4+y70vvwZfXfSa30Cckh5r3M8X7ARkCYyEoruVjawsuF4msfB6mzfUzDet91coNw6BrK/feDs19xtNk/ABH5wMSjFsAfo5P/vuqzzht6cMPP8zOnTtZtWoVQUF1UfsFF1zAl19+qapxBq0jSRLh4eEEBAQgubt87SnJoYIiPUxJgYMHWz38xAm4+27RfvZZGDDAuctJkkRERAQRERGN7s3AgeKnulol6WF5uc9IDlX1GR9jxYrmS7C15C/tnfbsMy3hls90Hgqhx0U7JwIKTzj0sTFdxar64fzD5JTmOHdNL+J1n7EvrKxjNO9nivaJ3y2teimEh0CQ96SHba6fsQ++MrNtckOT09kNNfcZT1JVAJvniXbyPdDRub0AvuozTgdf33zzDe+99x5nn312vf/owIEDOXLkiKrGGXgZJdlGpIc2OcbEwAW2KuWtSA9lGW66SSQOHDsW7r1XfXNUlR7+8guUlEC3bobkUMf4yOKkQXthxGywHgdTOKSsdUh+GB0cTf/Y/oD+V7+8RrW95NDY79Uitck2HJjNlKS6IstG1kPniR4G5iCwBNfJDXt2hWBDbljLtruh/BSE94Uhz2ltjddweviRk5NDXFzj5dLS0lKfijrbClarlRMnTlBSUoLVybTF9bBYoKRMtD218gUORzyffCK2UAUFCbmhK3tzrFYr6enppKenN3lvFOnh8uUihb1b2I/qdf49UM1nfIzWSrC15i/tmfbqM63hts+Y/WFAMshVIPWFvY4tw9fu+zqh3+DLqz6jFFYODda15BB00M8UOpDp0J4470kP21w/Yw6ADmdB9BNgBSLDoIvjckMFzX3GU5z8Do79CyQTjFsIfs5/d33VZ5wOvkaNGsUPP9Slx1UCrk8++YRxRl0jryPLMseOHePMmTPIsuz6iZRVr8AA9YorN8X06WLj1q5dkJra5CFpaXUrXc8/D/36uXYpWZY5evQoR48ebfLe9O8PgwcL6aGiGHSJ8vI67aLOJYegos/4GK2VYGvNX9oz7dVnWkMVn+k0CMLE3mlyo6AwrdWP+MK+L6/6TI7vZDnUvJ9xJM28PWHekx62yX4m/DoIHAFUu5zdUHOf8QSVebD5FtFO/jvEjnXpNL7qM04HXy+88AKPPPIIt912GzU1Nbz99ttMmTKF+fPn8/zzz3vCRgNv4Kn6Xg3p0AEuvFC0m5AeyjLMnSsUfBMmwF13edYcVaSHP/0EpaWQlCRSMhroEkNyaKBbhs8C6zEwhUHKulblh+MSxezBlswtVFuqvWGhfqmugYIzoq3z/V6aU1MKpQ5kOrRHkurua7YhPXSK8gqoGiralV9AcKC29uiJrXdCxWmI6A9DntbaGq/j9BDk7LPPJiUlhZqaGgYPHszy5cuJi4tjw4YNjBw50hM2GngDTyfbsKeFiOfDD+G33yA4GObP93wqcEV6+OuvkO9qNl3l/3HVVbqXHLZXjBJsBrrG7A8DBoJcKeSHe1peik+OTSYqKIqy6jJ2Ze3ykpE6RclyGBpspO5ujaL94ndgRwjq6PjnlBXFfO9kPWwTyDIcOA6yCSq2QO57UGXUSwPgxNeQ9l8hNxy7QOyLa2e4NP/bq1cvPv74YzZv3sy+ffv4z3/+w+DBg9W2zcBbyLL3Vr4ArrgC/P1h927Yv7/25WPH4O9/F+0XX4Q+fTxvSr9+MGSIKBGj7AdyirIy+P570TZG9brll19ECbbERCMfioFO6TQAwm0Fl/M6QP6xZg81SabarId6lh56BR+SHGqOs5JDhbAQCAoUK7J5RgDhEBlZYlLbbIKqBUCDYsvtlYpc2HKraPd/EGJHa2uPRjgdfG3fvp3du3fX/vvbb79l+vTpPPLII1RVValqnIGXKK8U0YdJEp2sp4mObiQ9tFrhxhuFeu+cc+COOzxvhoJb0kNFcti9Oxgrv7pF+dvOnm1IDg10zLBZYD0KplDYtbFF+aEv7PvyONVGYWWncDX4MgouO0dZBRzLEO2eidCht2jntuPvqsLW26EiW/jg4Ce1tkYznB6G3HLLLRy01Wg6evQoV199NSEhISxatIgHHnhAdQMNvEBtceVQ741MG0Q8//gHrFoFISFCbujNAbIiPVyxAvLynPywITnUPT6WD8WgPWP2g4GDbfLDPrDr62YP9YWMhx4n17YHKcyQHDqEEnxFORl8QV1wm18ENYb0sFlkGVKPgVWG6AjoHAsdxUQJueu1tU1r0hdB+pcgmUV2Q3P73QPn9BD34MGDDBs2DIBFixZx7rnn8t///pcFCxawZMkSte0z8AbelBwqKNLDvXtJ/2kvStz+yivQq5f3zADo2xeGDRNSdqekh6WlhuTQBzBKsBn4FHH9Idw2a17QEfKarp85JmEMEhLHCo9xuuS0Fw3UET5SWFk3uLryBSLADQ4UQUV+oapmtSlOZokxldkEfZNstdKUYssbQfaddOiqUpENW/4q2gMehg7tWynkdPAly3JtLv0VK1Ywbdo0ABITE8nNzVXXOoNWMZlMDBkyhA4dOmBydblIWfmK9EKyDYWoKLjoIgB+u3URZWUweTLcdpt6lzCZTAwbNoxhw4a1em9ckh7++KPY89WzJ4wY4bqhXkYVn/EhHC3B5oy/tDfam884isd8ZvgssB4BUwjs2gLWxisNEYERDIobBOhz9cvjPlNd7ZOFlTXrZ6pLoNRWxsCV4MteeuihrIc+38+UltfJDXslin1yAFFDwBwC1UVQfMDp0/r8s0mWReBVmSvuxaDHVTu1r/qMS3W+nnvuOf7973+zevVqLrnkEgCOHTtGp06dVDfQoGUkSSIqKorAwEDXilzXWESHAd7JdGiPLeIZk/4VoaHw6afqyg2VexMVFdXqvVGkh7/9Bg7PIfio5NBtn/EhnJEcOuMv7Y325DPO4DGfMZlh0DCwloOpN+xsWn5YKz3U4b4vj/tMbqH4HRYCwb4jOdSsnynaJ34HdYLAGNfO4WHpoU/3M7IMqcfF7+gIiI+te8/kBzG2MjQu7Pvy+WdT+ldwYglIfrbshurVkvVVn3F6qPvWW2+xfft2br/9dh599FF69xYbCRcvXsz48eNVN9DAw5yxSQ6DAiDA36uXPjLwcioJYAD7+fTevfTo4dXL16N3b7F4ZbHA181vs6ijpASUYuOG5FC3GCXYDHyWjv0g0iYnLOwEeYcaHaLU+9Jj8OVxso0sh07hjuRQIdQmPZRlyCtUxaw2w4nTYjxlNkO/7o0nZGNt4+Ocdrbvq/x0ndxw0GPQYbi29ugEp4OvIUOGsHv3boqKinjyybpMJa+++ioLFy5U1TiD1rFarWRmZlJaWlorB3UKb9b3ssNigevvjORnLgbgKtypctw0VquVjIwMMjIyHLo3TkkPf/hBLKv07i02jPkQbvuMD+HM4qSz/tKeaE8+4wwe95lhM23yw2DYtb2R/FBZ+dqSsYUqi76yDXvUZ6qqodA3Cytr1s+oEXzZF1zOUV966LP9TGk5HM8U7d6JENjEyk7tvi/nJ0p89tkky7DlNqjKh+hhMPAR1S/hqz6jmsgrKCgIf3/vrpwYiD14hw8fpri4GFmWnT9BkTbB19tvw7p1sCxIRDzSoq/EF1VFZFnm0KFDHDp0yKF7o0gPV66EnJxWDvZRySGo4DM+QlkZLFsm2o4sTjrrL+2J9uIzzuJxnzGZYcgIm/ywF6Qsrfd235i+dAjuQKWlkpTTKepf3w086jP1JIe+lTFNs35GjeAL6hdcVll66JP9jNUKB46J8UuHSOjUjKQzdqz4XbwfqpwLXH322ZT2Pzj5DZj8hdzQpH6M4JM+g4PBV3R0NB06dHDox8CHkOU62aEXMx0eOACPPiraZ798GQQGihf37PGaDU3Rs6co1WW1wtKlLRxYUiKSbYAhOdQxSj4UowSbgU8T0weis0S7uDPkpNa+JUlS+0w5bxRWdh61gq9QW1p/Q3ooOHEaSsrAz1yX3bApgjpCmFLva5P37NOK8lOiphfAoCcgeqi29ugMP0cOeuuttzxshoEmlFWImSuTSXSoXsBigRtugIoKmDIFrr8jAlZeDN9+K1aTBg/2ih3NcdVVsG2bMOWWW5o56PvvxX+gTx8YMsSr9hk4jg8vThoY1GfIDFj9FZj6wJ6dMLGXqAmGkB7+cOgH1p9cz13cHKKHfAAAhsZJREFUpbGhXsCHJYeaUV0MZSdE25UaX/YoWQ/TTokguLmVnvZASZm4DwC9uzUtN7Sn43goOSzqfXW52PP2aYUsw+ZbxApfh5Ew4EGtLdIdDgVf119/vaftMNACpb5XeIjXqhq/8QZs3AgREfDJJ7ZB8VVX1QVfzzyj6Uj5yivhwQdFwefsbIiLa+IgY1Sve4wSbAZtCpMZhoyGXRlg6gkpS2Dk1YBd0o32svKlFFYO9z3JoWYU7Re/gztDgAqrhR07iKAjvxhqasDPoaFk28JqrctuGBMFcQ5MBMSOg2P/cmnfl09x7N+QsQxMAR6TG/o6bo24KyoqKC4urvdj4EN4OdnGvn3wuK28w1tvQWKi7Y3LbNLDgwdh1y6v2NIcPXqIrHjNSg/PnDEkhz7Ajz+KfCg+VoLNwKB5YnpBB9tm1DMJkC0G1KO7jsYkmThRfIKM4gwNDfQSSo0pY9XLcdSSHCqEBNVJD5X9d+2NdAflhvbUJt3Y1GTtvjZBWQZsu1O0Bz8FUYM0NUevOB18lZaWcvvttxMXF0doaCjR0dH1fgx8CC8GXzU1MGcOVFbCtGmiXUt4uHgRnKxy7BlazHq4bJn4T/Trp7lE0qB5jMVJgzbJ4BkgHwIpEPbuAUsNYQFhDOkk5M9tPuV8VTUUKZJDY7zhMErwFTFAnfPZF1z2QNZD3VNSBuk2uWGfbo6X6YkcBH5hUHMGivd5zj6tkGXYfLMoJt3hLOh/v9YW6Rang68HHniAlStX8o9//IPAwEA++eQTnn76abp06cK//vUvT9ho4AlqasSeL/BKso1XX4UtWyAyEj76qIkBsX3Eo3HGGiXr4erVcPp0gzeNUb3uMUqwGbRZTCYYOhasJWDqIeSH1KWcX3+ijdcQUgb64aEQZEgOHUYJvtzd72WPsvJYYJMethfssxvGRjm3AmsyQ8wY0W6L9b6OLoDMH8EUCOMWiOLSBk3idPC1bNkyPvjgA2bNmoWfnx/nnHMOjz32GC+88AKff/65J2w0aAGTycTAgQOJjo7G5My+LWW/V1Cgx4sr79kDTz0l2u+8A127NnHQpZdCUBAcPgw7d6pyXZPJxODBgxk8eLBT9yYpCcaMaUJ6WFwsqvaCT4/qXfYZH8HVEmyu+kt7oK37jKto4jPRPSDGFoScSYCsvXUZD3W08uURn2kDWQ418Rm1ZYdQP+uhStJDn+hn0k+Jul5+ftDHQbmhPS7U+/KJZ1PpCdh+t2gPeRYiVVplbQWf8JkmcNrS/Px8evbsCUBERAT5+aIzPPvss1mzZo261hm0iiRJxMTEEBQUhORMJ6BIDiM9KzmsrhYSw6oqsbXruuuaOTAsDC65RLRVkh4q9yYmJsa5e0Mz0sPvvhP/kf79YaCKDzEv47LP+AiuLk664y9tnbbuM66imc8MugLkg0J+uG8/47ucBcD2U9uprKn0nh0toLrPVFbV1aX04eDL6z5TVQRlJ0VbzeALVC+4rPt+5kxpXXZDZ+SG9rgQfOn+2STLsHmeyKoZMxaS7/XapXXvM83gdPDVs2dPjh07BkBycjJf2UY6y5YtIyoqSlXjDDxIsXfqe738skjdHh0NH37YymBYR9LD2bPF7zVr4JStr2XRIvHbkBzqFiMfikG7wGSCYRNs8sPu9Dy+g44hHamyVLH91HatrfMMyuqKITl0jiLb3qLgLhAQpe65lSC4oBiq27j0UMluCOL/7Uh2w6ZQii2fOQgVuaqYpjlHPoVTv4A5yCY3NGttke5xOvi64YYb2GmThT300EO8//77BAUFcc8993D//cbmOm9jtVrJysqirKwMq9Xq2Idk2S748tzK186dInM8wLvvQufOrXzgkksgOBiOHIEdO9y+vtVq5fTp05w+fdrxe2OjWzcYO1bcqiVLgKIi+Pln8aayKcxHcclnfAR3SrC54y9tnbbsM+6gqc9EJUFsIQBSaRLjOopVDb3s+1LdZxTJYZzvrnqBBj7jCcmhQmiw+FGp4LKu+5m0TCE39PcTNb1cJbADRCSLdt5Ghz6i62dTaRpst610DXkeIvp59fK69pkWcHg33NGjR+nRowf33HNP7WsXXHABBw4cYNu2bfTu3ZshRsFZryPLMqmpqRQVFSE7ulpUViGqHZs9V1xZkRtWV8P06fCnPznwodBQEYAtXixWv9zMES7LMgcOHACgY8eOTn/+qqtETbKvvoLbI22SwwEDfFpyCC76jI/gTj4Ud/2lLdOWfcYdNPeZgZfDmv+B1I9xUle+Qz/7vlT1GXvJYaxvp5j3us94MvgCsQpUWg7Z+RAf69apdNvPFJeK1PIg9nm5u08+dhwUHxDSw66Xtnq45v1Mc8gybJwrsjd2nAD9vF/kXbc+0woOr3z16dOHnJyc2n9fffXVZGVlkZSUxMyZM10KvNasWcNll11Gly5dkCSJb775pt77kiQ1+fPqq6/WHnP55ZfTrVs3goKC6Ny5M9dddx2ZmZktXnfSpEmNznnrrbc6bb/PojzEwkM9Jp974QVISYGYGPjnP524jA6lh3/8ARX/shvVG+iSNpIPxcDAcUwmGDYRrGcYHzUREMGXLw1CHELZUxQRCkEB2tria3gj+AIoPNM2pYdWK6SKrTZ07KDOfkMX9n3pksMfQtZvYA6GMfMNuaETOBx8NezMf/zxR0pLS926eGlpKUOHDuX9999v8v1Tp07V+/nss8+QJIlZs2bVHjN58mS++uorUlNTWbJkCUeOHGG2MmpugXnz5tU79yuvvOLW/8Wn8HB9rx074LnnRPv996FTJyc+PG0ahITAsWNis5iGJCbC+PEQIRfi//sv4kUflxy2Zb7/3ijBZtAOiUqEjmcYFT4AP8lM5plMThSf0NoqdVGCL6OwsvN4OvgKsZMe5rbBml/HM4VayN9PJNlQAyX4ytsMVh8NWEuOwY6/i/bQFyGij7b2+BiaJuGfOnUqU6dObfb9+Pj4ev/+9ttvmTx5cm22RaCeDDIpKYmHHnqI6dOnU11djb9/80vDISEhjc7fbvBgso2qKrj+elH2Y9YsF1YgQkNF2vmvvhI/o0apbqMzXHUVbF//LWZLNQwaJGSHBrrEKMFm0G4ZcCkhef9jaGhftpXsZ/3xNXQb+metrVKHyqq6CUMfznKoCVWFUG5TAnky9bciPcwpgM46ksW5S3EJnLDJDfsmiQBMDSIHgH+EyA5YuBs6DFfnvN5CtsKmuVBTCh3PgX53aG2Rz+GwJynyvIaveYusrCx++OEHFi5c2Owx+fn5fP7554wfP77FwAvg888/5z//+Q/x8fFcdtllPP7444SEhDR7fGVlJZWVdSl8i4uLAaiurqa6utrJ/416WCyW2k2G1dXVmM2tLPtW1+BfLoorVwcHik1ZKvLUUyZ27zYTGyvz9ts1LtVelGbOxO+rr5C/+oqa555zeSRtsViwWCyAuDeubMa84grofbcY1RdcOIswDf/WauG0z/gAQnLoB0jMmFHtklur4S9tlbboM2qgK58ZPIGxB/uJ4GvHv5k14GrtbEE9nzGdzsUMWMNDsZgk1Z9Z3sabPiPl7cQPkIMTqJFCPHfvoiPwP56JXFBMTVm5y0GKrvoZixW/A8eQAGvHaCyRYareP3OHMZiyfsWS9QfW8EEtm6KnfgYwHf4H5qzfkc0h1Iz6CGosgEUTW3TlMzYbHMHhb4gsy8yZM4fAQJHitaKigltvvZXQ0PqrJ0vrVaVVj4ULFxIeHs7MmTMbvffggw/y3nvvUVZWxtixY/n+++9bPNef/vQnkpKS6NKlC7t27eLBBx8kNTW1RdtffPFFnn766UavL1++vMWgzdMomV4AVqxY0WqRuU5+gYwNi+WMpZqVvy5X1ZbDhyN5+WWx7+CGG7aydWvLe++awyxJXBwUhF9aGuvfeYfCPq4tZ9vfm+LiYpcK8PmXlDAFcZ9eTx/BWUoecx/GWZ/xBVatSqCqaiQJCWdIS1tJerrz51DDX9oqbdFn1EBvPtM7IAKAjfknSPlxPpk4o/lWF7V85uywWGL8AtmTlcGxEwfVNFETvOkzSdW/MAzIrurIRg8/u84N60iUXwB7Vv9BelWZS+fQUz8zICiCPkHhVFgtrDy8l+pDe1Q9f7+qDiQDmbuWsP1gy3JGPfUzIdZTTC5/AIDd5j9zbE0qkKqZPXryGYCyMsd8X5Id3Jl7ww03OHTC+fPnO3RcI0Mkia+//prp06c3+X5ycjIXXngh7777bqP3cnNzyc/PJy0tjaeffprIyEi+//57h1fmVq5cyfnnn8/hw4fp1atXk8c0tfKVmJhIbm4uERERDl3HE1gsFtauXcuRI0e49tprCQoKavF4U/opzCezxUyOWvplxF6bMWP82LdP4sorrXz+uXuzIOY//xnTV19hufderC+95NI5LBYL69atA2DChAkuzYhICxfiN28eOxnCbeN2sHq1NrM7auKsz/gCM2aY+eEHE489ZuGJJ1ybFVTDX9oqbdFn1EBvPnM8/yh9/5mMn2SmaNx/8D/7UvDTpiaWKj5TWYX/tv3IQM2oAe5nmdMB3vQZ0457MR9+D0vfu7EO9ey+dtPJLMzpp7FGhmEZ2PQ4qjX00s9IxaWY9xxGAmqSuyN3iFT/GqeX47f2UuTQXtRM29/isbrpZ2Qr5lUXYspdi7XjuVjO/QUkbYMdvfiMQnFxMbGxsRQVFbUYGzi88uVqUKUGa9euJTU1lS+//LLJ92NjY4mNjaVv377079+fxMRENm7cyLhx4xw6/5gxYwBaDL4CAwNrV/3s8ff3b1Xi6En8/PwYOHAgeXl5BAYGtm5LSTkApqgITCra/eSTsG8fxMXBBx+Y8Pd38wv5f/8HX32FefFizK+95pL00M/Pj8G2zAuBgYGuyWRtq6GLuIoNG0ycPm0iMdH50+gJp31G5xQWwq+/ivb//Z8Zf3/XHkyq+Esbpa35jFrozWd6x/UlPjSO06XZbCs7wzm7voMxjtT5UB9VfCYrDwApMgz/UO0UJmriVZ85Iwb15ujBmD39nY2PhfTTmIpKMMm4FCjrop+xWOCILWFNpxj8OrmXPr9ZOk0AJKTSI/hbCiAortlDddPPpL4DuWvBLxTTuPmYArQvdq4Ln7HD0ev7hHbk008/ZeTIkQwdOrTVYxXtp/0qVWukpKQA0LnVKsD6Q5IkOnbsSHBwcOtfSFmGM7ZkG5HqZTrcvBleflm0//lPiFWjr7r4YggLg/R0cQEXkCSJuLg44uLiXOus8vNrR/VHR4osh4sXu2SKrnDKZ3yA71Qqwea2v7Rh2prPqIXefEaSJMYlTgBgQ/FuKO8JGdpkjVXFZ7LbXpZDr/qMpzMd2hMcBGG2ADm30KVT6KKfOZYB5ZUieOztwZnWgKi6JCitpJzXRT9TfAhSHhLt4a9BWA9t7GiALnzGBTQNvkpKSkhJSakNfo4dO0ZKSgrpdhs2iouLWbRoETfddFOjz2/atIn33nuPlJQU0tLSWLlyJddccw29evWqXfXKyMggOTmZzbYB/JEjR3j22WfZtm0bx48f57vvvuMvf/kLEydObPtFokvLwWIFsxlC1FmaragQxZStVlFIecYMVU4LwcFw2WWiraSx8zbffCPSNg4dyvg5fTU1xaB57LMcGhi0d8YnjgdgQ/F6kPwg9QRUl2tslQtUVNZNFsZGaWqKT1KZDxW2TH2ezHRoj5KNMiffO9dTm8IzkJEt2n27g5+HE4L7Sr0vqwU23QCWcoi/AHrforVFPo+mwdfWrVsZPnw4w4eLNJv33nsvw4cP54knnqg95osvvkCWZa655ppGnw8JCWHp0qWcf/759OvXj7lz5zJkyBBWr15dKxGsrq4mNTW1dhNcQEAAK1asYMqUKSQnJ3Pfffcxa9Ysli1b5oX/sfrIskxOTg7l5eWtF9asre+lXnHlJ5+E/fshPh7eeUeVU9ahjKYXLRLRnZPIskx2djbZ2dmuFR21G9XPmiVu2caNuJTMQU845TM6p7AQltvyxrhbgs1tf2nDtCWfURM9+sy4BDGg21CWjmwpAHMCbPNMIqyWcNtnlNpekWEQ2HYKK3vNZ4r2id8h3cA/3HPXsce+4HKV85kBNe1nLBZIPS7a8bEQo/4+r0YowVfO+hYP07yfSX0bctaBXziM+URXtVx89dmkaZ2vSZMmtXqzbr75Zm6++eYm3xs8eDArV65s8fPdu3evd43ExERWr17tvLE6xWq1sn//fgoLC1tPP6pyfa8NG+C110T7ww8hJkaV09ahSA9PnIBNm8DBPXwKVquVffvEA+icc85xbpNqXh6sWCHaV15J584wcSKsXi2kh/fe65QpusIpn9E5334rsv+qUYLNLX9p47Qln1ETPfrMyC4j8Tf5k1WWw7HwE/Qsi4aK3nBiCySe5TU73PaZNlpY2Ws+403JoYIiPSwpEwWXuzS/j6kpNO1njmWI1dZAf+iV4J1rxopVavK3grUaTE3vF9K0nylOhV2PivaI1yE0yXvXdgBffTb5xJ4vA5WoXflyf79XeXmd3PC66+Dyy90+ZWOCgkShLfC+3u/rr8VM2PDhYEt1ryzEGdJD/WBIDg0M6hPkF8SIziMA2BAYCNIBkMxwKBOqXUsB7nXsJYdGYWXXqA2+vCQ5VKiVHhZ497ruUFjsXbmhQkRfCIgWcr6Cnd65pjNYLbBhDlgqIH4K9Gq8/cfANYzgq71QVS02kYIqK1+PPQYHD0LnzvD2226frnnclB66TBOj+pkzwWQSi3DHj3vPFIOmKShQT3JoYNCWqJUentwAI6aAtQDMXTWRH7qEMnCPCm8T6eU1QYuVL6hbqXRReuh17OWGnWPBA2nlm0UyQcxY0dbjvq8Db0DeRvCP0J3c0Ncxgq/2giI5DAlye1Zn3Tp4803R/vhjiPbkxOSUKRARARkZYsOVN8jJAUXOajeqj4+Hc88V7baQ9dDXUfKhDBkCyclaW2NgoB/GJdoFX2Fx0MU2cVXRB9K91I+6g5KwwVj1ch2tgq/gQAhXsh76wOrX0ZNQUSX2FfbUoI5MbdKNlvd9eZ2ifbDrcdEe8RaE+niNHZ1hBF/tBZUkh2VlQm4oy3DDDXDJJe6b1iJaSA8VyeHIkdCg7pshPdQPhuTQwKBplJWvnad3UlpVCv0uAmm/kB8ezobKUo0tbIHySjhjk0fGGsGXS1TmQUWWaHtbdgh1q1/ZOg++CoohM0e0+3UHPw32bHa07fvS08qXtUbIDa2V0GUa9JyjtUVtDiP4ai+oFHw98ggcPgxdu8Ibb6hglyN4W3q4aFH969qhSA+3bIFjxzxvikHTNMiHYmBgYEdiZCIJEQlYZAtbMreIF0deDNY8MHeB7V9ra2BLKKtehuTQdZRVr9Ak8FevpqfDKCuWRTqWHtbYyQ27dIToCG3siBkt5IelaVB+ShsbGrL/NcjfAv6RMPojQ27oAYzgqz1gtdbNJLqx32vNmrr9XZ98AlFR7pvmEBdeKKSHmZmw3sNL881IDhXi4mDSJNFWYjQD72NXgo2+fbW2xsBAf9Tu+zphm1EP7QhdbY/8yr6QpqOZdnvaaJZDr6KV5FAhKBDCbWMNvSbeOHoCKqsgKAB6eim7YVP4h0PkINHWw+pX4R7Y/aRoj3wHQrpqa08bxQi+fBxJkujXrx+RkZHNV/cuLRcBmJ/rxZVLS4XMEOCmm0QWeK8RGAjTp4u2E3o/SZJITk4mOTnZ8crnS5eKezVqFPRouoK7r0sPHfIZneMJyaFL/tJOaAs+4wn07DNK8LX+pN2EVd8LwbRfzLQfyYXKEo9d3yWfKa8QacqhzRZW9orPFGocfIFLBZe91s/kF8GpXNHu1x20LhHRSr0vr/Uz1mrYOAesVdD1MuhxneeupRK++mwygi8fx2Qy0alTJ0JCQjCZmvlzKsk2wl0vrvzQQ3D0KCQmwuuvu2isOyij7MWLxX4sBzCZTMTHxxMfH9/8vWmIA6N6RXq4bZu4J76GQz6jY3Jz4bffRFtNyaFL/tJO8HWf8RR69hkl6cbGkxvr19McOQ2suWDuDNs8Jz90yWfaQZZDr/iM1itfYCc9LBErTA7glX6mpgYOpol2lziI0khuaE9sy/u+vNbP7HsZ8reJ9PejP/QJuaGvPpt8x1ID11H2e0W6pv3+/Xd47z3R/vRToQD0OhdeCJGRcOqUSLfoCbKyYNUq0W5hVN+xI5x3nmgb0kPv8803jUqwGRgYNGB4/HACzYHkluVyOP9w3RshMZBgC2yq+sFxD/WnrqAEX3GG5NAt9BB82UsP9ZT18MhJm9wwEHrqRFKnrHzlbwOLY4Gq6hTsgj3PiPbIdyG4szZ2tBOM4MvHkWWZvLw8Kioq6s9u2uNGso0zZ+DGG0X7lltEDKQJAQEwY4ZoO6j3U+5NXl5e8/fGHkVyOHo0dO/e4qG+LD10yGd0jKeyHDrtL+0IX/cZT6Fnnwn0C2Rkl5GALeW8PX3OB7NNfni0ACrPqH59p32mHUgOwQs+U5EDlbYMfpH91T+/M8TZVr8czHro8X4mrwhO60huqBDeGwJjRXbBgh2N3va4z1irYeP14nfCdOj+J/Wv4SF89dlkBF8+jtVqZe/evRQUFGBtKhNgVbWoYQF1s1BO8MADoqBwUhK8+qp7trqNk9JDq9XK7t272b17d9P3piFOjOpnzBD99vbtIvujL9Gqz+iYVvKhuIXT/tKO8GWf8SR695nafV8nmthLMuISsOaAOR62fqP6tZ32GWXVKzoC/Num5BC84DO1mQ57gJ/rCbZUIda2glnsmPTQo/1MTQ0cPC7aXeOEtFUvSJJdseXG31WP+8zeF6AgBQJj4Kx/+oTcUMFXn01G8NXWUVa9QoOdrmGxYgX885+i/dlnEK51X3X++aKic1YW/PGHuuc+fRpWrxbt2bNbPTw2VpgDhvTQm7RQgs3AwKABtRkPG658AYR0gMRA0a7pD0fXetGyJjAKK6uDHiSHCkEBdRmWtc56ePiEmIwODoQeOpEb2qNVva/8HbDnOdEe9T4Ed/Lu9dspRvDV1ilyTXJYXAxz54r23/5Wt8dJU1yQHjrM0qWicvTYsWKZzwF8WXroqxiFlQ0MHEdJurEnew9nmpIW9j5PyA8Bjp+BimIvWmdHWQWUlIsZd6OwsnsowVeUDoIvqCsZoGXwlVcIWXmirSe5oT3Kvi9vBl+WKpHdUK6BxFnQzXiwegsj+GrrKJkOnazv9fe/Q3q6yLb+0ksesMtVXMh66BAujOqnTxd9eEoKHDyonikGTZOdLZK/gFFY2cDAEbqEdyEpMgmrbGVzxuamDxp1OVizwRwH2771roEK9oWV/f20saGtoKeVL6hbyXRQeqg61XbZDRM6QaTWEp5miDkLJDOUnYTSE9655t7noHCX2G921gc+JTf0dYzgqy1jtcIZJfhyfOXrl1/g449Fe/58CHMtSaJnOO886NBBjMTXrFHnnKdO1Z3LAcmhQkwMXHCBaBvSQ8/jQAk2AwODBiirX03u+wIIioRuIaJd0x+OrPKOYfYYhZXVQZb1F3wFBtSNP7RY/TqcbpMbBkF3HcoNFfxCIWqoaHtj9St/m9jrBSLwCorz/DUNajGCr7ZMSZnojP38hM7ZAYqKRBFlgDvvhHPP9aB9ruDvr770cMkScZ/GjROFzJzAkB56D0NyaGDgPC3u+1LoNQn8bPLD9HIoL/S4XbWUlUOpIjmM8t512yKVOVCZB0gQkay1NXW4UHBZFXILINt2zeTuYNb5kNdb0kNLJWy4HmQLdLsauhlSEm+jc080cAt7yaGDy8n33gsnT0Lv3vDCCx60zR2U0feSJSKDkbu4MaqfPl3Etrt2QWqq+6YYNE1WVl0+FENyaGDgOOMTxUb+jSc3YpVbyAY28gqwZIGpI2xb5iXrsMtyaEgO3UZZ9QrrCX4h2tpiT630sBQqKr1zTXu5YWK8S6V2vI63gq/dTwtfCYqDUe959loGTWIEXz6OJEn07t2biIgIpIYBlpP1vX78UWQ1lCQhNwzVOEtts0yeLDR/OTl1I/ImkCSJPn360KdPn8b3RiEjoy5zohOSQ4UOHepqn/mK9LBFn9EpTpRgcxmH/KWd4os+4w18wWeGdhpKsF8wBRUFHMxrYXNqUAR0jxBtS384vNKt6zrsM+1McuhRnynUmeRQITAAIluXHqrazxxOFwFYSBB07+LeubxFR1vwVbAdLBW1L6vqM3lbYP/Lon3WPyEo1r3zaYyvPpuM4MvHMZlMdOnShdDQUEymBn9OJ5JtFBTAvHmifffdcPbZ6tqpKv7+MHOmaLeg9zOZTHTt2pWuXbs2vjcKiuRwwgRISHDJHF+THrboMzrFG5JDh/ylneKLPuMNfMFn/M3+jOoyCmhh35dCz3Pq5IcnKqHMdZmYQz5Taic5jIly+Vq+hEd9pna/1wB1z6sGDmQ9VK2fybGTG/brATr9bjYitAcEdRLFjvO31b6sms9YKmxyQysk/QkSZ6hgtLb46rPJdyw1cI7KqrrMQg4EX/fcA5mZ0LcvPPech21TA2UUvnSpe9JDFUb1V1wh4sHdu2H/ftdNMWgaJ0uwGRgYNKB239cJB+RMo6aD5bSQH27/wbOG1SusbEgO3UZvyTbsUfbznfGw9LCqGg7Z5Ibd4p3O9KwpkuRZ6eGuJ6F4PwTFw6h31D+/gcMYwZePI8syhYWFVFZWIsty3RuK5DAspNWaFsuWwcKFYnJowQII0ZFUvFkmTRKVjnNzYdWqJg9R7k1hYWH9e6Nw8iSsWyc6vFmzXDYlOhqmTBFtX5AeNuszOkVZnHSiBJtLtOov7Rhf8xlv4Ss+o+z7ajHphkJgOPSMFrPjlv5w6DeXrumQz7TDwsoe8xk9Zjq0xwHpoSr9jCI3DA2GJB+RG9rTRPClis/kboQDr4n26A8hMMZNQ/WBrz6bjODLx7FarezatYv8/HysVrvN1EWOSQ7z8+Hmm0X7vvtEwj+fwM+vLmBqRu9ntVpJSUkhJSWl/r1RWLJE/D77bOjqXgpaX5IeNuszOsVbWQ5b9Zd2jK/5jLfwFZ9R0s3vy9lHYUVh6x/oPgECbBmETtZAWZ7T12zVZ0rLRXHldpbl0GM+U5EFVfkgmfSV6dCeVqSHbvcz2fl15+7X3XfkhvYowVfOehFQo4LP1JTbiilboft1kHC5evZqjK8+m3zQMw0cwsFkG3feKWRdycnwzDNesEtNlLR3S5dCdbXzn1dG9Sqkz7v8ciE93LtX/BioQ2YmrF0r2obk0MDANeJC4+gZ3RMZmU0nNzn2oZEzwHIKTDGw7Uf1jVJWvaIjxGSagXsoq16hPcEvWFtbmkNZ4fSE9LCqWqx6AXTrDOE+JDe0p8MokPyg4jSUpqlzzl2PQ3EqBHeGUW+rc04DtzCCr7aI1SpqfEGLwdc338Dnn9fJDYOCvGKdepx7LnTsCHl58Pvvzn32xAlYv95tyaFCVBRcdJFo+4L00FdwowSbgYGBHU5JDwECw6BXjJgtt/aHg7+qZ4ws161QxLWPLIceRwm+onQoOVQI8IfIcNFWs+CyLMMhe7lhZ/XO7W38giF6uGirse8rZx0ceEO0R38MAe1H4qtnjOCrLXLGVlzZ3w+CApo8JDcXbrlFtB94AMaM8aJ9auGA9LBZFi8Wv885B7qoowu3lx76kPRY1xiFlQ0M1MGhYssNSRpfJz/MsEJprjrGlFXUSQ5jItU5Z3tHz/u97InzQMHlnAJRUFmSINmHshs2h1pJN2rKYMMcQIaeN0DXS9y1zEAlfNxDDZrEXnLYTN2DO+6A7GwYOBCeesp7pqmOfdZDZ6SHHhjVX345BASIjIeG9NB93CzBZmBgYIcSfLVabLkhI2eCJdMmP/xZHWOUNOAdIg3JoVr4SvAVq0gPy6BcBelhveyGnUWSMV+nNvhqpTREa+x8BEoOQ3BXGPGG+3YZqIYRfLVFWqnvtXgxfPGFSIK4YAEEBnrPNNWZOBHi4kShst8czMqVlgYbN6omOVSIjISLLxZtQ3roPko+FDdKsBkYGNgY3Gkwof6hFFcWsy9nn+MfDAyF3nEgW0BOhtRf3DPEXnLYjrIcehRZ1m+B5YYE+EOUIj10c/VLluFgGtRYICxYpJZvC3QUEmEKdorVK1fIXgOptnTyYz6BgChVTDNQByP4amvIcovJNnJy4K9/Fe2HHoJRo7xomycwm+uWRRyVHiqSw3PPhXh1O2tDeqgehuTQwEA9/Ex+jO46GnCw3pc93cZC4CHRzjRBSbbrhpSWQ3lFuyqs7HHKT0F1oS3TYT+trWkdBwouO0R2PuQVCl/ypWLKrRGSCMFdQK6B/K3Of76mFDbeAMjQ6ybocrHqJhq4Rxvx1PaLJEn06NGD8PBwJEkShZWrqkVn1ES2n7/9TQRggwfD449rYLAnUEbnX38NVVW1L0uSRM+ePenZs6e4NwoeHNVfdplYSTxwAPbsUf30qtDIZ3SISiXYnKJZfzHwCZ/RAl/zGZf2fSmMmgmWk2CKhu3LWz28WZ9RBtwdIsGv5RqUbRGP+IwiOQzrDWYfyJyllBYoKROBuA2n+pnKqrrshkltRG6o0KDYstM+k/IQlBwVQdyI1z1rq8b46rPJCL58HJPJRGJiImFhYZhMpjrJYVgwmOv/eb/6Ssjh/PzagNzQnrPPFitYhYX1pIcmk4lu3brRrVs3cW8Ajh+HzZvFDNnMmaqbEhEBU6eKtl5rfjXyGR2iLE6qUILNYZr0FwPAN3xGC3zNZ5R6Xy4FX/4h0KermI2Xk2H/Ty0e3qTPyHKd1CyufUoOPeIzvrLfS6Ge9LBu9cvhfqae3DBE7PVqa9jV+3LKZ7J+h4PvifbYz8A/wrN2aoyvPpt8x1IDx2hGcpiVVSc3fOQRGDHCy3Z5Emekh8qoftIk6NTJI+YY0kP3MSSHBgbqMzZhLAAHcg+QX+7CfpvEsyDoiGif9oczp537fGm5SLJgkqBDlPPXN2gaXwu+oK7EgCvSw6w8yC+qy27oQyseDhNr2/eVu8HxgUR1CWy8UbR73wLxF3jGNgO3MYIvH0eWZc6cOUNVVRVyM/u9ZBluu02Uwxo6FB59VCNjPYlSKNlOeijLMsXFxRQXF4t7A6oWVm6OSy8Vq4oHD8KuXR67jMs08hmdkZ4OGzZ4V3IIzfiLAaB/n9EKX/OZ2JBY+sb0BUTWQ5cYqcgPo2DHimYPa9JncuyzHLY/ySF4yGd8Mfiylx6WCemhQ/1MZRUcPiHa3buIul5tkQ4jwBQAlTnIZ4445jMpD0DpcQhNguGves1ULfHVZ5MRfPk4VquVHTt2kJeXh7WmBkrKxRt2mQ7/9z8Rk/j5wcKFIh16m2PCBOjcGYqK4FdRDNRqtbJ9+3a2b9+O1WqFY8dgyxaPSQ4VwsNh2jTR1qP0sJ7PWJ1IOe0l7EuwdfaimqSRvxjUonef0Qpf9JnafV/OJt1Q8A+Gfgl18sN9PzR5WCOfqZflsP0WVlbdZ2QZimzZK/VcYLkh/v4QbZPE2fyi1X5GluHgcbBYxJ72xDaS3bApzIEQLSRKcs761n3m9Ao49A/RHvMZ+Id7yVBt8dVnkxF8tSGkknLROQX4Q6CIsE6dgttvF+8/8YRY+WqTOCI9VPK/T54s0tN7EEN66DqG5NDAwHMowdf6k27UEOo6CoJt8sOsIDhzqvXPlNhJDo3CyupRngnVRSCZIbyv1tY4h1JqwNGU86fzIL/Ylt2we9uUG9rjaLHl6mLYOFe0+/wN4s/zrF0GbmMEX20IU4mtHkREKEgSsgy33CJKYI0YIVLLt2mU0fo330BlE8UbvTiqv/RSCAqCw4chJcXjl2szpKXBpk3elxwaGLQXlKQbmzM2Y7FaXD/RiFlgSQdTJGxfCa3NOtdKDqPEZJmBOiiSw/A+YrXEl1AKLpeW10oPm6WiEo7Y5IY9urZduaE9tnpfUl4rEuHtf4eydAjtAcNe8oJhBu5iBF9tiLrgS+z3+s9/YNkysbq/YIH43aYZPx66dIHiYljeIBXykSOwbZt46M+Y4XFTwsLgkktE2yi47DgeLMFmYGAADOw4kPCAcEqqStiT7UY9DP8gkexArgH6wf4fmz/WKKzsOXxxv5eCv5+d9LCF1S8lu6EiN0zwTLIs3aGsfBXtwmwtb/qYU8vhyMeiPXY++Deu72qgP4zgqw1hOlMXfGVmwp13in8+9ZSo69XmMZnqEmk0kB5Kyqj+vPOgY0evmGNID53HkBwaGHgWs8nMmIQxgIsp5+3pMhxCbPLD7BAoymjyMKmsQqxcmEyG5FBtaoOvAdra4SqOFFw+lQsFxUKy2lazGzZFSFcISUSSrYRXH2j8flURbLLJDfveCZ3O9a59Bi5jBF9thHD/AKQai5AbhoVw882i7NWoUfDAA1pb50WUUfu330KFXfFGJfjy4qj+kksgOFgsuu3Y4bXL+iweLsFmYGBgo3bf1wk39n0pjLgSrGlgioCUVU3KD815RaIRE2lIDtWm0IdXvkBkPZSk5qWHFZVw1E5uGOIDRaTVxLb6FVG1t/F72++FspOiuPawF7xsmIE7GMFXGyE+2LbUHBbCwn+b+OEHkdVw4UKR5bDdMHYsJCTAmTO1WQ+DMzKQduzwmuRQITRU7P0CfWY91BuKPNODJdgMDAywy3jo7soXgF8A9OsFcjXQr8nsh6Z8W/BlSA7VRZah2Jbp0FeDL38/iBaZ+aTcwvrvyTKkHgeLVWyn6NoOHwy2el+RDYOvjB/h6GeAJOSGfqGNP2ugW4zgy8eRJImkpCQSIsRD7YwpjLvuEu898wwM8FElgsvYSQ9NixbRvXt3+u7cKd674AKIifGqOXqUHio+ExYWhqQj+YbWkkNJkujevTvdu3fX1X3RA3r1Ga3xVZ9Rii0fzj9MTmmO+yfsMgxCjot2ThgUnqj1mW7RsZgqq0Xf3MGQHKrqM2UnRaY7yc/3Mh3aY5MeSrkF9fuZUzlQeEb4TnL39iM3tMe28hVlSaV7UpK4L1UFsHmeeL/f3RB3tnb2aYyvPpuM4MvHMZlMJCUl0SlYzHq8syCU4mIYMwbuu09j47TCFnxJ331H906diLatgHmysHJzTJsGISGixNi2bV6/fJMoPhMeHo7JpI8u4OhR2LpVPGO9uDhZD5PJVDso0st90Qt69Bk94Ks+Ex0cTf/Y/oAbxZYbMnK2TX4YDilrMQFJSUn0ibJNeBmSQ0Bln6mX6dCHC3jGRIEkIZVVkNSxk+hnqqrhyEnxfo+uENzO5IYK0cPAHIS5poDuMdXCZ7bdI0oMhPeFoc9pbaGm+OqzyXcsNWgSS43M7jXFRJhEx/vhF6EEBorshu1KbmjPmDGQmAglJXD33SLXu8kEl13mdVNCQgzpoSN4sQSbgYEBKu/7AjD7Q/++IFeB1Bd2f4vp+Dq6B9jS7BqJNtTHlzMd2mPLemiRLazZ8R17ijeydt0iLJZqiAyDru34oWAOqC22zIE3YM8LcGwhSCYYuwD8QjQ1T2ssVgur01azpmANq9NWu1c+w4toGnytWbOGyy67jC5duiBJEt9880299yVJavLn1VdfrT3m8ssvp1u3bgQFBdG5c2euu+46MjMzW7xuRUUFf/vb34iJiSEsLIxZs2aRlZXlif+iR9n4fQFZ3+1ihN8xlIB/3bsHePXBApKTtbVNU0wmGDZMtD/6SPy2WmHkSFi61Ovm6E16KMsypaWlVFdXI+vBILSXHELdfSktLdXNfdELevQZPeDLPqPU+1Jl35dC/GAITQNALuiKOTMMf5NtxWLfVjjwk3rX8lFU9Zm2EnwBS3NW0n3j5Vyw+s88dvQlzt90I903Xs7Skg3tU26ocGIpcuEu0T78Iex6VLS7XAYdx2lnlw5Yun8p3d/uzoWfX8gbaW9w4ecX0v3t7izd7/1xnrNoGnyVlpYydOhQ3n///SbfP3XqVL2fzz77DEmSmGVXfXXy5Ml89dVXpKamsmTJEo4cOcLs2bNbvO4999zDsmXLWLRoEatXryYzM5OZPpZebeP3BYwOO0J8h+p6r3eNreZvk4+w8fsW0ra2dZYuFQXOGpKRAbNnez0AmzpVJN9IS4MtW7x66SaxWq1s27aN3NxcrK0VRvUCR47A9u1ez4fSCKvVypYtW9iyZYsu7oue0JvP6AVf9pnxiWIj/5bMLdRYa9Q7cWgEyDKS1GB4IXWA07HtPgBT1WeU4CvKt4OvpRv/xey1t3KyMrve6xmV2cz+7UaWbvyXRpZpzImlsHY21JQ0fi/jO/F+O2Xp/qXM/mo2J4tP1ns9oziD2V/N1n0ApmnwNXXqVJ577jlmNDPiio+Pr/fz7bffMnnyZHr27Fl7zD333MPYsWNJSkpi/PjxPPTQQ2zcuJHq6uomz1lUVMSnn37KG2+8wXnnncfIkSOZP38+69evZ+NGlbTvHsZSI9OtKh0QZS/sMZkAGRKr0rHU+NZMrCpYLNRmHGmIMst4993iOC8RElKneDQKLjdGuSdeLMFmYNDuSY5NJiooirLqMnZl7VLnpJYayGpmX5dkezidsh1n4B6yDEU+nukQsFhquGvVAzQ1WlFeu3v1A1jam89YLbDtLkCm2XW/bXeL49oZFquFu36+C7kJr1Feu/vnu3UtQfSZXUFZWVn88MMPLFy4sNlj8vPz+fzzzxk/fjz+/v5NHrNt2zaqq6u54IILal9LTk6mW7dubNiwgbFjxzb5ucrKSiorK2v/XVxcDEB1dXWzgZ6n2LWmhJExzV/TZIKuMdVsW13IkIntq9q5tHo1fidPNn+ALMOJE9T8/jvyud4rSDhzpsQXX/jx1Vcyzz9fo6mKwmKx1M64VldXY9Z4E/yXX/oBErNm1VBdrd2EgcViwWILyqurq31uJcOT6M1n9IKv+8zoLqNZfnQ5a4+vZXDsYLfPZzq+DrMptvkDJBNIHbEc/QNr9wluX88XUc1nStPwrylBlvypCeoOXh6HqMWafT9zsrL5bR8ycKIii1V7fmLigIu9Z5jGSNmr8StrYSyDDGUnqDn1O3Jc+yquvDptdaMVL3tkZE4Un+D3o79zbpJ3742j8YDPBF8LFy4kPDy8SXnggw8+yHvvvUdZWRljx47l+++/b/Y8p0+fJiAggKioqHqvd+rUidOnTzf7uRdffJGnn3660evLly8nJMS7Gx7PHOnKyJGtH7d/5xFOlmR43iAd0XXNGkY5cFzKTz+RUVrqcXsUZNlEUNBU0tP9ePvtDfTtq50s1Gq11u5xXLFihaYZgjIzQ0lJuQCTyUpIyHJ+/FG7AYT9fSkuLvapzEmeRk8+oyd83Wc6lIkU30u3LKV7dne3zzfYlEbPiPGtHpd2YBe79xW5fT1fRC2fiavZyjjgDJ35/edfVbTQu+wpdkxxtHHXekqO+9bkhjt0rXFwLLPxJzL8vDeW0QNrCtY4dNxPf/xE6V7v3puysjKHjvOZ4Ouzzz7j2muvJSiocbrR+++/n7lz55KWlsbTTz/NX/7yF77//ntVc/4//PDD3HvvvbX/Li4uJjExkSlTphAREaHadRxh15oS4Eirx/Uf2oshE4d63iAdIYWGwhtvtHrcsKlTGerFlS+Ar7828cUXkJk5gbvv1u4hYrFYWLt2LUeOHOGCCy5o8jvlLV56SQw8LrgA/u//LtTMDhD3Zd26dQBMmDDBWN2xQ08+oyd83WcCjgXwxf++4IR8gmnTprl9PtPxddByvisAkpKHkNiOV77U8BlT6n7YBWFdRzNtnPt/O60I22eCo60fN3bI+Ha28hUKqx0Yy4ydytB2tvIVmhbKG2mt35upZ0/1+sqXooprDZ8IvtauXUtqaipffvllk+/HxsYSGxtL37596d+/P4mJiWzcuJFx4xpngomPj6eqqorCwsJ6q19ZWVnEx8c3a0NgYCCBgYGNXvf3929W4ugphp0bReZ3/sRHV9PUpJnVCqcK/Bl2eRRmv3aWJWjyZEhIEMk1msokJUmQkIDf5Mlerzlz9dXwxRewZImZ1183N/m38wYmk6l2tlUL/7VnyRLx++qrTfj7a7tqYDKZagdC/v7+PjeQ9iR68hk94es+MyFpAhISxwqPkVeZR3xY889Ah+h5NpxcIZJrNEy4ASBbQc7D3PNCzGafGH6ojmo+c+aAOF/0YEw+/H2cNGgqkd+HUdRUUglAAhKCOjFp0NT25TOdJ0NIApRlQJM74iQIScCv82Qw+Va/4y6Te04mLCCMkqrmfEYiISKByT0nY/byvXH02egTGolPP/2UkSNHMnRo66s4in7afn+WPSNHjsTf35/ffvut9rXU1FTS09ObDNb0iNlPIj2gG0gi0LLHagUkOBHQrf0FXiACqrffBkBuuPKp/PuttzQp9nnxxRAWBidOwKZNXr+87khNhZ07RT266dO1tsbAoP0RERjBwDiRrGHDCRVSzpv9oLMMSMhyg4eT8u94WRxn4B5tJM38oYLDlFormn1fBt4695X2FXiBCKhG2sYyjVJu2P498q12F3gBbMrY1GLgBfDWxW95PfByBk2Dr5KSElJSUkhJSQHg2LFjpKSkkJ6eXntMcXExixYt4qabbmr0+U2bNvHee++RkpJCWloaK1eu5JprrqFXr161gVRGRgbJycls3rwZgMjISObOncu9997L77//zrZt27jhhhsYN25cs8k29MjYS6PZXNKL0wX1o+xTBf5sLunF2EujNbJMB8ycCYsXQ9eu9V9PSBCva1RWICgIrrhCtLUsuCxJEgkJCYSGhqoqzXUWJcvhBRdAhw6amVGLJEkkJiaSmJio6X3RI3rxGb3RFnxmfILYo6Vava/kqRCfC9b8+q9bsiH/IfBLU+c6PooqPiNboXi/aPtw8GWxWpjzzRxqrDUMix1MQmCnJo+TI0K9bJlOSJwJ5yyG4AZjmZAE8Xqib5VIUoPy6nJu+PYGAM5NOpeE8IR67ydEJLD4qsXM7K/ve6PpVMLWrVuZPHly7b+VPVXXX389CxYsAOCLL75AlmWuueaaRp8PCQlh6dKlPPnkk5SWltK5c2cuvvhiHnvssVqJYHV1NampqfU2wb355puYTCZmzZpFZWUlF110ER988IEH/6eeYeyl0Vhqoti2upD9O4/Qf2gvhl0eRdf2uOLVkJkzka64AtauhVOnoHNnOOccTVa87LnqKvj8cxF4vP46mkgPTSYTPXv25MCBA5omCNBDYWV7TCYTvXr10toMXaIXn9EbbcFnxiWO46PtH6lbbDl5KlKfGixH/yDtwC6SkodgrjkMWb/Djs3Q+WII66He9XwIVXymNB1qSsEUAOG91TFMA17f8DqbMjYRGRjJsut+pHNoPKv2/MTGXesZO2Q8K3LW8dK6l7nth9uYmDSRjqHtsBZJ4kykrldAzlooPwXBnaHjOe1yxQvgsZWPcTDvIF3Cu/D11V//f3v3Hd5U2T5w/Juku3SwS9llb7BYljIUZQ9B3EoBAQcuHLgQJ/oqIoKIKNDyvj+3IqCgUJElqzIqu+xV2jI7oSs5vz9CKki6k5xzkvtzXb1Ik5Nz7oS7T3vn3Od5CPYNZvWR1fz656/0u6mfKq2G5WFQKrzEumfKyMggJCSE9PR0l0+48W/5+fksX76c/v37y7UYGpeTAzVrQkYG/PkndFPpmnO1c2b/fmjRAry9ITUVKnvwiVq9UDtnhHMknkuk+ezm+Hn5kf5iOj4mH4ft+5qc8TLBql5wZh3U6Am3rrJ/XZgoWdIyWDsQQttAfwet0eZie8/upcPcDuSZ84gZEkN0+2jg2pyxGCx0/KIju8/sZkTLEXw3QsWWEaG6P0/8SfeY7igoLLtvGf2bWCea0dLvptLWBjLy6ZyiKOTk5FBQUIDU0deyvTc5OTmaeW+ubj1Ua8FlLeSM7bXfdpt2Ci8t5otWaCFntMgdcqZp1aZU8a9CTkEOCSkJDtvvdTljMELnGPAKhDNr4ID+uk0cwSE5o/PrvQosBYxcPJI8cx4DmgxgZLuRwPU54+vly8KhCzEZTHy/93u+2+OZxZc7jDMVlZ2Xzaglo1BQGN1+dGHhpdffTVJ86ZzFYiE+Pp6zZ8/qboFPZ7NYLGzevJnNmzdr6r2xtdl9//31E6a4ghZyRmsth6DdfNECLeSMFrlDzhgMBrrUsV4j7ZBJN66wmzOVIqD9f6y3EyZB5iGHHU8vHJIztuIruKXjAnOhDzZ8wNbTWwn1C+XzQZ8XXvtmL2duqHUDr9z8CgCPLXuM1KyiF2R2V+4wzlTUy6te5tCFQ9QJrsP0Pv9MM6/X301SfAnhYrfdBiEhcPo0bNyodjSut3cv7N5tbTm0nQUUQqinsPhy5HVfRWnyKNTsBeZLsHn0P7MgitKzFV+h+jvztSt1F1PWTAFgZt+ZhAeFl/icV7q/Qrua7Th/+TyPLntUV2c4RMWtPbaWmfEzAZg3aB4hfiEqR1RxUnwJ4WK+vv9Mra7mrIdqsbUc9ukDVy21J4RQSZe6Liy+DEbotAC8KlknEUic5fxjuhPFAun6nOkw35xP9JJo8i35DG42mAfaPlCq5/mYfIgdGouX0Yuf9v/EN7u/cXKkQiuy8rIYvXQ0AGNvGEufxn1UjsgxpPgSQgUjRlj//eEHMJvVjcXVbAWn7T0QQqgrqnYURoORE+knSMpIcv4BKzWADtOst/9+CTIOOP+Y7iL7mPWsodEHKulrps33/nyP7cnbqeJfhbkD55Zpqv32Ye2Z3H0yAI8vf5zkzGRnhSk05MXfX+TIxSPUC6nHtNunqR2Ow0jxJYQKbK2HycmwYYPa0bjOnj3WtkMfHxg8WO1ohBAAlXwq0bZmW8BFZ78AGo+DsN5gvgybR4HFwz6FKq802/VezcGon4WH/075mzfXvQnAJ/0+IaxSWJn38dJNL9EhrAMXcy7yyLJHpP3Qzf1x9A9m/zUbgPmD5xPsq+7M4o4kxZcQKvDxgTvusN72pNZD22uVlkMhtMUZk24Uy2CATvPAKwjObYTEGa45rt7pcKbDPHMe0Uusiynf0fwO7ml9T7n2423yZuHQhXgbvVmauJQvd33p4EiFVmTmZjJ6ibXd8JHIR+gd0VvliBxLii8hVGKb6c9TWg8VRZuzHAoh/im+Np5y4SxAgfXhhiszl/39CqTvd92x9UqHxdfU9VNJSEmgqn9V5gyYU6Z2w39rU7MNU3pYJ+x44tcnOJ152lFhCg15Ie4Fjqcfp0FoA96/7X21w3E4Kb50zmAwEB4eTkBAQIUGNHdke2/Cw8M1+d7ceqt1javUVFi/3nXHVStndu+2Lq7s66vNlkOt54uaZJyxz51yxjbpxvbk7eQW5FZ4f6XOmUZjoFYfsOTC5mi3bz+scM7orPjanrydd9a/A8CnAz6lZqWaRW5b2pyZdNMkImtFkpaTxrifx7l9+6E7jTOlEXc4js+2fQbAgsELCPINKnJbvf5ukuJL54xGI40bNyYkJASjUf47r2Y0GmnatClNmzbV5HtzdeuhKxdcVitnbK+xb18oZuF31Wg9X9Qk44x97pQzjSo3onpAdfLMeWxP3l7h/ZU6Z2zth94hcH4L7P+wwsfWsgrljMUMGfqZ6TDPnEf0Ymu74YiWI7irVfEtD6XNGS+jFwuHLsTH5MOyg8tY+PdCR4euKe40zpQkIzeDMUvHADDhxgn0atir2O31+rtJP5EK4YY8pfVQWg6F0DaDweDaKeevFlAHbvjIenvnZEjf69rj60X2UTDngMnPumC1xr219i12ndlF9YDqzO4/26H7blWjFW/2tE7g8fRvT3Mq45RD9y/U8eyKZzmZcZKIyhG81/s9tcNxGim+dE5RFPLy8jCbzW5/6r2sbO9NXl6eZt+bW26BKlXgzBlYt841x1QjZ3btgsREa8vhoEEuOWSZ6SFf1CLjjH3uljOF132drPh1X2XOmYhoCO8PljzYNBIsBRWOQYsqlDPpV890aHJ8cA609fRW3v3zXQDmDJhD9cDqJT6nrDnzbNdniaodRXpuOmN/HusWP4P2uNs4U5QVh1Ywb8c8AGKGxBDoE1jic/T6u0mKL52zWCxs3ryZM2fOYLFY1A5HUywWCxs3bmTjxo2afW+8vWHYMOttV816qEbO2F5b//4QVHT7tqr0kC9qkXHGPnfLmcIZD09tqvAfMmXOGYMBoj4H71C4sBX2fVCh42tVhXJGJ9d75RbkMnLxSMyKmXta38PwlsNL9byy5oyX0YvYIbH4mnz57dBvLNixoKKha5K7jTP2pOWkFbYbPtXpKbrX716q5+n1d5MUX0KozLbY8I8/QoEbfth7dcuhLKwshHbdWPtGTAYTpzNPczLjpOsDCKgNHWdab++aAmm7XB+DlqXpo/h6fc3r7D27l5qBNfmk3ydOPVaL6i14+5a3AXhmxTOcSD/h1OMJ55i4YiJJmUk0rtKYqbdOVTscp5PiSwiV9eoFVavC2bOwdq3a0Tje33/DwYPg5wcDB6odjRCiKAHeAbQPaw+4cL2vf2vwANQeBJZ82BRt/VdYZVy5Fk7DxdeWU1t4f6N1avC5A+dSNaCq04/5TOdn6FKnC5l5mTy89GFdtZ8JWHZgGTEJMRgwEDsklgDvALVDcjopvoRQmRqth66kh5ZDIYSVI6/7KheDAaLmgk9luLgd9rjvRfdlYjFDxpV10DRafOUU5BC9JBqLYuH+NvczpPkQlxzXZDQROzQWPy8/4o7E8cX2L1xyXFFxFy9fZOzPYwFrEd2tXjeVI3INKb6E0ADbDIDu1noosxwKoS+qzXh4Nf9a0PFKu9ruN+Hi3+rFohVZR67MdOgPlRqqHY1dr61+jf3n9hNWKYyZ/Wa69NhNqzZl6i3WdrVnVz7LsbRjLj2+KJ+nVzxNclYyTas2LWwf9QRSfAmhAT17QrVqcP48rF6tdjSOs2MHHD4M/v4wYIDa0QghStK1blcAdqTs4HL+ZfUCqX8v1LkDlALr4svmPPVi0YLCmQ5bgEF7f7ptPLmRaRunAfD5wM+p4l/F5TE82elJbqp3E1l5WYxZOgaLop8JGDzR0sSl/Pfv/2I0GFk4dCH+3v5qh+Qy2vsJFsIDeXnB8CsTQrlywWVns72WAQOgUiV1YxFClKx+SH3CKoVRYClgW/I29QIxGODGOeBbFS4mwB73vwi/WBqe6fBy/mVGLRmFgsLIdiMZ1Eyd9URMRhMxQ2Lw9/Lnj6N/8NnWz1SJQ5Ts/KXzjP9lPADPdXmOznU6qxyRa0nxpXMGg4GaNWvi7++PwWBQOxxNMRgMhIWFERYWpov3xtaWt2gR5DvxGnNX5YzeWg71li+uJOOMfe6YMwaDwSHXfTkkZ/xrQscri/PueQcubC93PFpR7pwpLL5aOiewCnj1j1c5cP4A4UHhzOg7o9z7cUTONK7SuHBx3hfiXuDIxSPljkcr3HGcefK3J0nJSqFFtRa80euNcu9Hr7+bpPjSOaPRSLNmzQgNDcVolP/OqxmNRpo3b07z5s118d507w41aji/9dBVObN9Oxw5AgEB1sk2tE5v+eJKMs7Y5645c/V6X+XlsJypdxfUvdNt2g/LnTMaPfP154k/+WjzRwB8MegLQv1Cy70vR+XMhKgJdK/fnez8bEYvGa379kN3G2d+2vcTX+36CqPBWDhRSnnp9XeTfiIVws1d3XroDrMe2l7DwIEQWPJC9UIIjbBd97XpZMUXW64wgwFu/BR8q1vX/dr9lrrxqMFS8M9Mh6HaKb6y87IL2w1Htx9N/yba+JTNaDASMySGQO9A1h5fy+z42WqHJK44d+kcjyx7BIBJ3SYRVTtK5YjUIcWXzimKgtlsxmKxqP9LUmNs743ZbNbNe2NbhNiZrYeuyBk9Lqysx3xxFRln7HPXnIkMj8Tb6E1qdmq5Z41zaM74Vbde/wWw9104v7Vi+1NRuXIm6zBY8sAUAIENnBpfWby86mUOXThEneA6TO8zvcL7c2TORFSO4P3brOuNTfp9EocuHKpwfGpxp3FmwvIJnMk+Q6vqrZjSY0qF96fX301SfOmcxWJhw4YNpKamYrHo+9S6o1ksFtavX8/69et1897YWg8vXoRVq5xzDFfkzNatcOyYfloOQZ/54ioyztjnrjnj5+VHh1odgPJf9+XwnKk3HOrdDYoZNo8Ec27F96mCcuVMYcuhdmY6XHtsLTPjrdPJzx88nxC/kArv09E580jHR7il4S1cLrBOCKLX9kN3GWe+3/M93+75FpPBxMKhC/H18q3wPvX6u0kbP8VCCABMJrjzTuttPbce2mIfNMhagAkh9KVrnSuth2qu9/VvHT8BvxqQvhd2va52NK6Tpq3rvbLyshi9dDQAY28Yy+2Nblc5IvuMBiPzB8+nkk8l/jzxJzO3uHbtMfGPM9lneGz5YwC8dNNLRIZHqhyRuqT4EkJjbDMD/vQT5Onw2nK9zXIohLieJhZb/je/anDjlenD970P57aoG4+raGyyjRd/f5EjF49QL6Qe026fpnY4xWoQ2oBpt1ljfGnVSxw4f0DliDyPoig8tuwxzl06R9uabZncY7LaIalOii8hNOammyAsDNLS4Pff1Y6m7OLj4cQJ6yQb/fqpHY0QojxsMx7+nfI32XnZKkdzlbp3QIP7QbFcmf0wR+2InE9DxdcfR/9g9l/WCSzmD55PsG+wyhGVbFzkOHpH9CanIIfoxdGYLWa1Q/Io3+35jh/3/YiX0YvYIbH4mHzUDkl1UnwJoTFXtx7qccFlW8yDB4O/5yxYL4RbqRtSl9pBtTErZv46/Zfa4Vwrcib4hVlnANz5mtrROJclHzITrbdVLr4yczMZvcTabvhox0fpHdFb1XhKy2AwMH/wfIJ8gth0alPh1PjC+VKyUgrbDV+9+dXCa0k9nRRfQmiQXlsPpeVQCPdx9ZTzmuJbBaI+t97eNw3Oln8xaM3LPGQtwLwCIbCeqqG8EPcCx9OP0yC0QeFMgnpRL6Re4YyMr/7xKvvP7Vc5IvenKAqPLnuUC5cv0D6sPS/f/LLaIWmGFF9CaFC3blCrFqSnQ1yc2tGU3pYtcPIkVKoEffuqHY0QoiIcsdiy09QZBA0fAhTYPAoKLqsdkXPYWg6DW6o602Hc4Tg+22a93m7B4AVU8qmkWizlNabDGPo06kOuOZeRi0dSYClQOyS39vXur1m8fzHeRm9ih8TibfJWOyTNkOJL5wwGA9WqVcPPzw+DwaB2OJpiMBioXr061atX1917YzT+sz6Wo2c9dGbO2GIdMgT8yr9ovSr0nC/OJuOMfe6eM1dPulHWNXRckjORM8A/HDIPwM5XnXMMBytzztiKLxUXV87IzWDM0jEATLhxAr0a9nLKcZydMwaDgXmD5xHiG0J8UjwfbvzQ4cdwBj2OM8mZyUxYPgGA13q8Rruwdk45jl5/N0nxpXNGo5GWLVtSuXJljEb577ya0WikVatWtGrVSpfvja34WrwYch24pI2zcsZi+ed6L70srHw1veeLM8k4Y5+750yHsA74mHw4d+lcmRepdUnO+FSGqC+st/d/BGf+dM5xHKjMOZO+1/qvitd7PbviWU5mnCSicgTv9X7PacdxRc7UCa7DjL4zAHhtzWvsObPHKcdxJL2NM4qiMP6X8VzMuUhkrUgmdZvktGPp9XeTfiIVwsN07Qrh4ZCRAStXqh1NyTZvhlOnICgI+vRROxohREX5evnSMbwjoNHWQ4Da/SFiFP+0H2poZkZHUHmmwxWHVjBvxzwMGIgdEkugT6AqcTjSyHYjGdBkAHnmPKKXREv7oYP9b+f/+PnAz/iYfIgdKu2G9kjxJYRGObP10Bn03HIohLCv8LovrU26cbUbpkNAHcg6BAludFG/Jd/aUgmqFF9pOWmF7YZPdnqSm+vf7PIYnMFgMPD5oM8J9Qtl6+mtvL9BX5OHaFlSRhJP/fYUAK/3eJ3WNVqrHJE2SfGlc2azmXXr1pGcnIzZLGtXXM1sNrNmzRrWrFmj2/fGNmPgkiWQ46DlbJyRM1e3HOp1lkN3yBdnkXHGPk/IGVvxtfFU2WYUdGnO+IRC1Dzr7QMzIXWtc49XAWXKmcyDV2Y6DIKAuq4J8CoTV0wkKTOJxlUaM/XWqU4/nitzJjwonJl9ZwLw+prX2ZW6y6nHqwi9jDOKojDul3Gk5aRxY/iNPN/teacfU6+/m6T4EkLDOneGOnUgMxNWrFA7mqJt3AinT0NwMNx+u9rRCCEcxTbpxu4zu8nMzVQ5mmKE94FGY623t4yG/Cx143GEwpbDluDiyQSWHVhGTEJMYbthgHeAS4/vCg+0fYDBzQaTb8ln5OKR5Jvz1Q5J12ITYll+cDm+Jl9ih8biZfRSOyTNkuJLCA27uvVQywsu22IbOhR8fVUNRQjhQOFB4dQPqY9FsRCfFK92OMW7YRoE1IOsI5DwotrRVFyaOtd7Xbx8kbE/WwvZiV0m0q1eN5ce31UMBgNzB86lin8VdqTs4N0/31U7JN06mX6Sp1c8DcBbvd6iZfWW6gakcVJ8CaFxV7ceXtbgUjbu0HIohCja1VPOa5p3MHSeb719cDak/KFuPBV19ZkvF3p6xdMkZyXTrGoz3ur1lkuP7WphlcKY1W8WAG+te4uElAR1A9IhRVEY+/NYMnIz6FynMxO7TFQ7JM2T4ksIjevUCerVg6wsbbYebtgAyckQEgK33aZ2NEIIRyu87utk2a77UkVYb2j8iPX2ltGQr+FWyZKoMNPh0sSl/Pfv/2I0GIkdGou/t7/Ljq2We1vfyx3N76DAUkD04mjyzHlqh6Qr83fMZ8XhFfh5+RE7JBaT0aR2SJonxZcQGmcwwJ13Wm9rcdZDW0xDh4KPj6qhCCGcwFZ8bT61GYtiUTmaUujwPgQ2gOzjsOMFtaMpH3OedcINcFnxdf7Secb/Mh6A57o8R+c6nV1yXLUZDAbmDJhDVf+q/J36N++se0ftkHTjeNpxJq6wnul655Z3aFatmcoR6YMUX0LogK2db+lSbbUems3www/W29JyKIR7ah/WHn8vfy7mXOTA+QNqh1My7yDovMB6+9BnkBynbjzlkXkAlAJrK2VAHZcc8snfniQlK4UW1VrwRq83XHJMrahZqSafDvgUgHfWv8P25O0qR6R9iqIwZukYMvMy6Va3G091ekrtkHRD1eJr3bp1DBo0iPDwcAwGA4sXL77mcYPBYPfrgw8+AODYsWOMGTOGhg0b4u/vT6NGjZgyZQp5ecWfMu7Zs+d1+3zkkUec9TKdymAwUKVKFXx9fTG4eDYkrbO9N1WqVNH9exMVZW09zM6GX3+t2L4cmTN//gkpKRAaCr17VywutblTvjiajDP2eUrOeJu8/1lsuZTrfameMzV7QZPHrbe3jIH8DNfHYEepc8bWchjsmpkOf9r3E1/t+gqTwcTCoQvx83L9Yo1q58xdre5iRMsRmBUzIxePJLcg1+Ux2KPVcWbutrmsOroKfy9/YobEqNJuqHbOlJeqxVd2djbt2rVj9uzZdh9PTk6+5mvBggUYDAaGDx8OwP79+7FYLMydO5c9e/bw0Ucf8dlnn/HyyyUvsjh27Nhr9v3++/pcZM9oNNK6dWuqVKmC0SgnMq9mNBpp27Ytbdu21f17YzD8c2apoq2HjswZWyx33KH/lkN3yhdHk3HGPk/KmbJe96WJnGn/HlSKgEsnYfuz6sTwL6XOGVvxFer8lsNzl87xyDLrB9AvdHuBG2vf6PRj2qOFnJndfzbVA6qz+8xu3lqnjclGtDjOHL14lOdWPgfAu7e+S5OqTVSJQws5Ux6qTsLfr18/+vXrV+TjYWFh13y/ZMkSevXqRUREBAB9+/alb9++hY9HRESQmJjInDlzmDZtWrHHDggIuG7/QmjZXXfBtGnw889w6RIEqLzsirQcCuE5dDPj4dW8K0HnGPi9BxyeB3WHQ3jfkp+nBS6cbGPC8gmcyT5Dq+qtmNJjitOPp2XVA6szZ8Ac7vz+Tt778z2GNBuiWjGqVRbFwpilY8jOz+bmejfzRKcn1A5Jd3SzAlpqairLli1j4cKFxW6Xnp5OlSpVStzfl19+yf/93/8RFhbGoEGDmDx5MgHF/DWbm5tLbu4/p6AzMqwtDPn5+eTnq7swn+34aschnKtdO2jQwItjxwwsXVrA8OFKuffliJxZs8bAmTNeVK6s0L17AZJ+7k3GGc/Wsaa17XDv2b2cyzxHiF9Iic/RRM5U7oKxyROYDs5C2fIwBbfvAJ9Q9eIpJa+03RiAgsBmKE58/37c9yPf7vkWk8HE/IHzMSpGVf+/tJAzg5sM5q6Wd/Hd3u8YuXgkW0ZvUaUNU6vmbJ3D6mOrCfAO4PMBn2MuMGPGrFo8WsgZm9LGoJvia+HChQQFBTFs2LAitzl06BCzZs0q8azXfffdR/369QkPD2fnzp1MmjSJxMREFi1aVORz3n33Xd544/oLUFeuXFls0eZsFouFM2fOALBixQpdnXZ1tqvfmxo1arjFe9OhQ0uOHWvCJ5+k4u+/tVz7cFTOfPZZW6AhkZEniItLKNc+tMQd88VRZJyxz9NypqZPTVLzUvlk8Sd0CO5Q7LZayhmTchM9DT9Q6XISp5fdS4Kvep/UlyZnjEo+Ay4dwgCs2ppCjnG5U2JJy0/jyf1PAjC8xnBSdqSwfIdzjlUaWsqZgcaBrPRayb5z+4iOjeah8IdUi0VL40xybjIvJFpnEH2gxgMkbkokkUTV4tFSzgBcunSpVNsZFEUp/8fnDmQwGPjpp58YOnSo3cebN2/ObbfdxqxZs+w+npSURI8ePejZsyfz5s0r07H/+OMPbr31Vg4dOkSjRo3sbmPvzFfdunU5d+4cwcHBZTqeI5nNZtavX8/hw4e5//778fOTT2dszGYzGzZsAKBbt26YTPpfe2L7dujc2ZuAAIWkpAICA8u+D0fkTEGB9SzcmTMGli0r4LbbNDGMVIg75oujyDhjn6flzMglI/l6z9e8etOrvNb9tWK31VrOGM5txLS6FwYUCm5ajFKrvypxlCpn0nbiHdcRxTuEgiFnnDLhhqIo3LPoHn5K/Ik2NdqwadQmfEzqXrirtZxZkriEET+OwGgwsu6hdUTVjlIlDq2MMxbFwm3/dxvrT66nR70erLh/BUaDusWO1nImIyODatWqkZ6eXmxtoIszX+vXrycxMZFvv/3W7uOnT5+mV69edO3alc8//7zM++/UqRNAscWXr68vvr6+193v7e2Nt7d3mY/pKEajsbDSVzsWrTEajYWDlLe3t1v8YRQVBRERcOSIgbg4b0aMKPs+HJEz69fDmTNQtSrcdpsX7pB27pgvjiLjjH2eljPd6nXj6z1fE58cX2IOaC5navWA5s/A/ul4bXsUBuwBn8ouD6NUOZNtnc7fENIKbyfNZPTt7m/5KfEnvIxeLBy6kEC/cnyS52Bay5k7W9/J/Qfu58tdX/LwsofZPm67KotOa2WcmbllJutPrifQO5CYoTH4+lz/N7GraS1nSnt8XfRIzJ8/n8jISNq1a3fdY0lJSfTs2ZPIyEhiYmLKdcoxISEBgFq1alU0VCGcymCgsOBSc8Hlq2c5VPtvKiGEa3St2xWALae26GOx5X9r+zYENYXLybDtabWjKZqTJ9tIyUrhseWPAfDqza/SoVbxLaSebGa/mYRVCmP/uf28trr4s73u7OD5g7z4+4sATLt9Gg0rN1Q5In1TtfjKysoiISGhsPg5evQoCQkJnDhxonCbjIwMvv/+ex5++OHrnm8rvOrVq8e0adM4e/YsKSkppKSkXLNN8+bNiY+PB+Dw4cO89dZbbNu2jWPHjrF06VIeeughunfvTtu2bZ37goVwANvMgsuWQVaW649fUAA//nhtLEII99emZhsCvQNJz01n39l9aodTdl7+0GUhGIxw9L9waqnaEdmXvtf6rxOKL0VReHTZo1y4fIH2Ye15+eaSl+bxZFX8q/D5QGtH1YebPiz1UgvuxGwxM2rJKC4XXKZ3RG/GR45XOyTdU7X42rp1Kx06dKBDB+unLhMnTqRDhw689to/ny588803KIrCvffee93z4+LiOHToEKtWraJOnTrUqlWr8MsmPz+fxMTEwovgfHx8+P3337n99ttp3rw5zz77LMOHD+fnn3928qsVwjE6dIBGjeDyZWsB5mpr1sC5c9aWw169XH98IYQ6vIxehdNu6/aP0GqdofmVNb/ix0PueXXjsceJa3x9vftrFu9fjLfRm4VDF+JtktaFkgxqNoiR7UaioBC9OJpL+aWbVMFdfLzlYzac3ECQTxDzBs3T1WLGWqVq8dWzZ08URbnuKzY2tnCbcePGcenSJUJCrp/WNjo62u7zr55DpEGDBiiKQs+ePQGoW7cua9eu5fz58+Tk5HDw4EHef/99VSfNEKIsHLngcnnYjjl8OHjp4qpRIYSjdK1jbT3U1Xpf/9b2TQhuDjkpsPVJtaO5ljkHsg5Zbzv4zFdyZjITlk8A4LUer9G2pnT7lNaMvjMIDwrn4IWDvPrHq2qH4zKJ5xJ55Y9XAPjw9g+pH1pf5Yjcgy6u+RLFCw0NxcdJF+XqXWhoKKGhoWqH4XC24mv5csjMLPvzy5sz+flgW5HBHVsO3TVfHEHGGfs8LWfKstiyZnPG5Aedr7QfHv8KTv7k0sMXmzMZiaBYrJOB+IU57JiKojD+l/FczLlIZK1IJnWb5LB9O5JWcybUL5QvBn0BwIzNM1h/fL1rj6/COGO2mIleEk1OQQ63N7qdh2+4/vIfLdBqzhRHii+dM5lMtG3blqpVq7r9TFtlZTKZaN++Pe3bt3e796ZdO2jSBHJy4JdfyvbciuTM6tVw/jxUrw49epTtuFrnzvlSUTLO2OeJOdO5TmcA9p/bz4XLF4rcTvM5Uy0KWlwpQP56BHLOueSwJebM1ZNtOLC96387/8fPB37Gx+RD7NBYTbYbaj1n+jfpz+j2o1FQGLVkFNl52S45rlrjzPRN09l8ajPBvsGabTfUes4URYovIXTo6tbD77933XFtx5KWQyE8U7WAajSp0gSAzac2qxxNBbWZYi1ycs7A1glqR2PlhJkOkzKSeOq3pwB4o+cbtK7R2mH79jTT+0ynTnAdDl88zEurXlI7HKfZd3Yfk1dPBmBGnxnUDamrckTuRYovIXSqoq2HZeXuLYdCiNKxTTm/6aSOr/sCMPlemf3QBCe+hRMu/CSrKIXFV0uH7E5RFMb9Mo60nDSiakfxXNfnHLJfTxXiF8K8QfMAmBU/i7XH1qockeMVWAqIXhJNrjmX/k36E90+Wu2Q3I4UXzpnNpvZtGkTqampmM1mtcPRFNuq8Bs2bHDL96ZNG2jWDHJzoSyTdZY3Z/74Ay5cgBo1oHv3cgSsce6eLxUh44x9npozXeqUfN2XbnKmSiS0vHIG46/HrGfBnKjEnElz7Jmv2IRYlh9cjq/Jl5ghMXgZtduyoJec6dO4D2NvGAvAqCWjyMpz7povrh5npm2cRnxSPCG+IXw+8HNNthva6CVn/k2KLzeQn5+PxaLDBS9dID8/n/z8fLXDcIqKLLhcnpy5epZDHbVWl4k750tFyThjnyfmjG3SjS1JWzBbiv6DRzc503oyhLaF3HPWAuyqGZOdocicKbgMWYettx1QfJ1MP8nTK54G4K1eb9GyumPOpjmTXnJm2u3TqBdSj6NpR5kU5/zJS1w1zuw+s5spa6YA1gWmawfXdvoxK0ovOXM1Kb6E0DFb+9+vv0JGhvOOk5cHP/107TGFEJ6pVfVWBPkEkZWXxe4zu9UOp+JMPtA5FgxecPJHOKHCGh4AGfsBBXyqgF/NCu1KURTG/jyWjNwMOtfpzMQuEx0TowAg2DeY+YPnA/Dp1k/54+gfKkdUcfnmfKIXR5NnzmNQ00E82PZBtUNyW1J8CaFjrVtD8+bW4mjpUucdZ9UquHgRataEm2923nGEENpnMproVKcToPP1vq5WpQO0sq5nxF+PweUU18fgwJkO5++Yz4rDK/Dz8iN2SCwmo5u2K6iod0RvHu34KACjl4wmM9cFF1870X82/Idtyduo7FeZuQPnarrdUO+k+BJCx1y14LJt33fe6b4th0KI0ivNdV+60+plqNwe8i5Yp593cvvhdRw00+HxtONMXGE90/XOLe/QrFqzikYmivD+be/TILQBx9OP83zc82qHU247U3fy5to3AZjVbxa1gmqpHJF7k+JLCJ2zFV8rVkBamuP3Ly2HQoh/sxVfG09uVDkSB7K1Hxq94dQSOPaVa4/vgOJLURTGLB1DZl4m3ep246lOTzkoOGFPJZ9KLBi8AIC52+ay8vBKlSMqu3xzPiMXjyTfks/Q5kO5r819aofk9qT4EkLnWrWCli2d13oYFwfp6VCrFnTr5vj9CyH0x7bY8qELhzibfVblaByocjto/Zr19rYn4HKy645tK75Cy198zd02l1VHV+Hv5U/MkBhpN3SBXg17MeFG6zpxDy99mPScdJUjKpup66eSkJJAVf+qfDbgM2k3dAEpvtxAUFAQ3t7aW61eC4KCgggKClI7DKcr64LLZckZ2z49oeXQU/KlPGScsc9Tc6ayf2VaVGsBFL3Ysm5zpuUk6xT0eRchfrzD2w/t5kzBJcg6ar1dzjNfRy8e5bmV1nW83uv9Hk2qNqlImKrQa8681/s9IipHcDLjJM+ufNbh+3fWOJOQksDb698GYHb/2dSsVLGJXtSgx5yR4kvnTCYTHTp0oFq1apjc/S/jMjKZTERGRhIZGen2741tyvnStB6WJWdyc2HxYuttd2859KR8KSsZZ+zz9Jwp7rovXeeM0ftK+6EPJP0MR//nsF0XmTMZ+wAFfKuBX40y79eiWBizdAzZ+dl0r9+dCVETHBazq+g5ZwJ9AokZEgNYJzv57dBvDtu3s8aZPHMeIxePpMBSwPAWw7mrlf5+yes1Z6T4EsINtGxpnfkwPx+WLHHcfm0th+Hh0LWr4/YrhNA/23pfbnXdl01oa2jzuvX2tifhUpJzj1fBxZXn/DWH1cdWE+AdwILBCzAa5M87V+tev3vhNXYPL32YtJw0dQMqwdvr3mZn6k6qBVTj0wGfSruhC8lPpxBuorwLLhfn6lkOjTJaCCGuYjvz9dfpvyiwFKgcjRO0eB6q3Aj56RA/zrmzH2bstf5bjuLr8IXDvPD7CwC83/t9GlVp5MjIRBlMvXUqjas0JikziWdWPKN2OEXadnobU9dPBeDT/p9SI7DsZ1tF+cmfUzpnNpuJj4/nzJkzmM1mtcPRFLPZzObNm9m8ebNHvDe24mvlSuuaXEUpbc7k5PxzFs3dWw7B8/KlLGScsc/Tc6ZF9RaE+IZwKf8SO1N3XvOYW+SM0Qu6xILRF04vhyOxFd5lkTlTzjNfFsXC6KWjuZR/iV4NevHojY9WOEa1uEPOBHgHEDskFgMGYhNiWXZgWYX36ehxJrcgl5GLR2JWzNzd6m5GtBpR4X2qRa85I8WXG8jJydFV0rlSTk4OOTk5aofhEi1aQJs2UFDwz3VaRSlNzqxcCRkZULs2dOniuDi1zJPypaxknLHPk3PGaDAWznq46eT11325Rc6EtIS21vWP2P40ZJ+s8C7t5kw5p5n/JP4T1h1fR6B3IPMHz9d9u6E75Ey3et14prP1rNfYn8dy8XIxn4aWkiPHmTfWvsGes3uoEViDT/p/4pB9qkmPOaPvn1IhxDUcueCybR8jRkjLoRDCvsL1vk654XVfNs2fhaqdIT8Dtjzs+PbDgmzILvtMhwfPH+TF318EYNrt02hYuaFj4xLl9vYtb9O0alOSs5J56jftrLX2V9Jf/GfDfwD4bMBnVAuopnJEnkn+pBLCjdhaD3//Hc6fL/9+Ll/2rJZDIUT52CbdsHfmy20YTdb2Q5MfpKyEw/Mcu//0fdZ//WqAX+n+GDZbzIxaMorLBZfpHdGb8ZHjHRuTqBB/b38WDl2I0WDkfzv/x5L9DpwJq5xyCnIYuXgkFsXCfW3u444Wd6gdkseS4ksIN9KsGbRrV7rWw+KsWAFZWVC3LnTq5LDwhBBuplPtThgwcDTtKKlZqWqH4zzBzaDtO9bb25+F7OOO23c5Wg4/3vIxG05uIMgniHmD5slMdRrUuU5nnutiXXdt/C/jOX+pAp+IOsCU1VPYd24fYZXCmNl3pqqxeDopvoRwM2VdcNke23Ol5VAIUZwQvxBa1bAWDfbW+3IrzZ6C6t2gIBM2j3Fc+2EZi6/Ec4m88scrAEzvM536ofUdE4dwuDd6vUGLai1IzU7liV+fUC2Ozac2M23TNADmDpxL1YCqqsUipPgSwu1UtPXw8mVYutR6W1oOhRAlKbzuyx3X+7qa0QSdYsDkD6mr4NBcx+y3sPhqWeKmZouZ6CXR5BTk0KdRH8Z0GOOYGIRT+Hn5ETs0FqPByNe7v2bRvkUuj+Fy/mWiF0djUSw82PZBBjcb7PIYxLWk+HIDAQEBeHl5qR2GJgUEBBAQEKB2GC7VpAm0bw9mM/z0k/1tisuZ336zthzWqwdRUc6LU4s8MV9KS8YZ+yRn/im+/n3myy1zJrgJtHvXenvHc5B1tMy7uC5nynDma/qm6Ww+tZlg32C+GPSF27UbumPORNWOYlK3SQA88ssjnM0+W+Z9VGScmbx6MonnE6lVqRYf9/24XPvQMj3mjBRfOmcymejYsSPVq1fHZDKpHY6mmEwmoqKiiIqK8rj3prhZD0vKmatnOXSz3+vF8uR8KYmMM/ZJzlh1rdsVgK2nt5JnzgPcPGeaPQHVb7bOUrhlDCiWUj/1upzJz/rn+rESiq99Z/cxefVkAGb0mUHdkLrlfgla5M45M6XHFFpVb8XZS2eZ8OuEMj23IuPMhhMbmL5pOgBfDPqCyv6Vy/R8rdNrzkjxJYQbsrUe/vEHnC3Dh2yXLsHPP1tvS8uhEKI0mlZtShX/KuQU5PB3yt9qh+N8BiN0jgFTAKSuhoNzyr+v9L3Wf/1qgm/R1+EUWAqIXhJNrjmX/k36E90+uvzHFC7n6+XLwqELMRlMfLfnO77fU4GLskvpUv4lopdEo6Awqv0oBjQd4PRjitKR4ksIN9S4MdxwQ/Gth/b8+itkZ0P9+nDjjc6LTwjhPgwGQ+Fiy25/3ZdNUCNob10viR0vQObh8u2nlC2H0zZOIz4pnhDfED4f+LnbtRt6gsjwSF666SUAHlv+GGeyzzj1eK+seoVDFw5RO6g20/tMd+qxRNlI8aVzZrOZrVu3cvbsWd2t8O1sZrOZ+Ph44uPjPfK9Kar1sLicsW17112e1XIIki/FkXHGPsmZf3StY209tF335RE50/QxqNETzJdg86hStR9elzOlKL52n9nNlDVTAJjZbya1g2s7InrN8YScmdxjMm1rtuXcpXM8tuwxlFLMmFmecWbd8XV8vMV6fde8wfMI9QutSNiapdeckeLLDVy6dImCggK1w9CkS5cucenSJbXDUIWt9XD1ajjzrw/Y7OVMdjb88ov1tqe2HHpyvpRExhn7JGesChdbvmrSDbfPGYMROi8Ar0A4ux4SZ5XqadfkTAnFV745n+jF0eSZ8xjUdBAPtn3QEZFrlrvnjI/Jh9ghsXgZvfhx3498u+fbUj2vLONMdl42o5aMQkHh4Q4P07dx34qErHl6zBkpvoRwUxER0LEjWCywqBSz2y5fbr3mq2FDiIx0fnxCCPcRVTsKo8HIifQTJGUkqR2O61RqCB2s6yfx90uQcbBszy+h+PrPhv+wLXkblf0qM3fgXGk3dAMdanXg1ZtfBeDx5Y+TkpXi0P2/+PuLHLl4hLrBdfmwz4cO3bdwDCm+hHBjZVlw2baNJ7YcCiEqppJPJdrUaAN4wGLL/9Z4PIT1BvNl2DIKLKVsf8rPgEsnrbdDry++dqbu5M21bwLwSf9PqBVUy1ERC5W9fPPLtA9rz4XLF3jkl0dK1X5YGquPruaTvz4BYMGQBQT7Bjtkv8KxpPgSwo3ZWg/XrIHU1KK3k5ZDIURF2aac33TSw4ovgwE6zQOvIDi7ARJLuZaSbaZD/1rgc+0U4PnmfEYuHkm+JZ+hzYdyb+t7HRy0UJO3yZuFQxfibfRmSeISvtr1VYX3mZWXxeilowEYHzme3hG9K7xP4RxSfAnhxho0sM5aWFLr4bJlcPmytVWxQweXhSeEcCNFLbbsEQLrww1XWrx2vgIZiSU+xZBxpfiy03I4df1UElISqOpflc8GfCbthm6obc22vNbjNQCe+PUJTmeertD+Xoh7gWNpx6gfUp8PbvvAESEKJ5HiSwg3V9yCyzaePMuhEMIxbJNubEveRm5BrsrRqKDRwxB2O5hzYFN0ye2H6faLr4SUBN5e/zYAs/vPpmalmk4IVmjBpG6TiKwVycWci4z/ZXy52w9/P/I7c7Za15tbMGQBQb5BjgxTOJgUX27Az89PVyt7u5Kfnx9+fn5qh6EqW+vh2rWQcuW63qtzJivLeuYLpOVQ8qVoMs7YJznzj0aVG1EtoBp55jy2p2z3vJyxtR96B8P5zbDf/tpKtpyxd+Yrz5zHyMUjKbAUcGfLO7mrlWcNyp6WM94mb2KHxuJj8uGXA7/w37//a3e74saZjNwMxiwdA8DjNz7OLQ1vcVq8WqTHnJHiS+dMJhNRUVHUqFFDd8nnbCaTic6dO9O5c2ePfm/q14dOnUBR4Mcfr8+ZX36BnBzrwszt26sdrXokX4om44x9kjPXMhgMhdd9xZ+O98ycCawLN3xkvb1z8j9nt664OmfsFV9vr3ubnak7qRZQjdn9Z3tUu6GnjjOta7Tm9R6vA/DUb09dN1toSePM8yuf50T6CRqGNuS93u+5ImTN0GvOSPElhAcorvVQWg6FEI7i0dd92USMglr9wJJ7pf3QzhpEeelw6ZT1dkhLALad3sbU9VMB+LT/p9QIrOGigIXanu/2PDeG30h6bjpjfx5b6vbDlYdX8vn2zwGIGRJDJZ9KzgxTOIgUX0J4gDvvtP67fj2cvuqa3sxM6/peIC2HQoiKsxVfG09udNj02bpjMECnL8A7BC78BfvsTH5QONNhbfAJJbcgl5GLR2JWzNzd6m5GtBrh2piFqryMXsQOjcXX5Muvh34lJiGmxOek56QXths+GfUkPRr0cHaYwkGk+NI5s9nMjh07OHfuHGZzKdcW8RBms5lt27axbds2j39v6tWDLl2srYfff28pzJmlSxVyc6FpU2jbVu0o1SX5UjQZZ+yTnLlex/COmAwmTmee5rdNv3luzgTUhsiZ1tu7Xoe03cA/OXNs55VPva60HL659k32nN1DjcAafNL/ExUCVp+njzMtq7fkrV5vAfDMimc4kX4CKHqcmbhiIqcyTtG4SmOm3jpVlZjVpteckeLLDWRmZpKfn692GJqUmZlJZmam2mFogu3M1g8/GApzZtEiU+Fj0nIo+VIcGWfsk5y5VqBPIO3D2gMQnxzv2TnT8EGoPQgsebA5GizW9yIzMxNT1n7rNiGt+CvpL97bYL1W57MBn1EtoJpKAavP08eZiV0m0rlOZzJyM3h46cOFZ4//Pc4sP7icBQkLMGAgZkgMgT6BaoWsOj3mjBRfQngIW+vhhg1w7pwvly97s3KldQiQlkMhhKPYWg/3Ze5TORKVGQwQNde6gPKFbbD3P4UPBRYcAyCnUhNGLh6JRbFwX5v7uKPFHSoFK7TAZDQROyQWPy8/4o7EMW/7vOu2uXj5ImN/HgvA052f5qZ6N7k6TFFBUnwJ4SHq1IGuXUFRDKxfX51duxqQm2ugWTNo3Vrt6IQQ7sK23teejD0qR6IB/rUgcpb19u43IW0nAIH5xwCYkriBfef2EVYpjJl9Z6oUpNCSZtWa8c4t7wAwceVEjqcdv+bxZ1Y8w+nM0zSt2pS3b3lbjRBFBXmpHYAQwnXuugs2boRly2pjNlcGrGfEpOVQCOEotjNfB7MOssm4iYgTEdza+FZMRv1MBe1QDe6Dkz/AqcUom6I5kt2R5PRzXCyADw5+BcDcgXOpGlBV5UCFVjzV6SkW7VvEhpMbGPPzGAaFDOJi/kX+/PNPFv69EKPBSOyQWAK8A9QOVZSDqme+1q1bx6BBgwgPD8dgMLB48eJrHjcYDHa/PvjAOnPQsWPHGDNmDA0bNsTf359GjRoxZcoU8vLyij1uTk4Ojz/+OFWrVqVSpUoMHz6c1NRUZ71MITQj4Mo4fexYJU6etE5jPG8eLFqkYlBCCLeyPXk7RoMRCxb+m/Ff+nzdhwYfN2DRPg8daAwGuPEzFl3yo+HfOxmzfwH3pcDj50BBoUdYKwY3G6x2lEJDTEYTMUNi8DH6sOb4Gp7d+Sxv73ubyWsmAzCo6aDCM8xCf1QtvrKzs2nXrh2zZ8+2+3hycvI1XwsWLMBgMDB8+HAA9u/fj8ViYe7cuezZs4ePPvqIzz77jJdffrnY4z7zzDP8/PPPfP/996xdu5bTp08zbNgwh78+IbRk0SIYPx7g2umfz5yxnv2SAkwIUVGL9i1ixPcjsCiWa+5Pykjizu/u9NgCbNHWD7kzKYdTdpb8Wpeyh0XrX3B9UELTdp3ZRZ7F/smEpYlLPfZnyR2o2nbYr18/+vXrV+TjYWFh13y/ZMkSevXqRUREBAB9+/alb9++hY9HRESQmJjInDlzmDZtmt19pqenM3/+fL766ituueUWAGJiYmjRogWbN2+mc+fOFX1ZLuft7Y3RKJfv2ePt7a12CJpgNsNTT1mnmodrewwVxfrB7NNPw5AhoKNF4h1O8qVoMs7YJznzD7PFzFO/PYXC9et72e4bvWQ0B84fwGjwnFyyWAp4b800O+/KP55eP50hXd7G5OXjsri0SMYZK9vPUnGe/u1phjQb4rntvFfoMWd0c81Xamoqy5YtY+HChcVul56eTpUqVYp8fNu2beTn59O7d+/C+5o3b069evXYtGlTkcVXbm4uubm5hd9nZGQAkJ+fr/oUlx07duTixYtYLBbVY9GaqKgoACwWCxaLpYSt3dfatQZOnSr6x11R4ORJWL26gB49PHRhVCRfiiPjjH2SM/9Ye3wtpzJOFbtNem46L616yUUR6YMCnMw3s2bHLLq3f1LtcFQl44xVST9LCgonM06y+shqetT37MWVtZQzpT2+boqvhQsXEhQUVGx74KFDh5g1a1aRZ70AUlJS8PHxITQ09Jr7a9asSUpKSpHPe/fdd3njjTeuu3/lypUEBGjjgse4uDi1QxAatW5dbaBjidv9+msC2dlJzg9I6JaMM6Io6y6uK9V2LQNbUtOnppOj0Y6LuQdIuFTyuLp55x9knW7sgoi0z9PHmdL+LP36569k78l2cjT6oIWcuXTpUqm2003xtWDBAu6//378/PzsPp6UlETfvn0ZMWIEY8eOdfjxX3rpJSZOnFj4fUZGBnXr1uX2228nODjY4ccri/z8fOLi4rjtttukBUbYFRhoYPr0krfr1689PXq0c35AQndknBElCTweyPTjJQ80Hw/92KM+rV+XMJPey58rcbvObW+he/v+LohIu2ScsSrtz1K/m/p51M+SPVrKGVtXXEl0UXytX7+exMREvv32W7uPnz59ml69etG1a1c+//zzYvcVFhZGXl4eaWlp15z9Sk1Nve4as6v5+vri6+t73f3e3t6q/mebzWb27dvH+fPnMRqNqieelpjNZnbt2gVAmzZtMHnwxUy9elnX+UpKsl33dS2Dwfp4r15eHnvNl+RL0WScsU9y5lq9InpRJ7gOSRlJdq/7MmCgTnAdekX08qjrVHp2eII6cZNIyjfbve7LANTxNtGzwxOYvDz3Z0vGmX/Iz1LpaC1nSnt8XVyhNn/+fCIjI2nX7vpP5JOSkujZsyeRkZHExMSUeNFdZGQk3t7erFq1qvC+xMRETpw4QZcu+py2My0trcTp9T1VWloaaWlpaoehOpMJPv7YettguHYgt63xNWOGZ0+2AZIvxZFxxj7JmX+YjCY+7msdaAz/mtjH9v2MvjM87o9Fk5cPH99s7Zz595KKtu9n3DzR4yfbABlnbORnqfT0mDOqFl9ZWVkkJCSQkJAAwNGjR0lISODEiROF22RkZPD999/z8MMPX/d8W+FVr149pk2bxtmzZ0lJSbnm2q2kpCSaN29OfHw8ACEhIYwZM4aJEyeyevVqtm3bxqhRo+jSpYsuZzoUorSGDYMffoData+9v04d6/2y2oIQoqKGtRjGD3f9QO2gaweaOsF1+OGuHxjWwjMHmmE3v88PtzxPbe9r/1iu423ih1ueZ9jN76sUmdAq+VlyX6q2HW7dupVevXoVfm+7pmrkyJHExsYC8M0336AoCvfee+91z4+Li+PQoUMcOnSIOnXqXPOYcqW3Kj8/n8TExGsugvvoo48wGo0MHz6c3Nxc+vTpw6effurolyeE5gwbBgMHWpg1K4G9ey9y993dufVWH48/4yWEcJxhLYYxsPFAZi2dxd4Te7l7wN3c2vhWj/+UftjN7zMw6g3+u+R5LuYmcUPLm+jZ7gk54yWKZPtZ+nTZp5zPO0/PyJ70bNjT43+W9E7V4qtnz56FRVJRxo0bx7hx4+w+Fh0dTXR0dLHPb9CgwXXH8PPzY/bs2UUu7iyEOzOZoH37NAIDD9G9+01SeAkhHM5kNNE+tD2BZwPpXq+7/LF4hcnLh8Y17gTg5vY3e/x1gqJktp8lgJsb3Cw/S25AF9d8CSGEEEIIIYTeSfElhBBCCCGEEC6gi6nmRfFMJhMGw7/nUBJAibNfeirJGfskX4omOWOf5EzRJGfsk5wpmuSMfZIzRdNjzkjxpXMmk4lu3bqRnp4uveP/YjKZ6N69u9phaI7kjH2SL0WTnLFPcqZokjP2Sc4UTXLGPsmZouk1Z6SUFkIIIYQQQggXkOJLCCGEEEIIIVxA2g51zmKxsHv3bi5cuIDFYlE7HE2xvTcArVu3lp7pKyRn7JN8KZrkjH2SM0WTnLFPcqZokjP2Sc4UTa85I8WXzimKwoULF8jNzS1xzTRPY3tvbLeFleSMfZIvRZOcsU9ypmiSM/ZJzhRNcsY+yZmi6TVnpHwWQgghhBBCCBeQ4ksIIYQQQgghXECKLyGEEEIIIYRwASm+hBBCCCGEEMIFpPgSQgghhBBCCBeQ2Q7LyTarSkZGhqpxmM1msrOzuXz5MhkZGeTl5akaj5bY3huw/j/pafVzZ5KcsU/ypWiSM/ZJzhRNcsY+yZmiSc7YJzlTNK3ljK0mKGnmRYOip7kZNeTUqVPUrVtX7TCEEEIIIYQQGnHy5Enq1KlT5ONSfJWTxWLh9OnTBAUFYTAYVI0lIyODunXrcvLkSYKDg1WNReiD5IwoK8kZUVaSM6KsJGdEWWkpZxRFITMzk/Dw8GIXw5a2w3IyGo3FVrVqCA4OVj3xhL5IzoiykpwRZSU5I8pKckaUlVZyJiQkpMRtZMINIYQQQgghhHABKb6EEEIIIYQQwgWk+HIDvr6+TJkyBV9fX7VDETohOSPKSnJGlJXkjCgryRlRVnrMGZlwQwghhBBCCCFcQM58CSGEEEIIIYQLSPElhBBCCCGEEC4gxZcQQgghhBBCuIAUX0IIIYQQQgjhAlJ86cTs2bNp0KABfn5+dOrUifj4+CK3jY2NxWAwXPPl5+fnwmiFFpQlZwDS0tJ4/PHHqVWrFr6+vjRt2pTly5e7KFqhBWXJmZ49e143zhgMBgYMGODCiIXayjrOzJgxg2bNmuHv70/dunV55plnyMnJcVG0QgvKkjP5+fm8+eabNGrUCD8/P9q1a8dvv/3mwmiFmtatW8egQYMIDw/HYDCwePHiEp+zZs0abrjhBnx9fWncuDGxsbFOj7PMFKF533zzjeLj46MsWLBA2bNnjzJ27FglNDRUSU1Ntbt9TEyMEhwcrCQnJxd+paSkuDhqoaay5kxubq7SsWNHpX///sqff/6pHD16VFmzZo2SkJDg4siFWsqaM+fPn79mjNm9e7diMpmUmJgY1wYuVFPWnPnyyy8VX19f5csvv1SOHj2qrFixQqlVq5byzDPPuDhyoZay5swLL7yghIeHK8uWLVMOHz6sfPrpp4qfn5+yfft2F0cu1LB8+XLllVdeURYtWqQAyk8//VTs9keOHFECAgKUiRMnKnv37lVmzZqlmEwm5bfffnNNwKUkxZcOREVFKY8//njh92azWQkPD1feffddu9vHxMQoISEhLopOaFFZc2bOnDlKRESEkpeX56oQhcaUNWf+7aOPPlKCgoKUrKwsZ4UoNKasOfP4448rt9xyyzX3TZw4UenWrZtT4xTaUdacqVWrlvLJJ59cc9+wYcOU+++/36lxCu0pTfH1wgsvKK1atbrmvrvvvlvp06ePEyMrO2k71Li8vDy2bdtG7969C+8zGo307t2bTZs2Ffm8rKws6tevT926dRkyZAh79uxxRbhCA8qTM0uXLqVLly48/vjj1KxZk9atWzN16lTMZrOrwhYqKu84c7X58+dzzz33EBgY6KwwhYaUJ2e6du3Ktm3bCtvMjhw5wvLly+nfv79LYhbqKk/O5ObmXnfZhL+/P3/++adTYxX6tGnTpmvyC6BPnz6l/j3mKlJ8ady5c+cwm83UrFnzmvtr1qxJSkqK3ec0a9aMBQsWsGTJEv7v//4Pi8VC165dOXXqlCtCFiorT84cOXKEH374AbPZzPLly5k8eTIffvghb7/9titCFiorT85cLT4+nt27d/Pwww87K0ShMeXJmfvuu48333yTm266CW9vbxo1akTPnj15+eWXXRGyUFl5cqZPnz5Mnz6dgwcPYrFYiIuLY9GiRSQnJ7siZKEzKSkpdvMrIyODy5cvqxTV9aT4ckNdunThoYceon379vTo0YNFixZRvXp15s6dq3ZoQqMsFgs1atTg888/JzIykrvvvptXXnmFzz77TO3QhA7Mnz+fNm3aEBUVpXYoQsPWrFnD1KlT+fTTT9m+fTuLFi1i2bJlvPXWW2qHJjTq448/pkmTJjRv3hwfHx8mTJjAqFGjMBrlz1ehX15qByCKV61aNUwmE6mpqdfcn5qaSlhYWKn24e3tTYcOHTh06JAzQhQaU56cqVWrFt7e3phMpsL7WrRoQUpKCnl5efj4+Dg1ZqGuiowz2dnZfPPNN7z55pvODFFoTHlyZvLkyTz44IOFZ0jbtGlDdnY248aN45VXXpE/qN1ceXKmevXqLF68mJycHM6fP094eDgvvvgiERERrghZ6ExYWJjd/AoODsbf31+lqK4nI53G+fj4EBkZyapVqwrvs1gsrFq1ii5dupRqH2azmV27dlGrVi1nhSk0pDw5061bNw4dOoTFYim878CBA9SqVUsKLw9QkXHm+++/Jzc3lwceeMDZYQoNKU/OXLp06boCy/aBj6IozgtWaEJFxhk/Pz9q165NQUEBP/74I0OGDHF2uEKHunTpck1+AcTFxZX672WXUXvGD1Gyb775RvH19VViY2OVvXv3KuPGjVNCQ0MLp49/8MEHlRdffLFw+zfeeENZsWKFcvjwYWXbtm3KPffco/j5+Sl79uxR6yUIFytrzpw4cUIJCgpSJkyYoCQmJiq//PKLUqNGDeXtt99W6yUIFytrztjcdNNNyt133+3qcIUGlDVnpkyZogQFBSlff/21cuTIEWXlypVKo0aNlLvuukutlyBcrKw5s3nzZuXHH39UDh8+rKxbt0655ZZblIYNGyoXL15U6RUIV8rMzFR27Nih7NixQwGU6dOnKzt27FCOHz+uKIqivPjii8qDDz5YuL1tqvnnn39e2bdvnzJ79myZal6U36xZs5R69eopPj4+SlRUlLJ58+bCx3r06KGMHDmy8Punn366cNuaNWsq/fv3lzUxPFBZckZRFGXjxo1Kp06dFF9fXyUiIkJ55513lIKCAhdHLdRU1pzZv3+/AigrV650caRCK8qSM/n5+crrr7+uNGrUSPHz81Pq1q2rPPbYY/KHtIcpS86sWbNGadGiheLr66tUrVpVefDBB5WkpCQVohZqWL16tQJc92XLkZEjRyo9evS47jnt27dXfHx8lIiICE2uPWlQFDnXL4QQQgghhBDOJtd8CSGEEEIIIYQLSPElhBBCCCGEEC4gxZcQQgghhBBCuIAUX0IIIYQQQgjhAlJ8CSGEEEIIIYQLSPElhBBCCCGEEC4gxZcQQgghhBBCuIAUX0IIIUQJ1qxZg8FgIC0tTe1QhBBC6JgUX0IIIYTGXbhwgfvvv5/g4GBCQ0MZM2YMWVlZaoclhBCijKT4EkIIITTu/vvvZ8+ePcTFxfHLL7+wbt06xo0bp3ZYQgghykiKLyGEEG6hZ8+eTJgwgQkTJhASEkK1atWYPHkyiqKU6vm5ublMmjSJunXr4uvrS+PGjZk/f77dbc+fP8+9995L7dq1CQgIoE2bNnz99dfXbPPDDz/Qpk0b/P39qVq1Kr179yY7OxuwtjFGRUURGBhIaGgo3bp14/jx43aPtW/fPn777TfmzZtHp06duOmmm5g1axbffPMNp0+fLsM7JIQQQm1SfAkhhHAbCxcuxMvLi/j4eD7++GOmT5/OvHnzSvXchx56iK+//pqZM2eyb98+5s6dS6VKlexum5OTQ2RkJMuWLWP37t2MGzeOBx98kPj4eACSk5O59957GT16NPv27WPNmjUMGzYMRVEoKChg6NCh9OjRg507d7Jp0ybGjRuHwWCwe6xNmzYRGhpKx44dC+/r3bs3RqORLVu2lPEdEkIIoSYvtQMQQgghHKVu3bp89NFHGAwGmjVrxq5du/joo48YO3Zssc87cOAA3333HXFxcfTu3RuAiIiIIrevXbs2zz33XOH3TzzxBCtWrOC7774jKiqK5ORkCgoKGDZsGPXr1wegTZs2gPX6rfT0dAYOHEijRo0AaNGiRZHHSklJoUaNGtfc5+XlRZUqVUhJSSn2dQkhhNAWOfMlhBDCbXTu3PmaM0hdunTh4MGDmM3mYp+XkJCAyWSiR48epTqO2Wzmrbfeok2bNlSpUoVKlSqxYsUKTpw4AUC7du249dZbadOmDSNGjOCLL77g4sWLAFSpUoXo6Gj69OnDoEGD+Pjjj0lOTi7nKxZCCKEnUnwJIYTweP7+/mXa/oMPPuDjjz9m0qRJrF69moSEBPr06UNeXh4AJpOJuLg4fv31V1q2bMmsWbNo1qwZR48eBSAmJoZNmzbRtWtXvv32W5o2bcrmzZvtHissLIwzZ85cc19BQQEXLlwgLCysHK9WCCGEWqT4EkII4Tb+fQ3U5s2badKkCSaTqdjntWnTBovFwtq1a0t1nA0bNjBkyBAeeOAB2rVrR0REBAcOHLhmG4PBQLdu3XjjjTfYsWMHPj4+/PTTT4WPd+jQgZdeeomNGzfSunVrvvrqK7vH6tKlC2lpaWzbtq3wvj/++AOLxUKnTp1KFa8QQghtkOJLCCGE2zhx4gQTJ04kMTGRr7/+mlmzZvHUU0+V+LwGDRowcuRIRo8ezeLFizl69Chr1qzhu+++s7t9kyZNiIuLY+PGjezbt4/x48eTmppa+PiWLVuYOnUqW7du5cSJEyxatIizZ8/SokULjh49yksvvcSmTZs4fvw4K1eu5ODBg0Ve99WiRQv69u3L2LFjiY+PZ8OGDUyYMIF77rmH8PDw8r1RQgghVCETbgghhHAbDz30EJcvXyYqKgqTycRTTz1V6vWw5syZw8svv8xjjz3G+fPnqVevHi+//LLdbV999VWOHDlCnz59CAgIYNy4cQwdOpT09HQAgoODWbduHTNmzCAjI4P69evz4Ycf0q9fP1JTU9m/fz8LFy7k/Pnz1KpVi8cff5zx48cXGduXX37JhAkTuPXWWzEajQwfPpyZM2eW/Q0SQgihKoNS2gVQhBBCCA3r2bMn7du3Z8aMGWqHIoQQQtglbYdCCCGEEEII4QJSfAkhhHB769evp1KlSkV+CSGEEK4gbYdCCCHc3uXLl0lKSiry8caNG7swGiGEEJ5Kii8hhBBCCCGEcAFpOxRCCCGEEEIIF5DiSwghhBBCCCFcQIovIYQQQgghhHABKb6EEEIIIYQQwgWk+BJCCCGEEEIIF5DiSwghhBBCCCFcQIovIYQQQgghhHABKb6EEEIIIYQQwgX+H/9FrSp1b3qcAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"false_negatives_K_compas.json\"\n",
    "\n",
    "# Caricare i dati dal file JSON\n",
    "with open(json_filename, \"r\") as f:\n",
    "    false_negatives_data = json.load(f)\n",
    "\n",
    "# Estrarre parametri dal JSON\n",
    "run6_params = false_negatives_data.get(\"run6_parameters\", {})\n",
    "min_sup = run6_params.get(\"min_sup\", \"N/A\")\n",
    "percentage = run6_params.get(\"percentage\", \"N/A\")\n",
    "th_redundancy = run6_params.get(\"th_redundancy\", \"N/A\")\n",
    "L = run6_params.get(\"L\", \"N/A\")\n",
    "K = int((percentage / 100) * L)  # K rappresenta il numero di sottogruppi\n",
    "\n",
    "# Lista dei valori di p da 0.5 a 1.0 con step 0.05\n",
    "p_values = np.arange(0.5, 1.05, 0.05)\n",
    "\n",
    "# Definiamo i colori per ogni N\n",
    "colors = [\"blue\", \"red\", \"orange\", \"pink\", \"green\"]\n",
    "labels = [f\"N={n}K\" for n in range(500, 2501, 500)]\n",
    "\n",
    "# Creazione della figura\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig.suptitle(\"FALSE NEGATIVE MITIGATION\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Disegniamo la linea tratteggiata \"Before Mitigation\"\n",
    "before_mitigation = false_negatives_data.get(\"N=500_run6\", {}).get(\"Before Mitigation\", None)\n",
    "if before_mitigation is not None:\n",
    "    ax.axhline(y=before_mitigation, color=\"purple\", linestyle=\"--\", linewidth=2, label=\"Before Mitigation\")\n",
    "\n",
    "# Aggiungere linee verticali per ogni valore di p\n",
    "for p in p_values:\n",
    "    ax.axvline(x=p, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Inizializziamo la lista per la legenda\n",
    "legend_handles = []\n",
    "\n",
    "# Loop sui vari N (da 500 a 2500)\n",
    "for i, n in enumerate(range(500, 2501, 500)):  # da 500 a 2500 con passo 500\n",
    "    N_key = f\"N={n}_run6\"\n",
    "    if N_key not in false_negatives_data:\n",
    "        continue\n",
    "    \n",
    "    data = false_negatives_data[N_key]\n",
    "    \n",
    "    # Estrarre i valori di falsi positivi per ogni p\n",
    "    false_negatives = [\n",
    "        data.get(f\"After SMOTE N = {n} p_class 1 = {round(p, 2)}\", None) \n",
    "        for p in p_values\n",
    "    ]\n",
    "    \n",
    "    # Filtriamo solo i valori validi\n",
    "    p_values_filtered = [p for j, p in enumerate(p_values) if false_negatives[j] is not None]\n",
    "    false_negatives_filtered = [fp for fp in false_negatives if fp is not None]\n",
    "    \n",
    "    # Se ci sono dati validi, plottiamo la linea\n",
    "    if false_negatives_filtered:\n",
    "        line, = ax.plot(\n",
    "            p_values_filtered, false_negatives_filtered, \n",
    "            marker=\"o\", linestyle=\"-\", color=colors[i], label=labels[i]\n",
    "        )\n",
    "        legend_handles.append(line)\n",
    "\n",
    "# Impostazioni asse\n",
    "ax.set_title(f\"Minsup = {min_sup}, pruning = {th_redundancy}, K% = {percentage}, subgroups: {K}/{L}\")\n",
    "ax.set_xlabel(\"p_class 0\")\n",
    "ax.set_ylabel(\"False Negatives\")\n",
    "ax.grid()\n",
    "\n",
    "# Aggiungere la leggenda\n",
    "#ax.legend(handles=legend_handles, loc=\"upper right\", fontsize=10, frameon=True, title=\"Legend\")\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
