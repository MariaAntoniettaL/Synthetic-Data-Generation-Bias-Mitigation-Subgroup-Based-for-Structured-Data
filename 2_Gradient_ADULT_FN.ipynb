{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_for_adult import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import torch\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "\n",
    "from divexplorer.outcomes import get_false_negative_rate_outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv(\"adult.data\", header = None, names = col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = 0.2\n",
    "percentage =  10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosità precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GDecisioN tree predictions\n",
    "X_train = df_train_enc.drop(columns = 'income', axis = 1)\n",
    "y_train = df_train_enc['income']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'income', axis = 1)\n",
    "y_test = df_test_enc['income']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'income', axis = 1)\n",
    "y_val = df_val_enc['income']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'income', axis = 1)\n",
    "y_holdout = df_holdout_enc['income']\n",
    "\n",
    "classifier_train = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.865     0.681                0.050   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.402              247              630   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       6508  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione è giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>2</td>\n",
       "      <td>0.077</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0</td>\n",
       "      <td>0.284</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass  fnlwgt  education  marital-status  occupation  relationship  \\\n",
       "18761          2   0.077          3               0           4             1   \n",
       "27582          3   0.048          3               1           4             0   \n",
       "30911          2   0.174          3               3           4             4   \n",
       "11128          0   0.012          2               1           2             0   \n",
       "683            0   0.284          3               3           2             4   \n",
       "\n",
       "       race  sex  capital-gain  capital-loss  native-country  age_group  \\\n",
       "18761     4    0         0.000         0.000               5          2   \n",
       "27582     4    1         0.000         0.000               5          5   \n",
       "30911     2    0         0.039         0.000               5          1   \n",
       "11128     2    1         0.000         0.507               5          3   \n",
       "683       2    1         0.000         0.000               5          0   \n",
       "\n",
       "       edu_num_group  hours_per_week_group  y_val_true  y_pred  \n",
       "18761              1                     1           0       0  \n",
       "27582              1                     2           1       0  \n",
       "30911              1                     1           0       0  \n",
       "11128              4                     1           1       1  \n",
       "683                1                     1           0       0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set\n",
    "y_pred_val_dt = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val_dt\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>fn</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.077</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>Self-emp</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>65-100</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.174</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.012</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>45-54</td>\n",
       "      <td>14 Master's Degree</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.284</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        workclass  fnlwgt        education marital-status    occupation  \\\n",
       "18761     Private   0.077    Non Graduated       Divorced  Self-emp-occ   \n",
       "27582    Self-emp   0.048    Non Graduated        Married  Self-emp-occ   \n",
       "30911     Private   0.174    Non Graduated      Separated  Self-emp-occ   \n",
       "11128  Government   0.012  Master's Degree        Married   Private-occ   \n",
       "683    Government   0.284    Non Graduated      Separated   Private-occ   \n",
       "\n",
       "         relationship    race      sex  capital-gain  capital-loss  \\\n",
       "18761   Not-in-family   White   Female         0.000         0.000   \n",
       "27582         Husband   White     Male         0.000         0.000   \n",
       "30911       Unmarried   Black   Female         0.039         0.000   \n",
       "11128         Husband   Black     Male         0.000         0.507   \n",
       "683         Unmarried   Black     Male         0.000         0.000   \n",
       "\n",
       "      native-country  income age_group       edu_num_group  \\\n",
       "18761  United-States       0     35-44          10 College   \n",
       "27582  United-States       1    65-100          10 College   \n",
       "30911  United-States       0     25-34          10 College   \n",
       "11128  United-States       1     45-54  14 Master's Degree   \n",
       "683    United-States       0     17-24          10 College   \n",
       "\n",
       "      hours_per_week_group    fn  y_pred  accuracy  \n",
       "18761             Overtime   NaN       0         1  \n",
       "27582            Part-time 1.000       0         0  \n",
       "30911             Overtime   NaN       0         1  \n",
       "11128             Overtime 0.000       1         1  \n",
       "683               Overtime   NaN       0         1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]\n",
    "\n",
    "df_val_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_val['fn'] = df_val_class['fn']\n",
    "\n",
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione è giusta 0 se la predizione è sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['accuracy'] = (df_val_class['y_val_true']==df_val_class['y_pred']).astype(int)\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_div</th>\n",
       "      <th>fn_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217</td>\n",
       "      <td>(capital-loss=0.0, workclass=Private, capital-gain=0.0, edu_num_group=9 High School Graduate)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>44.520</td>\n",
       "      <td>4</td>\n",
       "      <td>1413.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.217</td>\n",
       "      <td>(edu_num_group=9 High School Graduate, capital-gain=0.0, education=Non Graduated, capital-loss=0.0, workclass=Private)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>44.520</td>\n",
       "      <td>5</td>\n",
       "      <td>1413.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.208</td>\n",
       "      <td>(capital-loss=0.0, capital-gain=0.0, sex= Female, education=Non Graduated)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>30.076</td>\n",
       "      <td>4</td>\n",
       "      <td>1354.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.214</td>\n",
       "      <td>(capital-loss=0.0, capital-gain=0.0, education=Non Graduated, marital-status=Never-married)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>5.568</td>\n",
       "      <td>4</td>\n",
       "      <td>1390.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.288</td>\n",
       "      <td>(capital-loss=0.0, capital-gain=0.0, edu_num_group=9 High School Graduate)</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.605</td>\n",
       "      <td>44.591</td>\n",
       "      <td>3</td>\n",
       "      <td>1872.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.217   \n",
       "1    0.217   \n",
       "2    0.208   \n",
       "3    0.214   \n",
       "4    0.288   \n",
       "\n",
       "                                                                                                                  itemset  \\\n",
       "0                           (capital-loss=0.0, workclass=Private, capital-gain=0.0, edu_num_group=9 High School Graduate)   \n",
       "1  (edu_num_group=9 High School Graduate, capital-gain=0.0, education=Non Graduated, capital-loss=0.0, workclass=Private)   \n",
       "2                                              (capital-loss=0.0, capital-gain=0.0, sex= Female, education=Non Graduated)   \n",
       "3                             (capital-loss=0.0, capital-gain=0.0, education=Non Graduated, marital-status=Never-married)   \n",
       "4                                              (capital-loss=0.0, capital-gain=0.0, edu_num_group=9 High School Graduate)   \n",
       "\n",
       "     fn  fn_div   fn_t  length  support_count  \n",
       "0 1.000   0.608 44.520       4       1413.000  \n",
       "1 1.000   0.608 44.520       5       1413.000  \n",
       "2 1.000   0.608 30.076       4       1354.000  \n",
       "3 1.000   0.608  5.568       4       1390.000  \n",
       "4 0.996   0.605 44.591       3       1872.000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_diver = DivergenceExplorer(df_val)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_div</th>\n",
       "      <th>fn_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.288</td>\n",
       "      <td>(capital-loss=0.0, capital-gain=0.0, edu_num_group=9 High School Graduate)</td>\n",
       "      <td>3</td>\n",
       "      <td>1872.000</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.605</td>\n",
       "      <td>44.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.300</td>\n",
       "      <td>(capital-loss=0.0, capital-gain=0.0, marital-status=Never-married)</td>\n",
       "      <td>3</td>\n",
       "      <td>1952.000</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.589</td>\n",
       "      <td>20.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.232</td>\n",
       "      <td>(capital-loss=0.0, capital-gain=0.0, relationship= Not-in-family)</td>\n",
       "      <td>3</td>\n",
       "      <td>1512.000</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.578</td>\n",
       "      <td>25.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.215</td>\n",
       "      <td>(capital-gain=0.0, sex= Female, education=Non Graduated)</td>\n",
       "      <td>3</td>\n",
       "      <td>1398.000</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.563</td>\n",
       "      <td>17.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.243</td>\n",
       "      <td>(capital-gain=0.0, relationship= Not-in-family)</td>\n",
       "      <td>2</td>\n",
       "      <td>1581.000</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.528</td>\n",
       "      <td>17.881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support  \\\n",
       "4     0.288   \n",
       "16    0.300   \n",
       "22    0.232   \n",
       "24    0.215   \n",
       "33    0.243   \n",
       "\n",
       "                                                                       itemset  \\\n",
       "4   (capital-loss=0.0, capital-gain=0.0, edu_num_group=9 High School Graduate)   \n",
       "16          (capital-loss=0.0, capital-gain=0.0, marital-status=Never-married)   \n",
       "22           (capital-loss=0.0, capital-gain=0.0, relationship= Not-in-family)   \n",
       "24                    (capital-gain=0.0, sex= Female, education=Non Graduated)   \n",
       "33                             (capital-gain=0.0, relationship= Not-in-family)   \n",
       "\n",
       "    length  support_count    fn  fn_div   fn_t  \n",
       "4        3       1872.000 0.996   0.605 44.591  \n",
       "16       3       1952.000 0.981   0.589 20.195  \n",
       "22       3       1512.000 0.970   0.578 25.016  \n",
       "24       3       1398.000 0.955   0.563 17.789  \n",
       "33       2       1581.000 0.920   0.528 17.881  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 44\n",
      "total problematic 36\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_fp)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_fp[(df_pruned_fp['fn_div'] > 0) & (df_pruned_fp['fn_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (893, 7)\n",
      "Dim pruned th_redundancy  (44, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_fp.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset3 li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prima 3718\n",
      "dopo 361\n"
     ]
    }
   ],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "print('prima', len(df_holdout_filtered))\n",
    "df_holdout_filtered_solo1 = df_holdout_filtered[df_holdout_filtered['income']==1]\n",
    "\n",
    "\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered_solo1, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "df_holdout_filtered = df_holdout_filtered_solo1 \n",
    "\n",
    "print(\"dopo\", len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "TRAIN SET MITIGATED ROWS:  13375\n",
      "VALIDATION SET ROWS:  6508\n",
      "FILTERED DF holdout ROWS:  361\n",
      "TEST SET FILTERED ROWS:  6507\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'income', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['income']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361\n",
      "verifica : 361\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['income']\n",
    "\n",
    "classifier_train_mitigated_random = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Gradient Boosting performance when boolean outcomes = fn \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.381</td>\n",
       "      <td>278</td>\n",
       "      <td>598</td>\n",
       "      <td>13375</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.396</td>\n",
       "      <td>246</td>\n",
       "      <td>621</td>\n",
       "      <td>13375</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.865     0.681                0.050   \n",
       "After Mitigation(K=5, fp)     0.865     0.689                0.056   \n",
       "After RANDOM mitigation       0.867     0.686                0.050   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.402              247   \n",
       "After Mitigation(K=5, fp)                0.381              278   \n",
       "After RANDOM mitigation                  0.396              246   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      630       13014       6508  \n",
       "After Mitigation(K=5, fp)              598       13375       6508  \n",
       "After RANDOM mitigation                621       13375       6508  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "print(\"Overall Gradient Boosting performance when boolean outcomes = fn \")\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1</td>\n",
       "      <td>322</td>\n",
       "      <td>13014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.910</td>\n",
       "      <td>33</td>\n",
       "      <td>294</td>\n",
       "      <td>13375</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1</td>\n",
       "      <td>322</td>\n",
       "      <td>13375</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                         Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                    0.912     0.006   \n",
       "After Mitigation(K=5, on subgroups, fp)            0.911     0.151   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)     0.912     0.006   \n",
       "\n",
       "Metrics                                         False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                               0.000   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.010   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.000   \n",
       "\n",
       "Metrics                                         False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                               0.997   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.910   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.997   \n",
       "\n",
       "Metrics                                         False Positives  \\\n",
       "Before Mitigation, on subgroups                               1   \n",
       "After Mitigation(K=5, on subgroups, fp)                      33   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                1   \n",
       "\n",
       "Metrics                                         False Negatives  Train Size  \\\n",
       "Before Mitigation, on subgroups                             322       13014   \n",
       "After Mitigation(K=5, on subgroups, fp)                     294       13375   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              322       13375   \n",
       "\n",
       "Metrics                                         Test Size  \n",
       "Before Mitigation, on subgroups                      3682  \n",
       "After Mitigation(K=5, on subgroups, fp)              3682  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)       3682  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered_fp = K_subgroups_dataset_and_or(df_pruned_fp, df_test, K)\n",
    "inutile, df_test_filtered_enc_fp, inutile2, inutile3 = encoding_funct(df_train, df_test_filtered_fp, df_holdout, df_val)\n",
    "\n",
    "X_test_filtered_fp = df_test_filtered_enc_fp.drop(columns='income', axis = 1)\n",
    "y_true_test_filtered_fp = df_test_filtered_enc_fp['income']\n",
    "\n",
    "y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after = classifier_train_mitigated.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_random = classifier_train_mitigated_random.predict(X_test_filtered_fp)\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after )\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_random)\n",
    "\n",
    "\n",
    "metrics_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after, len(y_train_mitigated), len(y_pred_test_filtered_fp_after)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(y_train_mitigated_random), len(y_pred_test_filtered_fp_after_random)]\n",
    "})\n",
    "metrics_after_fp_sottogruppi = metrics_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi[metric] = metrics_after_fp_sottogruppi[metric].astype(int)\n",
    "\n",
    "metrics_after_fp\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fn\")\n",
    "metrics_after_fp_sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values([\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fn_div_list_no_mitigation  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fn_div_list_no_mitigation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fn_div_list_baseline1  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fn_div_list_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values([\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fn_div_list_random_per_confrontare_con_baseline1  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fn_div_list_random_per_confrontare_con_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.358</td>\n",
       "      <td>361.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.319</td>\n",
       "      <td>361.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.865     0.681             0.281   \n",
       "After Mitigation(K=5 fp)            0.865     0.689             0.297   \n",
       "After RANDOM Mitigation(K=5 fp)     0.867     0.686             0.279   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.598               0.547   \n",
       "After Mitigation(K=5 fp)           0.605               0.540   \n",
       "After RANDOM Mitigation(K=5 fp)    0.604               0.549   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.475               0.336   \n",
       "After Mitigation(K=5 fp)                      0.479               0.358   \n",
       "After RANDOM Mitigation(K=5 fp)               0.473               0.319   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)               361.000  \n",
       "After RANDOM Mitigation(K=5 fp)        361.000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fn_div_list_no_mitigation = np.nanmean(fn_div_list_no_mitigation)\n",
    "media_fn_div_list_nomitigation_primi10 = np.nanmean(fn_div_list_no_mitigation[:10])\n",
    "media_fn_div_list_nomitigation_primi20 = np.nanmean(fn_div_list_no_mitigation[:20])\n",
    "media_fn_div_list_nomitigation_primi40 = np.nanmean(fn_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fn_div_no_mitigation = max(abs(x) for x in fn_div_list_no_mitigation)\n",
    "\n",
    "media_fn_div_list_baseline1 = np.nanmean(fn_div_list_baseline1)\n",
    "media_fn_div_list_baseline1_primi10 = np.nanmean(fn_div_list_baseline1[:10])\n",
    "media_fn_div_list_baseline1_primi20 = np.nanmean(fn_div_list_baseline1[:20])\n",
    "media_fn_div_list_baseline1_primi40 = np.nanmean(fn_div_list_baseline1[:40])\n",
    "fn_div_massimo_valore_assoluto_fn_div_baseline1 = max(abs(x) for x in fn_div_list_baseline1)\n",
    "\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fn_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fn_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fn_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fn_div_list_no_mitigation, massimo_valore_assoluto_fn_div_no_mitigation,\n",
    "        media_fn_div_list_nomitigation_primi10, media_fn_div_list_nomitigation_primi20, media_fn_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_fn_div_list_baseline1, fn_div_massimo_valore_assoluto_fn_div_baseline1,\n",
    "        media_fn_div_list_baseline1_primi10, media_fn_div_list_baseline1_primi20, media_fn_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fn_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fn_div_random_per_confrontare_con_baseline1, media_fn_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fn_div_list_random_per_confrontare_con_baseline1_primi20, media_fn_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fn_sottogruppi = divergence_after_fn_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fn_sottogruppi\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUI INIZIA SMOTE come si deve DA METTERE NEL REPORT\n",
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p è la probabilità che il campione simulato sia di classe 0 qui (perchè voglio diminuire il numero di falsi negativi)\n",
    "- FISSO p VARIA N , aumento il numero di 0 per diminuire il numero di falsi negativi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 3435\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['fn', 'y_pred', 'accuracy', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 3070)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered['income'].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUI MODIFICO FACENDO SMOTE SU DF_VAL_FILTERED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smote_nc = SMOTENC(categorical_features=categorical_features,random_state=seed)\\nX_to_SMOTE, y_to_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\ncount_1 = y_to_SMOTE.sum()\\ncount_0 = len(y_to_SMOTE)-count_1\\ncount_0, count_1'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''smote_nc = SMOTENC(categorical_features=categorical_features,random_state=seed)\n",
    "X_to_SMOTE, y_to_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "count_1 = y_to_SMOTE.sum()\n",
    "count_0 = len(y_to_SMOTE)-count_1\n",
    "count_0, count_1'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.396</td>\n",
       "      <td>246</td>\n",
       "      <td>621</td>\n",
       "      <td>13375</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.393</td>\n",
       "      <td>256</td>\n",
       "      <td>616</td>\n",
       "      <td>13375</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.399</td>\n",
       "      <td>249</td>\n",
       "      <td>626</td>\n",
       "      <td>13375</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.398</td>\n",
       "      <td>250</td>\n",
       "      <td>624</td>\n",
       "      <td>13375</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.402</td>\n",
       "      <td>250</td>\n",
       "      <td>631</td>\n",
       "      <td>13375</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.405</td>\n",
       "      <td>249</td>\n",
       "      <td>635</td>\n",
       "      <td>13375</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.396</td>\n",
       "      <td>254</td>\n",
       "      <td>621</td>\n",
       "      <td>13375</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.867     0.686                0.050   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.866     0.686                0.052   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.866     0.683                0.050   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.866     0.684                0.051   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.865     0.680                0.051   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.864     0.679                0.050   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.866     0.684                0.051   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.396              246   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.393              256   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.399              249   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.398              250   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.402              250   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.405              249   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.396              254   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  621       13375       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              616       13375       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              626       13375       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              624       13375       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              631       13375       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              635       13375       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                621       13375       6508  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + int(N*0.5), 0: count_0 + int(N*0.5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + int(N*0.6), 1: count_1 + int(N*0.4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + int(N*0.7), 1: count_1 + int(N*0.3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 +int(N*0.8), 1: count_1 + int(N*0.2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + int(N*0.9), 1: count_1 + int(N*0.1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + int(N*1), 1: count_1 + int(N*0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.319</td>\n",
       "      <td>361.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=0.5)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.335</td>\n",
       "      <td>361.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=0.8)</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.312</td>\n",
       "      <td>361.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=1)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.321</td>\n",
       "      <td>361.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.281   \n",
       "After RANDOM Mitigation(K=5 fp)             0.867     0.686             0.279   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)     0.866     0.683             0.280   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)     0.865     0.680             0.282   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)       0.866     0.684             0.274   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.598               0.547   \n",
       "After RANDOM Mitigation(K=5 fp)            0.604               0.549   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)    0.607               0.544   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)    0.593               0.520   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)      0.604               0.537   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.475   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.473   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)               0.471   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)               0.449   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)                 0.462   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.336          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.319        361.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)               0.335        361.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)               0.312        361.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)                 0.321        361.000  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 2K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 2K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 2K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.402</td>\n",
       "      <td>237</td>\n",
       "      <td>631</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.5</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.295</td>\n",
       "      <td>503</td>\n",
       "      <td>463</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.6</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.284</td>\n",
       "      <td>541</td>\n",
       "      <td>445</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.7</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.284</td>\n",
       "      <td>567</td>\n",
       "      <td>445</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.8</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.277</td>\n",
       "      <td>582</td>\n",
       "      <td>434</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.9</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.268</td>\n",
       "      <td>594</td>\n",
       "      <td>420</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 1</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.266</td>\n",
       "      <td>600</td>\n",
       "      <td>417</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.867     0.683                0.048   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5     0.852     0.696                0.102   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6     0.848     0.695                0.110   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7     0.844     0.689                0.115   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8     0.844     0.691                0.118   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9     0.844     0.694                0.120   \n",
       "After SMOTE N = 2000 p_class 0 = 1       0.844     0.694                0.121   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.402              237   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5                0.295              503   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6                0.284              541   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7                0.284              567   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8                0.277              582   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9                0.268              594   \n",
       "After SMOTE N = 2000 p_class 0 = 1                  0.266              600   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  631       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.5              463       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.6              445       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.7              445       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.8              434       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.9              420       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 1                417       15014       6508  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 2000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 1000, 0: count_0 + 1000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 1200, 0: count_0 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 1400, 0: count_0 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 1600, 0: count_0 + 400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 1800, 0: count_0 + 200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 2000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 2000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1= metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.347</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=0.5)</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.234</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=0.8)</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.251</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=1)</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.236</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.281   \n",
       "After RANDOM Mitigation(K=5 fp)             0.867     0.686             0.280   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)     0.848     0.695             0.234   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)     0.844     0.691             0.251   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)       0.844     0.694             0.236   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.598               0.547   \n",
       "After RANDOM Mitigation(K=5 fp)            0.598               0.546   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)    0.695               0.516   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)    0.693               0.507   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)      0.716               0.491   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.475   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.471   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)               0.406   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)               0.381   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)                 0.348   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.336          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.347       2000.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)               0.234       2000.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)               0.251       2000.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)                 0.236       2000.000  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 2K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 2K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 2K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.398</td>\n",
       "      <td>242</td>\n",
       "      <td>624</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.277</td>\n",
       "      <td>570</td>\n",
       "      <td>434</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.272</td>\n",
       "      <td>587</td>\n",
       "      <td>426</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.258</td>\n",
       "      <td>622</td>\n",
       "      <td>405</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.267</td>\n",
       "      <td>614</td>\n",
       "      <td>419</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.261</td>\n",
       "      <td>653</td>\n",
       "      <td>410</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.256</td>\n",
       "      <td>684</td>\n",
       "      <td>402</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.867     0.686                0.049   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.846     0.693                0.115   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.844     0.693                0.119   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.842     0.694                0.126   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.841     0.690                0.124   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.837     0.685                0.132   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.833     0.682                0.138   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.398              242   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.277              570   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.272              587   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.258              622   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.267              614   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.261              653   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.256              684   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  624       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              434       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              426       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              405       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              419       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              410       16014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                402       16014       6508  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 3000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 1500, 0: count_0 + 1500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 1800, 0: count_0 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 2100, 0: count_0 + 900}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 2400, 0: count_0 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 2700, 0: count_0 + 300}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 3000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_3K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_3K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_3K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_3K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1= metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.323</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=0.5)</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.263</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=0.8)</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.253</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=1)</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.252</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.281   \n",
       "After RANDOM Mitigation(K=5 fp)             0.867     0.686             0.279   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)     0.844     0.693             0.263   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)     0.841     0.690             0.253   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)       0.833     0.682             0.252   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.598               0.547   \n",
       "After RANDOM Mitigation(K=5 fp)            0.602               0.529   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)    0.693               0.527   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)    0.696               0.514   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)      0.744               0.535   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.475   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.453   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)               0.404   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)               0.384   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)                 0.406   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.336          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.323       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)               0.263       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)               0.253       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)                 0.252       3000.000  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 3K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 3K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 3K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.406</td>\n",
       "      <td>242</td>\n",
       "      <td>637</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.271</td>\n",
       "      <td>596</td>\n",
       "      <td>425</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.268</td>\n",
       "      <td>603</td>\n",
       "      <td>420</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.262</td>\n",
       "      <td>648</td>\n",
       "      <td>411</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.252</td>\n",
       "      <td>663</td>\n",
       "      <td>395</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.240</td>\n",
       "      <td>705</td>\n",
       "      <td>377</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.242</td>\n",
       "      <td>739</td>\n",
       "      <td>380</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.865     0.679                0.049   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.843     0.691                0.121   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.843     0.692                0.122   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.837     0.686                0.131   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.837     0.689                0.134   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.834     0.688                0.143   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.828     0.680                0.150   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.406              242   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.271              596   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.268              603   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.262              648   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.252              663   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.240              705   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.242              739   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  637       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              425       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              420       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              411       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              395       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              377       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                380       17014       6508  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 4000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 2000, 0: count_0 + 2000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 2400, 0: count_0 + 1600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 2800, 0: count_0 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 3200, 0: count_0 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 3600, 0: count_0 + 400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 4000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_4K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_4K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_4K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_4K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1= metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.317</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=0.5)</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.254</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=0.8)</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.275</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=1)</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.260</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.281   \n",
       "After RANDOM Mitigation(K=5 fp)             0.867     0.686             0.261   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)     0.843     0.692             0.254   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)     0.837     0.689             0.275   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)       0.828     0.680             0.260   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.598               0.547   \n",
       "After RANDOM Mitigation(K=5 fp)            0.594               0.509   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)    0.711               0.522   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)    0.748               0.534   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)      0.758               0.534   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.475   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.440   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)               0.385   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)               0.402   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)                 0.391   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.336          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.317       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)               0.254       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)               0.275       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)                 0.260       4000.000  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 4K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 4K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 4K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.410</td>\n",
       "      <td>231</td>\n",
       "      <td>643</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.271</td>\n",
       "      <td>622</td>\n",
       "      <td>425</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.253</td>\n",
       "      <td>642</td>\n",
       "      <td>397</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.247</td>\n",
       "      <td>685</td>\n",
       "      <td>388</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.245</td>\n",
       "      <td>701</td>\n",
       "      <td>384</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.235</td>\n",
       "      <td>776</td>\n",
       "      <td>369</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.230</td>\n",
       "      <td>813</td>\n",
       "      <td>360</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.866     0.679                0.047   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.839     0.686                0.126   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.840     0.693                0.130   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.835     0.687                0.139   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.833     0.686                0.142   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.824     0.677                0.157   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.820     0.673                0.165   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.410              231   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.271              622   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.253              642   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.247              685   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.245              701   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.235              776   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.230              813   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  643       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              425       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              397       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              388       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              384       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              369       18014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                360       18014       6508  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 5000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 2500, 0: count_0 + 2500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 3000, 0: count_0 + 2000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 3500, 0: count_0 + 1500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 4000, 0: count_0 + 1000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 4500, 0: count_0 + 500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 5000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_5K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOTTOGRUPPI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1</td>\n",
       "      <td>322</td>\n",
       "      <td>13014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "      <td>18014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.505</td>\n",
       "      <td>311</td>\n",
       "      <td>163</td>\n",
       "      <td>18014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.486</td>\n",
       "      <td>329</td>\n",
       "      <td>157</td>\n",
       "      <td>18014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.446</td>\n",
       "      <td>367</td>\n",
       "      <td>144</td>\n",
       "      <td>18014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.443</td>\n",
       "      <td>371</td>\n",
       "      <td>143</td>\n",
       "      <td>18014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.384</td>\n",
       "      <td>444</td>\n",
       "      <td>124</td>\n",
       "      <td>18014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.359</td>\n",
       "      <td>475</td>\n",
       "      <td>116</td>\n",
       "      <td>18014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.912     0.006   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.912     0.000   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.871     0.403   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.868     0.406   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.861     0.412   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.860     0.412   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.846     0.412   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.839     0.412   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.000   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.000   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.093   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.098   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.109   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.110   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.132   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.141   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.997   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        1.000   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.505   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.486   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.446   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.443   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.384   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.359   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                       1   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              311   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              329   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              367   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              371   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              444   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                475   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     322   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      323   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              163   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              157   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              144   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              143   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              124   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                116   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       3682  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               18014       3682  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       18014       3682  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       18014       3682  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       18014       3682  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       18014       3682  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       18014       3682  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         18014       3682  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.331</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.251</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.255</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.268</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.281   \n",
       "After RANDOM Mitigation(K=5 fp)             0.867     0.686             0.271   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.840     0.693             0.251   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.833     0.686             0.255   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.820     0.673             0.268   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.598               0.547   \n",
       "After RANDOM Mitigation(K=5 fp)            0.590               0.518   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.693               0.512   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.719               0.529   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.770               0.562   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.475   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.447   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.387   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.382   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.382   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.336          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.331       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.251       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.255       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.268       5000.000  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 6000, p changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.390</td>\n",
       "      <td>252</td>\n",
       "      <td>612</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.5</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.262</td>\n",
       "      <td>641</td>\n",
       "      <td>411</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.6</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.263</td>\n",
       "      <td>646</td>\n",
       "      <td>413</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.7</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.240</td>\n",
       "      <td>713</td>\n",
       "      <td>377</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.8</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.239</td>\n",
       "      <td>751</td>\n",
       "      <td>375</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.9</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.226</td>\n",
       "      <td>810</td>\n",
       "      <td>355</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 1</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.233</td>\n",
       "      <td>856</td>\n",
       "      <td>365</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 6000         0.867     0.689                0.051   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5     0.838     0.687                0.130   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6     0.837     0.686                0.131   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7     0.833     0.686                0.144   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8     0.827     0.679                0.152   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9     0.821     0.676                0.164   \n",
       "After SMOTE N = 6000 p_class 0 = 1       0.812     0.663                0.173   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 6000                    0.390              252   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5                0.262              641   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6                0.263              646   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7                0.240              713   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8                0.239              751   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9                0.226              810   \n",
       "After SMOTE N = 6000 p_class 0 = 1                  0.233              856   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 6000                  612       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.5              411       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.6              413       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.7              377       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.8              375       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.9              355       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 1                365       19014       6508  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 6000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 3000, 0: count_0 + 3000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 3600, 0: count_0 + 2400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 4100, 0: count_0 + 1800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 4800, 0: count_0 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 5400, 0: count_0 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1+ 6000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 6000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 6000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_6K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_6K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_6K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_6K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOTTOGRUPPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1</td>\n",
       "      <td>322</td>\n",
       "      <td>13014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "      <td>19014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.492</td>\n",
       "      <td>326</td>\n",
       "      <td>159</td>\n",
       "      <td>19014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.477</td>\n",
       "      <td>352</td>\n",
       "      <td>154</td>\n",
       "      <td>19014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.430</td>\n",
       "      <td>379</td>\n",
       "      <td>139</td>\n",
       "      <td>19014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.390</td>\n",
       "      <td>432</td>\n",
       "      <td>126</td>\n",
       "      <td>19014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.365</td>\n",
       "      <td>470</td>\n",
       "      <td>118</td>\n",
       "      <td>19014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.341</td>\n",
       "      <td>514</td>\n",
       "      <td>110</td>\n",
       "      <td>19014</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.912     0.006   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.912     0.000   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.868     0.403   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.863     0.400   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.859     0.415   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.848     0.414   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.840     0.411   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.831     0.406   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.000   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.000   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.097   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.105   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.113   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.129   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.140   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.153   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.997   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        1.000   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.492   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.477   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.430   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.390   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.365   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.341   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                       1   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              326   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              352   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              379   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              432   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              470   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                514   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     322   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      323   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              159   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              154   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              139   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              126   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              118   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                110   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       3682  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               19014       3682  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       19014       3682  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       19014       3682  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       19014       3682  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       19014       3682  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       19014       3682  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         19014       3682  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_6K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_6K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_6K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_6K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.336</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.237</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.242</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.222</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.281   \n",
       "After RANDOM Mitigation(K=5 fp)             0.867     0.686             0.291   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.837     0.686             0.237   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.827     0.679             0.242   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.812     0.663             0.222   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.598               0.547   \n",
       "After RANDOM Mitigation(K=5 fp)            0.610               0.550   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.702               0.524   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.761               0.536   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.658               0.461   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.475   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.470   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.391   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.394   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.298   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.336          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.336       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.237       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.242       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.222       6000.000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 7000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.389</td>\n",
       "      <td>257</td>\n",
       "      <td>610</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.5</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.258</td>\n",
       "      <td>657</td>\n",
       "      <td>405</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.6</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.242</td>\n",
       "      <td>708</td>\n",
       "      <td>379</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.7</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.228</td>\n",
       "      <td>783</td>\n",
       "      <td>358</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.8</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.224</td>\n",
       "      <td>821</td>\n",
       "      <td>352</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.9</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.223</td>\n",
       "      <td>873</td>\n",
       "      <td>349</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 1</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.212</td>\n",
       "      <td>929</td>\n",
       "      <td>333</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.867     0.688                0.052   \n",
       "After SMOTE N = 8000 p_class 0 = 0.5     0.837     0.687                0.133   \n",
       "After SMOTE N = 8000 p_class 0 = 0.6     0.833     0.686                0.143   \n",
       "After SMOTE N = 8000 p_class 0 = 0.7     0.825     0.680                0.159   \n",
       "After SMOTE N = 8000 p_class 0 = 0.8     0.820     0.675                0.166   \n",
       "After SMOTE N = 8000 p_class 0 = 0.9     0.812     0.666                0.177   \n",
       "After SMOTE N = 8000 p_class 0 = 1       0.806     0.662                0.188   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.389              257   \n",
       "After SMOTE N = 8000 p_class 0 = 0.5                0.258              657   \n",
       "After SMOTE N = 8000 p_class 0 = 0.6                0.242              708   \n",
       "After SMOTE N = 8000 p_class 0 = 0.7                0.228              783   \n",
       "After SMOTE N = 8000 p_class 0 = 0.8                0.224              821   \n",
       "After SMOTE N = 8000 p_class 0 = 0.9                0.223              873   \n",
       "After SMOTE N = 8000 p_class 0 = 1                  0.212              929   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  610       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.5              405       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.6              379       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.7              358       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.8              352       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.9              349       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 1                333       21014       6508  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 8000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 4000, 0: count_0 + 4000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 4800, 0: count_0 + 3200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 5600, 0: count_0 + 2400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 6400, 0: count_0 + 1600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 7200, 0: count_0 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 8000, 0: count_0 }\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 8000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_8K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_8K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.320</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.247</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.226</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.235</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.281   \n",
       "After RANDOM Mitigation(K=5 fp)             0.867     0.686             0.273   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.833     0.686             0.247   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.820     0.675             0.226   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.806     0.662             0.235   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.598               0.547   \n",
       "After RANDOM Mitigation(K=5 fp)            0.611               0.533   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.705               0.490   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.666               0.487   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.654               0.466   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.475   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.455   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.344   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.343   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.298   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.336          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.320       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.247       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.226       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.235       8000.000  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.404</td>\n",
       "      <td>243</td>\n",
       "      <td>634</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.5</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.253</td>\n",
       "      <td>683</td>\n",
       "      <td>396</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.6</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.240</td>\n",
       "      <td>717</td>\n",
       "      <td>377</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.7</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.231</td>\n",
       "      <td>811</td>\n",
       "      <td>362</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.8</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.221</td>\n",
       "      <td>851</td>\n",
       "      <td>346</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.9</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.218</td>\n",
       "      <td>892</td>\n",
       "      <td>342</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 1</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.206</td>\n",
       "      <td>953</td>\n",
       "      <td>323</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.865     0.681                0.049   \n",
       "After SMOTE N = 9000 p_class 0 = 0.5     0.834     0.685                0.138   \n",
       "After SMOTE N = 9000 p_class 0 = 0.6     0.832     0.685                0.145   \n",
       "After SMOTE N = 9000 p_class 0 = 0.7     0.820     0.673                0.164   \n",
       "After SMOTE N = 9000 p_class 0 = 0.8     0.816     0.671                0.172   \n",
       "After SMOTE N = 9000 p_class 0 = 0.9     0.810     0.665                0.181   \n",
       "After SMOTE N = 9000 p_class 0 = 1       0.804     0.661                0.193   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.404              243   \n",
       "After SMOTE N = 9000 p_class 0 = 0.5                0.253              683   \n",
       "After SMOTE N = 9000 p_class 0 = 0.6                0.240              717   \n",
       "After SMOTE N = 9000 p_class 0 = 0.7                0.231              811   \n",
       "After SMOTE N = 9000 p_class 0 = 0.8                0.221              851   \n",
       "After SMOTE N = 9000 p_class 0 = 0.9                0.218              892   \n",
       "After SMOTE N = 9000 p_class 0 = 1                  0.206              953   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  634       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.5              396       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.6              377       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.7              362       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.8              346       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.9              342       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 1                323       22014       6508  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 9000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 4500, 0: count_0 + 4500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 5400, 0: count_0 + 2600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 6300, 0: count_0 + 2700}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 7200, 0: count_0 + 1800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 8100, 0: count_0 + 900}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 9000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 9000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_9K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_9K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.322</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.268</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.289</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.225</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.281   \n",
       "After RANDOM Mitigation(K=5 fp)             0.867     0.686             0.266   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.832     0.685             0.268   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.816     0.671             0.289   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.804     0.661             0.225   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.598               0.547   \n",
       "After RANDOM Mitigation(K=5 fp)            0.596               0.518   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.711               0.528   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.779               0.586   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.661               0.411   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.475   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.447   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.398   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.446   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.225   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.336          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.322       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.268       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.289       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.225       9000.000  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT: andamento di falsi positivi e di falsi negativi al variare di N e p di appartenere alla classe 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVxUVeMG8GdmkH0TBJRFFPeN3M1cSRMszd1UTFwyywXLcq1UtDQzTa3XtYQ0ywU13zQ1UVFES3DBHQFBc99YRNlm5vz+4Md9GYdVwbmMz/fzmU/NuWfuPWfuMyNn7r3nKoQQAkRERERERERU5pSGbgARERERERGRseKgm4iIiIiIiKiccNBNREREREREVE446CYiIiIiIiIqJxx0ExEREREREZUTDrqJiIiIiIiIygkH3URERERERETlhINuIiIiIiIionLCQTcRERERERFROeGgm6gCCA8Ph0KhQHh4uKGbUuHMnj0bCoXC0M0olaioKLz22muwsrKCQqHA6dOnDd2kchMSEgKFQoHo6GhDN4WISHYq4r9hRKSPg26icpQ3oCjoMW3aNEM3r0h5bTc3N8eNGzf0lnfu3BmNGzc2QMv0PXnyBLNnzzaKHyVycnIwYMAAPHz4EN999x3Wr18PT0/PF7LtmJgYKBQKxMbGAgC+++471KhR44Vsm16Mw4cP4+2334aHhwfMzc1RtWpV+Pn5ITIy0tBN07FmzRp06tQJLi4uMDMzQ82aNTFixAgkJSUVWP/OnTsYM2YM3NzcYG5ujho1amDUqFEvttEVzPLlyxESEmKw7R89ehTt27eHpaUlqlatisDAQKSnpxf7un///RdBQUFo3bo1KleujCpVqqBz584ICwt7Aa2m55GSkoL3338fTk5OsLKygo+PD06ePFni11+8eBF+fn6wtraGg4MD3n33Xdy7d0+nTlJSUqF/d23cuLGsu0RUYiaGbgDRy2DOnDmoWbOmTplcBqzFycrKwtdff43vv//e0E0p1JMnTxAUFAQg98eA/D7//HPZ/8CRX0JCAq5evYo1a9bgvffee6Hb/ueff+Dg4IC6desCAI4dO4ZXX331hbaBytfly5ehVCrxwQcfoGrVqkhOTsYvv/yCjh07YteuXfDz8zN0EwEAp06dQs2aNfH222+jcuXKSExMxJo1a7Bz507ExMTA1dVVqvvvv/+iXbt2AIAPPvgAbm5uuHnzJo4fP26o5lcIy5cvR5UqVTB8+PAXvu3Tp0+jS5cuaNCgARYvXozr16/j22+/RVxcHHbv3l3ka3fs2IEFCxagd+/eCAgIgFqtxrp16/DGG29g7dq1GDFixAvqxYtR0f4NK4xWq8Vbb72FmJgYTJ48GVWqVMHy5cvRuXNnnDhxAnXq1Cny9devX0fHjh1hZ2eHefPmIT09Hd9++y3Onj2L48ePw9TUVKf+4MGD8eabb+qUtW3btsz7RVRSHHQTvQDdu3dHy5YtDd2MZ9K0aVOsWbMG06dP1/lDt6IwMTGBiUnF+aq7e/cuAMDe3v6Fb/v48eNo3bq1dCrjsWPHMGnSpBfejvLw+PFjWFlZGboZBvfee+/p/ZgzduxYeHl5YcmSJbIZdC9fvlyvrHfv3mjZsiXWrVunMwgZM2YMTExMEBUVBUdHxxfZzArpyZMnsLS0NGgbZsyYgcqVKyM8PBy2trYAgBo1amD06NH466+/0K1bt0Jf6+Pjg2vXrqFKlSpS2QcffICmTZti5syZBhl0l+f3S0X7N6wwoaGhOHr0KLZs2YL+/fsDAAYOHIi6deti1qxZ+PXXX4t8/bx58/D48WOcOHEC1atXBwC0bt0ab7zxBkJCQvD+++/r1G/evDmGDh1aPp0hegY8vZzIgK5evYqxY8eiXr16sLCwgKOjIwYMGFDoKZT5xcXFoV+/fqhatSrMzc3h7u6OQYMGITU1VafeL7/8ghYtWsDCwgIODg4YNGgQ/v333xK3ccaMGdBoNPj6669LVL+k2/vPf/4DLy8vWFhYoHXr1oiIiEDnzp11jlRnZ2dj5syZaNGiBezs7GBlZYUOHTrg4MGDUp2kpCQ4OTkBAIKCgqTTyGbPng1A/3q4xo0bw8fHR689Wq0Wbm5u0h8DeWVLlixBo0aNYG5uDhcXF4wZMwbJyck6r42Ojoavry+qVKkCCwsL1KxZEyNHjizR+5Xf8OHD0alTJwDAgAEDoFAopPdj+PDhsLa2xo0bN9C7d29YW1vDyckJn376KTQaTam3lSc5ORn379/H/fv38c8//6Bx48a4f/8+zp8/j+vXr6NOnTq4f/++zmmft2/fxogRI+Du7g4zMzNUq1YNvXr10slt/n2QX40aNQo8svbkyROMGTMGjo6OsLW1xbBhw/TeZ61Wi9mzZ8PV1RWWlpbw8fHBhQsX9NaZd2nEoUOHMHbsWDg7O8Pd3V1avnz5cjRq1AhmZmZwdXXFuHHjkJKSUqJ2Pp3RvPkWNm3ahBkzZqBq1aqwsrLC22+/rZf7kn5mXzRLS0s4OTnpvQeF2bJli/QZr1KlCoYOHap3CUp55DXvUof87bx06RJ2796NyZMnw9HREZmZmcjJyXmm9ee3ceNGtGjRAjY2NrC1tUWTJk2wdOlSaXlh19nmZS//Z6FGjRro0aMH/vrrLzRt2hTm5uZo2LAhtm3bVuBrDx8+XOxnAShZjvMuAzpx4gQ6duwIS0tLzJgxAzVq1MD58+dx6NAh6Tvz6bOEyktaWhr27duHoUOHSgNuABg2bBisra2xefPmIl/fqFEjnQE3AJiZmeHNN9/E9evX8ejRo2dql0KhwPjx47FhwwbUq1cP5ubmaNGiBQ4fPqxTL2/fX7hwAUOGDEHlypXRvn17APrfD3mGDx+uc6lO3inQ3377LVavXo1atWrBzMwMrVq1QlRUVIHbK6itv//+Oxo3bgwzMzM0atQIe/bs0dt2eHg4WrZsCXNzc9SqVQurVq0yyHXioaGhcHFxQd++faUyJycnDBw4EDt27EBWVlaRr9+6dSt69OghDbgBoGvXrqhbt26hmXn8+DGys7PLpgNEz6ni/3RGVAGkpqbi/v37OmVVqlRBVFQUjh49ikGDBsHd3R1JSUlYsWIFOnfujAsXLhR6NCI7Oxu+vr7IysrChAkTULVqVdy4cQM7d+5ESkoK7OzsAABfffUVvvjiCwwcOBDvvfce7t27h++//x4dO3bEqVOnSnQ0tWbNmhg2bBjWrFmDadOmFXm0u6TbW7FiBcaPH48OHTrg448/RlJSEnr37o3KlSvrDI7S0tLw448/YvDgwRg9ejQePXqEn376Cb6+vjh+/DiaNm0KJycnrFixAh9++CH69Okj/YPu7e1dYBvfeecdzJ49G7dv30bVqlWl8iNHjuDmzZsYNGiQVDZmzBiEhIRgxIgRCAwMRGJiIn744QecOnUKkZGRqFSpEu7evYtu3brByckJ06ZNg729PZKSkvT+oC6JvGtS582bh8DAQLRq1QouLi7Sco1GA19fX7Rp0wbffvstwsLCsGjRItSqVQsffvhhqbcHAM2aNcPVq1el5+fOncO3334rPe/ZsycAICAgQLr+s1+/fjh//jwmTJiAGjVq4O7du9i3bx+uXbv2zNeAjx8/Hvb29pg9ezZiY2OxYsUKXL16VRrUAsD06dPxzTffoGfPnvD19UVMTAx8fX2RmZlZ4DrHjh0LJycnzJw5E48fPwaQ+wdsUFAQunbtig8//FDaVlRUlLRPn8VXX30FhUKBqVOn4u7du1iyZAm6du2K06dPw8LCosSf2YI8efIET548KbYNKpUKlStXLlF709LSkJ2djfv372PdunU4d+4cZsyYUezr8j4PrVq1wvz583Hnzh0sXboUkZGRet8pZZHXBw8eQKPR4Nq1a5gzZw4AoEuXLtLyvOt4XVxc0KVLFxw4cAAqlQpvvPEGVqxY8Ux53LdvHwYPHowuXbpgwYIFAHKvJY2MjMTEiRNLvT4g9weXd955Bx988AECAgIQHByMAQMGYM+ePXjjjTd06pbks1CaHD948ADdu3fHoEGDMHToULi4uKBz586YMGECrK2t8dlnn0nvYVGSk5NL9IOJpaVlkUfSz549C7VarXf2l6mpKZo2bYpTp04Vu42C3L59u9htF+fQoUPYtGkTAgMDYWZmhuXLl8PPzw/Hjx/XuyRswIABqFOnDubNmwchxDNt79dff8WjR48wZswYKBQKfPPNN+jbty+uXLlS7HfRkSNHsG3bNowdOxY2NjZYtmwZ+vXrh2vXrklnfJw6dQp+fn6oVq0agoKCoNFoMGfOHOmH6uKU5XfPqVOn0Lx5cyiVusf7WrdujdWrV+Py5cto0qRJga+9ceMG7t69W+AZg61bt8aff/6pVx4UFITJkydDoVCgRYsW+Oqrr4o8g4Ko3AkiKjfBwcECQIEPIYR48uSJ3muOHTsmAIh169ZJZQcPHhQAxMGDB4UQQpw6dUoAEFu2bCl020lJSUKlUomvvvpKp/zs2bPCxMREr7ywtkdFRYmEhARhYmIiAgMDpeWdOnUSjRo1KvX2srKyhKOjo2jVqpXIycmR6oWEhAgAolOnTlKZWq0WWVlZOutLTk4WLi4uYuTIkVLZvXv3BAAxa9YsvX7MmjVL5P+qi42NFQDE999/r1Nv7NixwtraWtonERERAoDYsGGDTr09e/bolG/fvl16n8pC3r5+et8GBAQIAGLOnDk65c2aNRMtWrR45u0dOXJE7Nu3T3zxxRfCxMRE7N69W+zbt090795dtGzZUuzbt0/s27dPnD9/XgiR+/4DEAsXLixyvYXtD09PTxEQECA9z8tZixYtRHZ2tlT+zTffCABix44dQgghbt++LUxMTETv3r111jd79mwBoMB1tm/fXqjVaqn87t27wtTUVHTr1k1oNBqp/IcffhAAxNq1awttZ55OnTrpZDRvf7m5uYm0tDSpfPPmzQKAWLp0qRCiZJ/ZwuRluLiHp6dnidfp6+srvc7U1FSMGTNGZGRkFPma7Oxs4ezsLBo3bqxTd+fOnQKAmDlzplRWVnk1MzOT2uno6CiWLVumszwwMFBa5ufnJzZt2iQWLlworK2tRa1atcTjx49LvK08EydOFLa2tjrZedrT3yt58rKXmJgolXl6egoAYuvWrVJZamqqqFatmmjWrJnea4v7LJQmx506dRIAxMqVK/Xa2qhRI50sFyevH8U9Cvrc57dlyxYBQBw+fFhv2YABA0TVqlVL3KY8cXFxwtzcXLz77rulfm2evPZHR0dLZVevXhXm5uaiT58+Ulnevh88eLDeOp7+fsgTEBCg8/lMTEyUcvvw4UOpfMeOHQKA+OOPP/S293RbTU1NRXx8vFQWExOj929bz549haWlpbhx44ZUFhcXJ0xMTArM79PK8rvHyspK59/tPLt27RIAxJ49ewp9bVRUlN7fRXkmT54sAIjMzEwhRO4+69atm1ixYoX473//K5YsWSKqV68ulEql2LlzZ7HtJCovPNJN9AL85z//kSanys/CwkL6/5ycHKSlpaF27dqwt7fHyZMn8e677xa4vryjYnv37sWbb75Z4C/727Ztg1arxcCBA3WOsletWhV16tTBwYMHS3RkCwC8vLzw7rvvYvXq1Zg2bRqqVav2zNuLjo7GgwcPMH/+fJ3r1Pz9/fHxxx/rrFOlUkGlUgHIPbU4JSUFWq0WLVu2LNWMp/nVrVsXTZs2xaZNmzB+/HgAuUfkQkND0bNnT2mfbNmyBXZ2dnjjjTd0+tOiRQtYW1vj4MGDGDJkiHRkb+fOnXjllVee+UhpSX3wwQc6zzt06ID169c/8/ryJqD6888/0apVK+ma3o8++ggDBgxA165ddepbWFjA1NQU4eHhGDVqVImPrBbn/fff13nvPvzwQ8yYMQN//vkn3n77bezfvx9qtRpjx47Ved2ECRMKPI0dAEaPHi3lB8g9KpqdnY2PPvpI52jL6NGjMWPGDOzateuZrwcdNmwYbGxspOf9+/dHtWrV8OeffyIwMLBEn9mi1p13+mpR8n+fFOfrr7/GJ598gn///Rc///wzsrOzoVari3xNdHQ07t69i9mzZ8Pc3Fwqf+utt1C/fn3s2rVLmtAwz/Pmdffu3cjMzMTFixfxyy+/SGcs5Mm77KFq1arYtWuXtF/d3d0xePBg/Prrr6WekNDe3h6PHz/Gvn37yuwad1dXV/Tp00d6nnfa+IIFC/TOuinus1DaHJuZmZXJdc4bNmxARkZGsfW8vLyKXJ63DjMzM71l5ubmJdpGfk+ePMGAAQNgYWFR4sugCtO2bVu0aNFCel69enX06tULf/zxBzQajc73ydPZfhbvvPOOzndohw4dAABXrlwp9rVdu3ZFrVq1pOfe3t6wtbWVXqvRaBAWFoY+ffronKFWu3ZtdO/eHX/88Uex2yjL756MjIxC93ne8qJeCxSemfzrr169Ovbu3atT591330XDhg3xySef4K233iq2rUTlgYNuohegdevWBZ4WlZGRgfnz5yM4OBg3btzQOUWtqOs8a9asiUmTJmHx4sXYsGEDOnTogLfffhtDhw6V/riPi4uDEKLQGUFLOzj8/PPPsX79enz99dc61zbmKen28k5lrl27ts5yExOTAk8F/fnnn7Fo0SJcunRJ51rNp2eDL4133nkHM2bMwI0bN+Dm5obw8HDcvXsX77zzjk5/UlNT4ezsXOA68iY869SpE/r164egoCB899136Ny5M3r37o0hQ4YU+AfC8zA3N9c7LbBy5coFXu9ZEqmpqdJ7un//frz++uu4f/8+Hj58iPPnz+PLL7/E/fv3UalSJSlXZmZmWLBgAT755BO4uLjg1VdfRY8ePTBs2DCdgUNpPZ0ba2trVKtWTbo2trDcODg4FDrwfzojeeuoV6+eTrmpqSm8vLx0TrN/3vYrFArUrl1ban9JPrOF8fLyKnYgU1pNmzaV/n/o0KFo3rw5hg8fjtDQ0EJfU9j7BwD169fHkSNHdMrKIq958y90794dvXr1QuPGjWFtbS39YJb3x/7AgQN1BqADBgzAu+++i6NHj5Z60D127Fhs3rwZ3bt3h5ubG7p164aBAwc+1wC8du3aetfQ5v0Qm5SUpPPZKelnoaQ5dnNz05vZ+Vnk/UD3vPL2WUHX8GZmZpbqxyONRoNBgwbhwoUL2L1793NP9lnQv19169bFkydPcO/ePZ399Dz/BuXJf30yAOm7rCSfkadfm/f6vNfevXsXGRkZet+ZgP73aGHK8rvHwsKi0H2et7yo1wKFZ6a41zs4OGDEiBH4+uuvcf36dZ3L2IheFA66iQxowoQJCA4OxkcffYS2bdvCzs4OCoUCgwYNglarLfK1ixYtwvDhw7Fjxw789ddfCAwMxPz58/H333/D3d0dWq0WCoUCu3fv1vl1Po+1tXWp2url5YWhQ4dKR7ufVtbbA3InZRs+fDh69+6NyZMnw9nZGSqVCvPnz0dCQkKp15fnnXfewfTp07FlyxZ89NFH2Lx5M+zs7HT+qNZqtXB2dsaGDRsKXEfeYEKhUCA0NBR///03/vjjD+zduxcjR47EokWL8Pfffz9TvwtT0Pv6PHr16oVDhw5Jz8+cOYMlS5ZIz/OOzHXq1EnnHugfffQRevbsid9//x179+7FF198gfnz5+PAgQNo1qxZkdt8nknfSqs0f7w/rbBJhp4+2lUaxX1mC5Oenl6i+xerVKoSX6uZn6mpKd5++218/fXXyMjIeK737en2lKVatWqhWbNm2LBhgzTozhtkPX09skqlgqOj4zP9IOXs7IzTp09j79692L17N3bv3o3g4GAMGzYMP//8M4Ci8yE3ZbU/7927V6L+WVtbF/m9l3em1K1bt/SW3bp1q1QD59GjR2Pnzp3YsGEDXn/99RK/riwU9L4qFIoCr+8u7H0r7DNS0DrK8rUlVZbfPdWqVSt0nwMocr8XlxkHB4dif+T28PAAADx8+JCDbjIIDrqJDCg0NBQBAQFYtGiRVJaZmVniWYSbNGmCJk2a4PPPP8fRo0fRrl07rFy5El9++SVq1aoFIQRq1qxZ4Kntz+Lzzz/HL7/8Ik0ulF9Jt+fp6QkAiI+P15lFXK1WIykpSWcCtNDQUHh5eWHbtm06f+TOmjVLZ52lnYW1Zs2aaN26tXSK+bZt29C7d2+df7Rr1aqFsLAwtGvXrkR/tL766qt49dVX8dVXX+HXX3+Fv78/Nm7c+MLvtV0aixYtQnJyMo4dO4agoCDs3LkTJiYm+P7773Hjxg3pVM2CjiTXqlULn3zyCT755BPExcWhadOmWLRoEX755RfpNU/nODs7u8A/moDcMwvy5yE9PR23bt2S7rOaPzf5jzA9ePCgxAOrvHXExsbqHL3Jzs5GYmKizqn0BbUfyD3KWNCRn7i4OJ3nQgjEx8frTehX1Ge2MN9++63eaduF9a8kdz4oSEZGBoQQePToUaF5z//+PT3AiY2NlZaXp4yMDJ2jXXmnAj89e3reJHHP8iMEkPtDRM+ePdGzZ09otVqMHTsWq1atwhdffIHatWtLn4mUlBSdyeMKO1siPj4eQgid76rLly8DgN4ZPiX9LJQkx0Up7fdmq1atSnQ2yKxZswq95APIvYOEiYkJoqOjMXDgQKk8Ozsbp0+f1ikryuTJkxEcHIwlS5Zg8ODBJXpNcZ7+HAO5+ylvhv/iVK5cucBTw5/nLJpn5ezsDHNzc8THx+stK6isIGX53dO0aVNERERAq9XqnJXyzz//wNLSssi/G9zc3ODk5ITo6Gi9ZXmTqhYnb78863cC0fPiLcOIDEilUun9Kv39998XezQhLS1N7/rLJk2aQKlUSn+Q9u3bFyqVCkFBQXrbEELgwYMHpW5vrVq1MHToUKxatQq3b9/WWVbS7bVs2RKOjo5Ys2aNTh82bNigN3jK+yU///r++ecfHDt2TKde3vWxJf2xAsg92v33339j7dq1uH//vs6p5UDu6aoajQZz587Ve61arZa2lZycrNffvD8AirsFiqG1aNECXbt2hVqtRuPGjeHn54euXbvizp076Nq1q/TIf43jkydP9GYLr1WrFmxsbHT6W6tWLb1b7axevbrQbK9evVrn8oEVK1ZArVaje/fuAHJnrDYxMcGKFSt0XvfDDz+UuL9du3aFqakpli1bprPPfvrpJ6Smpupc61erVi38/fffOreb2blzZ6G321u3bp3OrYpCQ0Nx69Ytqf0l+cwWZtiwYdi3b1+xj8LOysgv77KI/FJSUrB161Z4eHgUejkFkPvZdXZ2xsqVK3XavHv3bly8eLHMrpVUq9UF/pBy/PhxnD17VudSnc6dO0tnpOTPZUhICDQajd7M4CXx9HejUqmUfjzJ63fetbT5M/748WPpSPjTbt68ie3bt0vP09LSsG7dOjRt2lTvsoziPgulyXFRrKysSvWduWHDhhLlcNiwYUWux87ODl27dsUvv/yi85lZv3490tPTMWDAAKnsyZMnuHTpkt7dPxYuXIhvv/0WM2bMeOYZ5Qty7NgxnflC/v33X+zYsQPdunUr0ZkbtWrVwqVLl3Dv3j2pLCYmBpGRkWXWxpJSqVTo2rUrfv/9d9y8eVMqj4+Px+7du0u0jrL87unfvz/u3Lmjc2eP+/fvY8uWLejZs6fOj94JCQl6Z7P169dP7zt4//79uHz5sk5m8r/3eW7cuIG1a9fC29u7wDlpiF4EHukmMqAePXpg/fr1sLOzQ8OGDXHs2DGEhYVJt/sozIEDBzB+/HgMGDAAdevWhVqtxvr166FSqdCvXz8Auf/4f/nll5g+fbp0Sy4bGxskJiZi+/bteP/99/Hpp5+Wus2fffYZ1q9fj9jYWDRq1EgqL+n2TE1NMXv2bEyYMAGvv/46Bg4ciKSkJISEhKBWrVo6R1969OiBbdu2oU+fPnjrrbeQmJiIlStXomHDhjqnvFlYWKBhw4bYtGkT6tatCwcHBzRu3FjvFi/5DRw4EJ9++ik+/fRTODg46B0d6tSpE8aMGYP58+fj9OnT6NatGypVqoS4uDhs2bIFS5cuRf/+/fHzzz9j+fLl6NOnD2rVqoVHjx5hzZo1sLW1lY5MAbn3af3555+RmJj4zLfVKqnSbisyMhKvvfYagNwzLU6dOlXoJHuXL19Gly5dMHDgQDRs2BAmJibYvn077ty5o3O7tffeew8ffPAB+vXrhzfeeAMxMTHYu3ev3v1182RnZ0vrjY2NxfLly9G+fXu8/fbbAHJPH544cSIWLVqEt99+G35+foiJicHu3btRpUqVEh21c3JywvTp0xEUFAQ/Pz+8/fbb0rZatWqFoUOH6rQ/NDQUfn5+GDhwIBISEvDLL7/oTFyUn4ODA9q3b48RI0bgzp07WLJkCWrXro3Ro0cDKNlntjBleV1l9+7d4e7ujjZt2sDZ2RnXrl1DcHAwbt68iU2bNhX52kqVKmHBggUYMWIEOnXqhMGDB0u3DKtRo4beRIjPKj09HR4eHnjnnXfQqFEjWFlZ4ezZswgODoadnR2++OILqa6ZmRkWLlyIgIAAdOzYEe+++y6uXbuGpUuXokOHDjr3BA4PD4ePj0+xR2Lfe+89PHz4EK+//jrc3d1x9epVfP/992jatCkaNGgAAOjWrRuqV6+OUaNGYfLkyVCpVFi7di2cnJxw7do1vXXWrVsXo0aNQlRUFFxcXLB27VrcuXMHwcHBenWL+yyUJsdFadGiBVasWIEvv/wStWvXhrOzc5GnaJfVNd1A7i32XnvtNXTq1Anvv/8+rl+/jkWLFqFbt246l/kcP35cb59t374dU6ZMQZ06ddCgQQPp7Jo8b7zxhnS5QVJSEmrWrKlzy8OiNG7cGL6+vjq3DANQoqO9ADBy5EgsXrwYvr6+GDVqFO7evYuVK1eiUaNGSEtLK9E6ytLs2bPx119/oV27dvjwww+h0Wjwww8/oHHjxjh9+nSxry/L757+/fvj1VdfxYgRI3DhwgVUqVIFy5cvh0aj0Xt/824LmP/o+YwZM7Blyxb4+Phg4sSJSE9Px8KFC9GkSROdiQKnTJmChIQEdOnSBa6urkhKSsKqVavw+PHjAuejIXphXuxk6UQvl/y33SpIcnKyGDFihKhSpYqwtrYWvr6+4tKlS3q3K3r6lmFXrlwRI0eOFLVq1RLm5ubCwcFB+Pj4iLCwML1tbN26VbRv315YWVkJKysrUb9+fTFu3DgRGxv7zG3Pux1Q/luGlXZ7y5YtE56ensLMzEy0bt1aREZGihYtWgg/Pz+pjlarFfPmzZPqNWvWTOzcuVPv9itCCHH06FHRokULYWpqqnPbmsJu7SOEEO3atRMAxHvvvVfo+7B69WrRokULYWFhIWxsbESTJk3ElClTxM2bN4UQQpw8eVIMHjxYVK9eXZiZmQlnZ2fRo0cPndvOCCFEv379hIWFhUhOTi50W0IUfcswKysrvfoF9a+k2xIi97Zs1tbWYv369UKI3FuIARB3794tsP79+/fFuHHjRP369YWVlZWws7MTbdq0EZs3b9app9FoxNSpU0WVKlWEpaWl8PX1FfHx8YXeMuzQoUPi/fffF5UrVxbW1tbC399fPHjwQK+tX3zxhahataqwsLAQr7/+urh48aJwdHQUH3zwgd46C/vc/fDDD6J+/fqiUqVKwsXFRXz44YcFvleLFi0Sbm5uwszMTLRr105ER0cXesuw3377TUyfPl04OzsLCwsL8dZbb4mrV69K9UrzmS1PP/zwg2jfvr2oUqWKMDExEU5OTqJnz54F3r6pMJs2bRLNmjUTZmZmwsHBQfj7+4vr16/r1ClNXp+WlZUlJk6cKLy9vYWtra2oVKmS8PT0FKNGjdK5FVd+v/32m3jllVeEmZmZcHFxEePHj9e5hZsQQvzxxx+F3j4rv9DQUNGtWzfh7OwsTE1NRfXq1cWYMWPErVu3dOqdOHFCtGnTRqqzePHiQm8Z9tZbb4m9e/cKb29vYWZmJurXr6/3GS/NZ0GIkuX46Vs75nf79m3x1ltvCRsbG73bNb4IERER4rXXXhPm5ubCyclJjBs3Tm+f5X2+8t+GrLjbWOX9OylE7i0rAYhp06YV2x4AYty4ceKXX34RderUkf7Nyb++/Nu/d+9egev55ZdfhJeXlzA1NRVNmzYVe/fuLfSWYQXderGw/hbU1qcVdKvD/fv3i2bNmglTU1NRq1Yt8eOPP4pPPvlEmJubF/2GlIOHDx+KUaNGCUdHR2FpaSk6depU4Pe0p6dngbchO3funOjWrZuwtLQU9vb2wt/fX9y+fVunzq+//io6duwonJychImJiahSpYro06ePOHHiRHl1i6hEFEKU4YwLRETPSKvVwsnJCX379sWaNWsM3Zwy5+LigmHDhmHhwoVGtS1DS0lJQeXKlfHll1/is88+e+Hbzzt6umXLFvTv3/+Fb59KbsqUKfjtt98QHx9f5ncWKEqNGjXQuHFj7Ny5s8h6ISEhGDFiBKKiogq82wWV3vLly6Ujn09Ptvc0hUKBcePGleqSlYqqd+/eOH/+fIHXsBNR+eA13UT0wmVmZupdB71u3To8fPgQnTt3NkyjytH58+eRkZGBqVOnGtW2XrSC7uOaN9u6MeaGytbBgwfxxRdfvNABNxnWwYMHERgYWOyA25g9/b0ZFxeHP//8k9+ZRC8Yr+kmohfu77//xscff4wBAwbA0dERJ0+exE8//YTGjRvrTIhiLF7k9XyGunbwRdi0aRNCQkLw5ptvwtraGkeOHMFvv/2Gbt26len1pmScoqKiDN0EesG2bNli6CYYnJeXF4YPHy7dw33FihUwNTXFlClTDN00opcKB91E9MLVqFEDHh4eWLZsGR4+fAgHBwcMGzYMX3/9NUxNTQ3dPJIpb29vmJiY4JtvvkFaWpo0uVpRt9siInqZ+fn54bfffsPt27dhZmaGtm3bYt68eahTp46hm0b0UjH4Nd03btzA1KlTsXv3bjx58gS1a9dGcHCwdD1T3iy8+fn6+mLPnj3S84cPH2LChAn4448/oFQq0a9fPyxduhTW1tYvtC9ERERERERE+Rn0SHdycjLatWsHHx8f7N69G05OToiLi0PlypV16vn5+encVuPp67H8/f1x69Yt7Nu3Dzk5ORgxYgTef/99/Prrry+kH0REREREREQFMeiR7mnTpiEyMhIRERGF1hk+fDhSUlLw+++/F7j84sWLaNiwoc5sn3v27MGbb76J69evw9XVtTyaTkRERERERFQsgx7p/u9//wtfX18MGDAAhw4dgpubG8aOHYvRo0fr1AsPD4ezszMqV66M119/HV9++SUcHR0BAMeOHYO9vb3O7TW6du0KpVKJf/75B3369NHbblZWFrKysqTnWq0WDx8+hKOjIxQKRTn1loiIiIiIiIyFEAKPHj2Cq6srlMrCbwxm0EH3lStXsGLFCkyaNAkzZsxAVFQUAgMDYWpqioCAAAC5p5b37dsXNWvWREJCAmbMmIHu3bvj2LFjUKlUuH37NpydnXXWa2JiAgcHB9y+fbvA7c6fPx9BQUHl3j8iIiIiIiIybv/++y/c3d0LXW7QQbdWq0XLli0xb948AECzZs1w7tw5rFy5Uhp0Dxo0SKrfpEkTeHt7o1atWggPD0eXLl2eabvTp0/HpEmTpOepqamoXr06EhMTYWtrCwBQKpVQKpXQarXQarVS3bxyjUajc5/hwspVKhUUCgXUarVOG1QqFQBAo9GUqBwATp48iVdeeUWqo1AooFKp9NpYWLnc+mRiYgIhhE45+1Sx+pSdnY3Tp09LuTSGPhnjfnoZ+6TRaBATE4OmTZvC1NTUKPr0dBvZp4rXp7xcNm/eHAqFwij6VFTb2aeK0SetVouYmBh4e3tL7arofTLG/fSy9Umj0eiNfeTYp+TkZNSoUQM2NjYoikEH3dWqVUPDhg11yho0aICtW7cW+hovLy9UqVIF8fHx6NKlC6pWrYq7d+/q1FGr1Xj48CGqVq1a4DrMzMz0JmMDAAcHB2nQLTdqtRrW1taoXLkyTEx4pzeSB+aS5Covm/b29swmyUZeLm1tbZlLkg21Wg0rKyv+W06yUtH+xizuEuXCTzx/Adq1a4fY2FidssuXL8PT07PQ11y/fh0PHjxAtWrVAABt27ZFSkoKTpw4IdU5cOAAtFot2rRpUz4NJyIiIiIiIioBgw66P/74Y/z999+YN28e4uPj8euvv2L16tUYN24cACA9PR2TJ0/G33//jaSkJOzfvx+9evVC7dq14evrCyD3yLifnx9Gjx6N48ePIzIyEuPHj8egQYOMbuby/Kf8EMkFc0lyxWySHDGXJEfMJcmRMeXSoLcMA4CdO3di+vTpiIuLQ82aNTFp0iRp9vKMjAz07t0bp06dQkpKClxdXdGtWzfMnTsXLi4u0joePnyI8ePH448//oBSqUS/fv2wbNkyWFtbl6gNaWlpsLOzQ2pqqmxPLyciIiIiIiL5KOk40uCDbjmoCINuIQRSU1NhZ2fH25qRbDCXJFfMJskRc0lyxFySHFWUXJZ0HGnQ08up5DQaDS5dulTgrOZEhsJcklwxmyRHzCXJEXNJcmRsueSgm4iIiIiIiKiccNBNREREREREVE446K4gFAoFLCwsZH1NA718mEuSK2aT5Ii5JDliLkmOjC2XnEgNFWMiNSIiIiIiIpIPTqRmZLRaLe7evQutVmvophBJmEuSK2aT5Ii5JDliLkmOjC2XHHRXEFqtFleuXDGa4JFxYC5JrphNkiPmkuSIuSQ5MrZcctBNREREREREVE446CYiIiIiIiIqJxx0VxAKhQJ2dnZGM4MfGQfmkuSK2SQ5Yi5JjphLkiNjyyVnLwdnLyciIiIiIqLS4ezlRkar1eL69etGM5kAGQfmkuSK2SQ5Yi5JjphLkiNjyyUH3RWEsQWPjANzSXLFbJIcMZckR8wlyZGx5ZKDbiIiIiIiIqJywkE3ERERERERUTnhoLuCUCqVcHJyglLJXUbywVySXDGbJEfMJckRc0lyZGy55Ozl4OzlREREREREVDqcvdzIaLVaJCQkGM1kAmQcmEuSK2aT5Ii5JDliLkmOjC2XHHRXEFqtFvfu3TOa4JFxYC5JrphNkiPmkuSIuSQ5MrZcctBNREREREREVE446CYiIiIiIiIqJxx0VxBKpRLu7u5GM4MfGQfmkuSK2SQ5Yi5JjphLkiNjyyVnLwdnLyciIiIiIqLS4ezlRkaj0eDixYvQaDSGbgqRhLkkuWI2SY6YS5Ij5pLkyNhyaWLoBshJ9uNsZKuy9cqVKiVMzE106hVGoVSgkkWlZ6qb8yQHhZ14oNFokJqaKi0vqq5CoUAly3zrzciB0BZ+QoOplekz1VVnqqHVFD6jYGnqVrKsBIVCkVs3Sw2tuozqWlSCQplbV5OtgSan8A9uaeqamJtAqVKWvm6OBprsIuqamUBpUvq6WrUW6ix1oXVVpiqoKqlKX1ejhTqz8LpCIaRcFldXVUkFlWnueoVWICcjp0zqKk2UMDHL/XwKIZDzpIzqluJzL4fvCL3P/Uv+HSFEbjZzMnOgQdl87vkdUUDdUnzu+R1hIuUyKz0LJiYF/wnG74hnq8u/I/6/7jN8RwghkPwguchc8jviGery7wjJs3xHCCHw8O5DZLkWnks5fEcU1Zf8OOjOZ5HrIpjDXK+8zpt1MGTXEOn5t87fFvoh8+zkieHhw6XnS2ssxZP7Twqs69rSFaOjRkvP/9PwP0i9mlpg3SoNq6DFTy2k52tarcG9C/cKrGvnaYePkj6Snod0DMHN6JsF1rWsYonJ9yZLzzd034Crh64WWLeSZSXMeDxDer6532bE/RlXYF0AmCVmSf+//d3tuBB6odC609OnSx+cnWN2IubnmELrfnr3U1g5WQEA9k7ai+jl0YXWnZg4EfY17AEA+z/bj2PfHiu07ofnPoRzI2cAQMS8CBwKOlRo3feOvwe3Vm4AgL+X/o2wKWGF1g04GIAanWsAAE6sPoHd43cXWnfwzsGo+1ZdAMDZDWexY8SOQuv239wfjQY0AgBc3H4RoQNDC63bK7gXmg5vCgCI3xuP33r8Vmjd7j90R+txrQEA1yKu4Wefnwut+/rXr6NSp9wv3Vsnb+HH1j8WWrfTrE7oPLszAODexXtY0XhFoXXbftoW3RZ2AwCkXkvF0ppLC63bcmxLvPWftwAAT+4/wbfO3xZa95WAV9A7pDeA3H9M5lvPL7Ruw/4NMWDLAOl5UXXl8B3h1NAJY8+PlZ6/7N8RZpXNAABhn4bhxMoThdbld0Su8vqO6PpNV7Sb3A4AvyPyf0cscV3C7wjw7wg5fUfcPXQXCzssLLQuvyNy8e+IXC/qO+L0jNMIO1r4Z0MO3xEjzowodFl+PL2ciIiIiIiIqJxwIjX87wL4ezfvFXgBvBxO+RBCIPVJKqpUqQKlUmnwUz4AnhYml9PCAMOdOqpQKZCclowqVaoAAjwtrAR1X5bTwgDDn15+//592NvYA4VX5XfE/+Opo89Q9xm+I7RaLe7fvw9bC9tCZ+Tld8Sz1eXfEf9f9xm+I7RaLe7evgt7G/tCc8nviGeoy78jJM/yHaHVanH7+m04VHYoNJdy+I7IyMmAfWX7YidS46AbnL2ciIiIiIiISoezlxsZjUaDmJgYo5nBj4wDc0lyxWySHDGXJEfMJcmRseXS4IPuGzduYOjQoXB0dISFhQWaNGmC6Ojci9VzcnIwdepUNGnSBFZWVnB1dcWwYcNw86buhfo1atSAQqHQeXz99deG6E65EUIgIyOj0NM8iAyBuSS5YjZJjphLkiPmkuTI2HJp0NnLk5OT0a5dO/j4+GD37t1wcnJCXFwcKleuDAB48uQJTp48iS+++AKvvPIKkpOTMXHiRLz99tvSwDzPnDlzMHr0/2bns7GxeaF9ISIiIiIiInqaQQfdCxYsgIeHB4KDg6WymjVrSv9vZ2eHffv26bzmhx9+QOvWrXHt2jVUr15dKrexsUHVqlXLv9FEREREREREJWTQidQaNmwIX19fXL9+HYcOHYKbmxvGjh2rc8T6aWFhYejWrRtSUlKki9Vr1KiBzMxM5OTkoHr16hgyZAg+/vjjQm+knpWVhaysLOl5WloaPDw88ODBA2mdSqUSSmXujI5a7f9mrMsr12g0Oqc7FFauUqmgUCigVuvOxqhS5c6o+PR1CkWVp6SkwNraWppNT6FQQKVS6bWxsHK59cnExARCCJ1y9qli9Umj0UifxbxLOyp6n4xxP72MfRJCIC0tDfb29kX2tSL16ek2sk8Vr09CCDx69AiVK1eWclrR+1RU29mnitEnhUKBR48ewdraWq+NFbVPxrifXrY+AcDDhw+lvzHl2qfk5GQ4ODgUO5GaQY90X7lyBStWrMCkSZMwY8YMREVFITAwEKampggICNCrn5mZialTp2Lw4ME6nQoMDETz5s3h4OCAo0ePYvr06bh16xYWL15c4Hbnz5+PoKAgvfJTp07Byir3RuhOTk6oVasWEhMTce/e/24M7+7uDnd3d1y+fBmpqf+7ubyXlxecnZ1x7tw5ZGRkSOX169eHvb09Tp06pbPDvb29YWpqqneafMuWLZGdnY0zZ85IZSqVCq1atYJCocCJEyekcgsLC7zyyiu4f/8+rly5IpXb2dmhQYMGuHnzJq5fvy6Vy7FPqampuHTpEvtUQfv04MEDo+uTMe4n9ol9Yp/k1ScHBwej65Mx7qeXrU8xMTFG1ydj3E8vU5+uXLki+z7Fx8ejJAx6pNvU1BQtW7bE0aNHpbLAwEBERUXh2LFjOnVzcnLQr18/XL9+HeHh4UX+krB27VqMGTMG6enpMDMz01teEY90A8DJkyfxyiuvSHX4ixr7ZOg+ZWdn49SpU2jatKm0vYreJ2PcTy9jnzQaDU6fPo1mzZrB1NTUKPr0dBvZp4rXJ40mdzbe5s2bQ6FQGEWfimo7+1Qx+qTVahETEwNvb2+pXRW9T8a4n162Pmk0Gpw4cUL6G1OufaoQR7qrVauGhg0b6pQ1aNAAW7du1SnLycnBwIEDcfXqVRw4cKDYe2m3adMGarUaSUlJqFevnt5yMzOzAgfjJiYmeqek572hT8v/pVSS8sJOdS9puVqthlarhUqlKnEbS1v+ovsE5Aa8oHL2qeL0SQihl8uK3idj3E8vY5+EENL/G0ufSlLOPsm7T3l/tBlTn/KwTxWzT2q1GhqNpsC/MUvb9sLKuZ/YJ6D0fSrob8zC2l5YuaH6pNe2EtUqJ+3atUNsbKxO2eXLl+Hp6Sk9zxtwx8XF4eDBg3B0dCx2vadPn4ZSqYSzs3OZt5mIiIiIiIiopAw66P7444/x2muvYd68eRg4cCCOHz+O1atXY/Xq1QByB9z9+/fHyZMnsXPnTmg0Gty+fRsA4ODgAFNTUxw7dgz//PMPfHx8YGNjg2PHjuHjjz/G0KFDpVuPERERERERERmCQa/pBoCdO3di+vTpiIuLQ82aNTFp0iRp9vKkpCSdW4jld/DgQXTu3BknT57E2LFjcenSJWRlZaFmzZp49913MWnSpAJPIS9IWloa7Ozsij0X35DybhBvYWEhzeBHZGjMJckVs0lyxFySHDGXJEcVJZclHUcafNAtBxVl0J13vY2cg0cvF+aS5IrZJDliLkmOmEuSo4qSy5KOI/WvBidZ0mg0iI6OLnBWcyJDYS5JrphNkiPmkuSIuSQ5MrZcctBNREREREREVE446CYiIiIiIiIqJxx0ExEREREREZUTTqQGTqRG9KyYS5IrZpPkiLkkOWIuSY4qSi45kZoRys7ONnQTiPQwlyRXzCbJEXNJcsRckhwZUy456K4gNBoNzpw5YzQz+JFxYC5JrphNkiPmkuSIuSQ5MrZcctBNREREREREVE446CYiIiIiIiIqJxx0VyAqlcrQTSDSw1ySXDGbJEfMJckRc0lyZEy55OzlqBizlxMREREREZF8cPZyIyOEQEpKCvgbCckJc0lyxWySHDGXJEfMJcmRseWSg+4KQqPR4NKlS0Yzgx8ZB+aS5IrZJDliLkmOmEuSI2PLJQfdREREREREROWEg24iIiIiIiKicsJBdwWhUChgYWEBhUJh6KYQSZhLkitmk+SIuSQ5Yi5Jjowtl5y9HJy9nIiIiIiIiEqHs5cbGa1Wi7t370Kr1Rq6KUQS5pLkitkkOWIuSY6YS5IjY8slB90VhFarxZUrV4wmeGQcmEuSK2aT5Ii5JDliLkmOjC2XHHQTERERERERlRMOuomIiIiIiIjKCQfdFYRCoYCdnZ3RzOBHxoG5JLliNkmOmEuSI+aS5MjYcsnZy8HZy4mIiIiIiKh0OHu5kdFqtbh+/brRTCZAxoG5JLliNkmOmEuSI+aS5MjYcslBdwVhbMEj48BcklwxmyRHzCXJEXNJcmRsueSgm4iIiIiIiKiccNBNREREREREVE446K4glEolnJycoFRyl5F8MJckV8wmyRFzSXLEXJIcGVsuOXs5OHs5ERERERERlQ5nLzcyWq0WCQkJRjOZABkH5pLkitkkOWIuSY6YS5IjY8ulwQfdN27cwNChQ+Ho6AgLCws0adIE0dHR0nIhBGbOnIlq1arBwsICXbt2RVxcnM46Hj58CH9/f9ja2sLe3h6jRo1Cenr6i+5KudJqtbh3757RBI+MA3NJcsVskhwxlyRHzCXJkbHl0qCD7uTkZLRr1w6VKlXC7t27ceHCBSxatAiVK1eW6nzzzTdYtmwZVq5ciX/++QdWVlbw9fVFZmamVMff3x/nz5/Hvn37sHPnThw+fBjvv/++IbpEREREREREJDEx5MYXLFgADw8PBAcHS2U1a9aU/l8IgSVLluDzzz9Hr169AADr1q2Di4sLfv/9dwwaNAgXL17Enj17EBUVhZYtWwIAvv/+e7z55pv49ttv4erq+mI7RURERERERPT/DDro/u9//wtfX18MGDAAhw4dgpubG8aOHYvRo0cDABITE3H79m107dpVeo2dnR3atGmDY8eOYdCgQTh27Bjs7e2lATcAdO3aFUqlEv/88w/69Omjt92srCxkZWVJz9PS0gAAarUaarUaQO6MeUqlElqtVue0hrxyjUaD/HPQFVauUqmgUCik9eYvBwCNRlOicqVSCTc3N2i1WmldCoUCKpVKr42FlcutTyYmJhBC6JSzTxWrTwDg6uoq5dIY+mSM++ll7JNWq9X50dUY+vR0G9mnitcnrVYLNzc3o+pTUW1nnypGnwDA3d0dQgid9lfkPhnjfnrZ+qRUKnX+xpRzn0rCoIPuK1euYMWKFZg0aRJmzJiBqKgoBAYGwtTUFAEBAbh9+zYAwMXFRed1Li4u0rLbt2/D2dlZZ7mJiQkcHBykOk+bP38+goKC9MpPnToFKysrAICTkxNq1aqFxMRE3Lt3T6rj7u4Od3d3XL58GampqVK5l5cXnJ2dce7cOWRkZEjl9evXh729PU6dOqWzU7y9vWFqaqpz/ToAtGzZEtnZ2Thz5oxUplKp0KpVK9jY2ODkyZNSuYWFBV555RXcv38fV65ckcrt7OzQoEED3Lx5E9evX5fK5din1NRUXLp0iX2qoH16+PAhbt68iZs3bxpNn4xxP73MfcrJyTG6PhnjfnrZ+qRUKnHx4kWj6pMx7qeXqU/u7u6IiYkxqj4Z43562fp0584d6W9MufYpPj4eJWHQW4aZmpqiZcuWOHr0qFQWGBiIqKgoHDt2DEePHkW7du1w8+ZNVKtWTaozcOBAKBQKbNq0CfPmzcPPP/+M2NhYnXU7OzsjKCgIH374od52CzrS7eHhgQcPHkhTvcvt1yeFQoHY2FjUrl1bul8df1Fjnwzdp5ycHFy+fBl16tSBUqk0ij4Z4356Gfuk1WoRFxeHunXrolKlSkbRp6fbyD5VvD5ptVrEx8ejXr16AGAUfSqq7exTxeiTEALx8fGoVauW9DdmRe+TMe6nl61PWq0Wly5dkv7GlGufkpOT4eDgUOwtwwx6pLtatWpo2LChTlmDBg2wdetWAEDVqlUBAHfu3NEZdN+5cwdNmzaV6ty9e1dnHWq1Gg8fPpRe/zQzMzOYmZnplZuYmMDERPctyXtDn5a3c0ta/vR6S1uuVquRlpYGpVJZ4jaWtvxF9wnIDXhB5exTxeiTQqHAo0eP9HJZkftkjPvpZeyTWq3Go0ePoFAoiqxfkfpU0nL2Sb59yvu3XAhRaFsqWp/yM5b9lN/L0Ce1Wo3U1NQC/8YsbdsLK+d+Yp+A0vVJCFHg35iFtb2wckP1Se/1JapVTtq1a6d3hPry5cvw9PQEkDupWtWqVbF//35peVpaGv755x+0bdsWANC2bVukpKTgxIkTUp0DBw5Aq9WiTZs2L6AXRERERERERAUz6JHujz/+GK+99hrmzZuHgQMH4vjx41i9ejVWr14NIPeXiY8++ghffvkl6tSpg5o1a+KLL76Aq6srevfuDSD3yLifnx9Gjx6NlStXIicnB+PHj8egQYM4czkREREREREZlEEH3a1atcL27dsxffp0zJkzBzVr1sSSJUvg7+8v1ZkyZQoeP36M999/HykpKWjfvj327NkDc3Nzqc6GDRswfvx4dOnSBUqlEv369cOyZcsM0aVyo1Qq4eXlVeBpDUSGwlySXDGbJEfMJckRc0lyZGy5NOhEanKRlpYGOzu7Yi+AJyIiIiIiIgJKPo40jp8OXgIajQYxMTElvhcc0YvAXJJcMZskR8wlyRFzSXJkbLnkoLuCEEIgIyMDPDGB5IS5JLliNkmOmEuSI+aS5MjYcslBNxEREREREVE54aCbiIiIiIiIqJxw0F1BqFQq1K9fv8Q3YCd6EZhLkitmk+SIuSQ5Yi5Jjowtlwa9ZRiVnEKhgL29vaGbQaSDuSS5YjZJjphLkiPmkuTI2HLJI90VhFqtRlRUFNRqtaGbQiRhLkmumE2SI+aS5Ii5JDkytlxy0F2BGMuU+WRcmEuSK2aT5Ii5JDliLkmOjCmXHHQTERERERERlRMOuomIiIiIiIjKiUIYyx3Hn0NaWhrs7OyQmpoKW1tbQzenQHk3iLewsIBCoTB0c4gAMJckX8wmyRFzSXLEXJIcVZRclnQcySPdFYipqamhm0Ckh7kkuWI2SY6YS5Ij5pLkyJhyyUF3BaHRaBAdHW1UEwpQxcdcklwxmyRHzCXJEXNJcmRsueSgm4iIiIiIiKiccNBNREREREREVE446CYiIiIiIiIqJ5y9HBVn9nKNRgOVSiXrGfzo5cJcklwxmyRHzCXJEXNJclRRcsnZy41Qdna2oZtApIe5JLliNkmOmEuSI+aS5MiYcslBdwWh0Whw5swZo5nBj4wDc0lyxWySHDGXJEfMJcmRseWSg24iIiIiIiKicsJBNxEREREREVE54aC7AlGpVIZuApEe5pLkitkkOWIuSY6YS5IjY8olZy9HxZi9nIiIiIiIiOSDs5cbGSEEUlJSwN9ISE6YS5IrZpPkiLkkOWIuSY6MLZccdFcQGo0Gly5dMpoZ/Mg4MJckV8wmyRFzSXLEXJIcGVsuOegmIiIiIiIiKiccdBMRERERERGVEw66KwiFQgELCwsoFApDN4VIwlySXDGbJEfMJckRc0lyZGy55Ozl4OzlREREREREVDoVYvby2bNnQ6FQ6Dzq168PAEhKStJblvfYsmWLtI6Clm/cuNFQXSo3Wq0Wd+/ehVarNXRTiCTMJckVs0lyxFySHDGXJEfGlksTQzegUaNGCAsLk56bmOQ2ycPDA7du3dKpu3r1aixcuBDdu3fXKQ8ODoafn5/03N7evvwabCBarRZXrlyBg4MDlEpeFUDywFySXDGbJEfMJckRc0lyZGy5NPig28TEBFWrVtUrV6lUeuXbt2/HwIEDYW1trVNub29f4DqIiIiIiIiIDMngPxvExcXB1dUVXl5e8Pf3x7Vr1wqsd+LECZw+fRqjRo3SWzZu3DhUqVIFrVu3xtq1a43mJupERERERERUsRn0SHebNm0QEhKCevXq4datWwgKCkKHDh1w7tw52NjY6NT96aef0KBBA7z22ms65XPmzMHrr78OS0tL/PXXXxg7dizS09MRGBhY6HazsrKQlZUlPU9LSwMAqNVqqNVqAIBSqYRSqYRWq9W5liCvXKPR6AzuCytXqVRQKBTSevOXA9C74Xth5QqFAra2ttBqtdK6FAoFVCqVXhsLK5dbn0xMTCCE0ClnnypWn4QQsLGxkXJpDH0yxv30MvZJq9XCxsZGapcx9OnpNrJPFa9PWq0Wtra2UCgURtOnotrOPlWMPgkhYGdnp/M3ZkXvkzHup5exT/n/xpRzn0rCoIPu/Ndme3t7o02bNvD09MTmzZt1jmhnZGTg119/xRdffKG3jvxlzZo1w+PHj7Fw4cIiB93z589HUFCQXvmpU6dgZWUFAHByckKtWrWQmJiIe/fuSXXc3d3h7u6Oy5cvIzU1VSr38vKCs7Mzzp07h4yMDKm8fv36sLe3x6lTp3R2ire3N0xNTREdHa3ThpYtWyI7OxtnzpyRylQqFVq1agVXV1ecPHlSKrewsMArr7yC+/fv48qVK1K5nZ0dGjRogJs3b+L69etSuRz7lJqaikuXLrFPFbRPycnJePTokZRLY+iTMe6nl7lP165dM7o+GeN+etn6pFKpcPHiRaPqkzHup5epTw0aNEBMTIxR9ckY99PL1qcnT57ojH3k2Kf4+HiUhOxuGdaqVSt07doV8+fPl8rWr1+PUaNG4caNG3Byciry9bt27UKPHj2QmZkJMzOzAusUdKTbw8MDDx48kKZ6l9uvT0qlEjdu3ICLi4s0mYChf30yxl/U2KfS9UmtVuPmzZuoWrUqlEqlUfTJGPfTy9gnrVaL27dvw9XVFSYmJkbRp6fbyD5VvD5ptVrcuXMHbm5uEEIYRZ+Kajv7VDH6BAC3b9+Gi4uLzj2RK3KfjHE/vWx9EkLg+vXr0t+Ycu1TcnIyHBwcir1lmMEnUssvPT0dCQkJePfdd3XKf/rpJ7z99tvFDrgB4PTp06hcuXKhA24AMDMzK3C5iYmJNHt6nrw39Gl5O7ek5U+vt7TlarUaN27cQLVq1UrcxtKWv+g+AbkBL6icfaoYfQKAmzdvSgObPBW5T8a4n17GPuX9IOTq6lpk/YrUp5KWs0/y7VNR/5bnqWh9ys9Y9lN+L0Of1Gq1NLgpaLsVsU/FlbNP8u+TRqMp8G/MwtpeWLmh+qTXthLVKieffvopevbsCU9PT9y8eROzZs2CSqXC4MGDpTrx8fE4fPgw/vzzT73X//HHH7hz5w5effVVmJubY9++fZg3bx4+/fTTF9kNIiIiIiIiogIZdNB9/fp1DB48GA8ePICTkxPat2+Pv//+W+eI9tq1a+Hu7o5u3brpvb5SpUr4z3/+g48//hhCCNSuXRuLFy/G6NGjX2Q3iIiIiIiIiAoku2u6DSEtLQ12dnbFnotvSFqtFomJiahZs2aBpzYQGQJzSXLFbJIcMZckR8wlyVFFyWVJx5EcdKNiDLqJiIiIiIhIPko6jpTvzwakQ6vVIiEhQWfWPCJDYy5JrphNkiPmkuSIuSQ5MrZcctBdQWi1Wty7d89ogkfGgbkkuWI2SY6YS5Ij5pLkyNhyyUE3ERERERERUTnhoJuIiIiIiIionHDQXUEolUq4u7vLevY+evkwlyRXzCbJEXNJcsRckhwZWy45ezk4ezkRERERERGVDmcvNzIajQYXL16ERqMxdFOIJMwlyRWzSXLEXJIcMZckR8aWSw66KwghBFJTU8ETE0hOmEuSK2aT5Ii5JDliLkmOjC2XHHQTERERERERlRMOuomIiIiIiIjKCQfdFYRSqYSXl5fRzOBHxoG5JLliNkmOmEuSI+aS5MjYcsnZy8HZy4mIiIiIiKh0OHu5kdFoNIiJiTGaGfzIODCXJFfMJskRc0lyxFySHBlbLjnoriCEEMjIyDCaGfzIODCXJFfMJskRc0lyxFySHBlbLjnoJiIiIiIiIionHHQTERERERERlRMOuisIlUqF+vXrQ6VSGbopRBLmkuSK2SQ5Yi5JjphLkiNjy6WJoRtAJaNQKGBvb2/oZhDpYC5JrphNkiPmkuSIuSQ5MrZc8kh3BaFWqxEVFQW1Wm3ophBJmEuSK2aT5Ii5JDliLkmOjC2XHHRXIMYyZT4ZF+aS5IrZJDliLkmOmEuSI2PKJQfdREREREREROWEg24iIiIiIiKicqIQxnLH8eeQlpYGOzs7pKamwtbW1tDNKVDeDeItLCygUCgM3RwiAMwlyRezSXLEXJIcMZckRxUllyUdR/JIdwViampq6CYQ6WEuSa6YTZIj5pLkiLkkOTKmXHLQXUFoNBpER0cb1YQCVPExlyRXzCbJEXNJcsRckhwZWy456CYiIiIiIiIqJxx0ExEREREREZUTDrqJiIiIiIiIyglnL0fFmb1co9FApVLJegY/erkwlyRXzCbJEXNJcsRckhxVlFxWiNnLZ8+eDYVCofOoX7++tLxz5856yz/44AOddVy7dg1vvfUWLC0t4ezsjMmTJ0OtVr/orrwQ2dnZhm4CkR7mkuSK2SQ5Yi5JjphLkiNjyqXBTy9v1KgRbt26JT2OHDmis3z06NE6y7/55htpmUajwVtvvYXs7GwcPXoUP//8M0JCQjBz5swX3Y1yp9FocObMGaOZwY+MA3NJcsVskhwxlyRHzCXJkbHl0sTgDTAxQdWqVQtdbmlpWejyv/76CxcuXEBYWBhcXFzQtGlTzJ07F1OnTsXs2bON6t5uREREREREVPEY/Eh3XFwcXF1d4eXlBX9/f1y7dk1n+YYNG1ClShU0btwY06dPx5MnT6Rlx44dQ5MmTeDi4iKV+fr6Ii0tDefPn39hfSAiIiIiIiIqiEGPdLdp0wYhISGoV68ebt26haCgIHTo0AHnzp2DjY0NhgwZAk9PT7i6uuLMmTOYOnUqYmNjsW3bNgDA7du3dQbcAKTnt2/fLnS7WVlZyMrKkp6npaUBANRqtXQ9uFKphFKphFarhVarlermlWs0GuSfg66w8ryL/5++zlylUgGA3ikThZXnbSN/uUKhgEql0mtjYeVy65OJiYk0SQL7VHH7pFAopGXG0idj3E8vW580Gg0UCoVUxxj69HQb2aeK1yeNRgOlUin9vzH0qai2s08Vo09arRYqlarANlbUPhnjfnrZ+pS3nfztkWufSsKgg+7u3btL/+/t7Y02bdrA09MTmzdvxqhRo/D+++9Ly5s0aYJq1aqhS5cuSEhIQK1atZ55u/Pnz0dQUJBe+alTp2BlZQUAcHJyQq1atZCYmIh79+5Jddzd3eHu7o7Lly8jNTVVKvfy8oKzszPOnTuHjIwMqbx+/fqwt7fHqVOndHaKt7c3TE1NER0drdOGli1bIjs7G2fOnJHKVCoVWrVqhbp16+LUqVNSuYWFBV555RXcv38fV65ckcrt7OzQoEED3Lx5E9evX5fK5din1NRUXLp0iX2qoH1KSUmBEELKpTH0yRj308vcp3///dfo+mSM++ll65OJiQkuXrxoVH0yxv30MvWpVatWiImJMao+GeN+etn6pFQqdcY+cuxTfHw8SkJ2twxr1aoVunbtivnz5+ste/z4MaytrbFnzx74+vpi5syZ+O9//4vTp09LdRITE+Hl5YWTJ0+iWbNmBW6joCPdHh4eePDggTTVu9x+fVKpVEhJSYG1tbU0bT5/UWOfDN0njUaDlJQU2NraSncYqOh9Msb99DL2SQiBtLQ02NvbF9nXitSnp9vIPlW8Pgkh8OjRI1SuXFnKaUXvU1FtZ58qRp8UCgUePXoEa2trvTZW1D4Z43562foEAA8fPpT+xpRrn5KTk+Hg4FDsLcNkNehOT09H9erVMXv2bAQGBuotj4yMRPv27RETEwNvb2/s3r0bPXr0wK1bt+Ds7AwAWL16NSZPnoy7d+/CzMysRNutCPfpVqvViI6ORsuWLWFiYvD574gAMJckX8wmyRFzSXLEXJIcVZRcVoj7dH/66ac4dOgQkpKScPToUfTp0wcqlQqDBw9GQkIC5s6dixMnTiApKQn//e9/MWzYMHTs2BHe3t4AgG7duqFhw4Z49913ERMTg7179+Lzzz/HuHHjSjzgJiIiIiIiIiovBv3Z4Pr16xg8eDAePHgAJycntG/fHn///TecnJyQmZmJsLAwLFmyBI8fP4aHhwf69euHzz//XHq9SqXCzp078eGHH6Jt27awsrJCQEAA5syZY8BeEREREREREeUy6KB748aNhS7z8PDAoUOHil2Hp6cn/vzzz7JsliwpFApYWFhI1zQQyQFzSXLFbJIcMZckR8wlyZGx5VJW13QbSkW4ppuIiIiIiIjko0Jc000lp9VqcffuXZ1Z84gMjbkkuWI2SY6YS5Ij5pLkyNhyyUF3BaHVanHlyhWjCR4ZB+aS5IrZJDliLkmOmEuSI2PLJQfdREREREREROWEg24iIiIiIiKiclLqQffJkydx9uxZ6fmOHTvQu3dvzJgxA9nZ2WXaOPofhUIBOzs7o5nBj4wDc0lyxWySHDGXJEfMJcmRseWy1IPuMWPG4PLlywCAK1euYNCgQbC0tMSWLVswZcqUMm8g5VKpVGjQoAFUKpWhm0IkYS5JrphNkiPmkuSIuSQ5MrZclnrQffnyZTRt2hQAsGXLFnTs2BG//vorQkJCsHXr1rJuH/0/rVaL69evG81kAmQcmEuSK2aT5Ii5JDliLkmOjC2XpR50CyGkzoeFheHNN98EAHh4eOD+/ftl2zqSGFvwyDgwlyRXzCbJEXNJcsRckhwZWy5LPehu2bIlvvzyS6xfvx6HDh3CW2+9BQBITEyEi4tLmTeQiIiIiIiIqKIq9aB7yZIlOHnyJMaPH4/PPvsMtWvXBgCEhobitddeK/MGEhEREREREVVUJqV9gbe3t87s5XkWLlxoNBe6y5FSqYSTkxOUSt7ljeSDuSS5YjZJjphLkiPmkuTI2HKpEEKI0r4oJSUFoaGhSEhIwOTJk+Hg4ICTJ0/CxcUFbm5u5dHOcpWWlgY7OzukpqbC1tbW0M0hIiIiIiIimSvpOLLUPx2cOXMGderUwYIFC/Dtt98iJSUFALBt2zZMnz79mRtMRdNqtUhISDCayQTIODCXJFfMJskRc0lyxFySHBlbLks96J40aRJGjBiBuLg4mJubS+VvvvkmDh8+XKaNo//RarW4d++e0QSPjANzSXLFbJIcMZckR8wlyZGx5bLUg+6oqCiMGTNGr9zNzQ23b98uk0YRERERERERGYNSD7rNzMyQlpamV3758mU4OTmVSaOIiIiIiIiIjEGpZy9/++23MWfOHGzevBkAoFAocO3aNUydOhX9+vUr8wZSLqVSCXd3d6OZwY+MA3NJcsVskhwxlyRHSqUSbm5u0Gg0UKvVhm4OEYDc08urVq2K7Oxsg+ZSpVLBxMQECoXiudZT6tnLU1NT0b9/f0RHR+PRo0dwdXXF7du30bZtW/z555+wsrJ6rgYZAmcvJyIiIqKXUXZ2Nm7duoUnT54YuilEsmRpaYlq1arB1NRUb1lJx5GlPtJtZ2eHffv24ciRIzhz5gzS09PRvHlzdO3atbSrolLQaDS4fPky6taty/uhk2wwlyRXzCbJEXNJcqPVanHlyhUAgKurK0xNTZ/7iB5RWRBCICsrC2ZmZgbLpBAC2dnZuHfvHhITE1GnTp1nPlOp1IPuf//9Fx4eHmjfvj3at2//TBul0hNCIDU1Fc9wW3WicsNcklwxmyRHzCXJTXZ2NrRaLZydnWFra8sBN8mGEAIajQbm5uYGzaWFhQUqVaqEq1evIjs7W+fuXaVR6qF6jRo10KlTJ6xZswbJycnPtFEiIiIiIpIHDraJClcW83CUeg3R0dFo3bo15syZg2rVqqF3794IDQ1FVlbWczeGiIiIiIiIyJiUetDdrFkzLFy4ENeuXcPu3bvh5OSE999/Hy4uLhg5cmR5tJGQ+wuLl5cXZzwlWWEuSa6YTZIj5pLkqqAJooxZSEgI7O3tDd0Mgxs+fDh69+5t6GYUyszMzNBNKDPP/K2vUCjg4+ODNWvWICwsDDVr1sTPP/9clm2jfJRKJZydnfkPNckKc0lyxWySHDGXJEcKhQKVKlV67lPMNRoNwsPD8dtvvyE8PBwajaaMWliw4cOHQ6FQ6D3i4+PLdbslERISAoVCAT8/P53ylJQUKBQKhIeHv9D2JCUlQaFQ4PTp0zrlS5cuRUhIyAttS37btm3DG2+8AScnJ9ja2qJt27bYu3cvgP/lcsSIEXo/DISGhsLc3ByLFi0yQKufzTN/61+/fh3ffPMNmjZtitatW8Pa2hr/+c9/yrJtlI9Go0FMTEy5f4ERlQZzSXLFbJIcMZckR0IIZGRkPNcEf9u2bUONGjXg4+ODIUOGwMfHBzVq1MC2bdvKsKX6/Pz8cOvWLZ1HzZo1y3WbJWViYoKwsDAcPHjQ0E0plJ2dnUGP+B8+fBhvvPEG/vzzT5w4cQI+Pj7o2bMnTp06BSFEgbex+/HHH+Hv748VK1bgk08+MUCrn02pB92rVq1Cp06dUKNGDaxbtw7vvPMOEhISEBERgQ8++KA82kgomy9EorLGXJJcMZskR8wlyZVWq33m127btg39+/fH9evXdcpv3LiB/v37l+vA28zMDFWrVtV5qFQqLF68GE2aNIGVlRU8PDwwduxYpKenF7qemJgY+Pj4wMbGBra2tmjRogWio6Ol5UeOHEGHDh1gYWEBDw8PBAYG4vHjx0W2zcrKCiNHjsS0adOKrPfvv/9i4MCBsLe3h4ODA3r16oWkpCRpuVqtRmBgIOzt7eHo6IipU6ciICBA5+jvnj170L59e6lOjx49kJCQIC3P+yGiWbNmUCgU6Ny5MwDd08tXr14NV1dXvSz06tVL5xLiHTt2oHnz5jA3N4eXlxeCgoKgVqsB5H7HzZ49G9WrV4eZmRlcXV0RGBhYaN+XLFmCKVOmoFWrVqhTpw7mzZuHOnXq4I8//gCgn8tvvvkGEyZMwMaNGzFixIgi31e5KfWg+8svv0SbNm1w4sQJnDt3DtOnT4enp2d5tI2IiIiIiF4gIQQeP35cokdaWhoCAwML/CEpr2zixIlIS0sr0frK6gcppVKJZcuW4fz58/j5559x4MABTJkypdD6/v7+cHd3R1RUFE6cOIFp06ahUqVKAICEhAT4+fmhX79+OHPmDDZt2oQjR45g/PjxxbZj9uzZOHv2LEJDQwtcnpOTA19fX9jY2CAiIgKRkZGwtraGn58fsrOzAQALFizAhg0bEBwcjMjISKSlpeH333/XWc/jx48xadIkREdHY//+/VAqlejTp480aD1+/DgAICwsDLdu3Srwh5ABAwbgwYMHOkfmHz58iD179sDf3x8AEBERgWHDhmHixIm4cOECVq1ahZCQEHz11VcAgK1bt+K7777DqlWrEBcXh99//x1NmjQp9n3Ko9Vq8ejRIzg4OOgtmzp1KubOnYudO3eiT58+JV6nbIhS0mq1pX2J7KWmpgoAIjU11dBNKVROTo44duyYyMnJMXRTiCTMJckVs0lyxFyS3GRkZIjz58+L+/fvS3/jp6enCwAGeaSnp5e47QEBAUKlUgkrKyvp0b9//wLrbtmyRTg6OkrPg4ODhZ2dnfTcxsZGhISEFPjaUaNGiffff1+nLCIiQiiVSpGRkVHga/Kvf9q0aaJu3boiJydHJCcnCwDi4MGDQggh1q9fL+rVq6czvsrKyhIWFhZi7969QgghXFxcxMKFC6XlarVaVK9eXfTq1avAbQshxL179wQAcfbsWSGEEImJiQKAOHXqlE69gIAAnfX06tVLjBw5Unq+atUq4erqKjQajRBCiC5duoh58+bprGP9+vWiWrVqQgghFi1aJOrWrSuys7MLbVtRFixYICpXrizu3LkjtFqtePTokQgICBCmpqYCgNi/f/8zrfd5ZWRkiAsXLhS4v0s6jizRke4zZ85Iv5ScPXsWZ86cKfRB5UOlUqF+/fpQqVSGbgqRhLkkuWI2SY6YS5IjhUJRYWeJ9vHxwenTp6XHsmXLAOQe0e3SpQvc3NxgY2ODd999Fw8ePCjwGmEAmDRpEt577z107doVX3/9tc6p2TExMQgJCYG1tbX08PX1hVarRWJiYrFtnDp1Ku7du4e1a9fqLYuJiUF8fDxsbGykdTs4OCAzMxMJCQlITU3FnTt30Lp1a+k1KpUKLVq00FlPXFwcBg8eDC8vL9ja2qJGjRoAgGvXrhXbvvz8/f2xdetW6VbQGzZswKBBg6TJH2NiYjBnzhyd92L06NG4desWnjx5ggEDBiAjIwNeXl4YPXo0tm/fLp16Xpxff/0VQUFB2Lx5M5ydnQEA5ubmAABvb2/UqFEDs2bNKvIyATkzKUmlpk2b4vbt23B2dkbTpk2hUCh0Tv/Ie65QKDg5SDlRKBS8tQHJDnNJcsVskhwxlyRXJiYm0uzllpaWJR7YHD58GG+++Wax9f7880907Nix2HqWlpYl2m4eKysr1K5dW6csKSkJPXr0wIcffoivvvoKDg4OOHLkCEaNGoXs7OwCtzF79mwMGTIEu3btwu7duzFr1ixs3LgRffr0QXp6OsaMGVPgtcnVq1cvto329vaYPn06goKC0KNHD51l6enpaNGiBTZs2KD3Oicnp2LXnadnz57w9PTEmjVrpOuyGzduLJ2iXpr1CCGwa9cutGrVChEREfjuu+902hsUFIS+ffvqvdbc3BweHh6IjY1FWFgY9u3bh7Fjx2LhwoU4dOiQdLp+QTZu3Ij33nsPW7ZsQdeuXQHkfl+amOQOVd3c3BAaGgofHx/4+flh9+7dsLGxKVXfDK1Eg+7ExERpx5fkFx0qe2q1GqdOnUKzZs2kABIZGnNJcsVskhwxlyRH4v9niTYzM5Nuu2VlZVWi13br1g3u7u64ceNGgddjKxQKuLu7o1u3bi/sDI8TJ05Aq9Vi0aJF0hHazZs3F/u6unXrom7duvj4448xePBgBAcHo0+fPmjevDkuXLigN7gvjQkTJmDZsmVYunSpTnnz5s2xadMmODs7w9bWtsDXuri4ICoqSvrRQqPR4OTJk2jatCkA4MGDB4iNjcWaNWvQoUMHALkTv+WXdx/24g6Ompubo2/fvtiwYQPi4+NRr149NG/eXKe9sbGxRb4XFhYW6NmzJ3r27Ilx48ahfv36OHv2rM568vvtt98wcuRIbNy4EW+99ZZULp6avdzT0xOHDh2SBt579uypUAPvEp1e7unpKf36dfXqVbi5ucHT01Pn4ebmhqtXr5ZrY192PIuA5Ii5JLliNkmOmEuSo4IGzCWhUqmkgeTT9/nOe75kyZIXeklF7dq1kZOTg++//x5XrlzB+vXrsXLlykLrZ2RkYPz48QgPD8fVq1cRGRmJqKgoNGjQAEDu6eFHjx7F+PHjcfr0acTFxWHHjh0lmkgtj7m5OYKCgqTT3/P4+/ujSpUq6NWrFyIiIpCYmIjw8HAEBgZKs8FPmDAB8+fPx44dOxAbG4uJEyciOTlZen8rV64MR0dHrF69GvHx8Thw4AAmTZqksx1nZ2dYWFhgz549uHPnDlJTUwttq7+/P3bt2oW1a9dKE6jlmTlzJtatW4egoCCcP38eFy9exMaNG/H5558DyL0/+U8//YRz587hypUr+OWXX2BhYVHopNu//vorhg0bhkWLFqFNmza4ffs2bt++LbXv6Vx6eHggPDwcd+/eha+vL9LS0op762Wj1LOX+/j44OHDh3rlqamp8PHxKZNGERERERGR/PXt2xehoaFwc3PTKXd3d0doaGiBpyKXp1deeQWLFy/GggUL0LhxY2zYsAHz588vtL5KpcKDBw8wbNgw1K1bFwMHDkT37t0RFBQEIPd64kOHDuHy5cvo0KEDmjVrhpkzZ8LV1bVU7QoICICXl5dOmaWlJQ4fPozq1aujb9++aNCgAUaNGoXMzEzpyPfUqVMxePBgDBs2DG3btpWuKc+73lmpVGLjxo04ceIEGjdujI8//hgLFy7U2Y6JiQmWLVuGVatWwdXVFb169Sq0na+//jocHBwQGxuLIUOG6Czz9fXFzp078ddff6FVq1Z49dVX8d1330mDant7e6xZswbt2rWDt7c3wsLC8Mcff8DR0bHAba1evRpqtRrjxo1DtWrVpMfEiRMLbZ+7uzvCw8Nx//79CjXwVohS/rSlVCpx584dvesMLl++jJYtW1aYjueXlpYGOzs7pKamFnpqh6Gp1WpER0ejZcuWPCWNZIO5JLliNkmOmEuSm8zMTFy5cgUuLi5wcHDQO1pdGhqNBhEREbh16xaqVauGDh06cNLAcqDVatGgQQMMHDgQc+fONXRzyo34/1vXWVlZPVcuy0JmZiYSExNRs2ZN6ceOPCUdR5b4Gz/vVyqFQoHhw4frzHKo0Whw5swZvPbaa6XtA5WQSqWCt7c3v7xIVphLkitmk+SIuSQ5UigUegOJZ6FSqdC5c+fnbxDpuHr1Kv766y906tQJWVlZ+OGHH5CYmKh3FNoYWVhYGLoJZabEg247OzsAub862NjY6LwJpqamePXVVzF69OiybyFJ8iZBIJIT5pLkitkkOWIuSY7yJhwj+VEqlQgJCcGnn34KIQQaN26MsLAw6ZpzY2ZMuSzxoDs4OBgAUKNGDXz66aclntWQyoZGo+EpaSQ7zCXJFbNJcsRckhzlzRJdFke7qex5eHggMjLS0M0wiLzTy41Bqb/xZ82aVR7tICIiIiIiIjI6JRp0N2/eHPv370flypXRrFmzIi9mP3nyZJk1joiIiIiIiKgiK9Ggu1evXtLEab179y7P9hAREREREREZjVLfMswYVYRbhgkhoNFooFKpDD5tPlEe5pLkitkkOWIuSW7yboVUo0YNmJubM5ckG/mHqIbOZVncMsx4poR7CWRnZxu6CUR6mEuSK2aT5Ii5JDnSarWGbgKRHmPKZakH3RqNBt9++y1at26NqlWrwsHBQedB5SPvXugajcbQTSGSMJckV8wmyRFzSXIkhEBmZqahm0GkJyMjw9BNKDOlHnQHBQVh8eLFeOedd5CamopJkyahb9++UCqVmD17djk0kYiIiIiIqGyEhITA3t7e0M0wuOHDh3O+rhek1IPuDRs2YM2aNfjkk09gYmKCwYMH48cff8TMmTPx999/l0cbiYiIiIhIzjQaIDwc+O233P+W8xkdw4cPh0Kh0HvEx8eX63ZLIiQkBAqFAn5+fjrlKSkpUCgUCA8Pf6HtSUpKgkKhwOnTp3XKly5dipCQkBfalvyOHDmCdu3awdHRERYWFqhfvz6+++47nTojRozQ+2EgNDQU5ubmWLRo0Qts7fMp9X26b9++jSZNmgAArK2tkZqaCgDo0aMHvvjii7JtHelQqVSGbgKRHuaS5IrZJDliLkmOnnuiqm3bgIkTgevX/1fm7g4sXQr07ft86y6Cn58fgoODdcqcnJzKbXulYWJigrCwMBw8eBA+Pj6Gbk6B7OzsDLp9KysrjB8/Ht7e3rCyssKRI0cwZswYWFlZYfTo0QXm8scff8S4ceOwcuVKjBgxwgCtfjalPtLt7u6OW7duAQBq1aqFv/76CwAQFRUl3VaMyp6JiQlatWoFE5NS/05CVG6YS5IrZpPkiLkkOVIoFLC0tHz2gfe2bUD//roDbgC4cSO3fNu2529kIczMzFC1alWdh0qlwuLFi9GkSRNYWVnBw8MDY8eORXp6eqHriYmJgY+PD2xsbGBra4sWLVogOjpaWn7kyBF06NABFhYW8PDwQGBgIB4/flxk26ysrDBy5EhMmzatyHr//vsvBg4cCHt7ezg4OKBXr15ISkqSlqvVagQGBsLe3h6Ojo6YOnUqAgICdI7+7tmzB+3bt5fq9OjRAwkJCdLymjVrAgCaNWsGhUKBzp07A9A9vXz16tVwdXXVm7ysV69eGDlypPR8x44daN68OczNzeHl5YWgoCCo1WoAufMDzJ49G9WrV4eZmRlcXV0RGBhYaN+bNWuGwYMHo1GjRqhRowaGDh0KX19fREREQKFQwMrKSqf+N998gwkTJmDjxo0VasANPMOgu0+fPti/fz8AYMKECfjiiy9Qp04dDBs2TGeHUNkSQiAlJQW8wxvJCXNJcsVskhwxlyRXarX6f7kUAnj8uGSPtDQgMDD3NU/LK5s4MbdeSdZXRp8NpVKJZcuW4fz58/j5559x4MABTJkypdD6/v7+cHd3R1RUFE6cOIFp06ahUqVKAICEhAT4+fmhX79+OHPmDDZt2oQjR45g/PjxxbZj9uzZOHv2LEJDQwtcnpOTA19fX9jY2CAiIgKRkZGwtraGn5+fdKeDBQsWYMOGDQgODkZkZCTS0tLw+++/66zn8ePHmDRpEqKjo7F//34olUr06dNHGkAfP34cABAWFoZbt25hWwE/hAwYMAAPHjzAwYMHpbKHDx9iz5498Pf3BwBERERg2LBhmDhxIi5cuIBVq1YhJCQEX331FQBg69at+O6777Bq1SrExcXh999/l86QLolTp07h6NGj6NSpE4QQ0mAeAKZOnYq5c+di586d6NOnT4nXKRviOR09elQsWrRI/Pe//33eVRlMamqqACBSU1MN3ZRC5eTkiGPHjomcnBxDN4VIwlySXDGbJEfMJclNRkaGOH/+vLh//77QarW5henpQuQOf1/8Iz29xG0PCAgQKpVKWFlZSY/+/fsXWHfLli3C0dFReh4cHCzs7Oyk5zY2NiIkJKTA144aNUq8//77OmURERFCqVSKjIyMAl+Tf/3Tpk0TdevWFTk5OSI5OVkAEAcPHhRCCLF+/XpRr169/733QoisrCxhYWEh9u7dK4QQwsXFRSxcuFBarlarRfXq1UWvXr0K3LYQQty7d08AEGfPnhVCCJGYmCgAiFOnTunUCwgI0FlPr169xMiRI6Xnq1atEq6urkKj0QghhOjSpYuYN2+ezjrWr18vqlWrJoQQYtGiRaJu3boiOzu70LYVxM3NTZiamgqlUinmzJkjhBBCq9WKR48eiYCAAGFqaioAiP3795dqvWUlIyNDXLhwocD9XdJx5HPfp7tt27aYNGkSevbs+byrIiIiIiIiKhEfHx+cPn1aeixbtgxA7hHdLl26wM3NDTY2Nnj33Xfx4MEDPHnypMD1TJo0Ce+99x66du2Kr7/+WufU7JiYGISEhMDa2lp6+Pr6QqvVIjExsdg2Tp06Fffu3cPatWv1lsXExCA+Ph42NjbSuh0cHJCZmYmEhASkpqbizp07aN26tfQalUqFFi1a6KwnLi4OgwcPhpeXF2xtbVGjRg0AwLVr14ptX37+/v7YunUrsrKyAOROoD1o0CAolUqpvXPmzNF5L0aPHo1bt27hyZMnGDBgADIyMuDl5YXRo0dj+/btOkerCxMREYHo6GisXLkSS5YswW+//aaz3NvbGzVq1MCsWbOKvExAzkp9UdF///vfAssVCgXMzc1Ru3Zt6boBIiIiIiKqQCwtgZIObA4fBt58s/h6f/4JdOxYsm2XgpWVFWrXrq1TlpSUhB49euDDDz/EV199BQcHBxw5cgSjRo1CdnY2LAvYxuzZszFkyBDs2rULu3fvxqxZs7Bx40b06dMH6enpGDNmTIHXJlevXr3YNtrb22P69OkICgpCjx49dJalp6ejRYsW2LBhg97rSjMhXM+ePeHp6Yk1a9ZI12U3btxYOkW9NOsRQmDXrl1o1aoVIiIidGYTT09PR1BQEPoWMDmeubk5PDw8EBsbi7CwMOzbtw9jx47FwoULcejQIel0/YLkjR2bNGmCO3fuYPbs2Rg0aJC03M3NDaGhofDx8YGfnx92794NGxubUvXN0Eo96O7duzcUCoXe9Uh5ZQqFAu3bt8fvv/+OypUrl1lDX3YKhQIWFhbPP7skURliLkmumE2SI+aS5CrvSCYAQKEAnprAqlDduuXOUn7jRsHXYysUucu7dQNe0Mz9J06cgFarxaJFi6R+bd68udjX1a1bF3Xr1sXHH3+MwYMHIzg4GH369EHz5s1x4cIFvcF9aUyYMAHLli3D0qVLdcqbN2+OTZs2wdnZGba2tgW+1sXFBVFRUej4/z9aaDQanDx5Ek2bNgUAPHjwALGxsVizZg06dOgAIHfit/xMTU2l1xbF3Nwcffv2xYYNGxAfH4969eqhefPmOu2NjY0t8r2wsLBAz5490bNnT4wbNw7169fH2bNnddZTFK1WKx1pz59LT09PHDp0SBp479mzp0INvEt9evm+ffvQqlUr7Nu3D6mpqUhNTcW+ffvQpk0b7Ny5E4cPH8aDBw/w6aeflkd7X1oqlQqvvPIKbzVCssJcklwxmyRHzCXJ0XP9GKRS5d4WLHdFT684979LlrywATcA1K5dGzk5Ofj+++9x5coVrF+/HitXriy0fkZGBsaPH4/w8HBcvXoVkZGRiIqKQoMGDQDknh5+9OhRjB8/HqdPn0ZcXBx27NhRoonU8pibmyMoKEg6/T2Pv78/qlSpgl69eiEiIgKJiYkIDw9HYGAgrv//bPATJkzA/PnzsWPHDsTGxmLixIlITk6W9lflypXh6OiI1atXIz4+HgcOHMCkSZN0tuPs7AwLCwvs2bMHd+7ckW75XBB/f3/s2rULa9eulSZQyzNz5kysW7cOQUFBOH/+PC5evIiNGzfi888/B5B7f/KffvoJ586dw5UrV/DLL7/AwsICnp6eBW7rP//5D/744w/ExcUhLi4OP/30E7799lsMHTpUmlU/Pw8PD4SHh+Pu3bvw9fVFWlpaCd59mSjtheSNGjUSkZGReuVHjhwRDRs2FEIIsW/fPuHh4VHaVRtMRZhITaPRiDt37kgTGRDJAXNJcsVskhwxlyQ3eROppaWl6UzmVWpbtwrh7q47KZqHR255OXl6ErD8Fi9eLKpVqyYsLCyEr6+vWLdunQAgkpOThRC6E51lZWWJQYMGCQ8PD2FqaipcXV3F+PHjdSbNOn78uHjjjTeEtbW1sLKyEt7e3uKrr74qtG1PT9QmRO4EaA0bNtSZSE0IIW7duiWGDRsmqlSpIszMzISXl5cYPXq0NC7JyckR48ePF7a2tqJy5cpi6tSpYsCAAWLQoEHSOvbt2ycaNGggzMzMhLe3twgPDxcAxPbt26U6a9asER4eHkKpVIpOnToV+h5qNBpRrVo1AUAkJCTo9W3Pnj3itddeExYWFsLW1la0bt1arF69WgghxPbt20WbNm2Era2tsLKyEq+++qoICwsr9H1atmyZaNSokbC0tBS2traiWbNmYvny5UKj0QitViuys7MLbOP169dFnTp1xKuvvvpCxm9lMZGaQojSzc1vYWGBqKgoNG7cWKf87NmzaN26NTIyMnD16lU0aNCg0MkK5CYtLQ12dnZITU0t9NQOQ1Or1YiOjkbLli15f0+SDeaS5IrZJDliLkluMjMzceXKFbi4uMDBweH5Ln3QaICICODWLaBaNaBDhxd6hPtlodVq0aBBAwwcOBBz5841dHPKjRACjx8/hpWVlcEvycnMzERiYiJq1qwJc3NznWUlHUeW+hu/RYsWmDx5MtatWydd4H/v3j1MmTIFrVq1ApA7g56Hh0dpV01ERERERBWRSgV07mzoVhidq1ev4q+//kKnTp2QlZWFH374AYmJiRgyZIihm0alUOpB908//YRevXrB3d1dGlj/+++/8PLywo4dOwDkzmyXd24/ERERERERlZ5SqURISAg+/fRTCCHQuHFjhIWFSdecU8VQ6kF3vXr1cOHCBfz111+4fPmyVPbGG29IM8z17t27TBtJuZNc2NnZGfz0CqL8mEuSK2aT5Ii5JLni5H7y5eHhgcjISEM3wyCMKZelvqY7v8zMTJiZmVX4fzwqwjXdRERERERlqahrVYkoV1lc013qW4ZptVrMnTsXbm5usLa2RmJiIgDgiy++wE8//VTa1VEJabVaXL9+HVqt1tBNIZIwlyRXzCbJEXNJciSEQHZ2Np7jOBxRmTO2XJZ60P3ll18iJCQE33zzjXSjdQBo3LgxfvzxxzJtHP0P/6EmOWIuSa6YTZIj5pLkKicnx9BNINKTnZ1t6CaUmVIPutetW4fVq1fD399f5zz7V155BZcuXSrTxhERERERERFVZKUedN+4cQO1a9fWK9dqtfyVjIiIiIiIiCifUg+6GzZsiIiICL3y0NBQNGvWrEwaRfqUSiWcnJykGeKJ5IC5JLliNkmOmEuSKxOTUt/QiKjcGVMuS92TmTNnIiAgADdu3IBWq8W2bdsQGxuLdevWYefOneXRRkLuP9S1atUydDOIdDCXJFfMJskRc0lypFAojOJuRKUREhKCjz76CCkpKYZuikENHz4cKSkp+P333w3dFD0KhcKoZtQv9U+tvXr1wh9//IGwsDBYWVlh5syZuHjxIv744w+88cYb5dFGQu7p+wkJCZx8hWSFuSS5YjZJjphLkiMhBLKysp57lmiNVoPwpHD8dvY3hCeFQ6PVlFELCzZ8+HAoFAq9R3x8fLlutyRCQkKgUCjg5+enU56SkgKFQoHw8PAX2p6kpCQoFAqcPn1ap3zp0qUICQl5oW0pTGRkJExMTNC0aVMAubnMzMzE8OHD0bt3b526oaGhMDc3x6JFi158Q5/RMx2z79ChA/bt21fWbaEiaLVa3Lt3D56enjwtjWSDuSS5YjZJjphLkiu1Wv1cr992cRsm7pmI62nXpTJ3W3cs9VuKvg36Pm/zCuXn54fg4GCdMicnp3LbXmmYmJggLCwMBw8ehI+Pj6GbUyA7OztDNwFA7o8Rw4YNQ5cuXXDnzh2pvKBc/vjjjxg3bhxWrlyJESNGvMhmPhd+4xMRERER0TPZdnEb+m/urzPgBoAbaTfQf3N/bLu4rdy2bWZmhqpVq+o8VCoVFi9ejCZNmsDKygoeHh4YO3Ys0tPTC11PTEwMfHx8YGNjA1tbW7Ro0QLR0dHS8iNHjqBDhw6wsLCAh4cHAgMD8fjx4yLbZmVlhZEjR2LatGlF1vv3338xcOBA2Nvbw8HBAb169UJSUpK0XK1WIzAwEPb29nB0dMTUqVMREBCgc/R3z549aN++vVSnR48eSEhIkJbXrFkTANCsWTMoFAp07twZAHSOIq9evRqurq56Z+L06tULI0eOlJ7v2LEDzZs3h7m5Oby8vBAUFCQNjoUQmD17NqpXrw4zMzO4uroiMDCwyP4DwAcffIAhQ4agbdu2Rdb75ptvMGHCBGzcuLFCDbiBUgy6a9asCS8vryIfvE6JiIiIiKjiEkLgcfbjEj3SMtMQuDsQAvqnpueVTdw9EWmZaSVa3/Oe4p5HqVRi2bJlOH/+PH7++WccOHAAU6ZMKbS+v78/3N3dERUVhRMnTmDatGmoVKkSACAhIQF+fn7o168fzpw5g02bNuHIkSMYP358se2YPXs2zp49i9DQ0AKX5+TkwNfXFzY2NoiIiEBkZCSsra3h5+cn3aN6wYIF2LBhA4KDgxEZGYm0tDS9a7AfP36MSZMmITo6Gvv374dSqUSfPn2kAfTx48cBAGFhYbh16xa2bdP/IWTAgAF48OABDh48KJU9fPgQe/bsgb+/PwAgIiICw4YNw8SJE3HhwgWsWrUKISEh+OqrrwAAW7duxXfffYdVq1YhLi4Ov//+O5o0aVLkexQcHIwrV65g1qxZRdabOnUq5s6di507d6JPnz5F1pWjEp9e/tFHHxW6LCkpCatWrUJWVlZZtIkKoFQq4e7uztPRSFaYS5IrZpPkiLkkucobYALAk5wnsJ5vXSbrFRC4/ug67BaU7DTm9OnpsDK1KvH6d+7cCWvr/7W1e/fu2LJli864pUaNGvjyyy/xwQcfYPny5QWu59q1a5g8eTLq168PAKhTp460bP78+fD395fWWadOHSxbtgydOnXCihUripzsy9XVFRMnTsRnn32md10yAGzatAlarRY//vijNJFdcHAw7O3tER4ejm7duuH777/H9OnTpYHmDz/8gD///FNnPf369dN5vnbtWjg5OeHChQto3LixdMq9o6MjqlatWmBbK1eujO7du+PXX39Fly5dAOReO12lShXp9PigoCBMmzYNAQEBAAAvLy/MnTsXU6ZMwaxZs3Dt2jVUrVoVXbt2RaVKlVC9enW0bt260PcnLi4O06ZNQ0RERIEzlZuamgIAdu/ejR07dmD//v14/fXXC12fnJV40D1x4kS9socPH2Lu3LlYsWIF2rRpgwULFpRp4+h/8v6hJpIT5pLkitkkOWIuSY4UCgVMTU0r5OzlPj4+WLFihfTcyip3wB4WFob58+fj0qVLSEtLg1qtRmZmJp48eQJLS0u99UyaNAnvvfce1q9fj65du2LAgAHSGbwxMTE4c+YMNmzYINUXQkCr1SIxMRENGjQoso1Tp07FqlWrsHbtWgwcOFBnWUxMDOLj42FjY6NTnpmZiYSEBKSmpuLOnTs6A1eVSoUWLVronAYeFxeHmTNn4p9//sH9+/elZdeuXUPjxo2LbF9+/v7+GD16NJYvXw4zMzNs2LABgwYNkn4ojImJQWRkpHRkGwA0Go303g4YMABLliyBl5cX/Pz88Oabb6Jnz54FDqg1Gg2GDBmCoKAg1K1bV295Xi4BwNvbG/fv38esWbPQunVrnR9aKopnmkgtIyMDixcvxrfffgtPT09s27YNb775Zlm3jfLRaDS4fPky6tatC5VKZejmEAFgLkm+mE2SI+aS5Chvlui824ZZVrJE+vTCr3/O7/DVw3jz1+LHAH8O+RMdPTsWW8+ykv6AuChWVlaoXbu2TllSUhJ69OiBDz/8EF999RUcHBxw5MgRjBo1CtnZ2QUOumfPno0hQ4Zg165d2L17N2bNmoWNGzeiT58+SE9Px5gxYwq8Nrl69erFttHe3h7Tp09HUFAQevToobMsPT0dLVq00BnQ5ynNhHA9e/aEp6cn1qxZI12X3bhxY+kU9dKsRwiBXbt2oVWrVoiIiMB3332n096goCD07as/OZ65uTk8PDwQGxuLsLAw7Nu3D2PHjsXChQtx6NAhnbMpAODRo0eIjo7GqVOnpFP1tVothBAwMTHB3r178dprrwEA3NzcEBoaCh8fH/j5+WH37t16P1TIXakG3RqNBmvWrEFQUBDMzc2xbNkyDB06tEL+MlbRCCGQmppaZte6EJUF5pLkitkkOWIuSa40mv/d3kuhUJT4FO9utbrB3dYdN9JuFHhdtwIKuNu6o1utblApX8wPTSdOnIBWq8WiRYukI7SbN28u9nV169ZF3bp18fHHH2Pw4MEIDg5Gnz590Lx5c1y4cEFvcF8aEyZMwLJly7B06VKd8ubNm2PTpk1wdnaGra1tga91cXFBVFQUOnbM/dFCo9Hg5MmT0q21Hjx4gNjYWKxZswYdOnQAkDvxW355R4zz7+eCmJubo2/fvtiwYQPi4+NRr149NG/eXKe9sbGxRb4XFhYW6NmzJ3r27Ilx48ahfv36OHv2rM56AMDW1hZnz57VKVu+fDkOHDiA0NBQ1KhRQ6e9np6eOHTokDTw3rNnT4UaeJd40L1582Z8/vnnSElJwWeffYYPP/xQ2oFERERERPRyUSlVWOq3FP0394cCCp2BtwK5B+WW+C15YQNuAKhduzZycnLw/fffo2fPnoiMjMTKlSsLrZ+RkYHJkyejf//+qFmzJq5fv46oqCjpOumpU6fi1Vdfxfjx4/Hee+/BysoKFy5cwL59+/DDDz+UqE3m5uYICgrCuHHjdMr9/f2xcOFC9OrVC3PmzIG7uzuuXr2Kbdu2YcqUKXB3d8eECRMwf/581K5dG/Xr18f333+P5ORk6aBn5cqV4ejoiNWrV6NatWq4du2a3ozpzs7OsLCwwJ49e+Du7g5zc/NCbxfm7++PHj164Pz58xg6dKjOspkzZ6JHjx6oXr06+vfvD6VSiZiYGJw7dw5ffvklQkJCoNFo0KZNG1haWuKXX36BhYUFPD099bajVCr1Tn13dnaGubk5GjdunDuh31MzxHt4eCA8PBw+Pj7w9fXFnj17Cv2xQm5KPJPHoEGDcOPGDbz99tu4evUqpk2bhkmTJuk9iIiIiIjo5dC3QV+EDgyFm62bTrm7rTtCB4aW6326C/LKK69g8eLFWLBgARo3bowNGzZg/vz5hdZXqVR48OABhg0bhrp162LgwIHo3r07goKCAOReT3zo0CFcvnwZHTp0QLNmzTBz5ky4urqWql0BAQHw8vLSKbO0tMThw4dRvXp19O3bFw0aNMCoUaOQmZkpDSanTp2KwYMHY9iwYWjbti2sra3h6+srTeCmVCqxceNGnDhxAo0bN8bHH3+MhQsX6mzHxMQEy5Ytw6pVq+Dq6opevXoV2s7XX38dDg4OiI2NxZAhQ3SW+fr6YufOnfjrr7/QqlUrvPrqq/juu++kQbW9vT3WrFmDdu3awdvbG2FhYfjjjz/g6OhYqveqKO7u7ggPD8f9+/fh6+uLtLS0Mlt3eVKIEp7j1Llz52JPI1coFDhw4ECZNOxFSktLg52dHVJTU2X7a4lWq8X9+/dRpUoVznpKssFcklwxmyRHzCXJTWZmJq5cuQIPDw9YW1s/1yWjGq0GEdcicOvRLVSzqYYO1Tu80CPcLwutVosGDRpg4MCBmDt3rqGbU26EEFCr1TAxMTH4pcyZmZlITExEzZo19WarL+k4ssSnl4eHhz9zQ+n5KZVKODs7G7oZRDqYS5IrZpPkiLkkOVIoFKhUqdJzD2xUShU61+hcNo0iydWrV/HXX3+hU6dOyMrKwg8//IDExES9o9DGJi+XxoI/s1YQGo0GMTExxU6AQPQiMZckV8wmyRFzSXIkhEBGRgYn+JMppVKJkJAQtGrVCu3atcPZs2cRFhZW7K3KKjohBJ48eWI0uXymW4bRi8cvRJIj5pLkitkkOWIuSa7y3/OZ5MXDwwORkZGGboZBGFMueaSbiIiIiIiIqJxw0E1ERERERERUTjjoriBUKhXq168PlYqzQJJ8MJckV8wmyRFzSXKkUChgZmZm6GYQ6Xl6pvCK7JkG3RERERg6dCjatm2LGzduAADWr1+PI0eOlGnj6H8UCgXs7e0NPmU+UX7MJckVs0lyxFySXMnhtkxE+SkUCqPKZakH3Vu3boWvry8sLCxw6tQpZGVlAQBSU1Mxb968Mm8g5VKr1YiKioJarTZ0U4gkzCXJFbNJcsRckhwZ2yzRZByEEHj8+LHR5LLUg+4vv/wSK1euxJo1a3TundauXTucPHmyTBtHuniLEZIj5pLkitkkOWIuSY6MZWBDxsWYclnqQXdsbCw6duyoV25nZ4eUlJSyaBMREREREVG5CAkJgb29vaGbYXDDhw9H7969Dd2Ml0KpB91Vq1ZFfHy8XvmRI0fg5eVVJo0iIiIiIqKKQ6MBwsOB337L/W95n9QxfPhwKBQKvUdB45QXLSQkBAqFAn5+fjrlKSkpUCgUCA8Pf6HtSUpKgkKhwOnTp3XKly5dipCQkBfalvzCw8ML3Ie3b9+W6owYMULvh4HQ0FCYm5tj0aJFL7jFz86ktC8YPXo0Jk6ciLVr10KhUODmzZs4duwYPv30U3zxxRfl0UZC7oyn3t7enPGUZIW5JLliNkmOmEuSI4VC8dyzRG/bBkycCFy//r8yd3dg6VKgb9/nbGAR/Pz8EBwcrFPm5ORUfhssBRMTE4SFheHgwYPw8fExdHMKZGdnZ+gmAMg9k9rW1lZ67uzsDACwsLDQq/vjjz9i3LhxWLlyJUaMGPHC2vi8Sn2ke9q0aRgyZAi6dOmC9PR0dOzYEe+99x7GjBmDCRMmlEcb6f+ZmpoauglEephLkitmk+SIuSQ5Uiqf/S7C27YB/fvrDrgB4MaN3PJt256zcUUwMzND1apVdR4qlQqLFy9GkyZNYGVlBQ8PD4wdOxbp6emFricmJgY+Pj6wsbGBra0tWrRogejoaGn5kSNH0KFDB1hYWMDDwwOBgYF4/PhxkW2zsrLCyJEjMW3atCLr/fvvvxg4cCDs7e3h4OCAXr16ISkpSVquVqsRGBgIe3t7ODo6YurUqQgICNA5+rtnzx60b99eqtOjRw8kJCRIy2vWrAkAaNasGRQKBTp37gxA9/Ty1atXw9XVFVqtVqd9vXr1wsiRI6XnO3bsQPPmzWFubg4vLy8EBQVJk0MKITB79mxUr14dZmZmcHV1RWBgYJH9B3IH2fn3YV4en87lN998gwkTJmDjxo0VasANPMOgW6FQ4LPPPsPDhw9x7tw5/P3337h37x7mzp1bHu2j/6fRaBAdHc0JWEhWmEuSK2aT5Ii5JDnKm738f8+Bx49L9khLAwIDc1+jv97c/06cmFuvJOsrq3mzlEolli1bhvPnz+Pnn3/GgQMHMGXKlELr+/v7w93dHVFRUThx4gSmTZsmTRidkJAAPz8/9OvXD2fOnMGmTZtw5MgRjB8/vth2zJ49G2fPnkVoaGiBy3NycuDr6wsbGxtEREQgMjIS1tbW8PPzQ3Z2NgBgwYIF2LBhA4KDgxEZGYm0tDT8/vvvOut5/PgxJk2ahOjoaOzfvx9KpRJ9+vSRBtDHjx8HAISFheHWrVvYVsAvIQMGDMCDBw9w8OBBqezhw4fYs2cP/P39AeTeNnrYsGGYOHEiLly4gFWrViEkJARfffUVgNy7XH333XdYtWoV4uLi8Pvvv6NJkybFvk9NmzZFtWrV8MYbbyAyMlKnX3mmTp2KuXPnYufOnejTp0+x65Qd8ZxSU1PF9u3bxYULF553VQaTmpoqAIjU1FRDN6VQOTk54tixYyInJ8fQTSGSMJckV8wmyRFzSXKTkZEhzp8/L+7fvy+0Wq0QQoj0dCFyh78v/pGeXvK2BwQECJVKJaysrKRH//79C6y7ZcsW4ejoKD0PDg4WdnZ20nMbGxsREhJS4GtHjRol3n//fZ2yiIgIoVQqRUZGRoGvyb/+adOmibp164qcnByRnJwsAIiDBw8KIYRYv369qFevnvTeCyFEVlaWsLCwEHv37hVCCOHi4iIWLlwoLVer1aJ69eqiV69eBW5bCCHu3bsnAIizZ88KIYRITEwUAMSpU6d06gUEBOisp1evXmLkyJHS81WrVglXV1eh0WiEEEJ06dJFzJs3T2cd69evF9WqVRNCCLFo0SJRt25dkZ2dXWjb8rt06ZJYuXKliI6OFpGRkWLEiBHCxMREnDhxQmi1WvHo0SMREBAgTE1NBQCxf//+Eq23rGVkZIgLFy4UuL9LOo4s9ZHugQMH4ocffgAAZGRkoFWrVhg4cCC8vb2xdevWMvw5gIiIiIiIqGA+Pj44ffq09Fi2bBmA3CO6Xbp0gZubG2xsbPDuu+/iwYMHOkf085s0aRLee+89dO3aFV9//bXOqdkxMTEICQmBtbW19PD19YVWq0ViYmKxbZw6dSru3buHtWvX6i2LiYlBfHw8bGxspHU7ODggMzMTCQkJSE1NxZ07d9C6dWvpNSqVCi1atNBZT1xcHAYPHgwvLy/Y2tqiRo0aAIBr164V2778/P39sXXrVmRlZQEANmzYgEGDBkmnecfExGDOnDk678Xo0aNx69YtPHnyBAMGDEBGRga8vLwwevRobN++XTr1vCD16tXDmDFj0KJFC7z22mtYu3YtXnvtNXz33Xc69by9vVGjRg3MmjWryMsE5KzUg+7Dhw+jQ4cOAIDt27dDq9UiJSUFy5Ytw5dfflnmDSQiIiIiohfD0hJITy/Z488/S7bOP/8s2fosLUvXVisrK9SuXVt6VKtWDUlJSejRo4d0QPDEiRP4z3/+AwDSKdtPmz17Ns6fP4+33noLBw4cQMOGDbF9+3YAQHp6OsaMGaMzuI+JiUFcXBxq1apVbBvt7e0xffp0BAUF6Q3609PT0aJFC511nz59GpcvX8aQIUNK/D707NkTDx8+xJo1a/DPP//gn3/+KbK/Ra1HCIFdu3bh33//RUREhHRqeV57g4KCdNp69uxZxMXFwdzcHB4eHoiNjcXy5cthYWGBsWPHomPHjsjJySlxG1q3bq03A72bmxvCw8Nx48YN+Pn54dGjR6XqlxyUevby1NRUODg4AMi9aL9fv36wtLTEW2+9hcmTJ5d5AymXSqVCy5YtOeMpyQpzSXLFbJIcMZckRwqFApb5RrsKBWBlVbLXduuWO0v5jRsFX4+tUOQu79YNeFGxP3HiBLRaLRYtWiQdod28eXOxr6tbty7q1q2Ljz/+GIMHD0ZwcDD69OmD5s2b48KFC6hdu/Yzt2nChAlYtmwZli5dqlPevHlzbNq0Cc7Ozjqzd+fn4uKCqKgodOzYEUDu3BAnT55E06ZNAQAPHjxAbGws1qxZIx0YPXLkiM468iZwLG4+CXNzc/Tt2xcbNmxAfHw86tWrh+bNm+u0NzY2tsj3wsLCAj179kTPnj0xbtw41K9fH2fPntVZT1FOnz6NatWqAcj9USWPp6cnDh06BB8fH/j5+WHPnj2wsbEp0TrloNRHuj08PHDs2DE8fvwYe/bsQbdu3QAAycnJz327ASpaaX+tInoRmEuSK2aT5Ii5JDl6esbqklKpcm8LBuQOsPPLe75kyYsbcANA7dq1kZOTg++//x5XrlzB+vXrsXLlykLrZ2RkYPz48QgPD8fVq1cRGRmJqKgoNGjQAEDu6eFHjx7F+PHjcfr0acTFxWHHjh0lmkgtj7m5OYKCgqTT3/P4+/ujSpUq6NWrFyIiIpCYmIjw8HAEBgbi+v9PBz9hwgTMnz8fO3bsQGxsLCZOnIjk5GQo/v8Nrly5MhwdHbF69WrEx8fjwIEDmDRpks52nJ2dYWFhgT179uDOnTtITU0ttK3+/v7YtWsX1q5dq3OUGwBmzpyJdevWISgoCOfPn8fFixexceNGfP755wBy70/+008/4dy5c7hy5Qp++eUXWFhYwNPTs8BtLVmyBDt27EB8fDzOnTuHjz76CAcOHMC4ceMA6OfSw8MD4eHhuHv3Lnx9fZGWllbcWy8bpR50f/TRR9IMf66urtKU84cPHy7R7HT0bDQaDc6cOcMZT0lWmEuSK2aT5Ii5JDkSQiAzM/OZX9+3LxAaCri56Za7u/8fe3ce31SV9gH8d5OmTfd939KFlkIBy6aIQFEUdESUQRBwxHGZTRT1dcFxQXQcRx0VUOcdRQVfBVGhOo4LskjZVGSHQve9pXTftzQ35/3jkrRpbtqkJM1N+nz53E/bm5ubk/D0Nk/OOc8R9ttynW4xEyZMwBtvvIFXXnkFqamp2LJlC15++WWTx8vlctTX1+Ouu+5CUlISFi9ejBtvvBFr164FIMwn3r9/P/Ly8jBjxgykpaXhueeeQ0REhEXtWrFiBeLj4w32eXh44MCBA4iJicHChQuRkpKCe++9F11dXfqe7yeffBJLly7FXXfdhWnTpunnlOs6O2UyGbZt24bjx48jNTUVjzzyCF577TWDx3FxccGGDRvw7rvvIiIiAgsWLDDZzmuvvRYBAQHIzc01GuI+d+5cfPPNN9i1axemTJmCq666Cm+++aY+qfbz88PGjRsxffp0jB8/Hnv27MF///tfBAYGij6WWq3G//zP/2DcuHGYNWsWTp8+rZ+PDwgfiPQXFRWFzMxM1NXVOVTizTFmeXH+Y8eOoby8HNdffz28vLwAAN9++y38/Pwwffp0qzfS1lpaWuDr64vm5maTQzvsTaPR4NixY5g8eTJcXCyeFUCITVBcEqmi2CRSRHFJpKarqwtFRUUIDQ1FQECAvvd0KHgeOHgQqKoCwsOBGTOGt4d7pNBqtUhJScHixYudeslmxhja29vh6el5WXFpDV1dXSguLkZcXJzRyG5z88ghXfEnT56MyZMnG+z7zW9+M5RTEUIIIYQQQhycXA5cGgBLrKi0tBS7du3CrFmz0N3djbfffhvFxcUWFVoj9mdW0t1/XsBA3njjjSE3hgyMCq8QKaK4JFJFsUmkiOKSSJG9exKJaTKZDJs3b8Zjjz0GxhhSU1OxZ88e/ZxzZ+ZMcWlW0n3y5EmzTuZML4zUuLi4YMqUKfZuBiEGKC6JVFFsEimiuCRSpKteTu/jpSk6OhqHDx+2dzOGHcdxBtXLHZ1ZSfe+ffts3Q4yCMYYmpub4evrSxdFIhkUl0SqKDaJFFFcEqnSaDRgjFFcEslgjIHnecjlcqeIS4urlxP74HkeOTk5VPGUSArFJZEqik0iRRSXRIoYY+ju7rZ3MwgxcjlV9aVmSIXUjh07hs8//xxlZWVG601mZGRYpWGEEEIIIYQQQoijs7ine9u2bbj66quRnZ2NL7/8Ej09PTh37hx+/PFH+Pr62qKNhBBCCCGEEEKIQ7I46f773/+ON998E//973/h6uqK9evXIycnB4sXL0ZMTIwt2kggFBNwd3d3ijkNxHlQXBKpotgkUkRxSaRKJqMZp0R6nCkuLX4mhYWF+jW5XV1d0d7eDo7j8Mgjj+C9996zegOJQC6XY8KECbTUCJEUiksiVRSbRIooLokU0YdBRIqcraq+xUm3v78/WltbAQCRkZHIysoCADQ1NaGjo8O6rSN6Wq0WNTU10Gq19m4KIXoUl0SqKDaJFFFcEilijKGnpweMMXs3Zdhs3rwZfn5+9m6G3d1999249dZb7d0MUc4WlxYn3TNnzsTu3bsBALfffjtWrVqF+++/H0uXLsV1111n9QYSgVarRVFREf2hJpJCcUmkimKTSBHFJZGq/oWRh0TLA9WZQMmnwletbav033333eA4zmgrKCiw6eOaY/PmzeA4DvPmzTPY39TUBI7jkJmZOaztKSkpAcdxOHXqlMH+9evXY/PmzcPalv66u7vx9NNPIzY2Fm5ublCpVPjwww/1tz3//PO44oorDO5z8OBB+Pn54eGHH3aYpNzi6uVvv/22vnz7008/DYVCgZ9++gm//e1v8cwzz1i9gYQQQgghhBAJK88Ajq8COip693lEAZPWA9ELbfaw8+bNw6ZNmwz2BQcH2+zxLOHi4oI9e/Zg3759mD17tr2bI0oKRbAXL16M6upqfPDBB0hMTERVVdWAH0x+++23uP3227F69Wo899xzw9jSy2N2T/fMmTPR1NSEgIAARERE4Ouvv0Z3dzdWr16Nr7/+Gq+//jr8/f1t2VZCCCGEEEKIlJRnAAcXGSbcANBRKewvt91ywm5ubggLCzPY5HI53njjDYwbNw6enp6Ijo7GX/7yF7S1tZk8z+nTpzF79mx4e3vDx8cHkyZNwrFjx/S3Hzp0CDNmzIC7uzuio6Px0EMPob29fcC2eXp64p577sHq1asHPK68vByLFy+Gn58fAgICsGDBApSUlOhv12g0eOihh+Dn54fAwEA8+eSTWLFihcGw8J07d+Kaa67RH3PzzTejsLBQf3tcXBwAIC0tDRzHIT09HYDh8PL33nsPERERRgnvggULcM899+h//s9//oOJEydCqVQiPj4ea9euhUajASAMCX/++ecRExMDNzc3RERE4KGHHjL53Hfu3In9+/fju+++w5w5c6BSqTBt2jRMnz5d9PitW7di4cKFePXVVx0q4QYsSLoPHTpkMPTkzjvvRFVVlU0aRYxxHAdfX1+nKSZAnAPFJZEqik0iRRSXRKoMivsxBmjazdvULcCxhwCIDfG9tO/YKuE4c85npaHCMpkMGzZswLlz5/DRRx/hxx9/xBNPPGHy+OXLlyMqKgpHjx7F8ePHsXr1aigUCgBCEel58+bht7/9Lc6cOYPPPvsMhw4dwsqVKwdtx/PPP4+zZ89i+/btorf39PRg7ty58Pb2xsGDB3H48GF4eXlh3rx5+rzrlVdewZYtW7Bp0yYcPnwYLS0t+OqrrwzO097ejkcffRTHjh3D3r17IZPJcNttt+kT6F9//RUAsGfPHlRVVSEjw/iDkNtvvx319fXYt2+ffl9DQwN27tyJ5cuXAxCGdd91111YtWoVzp8/j3fffRebN2/GSy+9BADYsWMH3nzzTbz77rvIz8/HV199hXHjxpl8fb7++mtMnjwZr776KiIjI5GUlITHHnsMnZ2dAAzj8p133sHvf/97fPjhh2a99lJj8fByHUcZP+8s5HI5UlJS7N0MQgxQXBKpotgkUkRxSaSI4zgolcreD4P4DuBzLyudnQGdFcB2M4cxL24DXDzNPvs333wDL6/ett5444344osv8PDDD+v3qVQq/O1vf8Of/vQn/Otf/xI9T1lZGR5//HGMHj0aADBq1Cj9bS+//DKWL1+uP+eoUaOwYcMGzJo1C//7v/8LpVJpsn0RERFYtWoVnn76adGCZZ999hm0Wi3ef/99/eu/adMm+Pn5ITMzEzfccAPeeustPPXUU7jtttsACFN9v/vuO4Pz/Pa3vzX4+cMPP0RwcDDOnz+P1NRU/ZD7wMBAhIWFibbV398fN954I7Zu3aqv07V9+3YEBQXph8evXbsWq1evxooVKwAA8fHxePHFF/HEE09gzZo1KCsrQ1hYGObMmQOFQoGYmBhMnTrV5OtTVFSEQ4cOQalU4ssvv0RdXR3+8pe/oL6+Hps2bdJX1c/OzsbKlSvxwQcf6D8AcDTOs/iZk9NqtaioqKDiK0RSKC6JVFFsEimiuCRSxBiDWq12yA612bNn49SpU/ptw4YNAIQe3euuuw6RkZHw9vbG7373O9TX15tcaenRRx/Ffffdhzlz5uAf//iHwdDs06dPY/PmzfDy8tJvc+fOhVarRXFx8aBtfPLJJ1FbW6svDtbX6dOnUVBQAG9vb/25AwIC0NXVhcLCQjQ3N6O6utogcZXL5Zg0aZLBefLz87F06VLEx8fDx8cHKpUKgPBhgiWWL1+OHTt2oLu7GwCwZcsW3HHHHfr1sk+fPo0XXnjB4LW4//77UVVVhY6ODtx+++3o7OxEfHw87r//fnz55Zf6oeditFotOI7Dli1bMHXqVNx0001444038NFHH6Gjo0Mfl1FRUZg4cSJee+01hx1pbVFP9w8//KCfcK/VarF37179kmE6t9xyi/VaR/R0f6jDwsKcaqF44tgoLolUUWwSKaK4JFLV09PT+4PcQ+hxNkfNASDzpsGPS/8OCJk5+HFyD/Me9xJPT08kJiYa7CspKcHNN9+MP//5z3jppZcQEBCAQ4cO4d5774VarYaHh/FjPP/881i2bBm+/fZbfP/991izZg22bduG2267DW1tbfjjH/8oOjc5JiZm0Db6+fnhqaeewtq1a3HzzTcb3NbW1oZJkyZhy5YtRvezpCDc/PnzERsbi40bN+rnZaemplpclX7+/PlgjOHbb7/FlClTcPDgQbz55psG7V27di0WLjQujqdUKhEdHY3c3Fzs2bMHu3fvxl/+8he89tpr2L9/v364fl/h4eGIjIw0KOiWkpICxhgqKioQEREBAPD29saePXtw/fXXY/bs2di3bx/Cw8Mtem72ZlHSrRtKoPPHP/7R4GeO48Dztl0egBBCCCGEEGIjHGf+EO+wG4Qq5R2VEJ/XzQm3h90AyOQit1vf8ePHodVq8frrr+s/3Pr8888HvV9SUhKSkpLwyCOPYOnSpdi0aRNuu+02TJw4EefPnzdK7i3x4IMPYsOGDVi/fr3B/okTJ+Kzzz5DSEgIfHx8RO8bGhqKo0ePYuZM4UMLnudx4sQJ/TJa9fX1yM3NxcaNGzFjxgwAQi2uvlxdXfX3HYhSqcTChQuxZcsWFBQUIDk5GRMnTjRob25u7oCvhbu7O+bPn4/58+fjgQcewOjRo3H27FmD8+hMnz4dX3zxBdra2vTTBPLy8iCTyRAVFWUwKsjf3x979uzBDTfcgPT0dOzbt0+flDsCsz9m1Wq1g26UcBNCCCGEEDJCyOTCsmAAgP4FAi/9PGndsCXcAJCYmIienh689dZbKCoqwscff4x///vfJo/v7OzEypUrkZmZidLSUhw+fBhHjx7V11948skn8dNPP2HlypU4deoU8vPz8Z///MeiYl5KpRJr167VD3/XWb58OYKCgrBgwQIcPHgQxcXFyMzMxEMPPYSKCqEa/IMPPoiXX34Z//nPf5Cbm4tVq1ahsbFRPwfc398fgYGBeO+991BQUIAff/wRjz76qMHjhISEwN3dHTt37kR1dTWam5tNtnX58uX49ttv8eGHHxrNn37uuefwf//3f1i7di3OnTuH7OxsbNu2Tb9s9ObNm/HBBx8gKysLRUVF+OSTT+Du7o7Y2FjRx1q2bBkCAwPx+9//HufPn8eBAwfw+OOP45577oG7u7vR8X5+fti9ezf8/f2Rnp6OCxcuDPLKSweNbXIQMpkMwcHBNByNSArFJZEqik0iRRSXRKpcXIZcW1lYh3vGdsAj0nC/R5Sw34brdIuZMGEC3njjDbzyyitITU3Fli1b8PLLL5s8Xi6Xo76+HnfddReSkpKwePFi3HjjjVi7di0AYPz48di/fz/y8vIwY8YMpKWl4bnnnrO4l3XFihWIj4832Ofh4YEDBw4gJiYGCxcuREpKCu699150dXXpe76ffPJJLF26FHfddRemTZumn1OuK+Amk8mwbds2HD9+HKmpqXjkkUfw2muvGTyOi4sLNmzYgHfffRcRERFYsGCByXZee+21CAgIQG5uLpYtW2Zw29y5c/HNN99g165dmDJlCq666iq8+eab+qTaz88PGzduxPTp0zF+/Hjs2bMH//3vfxEYGCj6WF5eXti9ezeampowefJkLF++HPPnz9d/OCEWl76+vti1axeCgoIwa9YsVFZWDvSySwbHHLFqgpW1tLTA19cXzc3NJod2EEIIIYQQ4ky6urpQXFyMuLi4Aatwm0XLA7UHgc4qwD0cCJ4xrD3cI4VWq0VKSgoWL16MF1980d7NGREG+j0xN4+kj1odhFarRWFhIVU8JZJCcUmkimKTSBHFJZEixhi6u7svv3q5TA6EpgOqpcJXSritorS0FBs3bkReXh7Onj2LP//5zyguLjbqhXY2jDF0dXU5ZFV9MZR0OwitVova2lr6Q00kheKSSBXFJpEiiksiVQMt60TsSyaTYfPmzZgyZQqmT5+Os2fPYs+ePfo5587MmeLyMiZwEEIIIYQQQgixlejoaBw+fNjezSCXyeKe7vj4eNTX1xvtb2pqMioOQAghhBBCCCGEjGQWJ90lJSWiS4N1d3c7TPU4R6Rbr44qnhIpobgkUkWxSaSI4pJIlUKhsHcTCDGiW1/cGZg9vPzrr7/Wf//DDz/A19dX/zPP89i7dy9UKpVVG0d66f5QEyIlFJdEqig2iRRRXBIp4jgOrq6u+nWfCZECXVw6C7OT7ltvvRWA8AKsWLHC4DaFQgGVSoXXX3/dqo0jvXieR15eHpKSkiCXUzVIIg0Ul0SqKDaJFFFcEinSVYl2c3OjxJtIhi4ulUqlU8Sl2Um3rtJmXFwcjh49iqCgIJs1ihhjjKG5udlpyuYT50BxSaSKYpNIEcUlkSqxqaOE2JszxaXF1cuLi4tt0Q5CCCGEEEIIIcTpDGnJsL1792Lv3r2oqakxWmvyww8/tErDCCGEEEIIIcRaOI7Dl19+qZ82K+buu+9GU1MTvvrqK7POWVJSgri4OJw8eRJXXHGFVdrZ1/PPP4+vvvoKp06dsvq5HUl6ejquuOIKrFu3zt5NGRKLy2euXbsWN9xwA/bu3Yu6ujo0NjYabMQ2ZDIZ4uPjqeIpkRSKSyJVFJtEiiguiVQ5YsGqu+++e8DkWUxVVRVuvPFGAEKyzHGcUTK7fv16bN682TqNvCQ9PR0cxxltGo3Gqo8zFM8//zw4jsOf/vQng/2nTp0Cx3EoKSkZ1vZkZmaC4zg0NTXBzc1Nvz8jIwMvvvjisLbFmizu6f73v/+NzZs343e/+50t2kNMkMlkCAkJsXczCDFAcUmkimKTSBHFJZEijuOgUCicoljVYMLCwgY9pu8KTdZ0//3344UXXjDY5+IypEHHVqdUKvHBBx/gf/7nfzBq1Ch7NwdAb1zqBAQE2LE1l8/ij1rVajWuvvpqW7SFmKBbku0f//gH9u7d61RFBYhj43kep0+fppgkkkOxSaSI4pJIEWMMnZ2dDl/gLz09HQ899BCeeOIJBAQEICwsDM8//7zBMRzH6YeNx8XFAQDS0tLAcRzS09MBGPeg79y5E9dccw38/PwQGBiIm2++GYWFhRa3z8PDA2FhYQYbADz55JNISkqCh4cH4uPj8eyzz6Knp8fkeTIzMzF16lR4enrCz88P06dPR2lpqf72//znP5g4cSKUSiXi4+Oxdu3aQXvUk5OTMXv2bDz99NMDHpeVlYUbb7wRXl5eCA0Nxe9+9zvU1dXpb29tbcXy5cvh6emJ8PBwvPnmm0hPT8fDDz+sP+bjjz/G5MmT4e3tjbCwMCxbtgw1NTUAhNEHs2fPBgD4+/uD4zjcfffdAGBwnr/+9a+48sorjdo3YcIEgw823n//faSkpECpVGL06NH417/+pb9NrVZj5cqVCA8Ph1KpRGxsLF5++eUBn//lsDjpvu+++7B161ZbtIWIyMjIgEqlwpw5c/DUU09hzpw5UKlUyMjIsHfTCHGaP9TE+VBsEimiuCRS1b9GEwCo29UmN02Xxuxjezp7zDrWGj766CN4enriyJEjePXVV/HCCy9g9+7dosf++uuvAIA9e/agqqrK5Hvr9vZ2PProozh27Bj27t0LmUyG2267TfQ1Gwpvb29s3rwZ58+fx/r167Fx40a8+eabosdqNBrceuutmDVrFs6cOYOff/4Zf/jDH/SjFA4ePIi77roLq1atwvnz5/Huu+9i8+bNeOmllwZtxz/+8Q/s2LEDx44dE729qakJ1157LdLS0nDs2DHs3LkT1dXVWLx4sf6YRx99FIcPH8bXX3+N3bt34+DBgzhx4oTBeXp6evDiiy/i9OnT+Oqrr1BSUqJPrKOjo7Fjxw4AQE5ODgoKCkTncC9fvhy//vqrwYcf586dw5kzZ7Bs2TIAwJYtW/Dcc8/hpZdeQnZ2Nv7+97/j2WefxUcffQQA2LBhA77++mt8/vnnyM3NxZYtW6BSqQZ9nYbK4jENXV1deO+997Bnzx6MHz/eoNsfAN544w2rNW6ky8jIwKJFi4z+OFdWVmLRokXYvn07Fi5caKfWEUIIIYQQZ/Wyl+lev1E3jcKyb5fpf/5nyD/R0yHeOxs7KxZ3Z96t/3m9aj066jqMjlvD1gy9sZeMHz8ea9YI5xk1ahTefvtt7N27F9dff73RscHBwQCAwMDAAYed//a3vzX4+cMPP0RwcDDOnz+P1NRUs9v2r3/9C++//77+5z/+8Y94/fXX8cwzz+j3qVQqPPbYY9i2bRueeOIJo3O0tLSgubkZN998MxISEgAAKSkp+tvXrl2L1atXY8WKFQCA+Ph4vPjii3jiiSf0r4spEydOxOLFi/Hkk09i7969Rre//fbbSEtLw9///nf9vg8//BDR0dHIy8tDeHg4PvroI2zduhXXXXcdAGDTpk2IiIgwOM8999yj/z4+Ph4bNmzAlClT0NbWBi8vL/0w8pCQECgUCnh6ehq1ZezYsZgwYQK2bt2KZ599FoCQZF955ZVITEwEAKxZswavv/66PleKi4vTfxCxYsUKlJWVYdSoUbjmmmvAcRxiY2MHfH0ul8VJ95kzZ/SV+bKysgxuGwlzQYYLz/NYtWqV6KfhjDFwHIeHH34YCxYsgFwut0MLCSGEEEIIkY7x48cb/BweHq4fujxU+fn5eO6553DkyBHU1dXpe7jLysosSrqXL19uMHzbz88PAPDZZ59hw4YNKCwsRFtbGzQaDXx8fETPERAQgLvvvhtz587F9ddfjzlz5mDx4sUIDw8HAJw+fRqHDx826NnmeR5dXV3o6OiAh4fHgG3829/+hpSUFOzatcuo/sTp06exb98+eHl5Gd2vsLAQnZ2d6OnpwdSpU/X7fX19kZycbHDs8ePH8fzzz+P06dNobGw0eD3HjBkzYPv6Wr58OT788EM8++yzYIzh008/xaOPPgpAGJ1QWFiIe++9F/fff7/+PhqNRj9n/+6778b111+P5ORkzJs3DzfffDNuuOEGsx/fUhYn3fv27bNFO0g/Bw8eREVFhcnbGWMoLy/HK6+8gmXLliE2NpY+9CDDTi6XY/To0fTBD5Ecik0iRRSXRIo4jjOoEq3zVNtTJu8jkxvOUH2s5jHT55cZvj9dVbLKwhaar/8IXI7jLnsY+Pz58xEbG4uNGzciIiICWq0WqampUKstGxLv6+ur74XV+fnnn7F8+XKsXbsWc+fOha+vL7Zt24bXX3/d5Hk2bdqEhx56CDt37sRnn32GZ555Brt378ZVV12FtrY2rF27VnQkrFKpHLSNCQkJuP/++7F69Wp88MEHBre1tbVh/vz5eOWVV4zuFx4ejoKCgkHP397ejrlz52Lu3LnYsmULgoODUVZWhrlz54q+ngO1eenSpXjyySdx4sQJdHZ2ory8HEuWLNG3FQA2btxoNPdbd/2dOHEiiouL8f3332PPnj1YvHgx5syZg+3btw/6PIZCGiXziJGqqiqzjnv66afx9NNPw9vbG+PGjTPa/P39bdxSMpJxHKf/pJYQKaHYJFJEcUmkysXFxajzxtXT/GXEbHWsLemWSRuosGF9fT1yc3OxceNGzJgxAwBw6NAhq7Xhp59+QmxsrEEPeN+iaKakpaUhLS0NTz31FKZNm4atW7fiqquuwsSJE5Gbm2uU3FviueeeQ0JCArZt22awf+LEidixYwdUKpVo1fX4+HgoFAocPXoUMTExAIDm5mbk5eVh5syZAIR52vX19fjHP/6B6OhoADCaQ677f9FqtQNWd4+KisKsWbOwZcsWdHZ24vrrr9f3zoeGhiIiIgJFRUVYvny5yXP4+PhgyZIlWLJkCRYtWoR58+ahoaHBJpXSLU66Z8+ePWCP6o8//nhZDSIC3TCRwcTHx6O8vBytra346aef8NNPPxncHhUVhXHjxmH8+PH6RHz06NEOuR4jkR6NRoOTJ08iLS1NMsteEAJQbBJporgkUsQYQ0dHB9zc3EbUqMmQkBC4u7tj586diIqKglKpNFouzN/fH4GBgXjvvfcQHh6OsrIyrF692mptGDVqFMrKyrBt2zZMmTIF3377Lb788kuTxxcXF+O9997DLbfcgoiICOTm5iI/Px933XUXACFhvvnmmxETE4NFixZBJpPh9OnTyMrKwt/+9jez2hQaGopHH30Ur732msH+Bx54ABs3bsTSpUv1FeILCgqwbds2vP/++/D29saKFSvw+OOPIyAgACEhIVizZg1kMpk+rmJiYuDq6oq33noLf/rTn5CVlWW09rZu9O5///tfpKenIzAwEN7e3qJtXb58OdasWQO1Wm1UfG7t2rV46KGH4Ovri3nz5qG7uxvHjh1DY2MjHn30UbzxxhsIDw9HWloaZDIZvvjiC4SFhdnsg1GLq5dfccUVmDBhgn4bM2YM1Go1Tpw4gXHjxtmijSPSjBkzEBUVZfLix3GcvnBBe3s7zp49i61bt+Kpp57S/7IBQEVFBb7//nu88soruPPOOzFhwgR4enpi3LhxWLZsGV5++WV8++23KCsro2qqZEho6RsiVRSbRIooLokUjcT3gC4uLtiwYQPeffddREREYMGCBUbHyGQybNu2DcePH0dqaioeeeQRo2T0ctxyyy145JFHsHLlSlxxxRX46aef9IXBxHh4eCAnJwe//e1vkZSUhD/84Q944IEH8Mc//hEAMHfuXHzzzTfYtWsXpkyZgquuugpvvvmmxUXCHnvsMaO52xERETh8+DB4nscNN9yAcePG4eGHH4afnx9kMiGlfOONNzBt2jTcfPPNmDNnDqZPn65fsgsQitdt3rwZX3zxBcaMGYN//OMf+Oc//2nwOJGRkVi7di2eeuopxMfH48EHHzTZzkWLFqG+vh4dHR0Gy7wBwopb77//PjZt2oRx48Zh1qxZ2Lx5s36pOG9vb7z66quYPHkypkyZgpKSEnz33Xf652JtHLPSb9nzzz+PtrY2oxfOEbS0tMDX1xfNzc0mCxfYg656OWB4MdQl4oNVL29ubkZWVhbOnDmDs2fP6rfm5mbR4319fUWHqPf/1I8QHY1Gg2PHjmHy5MnUa0MkhWKTSBHFJZGarq4uFBUVITQ0FAEBASOqp5vYXnt7OyIjI/H666/j3nvvtei+jDG0t7fD09PT7nHZ1dWF4uJixMXFGc0zNzePtNoV/84778TUqVMdMumWqoULF2L79u1YtWqVQVG1qKgorFu3btDlwnx9fTF9+nRMnz5dv09XgE2XgOsS8pycHDQ3N+PQoUNGc1ViYmKMhqgnJycbFasghBBCCCGEjEwnT55ETk4Opk6diubmZrzwwgsAIDqKYKSxWtL9888/m1UVj1hm4cKFWLBgAQ4cOIDS0lLExsZi5syZQ658ynEcYmJiEBMTg9/85jf6/Wq1Grm5uUa94uXl5SgrK0NZWRm+/fZb/fEKhQIpKSn6JFyXkEdGRtr90ygyfORyOcaPH0+VeInkUGwSKaK4JFLEcRy9hydW889//hO5ublwdXXFpEmTcPDgQQQFBQ3pXO7u7lZunf1YnHT3711ljKGqqgrHjh0bcA4CGTq5XI709HTwPA+5XG6TpNbV1VWfQPfV2NiIrKwsg17xs2fPorW1FWfOnMGZM2cMjvfz8zPqFU9NTZXUsH1iXVSUj0gVxSaRIopLIkW2msdKRpa0tDQcP37caudzpri0OOnuP79XJpMhOTkZL7zwgk0XFB/peJ63yzwwf39/zJgxQ79MAiB80FJaWmrQI37mzBnk5uaiqakJBw8exMGDBw3Oo1KpjHrFk5KSaE6bg7NXXBIyGIpNIkUUl0SKdNXLqbebSI1uTrczsPiKv2nTJlu0gzgQjuOgUqmgUqkwf/58/f7u7m7k5OQYDVGvrKxESUkJSkpK8N///ld/vKurK8aMGWNQtG38+PEIDw+nIeqEEEIIIYQQpzDkj1mPHz+O7OxsAMDYsWORlpZmtUYRx+Tm5qZfSq6vhoYGo8JtWVlZaGtrw6lTp3Dq1CmD4wMCAkSHqPdfuoAQQgghhFy+kbhkGCHm0mq1l30Oi5Pumpoa3HHHHcjMzNQvHt7U1ITZs2dj27ZtCA4OvuxGEecSEBCAWbNmYdasWfp9Wq0WpaWlBr3iZ86cQV5eHhoaGrB//37s37/f4Dzx8fFGQ9QTExNpiB4hhBBCyBC4urpCJpOhtrYWCoUCrq6uNNqQSAJjDN3d3TarZ2VuG9RqNWprayGTyS6rJofF63QvWbIERUVF+L//+z+kpKQAAM6fP48VK1YgMTERn3766ZAbYy9SXae7L8aYTQupSUVXVxeys7ONCrdVVVWJHu/m5oYxY8YY9IqPHz8eoaGhTv06ScVIiUvieCg2iRRRXBIp6u7uxoULF9DV1WXvphBigDEmiWulh4cHwsPDRZNuc/NIi5NuX19f7NmzB1OmTDHY/+uvv+KGG25AU1OTJaeTBEdJujs7O+Hu7i6J4BtudXV1RoXbsrKy0NHRIXp8UFCQUa/42LFjnaYYg1SM9Lgk0kWxSaSI4pJIka6QmkKhsMowWkKsgTGGrq4uKJVKu14v5XI5XFxcTLbB3DzS4nG5Wq0WCoXCaD/9otoWz/M4c+bMiK14GhQUhNmzZ2P27Nn6fVqtFsXFxUaF2/Lz81FXV4d9+/Zh3759+uM5jkNCQoJR4baEhARaM3WIRnpcEumi2CRSRHFJpIjneZw9exaTJ0+mJe2IZGg0Gpw+fdpprpcWP4Nrr70Wq1atwqeffoqIiAgAQGVlJR555BFcd911Vm8gIabIZDIkJCQgISEBt912m35/Z2cnzp8/bzREvbq6GgUFBSgoKMCXX36pP97d3d1oiPq4ceMQGhpqj6dFCCGEEEIIcSIWJ91vv/02brnlFqhUKkRHRwMAysvLkZqaik8++cTqDSTEUu7u7pg0aRImTZpksL+mpsZoiPq5c+fQ2dmJ48eP4/jx4wbHh4SEGA1RHzNmDDw8PIbz6RBCCCGEEEIcmMVJd3R0NE6cOIE9e/YgJycHAJCSkoI5c+ZYvXHEEA2BvjwhISG47rrrDEZk8DyPoqIio17xgoIC1NTUYO/evdi7d6/+eI7jkJiYaFS4LT4+HjKZzB5Py+4oLolUUWwSKaK4JFJEcUmkyJni0uJCas7IEQqpkeHV3t6uH6LeNyGvra0VPd7DwwNjx441Wl+cltAjhBBCCCHEOVm9evmPP/6IlStX4pdffjE6YXNzM66++mr8+9//xowZMy6v5XbgCEk3YwzNzc3w9fWliqd2VF1dbdQrfu7cOZPLbISFhRkVbhszZgyUSuUwt9w2KC6JVFFsEimiuCRSRHFJpMhR4tLqSfctt9yC2bNn45FHHhG9fcOGDdi3b59BgSpH4QhJt0ajwbFjx5ymgp8z4XkeBQUFRsl4UVERxH69ZDIZRo0aZTREXaVSOdwQdYpLIlUUm0SKKC6JFFFcEilylLi0+pJhp0+fxiuvvGLy9htuuAH//Oc/LWslIU5ALpcjOTkZycnJWLRokX5/W1sbzp07ZzREvb6+Hrm5ucjNzcUXX3yhP97T0xOpqalGQ9QDAwPt8bQIIYQQQgghVmB20l1dXS26Prf+RC4uJue7EjISeXl54corr8SVV16p38cYw8WLF416xc+fP4/29nYcOXIER44cMThPeHi4Ua94SkoK3NzchvspEUIIIYQQQixkdtIdGRmJrKwsJCYmit5+5swZhIeHW61hxBDHcXB3d5f0nAYyOI7jEB4ejvDwcNxwww36/RqNBvn5+Ua94sXFxaiqqkJVVRV++OEH/fFyuRxJSUlGveKxsbHDOkSd4pJIFcUmkSKKSyJFFJdEipwtLs2e0/3ggw8iMzMTR48eNSoC1dnZialTp2L27NnYsGGDTRpqS44wp5uMTK2trcjKyjJKxhsbG0WP9/b21g9R75uQ+/v7D3PLCSGEEEIIcW5WL6RWXV2NiRMnQi6XY+XKlUhOTgYA5OTk4J133gHP8zhx4gRCQ0Ot8wyGkSMk3VqtFnV1dQgKCnK4YlvEuhhjuHDhgtEQ9ezsbKjVatH7REZGGg1RHz16NFxdXYfcDp7nsX//fuTl5SEpKQmzZs1yqvUUieOi2CRSRX/LiRRRXBIpcpS4tHrSDQClpaX485//jB9++EFflZnjOMydOxfvvPMO4uLiLr/lduAISbejVPAj9tPT04O8vDyjXvHS0lLR411cXJCcnGw0RD0mJmbQoTwZGRlYtWoVKioq9PuioqKwfv16LFy40KrPixBLUGwSKaO/5USKKC6JFDlKXNok6dZpbGxEQUEBGGMYNWqUww9dpaSbOLOWlhZkZWUZ9IqfOXMGzc3Nosf7+PgYrS2empoKPz8/AEJSs2jRIqPl0HSJ+vbt2ym5IXZBsUmkjv6WEymiuCRS5ChxadOk29lQ0k1GGsYYKioqjHrFc3Jy0NPTI3qf6OhojBs3DgcPHkRra6voMRzHISoqCsXFxTSclwwrnuehUqkMerj7otgkUkB/y4kUUVwSKXKUuLT6Ot3EvjiOg6+vr9NU8CP2xXEcoqOjER0djZtuukm/X61WIzc3V5+M6xLy8vJy/TYQxhjKy8uRnJwMb29vWz8NQvRaW1tNJtxAb2x++OGHWLBggeTniBHnRH/LiRRRXBIpcra4pJ5uOEZPNyH21NTUhKysLHz44YfYtGmTvZtDyGVzdXVFZGQkIiMjERUVhaioKKPvw8PDJf3pOiGEEELsi4aXW8ARkm6tVosLFy4gIiKCemeI3WRmZmL27NmDHvfqq69iwoQJw9AiQgSnT5/GE088Mehx/v7+aGpqMpr3LUYmkyEsLMwgGRdLzvsvo0mIKfS3nEgRxSWRIkeJS0q6LeAISbejzGsgzk03b7ayslI0aaF5s8ReLIlNnudRVVWFiooKVFZWoqKiwuj7CxcuQKPRmPXYgYGBosl43+99fHycZogcGTr6W06kiOKSSJGjxCXN6SaEWJ1cLsf69euxaNEicBxnkNzoEop169ZRwk2GnSWxKZfLERsbi9jYWJPn02q1qKmpGTAxr6ioQGdnJ+rr61FfX4/Tp0+bPJ+Xl9egiTnNMyeEEEKcEyXdhBCLLFy4ENu3bxddC3ndunW0JBOxG2vGpm5oeVhYGCZPnix6DGMMTU1NAybmlZWVaGxsRFtbG3JycpCTk2PyMWmeOSGEEOKcaHg5HGN4uVarRXFxMeLi4qgnhEgCz/PYv38/zpw5g/Hjx2PWrFnUw00kQWqx2d7ejsrKygET8+rq6iHPM+//fWRkJNzd3YfhmRFL0d9yIkUUl0SKHCUuaU63BRwh6SaEEOK81Go1qqqqBkzMKysrLZpnbioxp3nmhBBCiHVQ0m0BR0i6HeXTHjKyUFwSqXLG2NTNMx9ojrlunrk5aJ758HPGuCSOj+KSSJGjxCUVUnMyWq0WtbW1iI2NlXTgkZGF4pJIlTPGZt955pMmTRI9ZrB55rqvNM/cPpwxLonjo7gkUuRscUl/JQkhhBAnwXEc/P394e/vj3Hjxpk8ztx55mq1GsXFxSguLjZ5LppnTgghhAyMkm5CCCFkhPH09ERSUhKSkpJMHmPJPPMLFy7gwoULOHr0qMnzDTTPXPc9zTMnhBDijCjpdhAymQxRUVFOMbyCOA+KSyJVFJuXz9XV1ez1zAdKzCsqKtDR0aFfz/zMmTMmz+fl5TVoYu7I88wpLokUUVwSKXK2uKRCanCMQmqEEEKII9LNMx8sMW9sbDTrfDTPnBBCiFRQ9XILSD7p5nnwmZm4ePIkwtLSIE9PB2g9ZCIBPM8jLy8PSUlJtEY3kRSKTcfT0dExaGLuyOuZ8zyPzMxMnDx5EmlpaUhPT6fYJJJA10siRY4Sl1S93FlkZACrVkFeUYFI3b6oKGD9emDhQnu2jBAwxtDc3GzWm2BChhPFpuPx8PDAqFGjMGrUKJPH9PT0oKqqasDEXIrzzDMyMrBq1SpUVFTo90VFRWH9+vVYSH/LiZ3R9ZJIkbPFJSXdUpaRASxaBPQPtspKYf/27ZR4E0IIGTEUCgViYmIQExNj8hjdMjMDJebDOc88IyMDixYtMnrjWFlZiUWLFmH79u2UeBNCiJOjpFuqeB5Ytco44QaEfRwHPPwwsGABDTUnhBBCLpHJZAgNDUVoaOiA65k3NzcPmpjr1jPPzc1Fbm6uycd0dXVFRESEUTIeHh6Ohx56SLSnhjEGjuPw8MMPY8GCBZIePkkIIeTy0JxuSHROd2YmMHv24MetXAlMmwYEBQlbcLDwldZDJcNAq9Wirq7OoasJE+dEsUmsoe88c1OJubnzzAeyY8cO3HbbbbRcGrELul4SKXKUuKRCahaQZNL96afAsmVDv7+HR28i3nfTJeX9t8BAQKGwXvsJIYSQEWCgeeanTp1CXl6eWefx8vJCQkKCwZaYmIiEhARER0dTTzghhEgQJd0WkGTSbW5Pd3o6IJMBdXW9m1o9tMf09TWdlIsl7X5+wmOTEYvneWRlZSE1NZXeEBJJodgkUpCZmYnZ5vwtH4RCoYBKpTJIxHVbfHw8lEqlFVpLRiq6XhIpcpS4pOrljm7GDKFKeWWl+LxujhNu37PHcE43Y0BbW28CXltrmJD33XS31dcL92tuFraCAvPaKJMJPeTm9qYHBQFeXkLbiVNgjKGzs9NpKksS50GxSaRgxowZiIqKQmVlpWgschyHqKgo5OTkoLy8HIWFhSgoKEBhYaF+KyoqglqtRn5+PvLz80UfJyoqSrSHPCEhAX5+fjZ+lsTR0fWSSJGzxSUl3VIllwvLgi1aJCSpfQNOl7SuW2dcRI3jAG9vYYuLM++xeB5oajKdlIttzc2AViscU1tr/vNycxu4J71/0h4YCNAn+IQQQhyQXC7H+vXrsWjRInAcZ/DmUTd/e926dfDw8EBycjKSk5ONzsHzPCorKw0S8b6JeUtLi344+/79+43uHxAQINpDnpCQgPDwcJpHTgghw4CSbilbuFBYFmzVKqDP2p6IihISbmstMSKXC8ltYCAg8gdflFot9JCbSsr7J+21tUBXF9DdLfTeV1aa3z4vL/N70oOCgIAAwIVCmxBCiP0tXLgQ27dvF12ne926dYMuFyaXy/XLpPUfqs4YQ319vVHvuC4xr66uRkNDAxoaGkTXK/fw8EB8fLxoD3lsbCxc6G8pIYRYBc3phkTndPfF82AHDqCjsBAeCQngZs50zGXCOjrM70nX3cbzlj8OxwH+/ub3pgcFCfPZ6dN+i+mW3fH19aXeEiIpFJtEaniex4EDB1BYWIiEhATMnDnT5vMU29raUFRUJDpsvbS0FFqt1uR95XI5YmNjjXrIExMTER8fDw8PD5u2nQwful4SKXKUuKRCahaQfNI9UunmmQ/Wi953a2gY2mO5uBjOTzenoBy94SCEEOKg1Go1SktLRYetFxUVoaura8D7h4eHi/aQJyQkICAgQNJvkgkhxFoo6baAIyTdGo0GJ0+eRFpaGg33GohGIyTe5g57r6sTCs8Nhbu7+T3puvnprq7Wfb52RnFJpIpik0iRo8SlVqtFVVWVaA95QUEBmpqaBry/r6+vaA95QkICIiIiJL3m7kjkKHFJRhZHiUuqXu6E+KEMtR5pXFyAkBBhM1dXl+H89IGGvetuV6uBzk6gvFzYzOXjY1lvur+/dJdl43lw+/fD7/BhcC0twvJ1jjjtgTgtumYSKXKEuJTJZIiMjERkZCRmzpxpdHtDQ4PJwm4XLlxAc3Mzjh8/juPHjxvdV6lUIi4uTrSHXKVSwdXJPpx2FI4Ql2Tkcaa4pKSbEKUSiIwUNnP0X5bNnKHv9fVCtfeWFmErKjLvsWQyoTCcub3pQUFC5XpbD+vLyABWrYK8ogKjdPuiooSK+9Yq8EcIIUSSAgICEBAQgClTphjd1tHRoZ9H3j8xLy0tRVdXF7Kzs5GdnW10X5lMhpiYGJPLn3l5eQ3H0yOEEKujpNsBqHt4vPX5afxyvBJXFSrw4OIr4KqgHkW7GcqybFpt77Js5hSQ67ssm+5ncykU5vWk9z3GkmXZMjKEpez6z0yprBT2b99OiTchhIxQHh4eSE1NRWpqqtFtGo0GZWVlosPWCwsL0dHRgZKSEpSUlGDv3r1G9w8JCTG5/FlwcDDNIyeESBbN6Ya053Q/seEXvPFcDPjmCP0+ue8FPPpCGV596Co7tozYnFptPD99sIS9s3Noj+XpaV5vur8/MG8eUFUlfh6OE3q8i4tpqDmxK8YYOjs74e7uTm/EiWRQXJrGGMPFixdNDluvr68f8P7e3t4me8ijoqJsXinekVFcEilylLikQmoWkGrS/cSGX/DaqqmXfuo7r1dY4uPx9b9S4k0M9V+WzZyEXaOxfjv27RPmeBNiJ4wx8DwPuVwu6T/WZGShuBy65uZmk4Xd+q5/LsbV1RUqlUq0hzwuLg5KS0Z7OSGKSyJFjhKXlHRbQIpJt7qHh0dwNfjmMBgm3DpayP2q0FETRkPNydAxJswxN7eAXGUl0N4++HmTk4Hf/AaYMkXY4uNpHXQyrDQaDY4dO4bJkydLuuopGVkoLm2jq6sLxcXFoj3kxcXF6OnpMXlfjuMQFRVlcvkzX1/fYXwm9kFxSaTIUeKSqpc7uH/tOAu++YoBjpCBb4pEyIO3InJ8PrxcveDt6i18dfPu/b7PPt3Pfb/X3eah8ICMk2iVbGI7HAf4+gpbQsLgx2dmArNnD35cbq6w6QQEAJMnC5suETe3cB0hhBAyAKVSiZSUFKSkpBjdxvM8ysvLRQu7FRYWoq2tDeXl5SgvL0dmZqbR/QMDA00ufxYaGirpHjhCiHRQ0i1RhaUdZh3X/OVaNBd/BCTsAkJ+BYZ47efAwdPV03SSrvASTdbFjtf97CKj8HI6M2YIc7YrK40LqQFCEh8aCrz0EnD8OHD0KHD6tDA3fdcuYdMJD+9NwHXJeGDg8D0XQgghTk8ul0OlUkGlUuG6664zuI0xhtraWpOF3WpqalBfX4/6+nocOXLE6Nyenp6Ij48X7SGPiYmRdO8cIWR40dVAohJiPcw7sGYCsOsNAIB/cAdGX1mOuMn5iJhwDlr3GrSqW9Gmbuv92t1q8H2bug3s0r82dRva1G1Wew5KF+XAve2KwXvg+97mJnejT5TtTS4XlgVbtEhIsPsm3rr/m3feEaqX33OP8LNaDZw9KyTguu3cOaEY29dfC5tOXFxvIj5lCjBxolAlnhBCCLEyjuMQEhKCkJAQTJs2zej21tZWk4XdysvL0d7ejrNnz+Ls2bNG93VxcYFKpRLtIY+Pj4e7u/twPEVCiETQnG447pxumXcdXlkThL17ZNi/37BwNccJ+crcucANNwDTpgGursZnYYyho6dDn5jrEvGBkvS+ibzY8T1a03OnLoeckw/c227mUHrdz56unjSkfqgurdONvsVroqOBdevMWy6svR04eRI4dqw3Ec/PNz6O44DRow0T8QkTLFvijIxIjlKAhYwsFJfOQ61Wo6SkRLSwW3FxMbq7uwe8f0REhMnlzwICAobpWQgoLokUOUpcUiE1C0gx6QYsq17e1QUcOiSM3v3hB+DMGcNzeXkJU3FvuEFIxBMTbVfXSs2rTSbrYkm6/jYTyX1Hj3lD7YfCU+FpdiI/0FB63fcKucJmbZUavkeNA9+8g/ILuYiOSMbMmx+AXCHyyY65GhuFIel9E/HycuPjXFyAceMME/GxY4X9hFziKEuNkJGF4nJk0Gq1qKysFO0hLywsRHNz84D39/f3N7n8WXh4OGQy63UY8DyPAwcOoLS0FLGxsZg5cyYtr0YkwVGul5R0W0CqSTdgYp1uv0o8urZ8wOXCqqqAPXuEBHzXLqHwdF8qVW8v+LXXAn5+tmm/NfBaXj/03awe+L63mThGy7Q2aaub3G3w3vZBEvm+3ytdlJK80GRkZ2DVzlWoaOnt6Y7yicL6eeuxMMWMnm5zVVf3JuC6ZLx/MAOAuzuQlmZYqG3UKMCKb0yIY3GUqqdkZKG4JIwx1NfXmyzsdvHixQHvr1QqER8fL9pDrlKpoFCY/+F/RkYGVq1aZbDkWlRUFNavX4+F5oxaI8SGHOV6SUm3BaScdAPCUPO3Pj+FX46X4KpJKjy4+AqLlgnTaoVaVrpe8EOHgL6rZ8jlwJVX9vaCT5ki7HNWjDF0ajrN74HvbkVbz8DJvZpX26Stck4OL1evwXvbzZgTrzvP5Q6pz8jOwKLPF4HB8NLBXarit33xdusm3n0xBpSVGc4PP35cWPasPx8f44rpMTG0dNkI4Sh/rMkIwvPgMzNRdPgw4qdPhzw93bn/2JIhaW9vR1FRkWhht9LSUvA8b/K+crkcMTExJpc/8/T01B+bkZGBRYsWoX8aoPugf/v27ZR4E7tylL/jlHRbQOpJN2DdwGtvF1Z+0iXhfVd2AoRe7zlzepPwmJjLergRQc2rLeuBF0nk+35vyyH1HgoP073tioGTew+FB377+W9R3V4tem4OHKJ8olC8qhhy2TC9mdRqhfngfRPxkyeFORf9BQcbVkufMkWotk6cjqP8sSYjhFgdjKgooTAlJTbETD09PSgtLRUdtl5UVITOvsV9RISGhiIxMRFxcXH4+uuv0SL2gTV61y4vLi6moebEbhzl7zgl3RZwlKT75MmTSEtLs3rglZYCu3cLCfiePUBTk+Htycm9CfisWcL8cGJbvJZHe0/74D3w/QrbDZT422pIvZilqUsxOWIyQj1DEeoVihDPEIR6hiLII2h4kvGeHuD8ecNE/OxZQKMxPjY62nDpssmTpT3fgpjFltdMQiySkSGs+ND/7ZZu1M327ZR4k8um1Wpx8eJF0cJuhYWFaGxstPic8fHxCAwMhFKphJubm+jXgW6z5Bg3NzcoFApJTqkj9uEof8cp6baAIyTdw4XnhfxE1wt+5IiwT0ehAK65pjcJnzCBps06At2QerN64AeoUH+x7SLqOuqG3A4OHII8ghDqFYpQz95kPMQzxHDfpURd6WLFKuWdncI8i76F2nJyxNcbHzXKsFBbWhrgYeYyfoQQosPzQhGVvj3cfXGc0ONdXExDzYlNNTY26hPxHTt24IsvvrB3k4xwHGd2gm5JMm/psS4uLpT82xnP8zh48CCqqqoQHh6OGTNmSHbUBSXdFnCEpJsxhubmZvj6+g7rhaCpCdi3T0jAf/gBKCkxvD04GLj+eiEBv/56IDx82JpG7CCzJBOzP5o96HELRy+Eq4srqtuqUdNeg+r2atR31BvNAx+Mj5uPUW+5qSTd29Xb8t+NlhbgxAnDRLy42Pg4mUyokN43ER83TnwdPiIJ9rpmkhGsrQ0oLAQKCoSvhYXCteXEicHvGxkpJOehocIWEiL+vbc31aUgly0zMxOzZw/+t/y1115DcnIyuru70dXVZfLrQLcNdmxP3yJDEiGTyeye+OuS/5HI0Qr8UdJtAUdIuqUwr4Ex4b2Erhd83z7hPUZf48f39oJfcw0tp+xseC0P1XoVKlsqRRPogeZ0a7Qa1HXUobqtGtXtl5Lxvt+3V+uT9Jr2GovXe1e6KA17zvsn632+D/QINF1Qrq6uNwnXfa2qMj7O1VUY6tE3ER89mnqrJEIK10ziZBgTVk/QJdT9E+yaGtu3QansTcL7f+3/fUAAXY+IKJ7noVKpUFlZaVRIDRjeOd1ardaqSfxQj9GITT+zM5lMZreEv+++4fwb6ogF/ijptgAl3UOjVgO//NK7LNnx44YjdZVKYQ64bmmyMWPoA3pnoKteDsAg8bZm9XLGGJq6mgwScaPv+yTu7T3tFp1fxskQ7BFs9jB314u1hvPDjx0T1hXvz8sLmDjRsFBbfDwFvh1I8ZpJHADPC0PB+yfUuq21deD7BwUBCQm9W08P8I9/DP6469YBERFC4l5dLWy673Vf+3/KPRiZTBiOZiox77svOBhwc7Ps/MSh6ZIbAAYJjpSTG1vied6qif5QPxQYqDq9vcjl8mFJ/BUKBRYuXIgaEx9gSrXAHyXdFqCk2zpqa4G9e3uT8AsXDG+PjOztBZ8zBwgMtE87yeUTW6c72ica6+ats91yYQNoV7frk/GBetCr26vR0Nlg8fn9lH79estDENrtipDqVoQW1yLkfClCT+YhtLYTnmrAIMUOCDBeuiwy0mrPnYhzhGsmsZOuLmEaiViPdUmJ8ImyKbo52AkJQGKiYYKdkAD4+hoer5vTXVkpXj/CkjndHR3iSblYgl5fb+mrIhSQHKjnvG+y7uVFHyY6AbFhvNHR0Vi3bt2ISrilRKPRoLu72+Y9+wMd29XVBa12+IrvWmrfvn1IT0+3dzP0KOm2gCMk3TzPIysrC6mpqZL6dMcUxoBz54Tke9cuYP9+wxWcOA6YNKm3F3zaNKFIG3EcvJZHZnEmjuYcxZTRU5Aelz58y4Rdhh6+B7UdtWb1oNe014Bnln3q7M65IlTjhtAWLUJqOxDayhDaDoS0A6FtEL53D0Lo6MnwT5sG2ZSpQiJOn0JZlaNdM4mVNTeLDwEvLBR6sgd66+PqCsTFGSbTugRbpbJ83pSuejlg+Li2rF7e0yNMlTEnQa+pEV/ZYSDu7uYl6KGhgL8/VVyVMJ7nkZmZiaNHj2LKlClIT0+naybRJ//DOdy/rq4OdXWDF+vdunUrli5dOgyvgnko6baAIyTdjq6zEzh0qLcX/OxZw9u9vYHZs3uT8MRE+7STkL60TIvGzkbxHnSR3vROzcBrpPbnwgPBHUIyHqJ1F3rQg1UIiU5BaNIVCA1U6Ye5B3sEQyGnT6YIASAkr9XV4kPACwoG7+n19jZOqHVbVJT150KLrdMdHS0MK7d3j6JWK1RNHShB7/t9R4dl53dxEYavm5OgBwfTJ/CEjFDmFvijnm4H5ghJt1arRV1dHYKCgiBzgk+ML1wQ1gbX9YT3/2ArPr53KPrs2cYj9ogEaHloq/ejtTYP3sFJkIXOAhygp9uW2tRtg/egt1ahpuUiGjWDzA0VEaAMEOace4UOWjTOQzGylzhztmvmiKTRAGVl4j3WRUVA+yC1HEJCxIeAJyYKc6+He3g0z0O7fz9a8/LgnZQE2axZjlnorL3d/AR9CGtDIyDAvEJxISGAp6f1n98IRNdLIgVSKvBnCUq6LeAISbczz0/UaoFTp3p7wQ8fFkbG6cjlwFVX9faCT57smO9TnEp5BnB8FdDRp9fGIwqYtB6Ipnlg5lDzan2l9uqLBag+fxQ1xVmoripATcsFVHMdqPYEajyBWk+At/B9kKfC06hQnKlq7n5KP6dbVsuZr5lOpaNDSKDFeqtLSwce9iyTATEx4sPA4+OF3myJGXFxqVYLBV/MSdBra4U58Jbw9DQ/Qff3p3noJoy4uCSS5YgF/ijptgAl3dLS2irMAdcl4Xl5hrf7+wuF2HRJeHS0fdo5YpVnAAcXAUZLhl16MzNjOyXe1nDxon7JMu3RX1F/9lfUdDeg2gv6ZLzaC6j2laMm3AfV/q6oUfKoZq3o4rsteiiFTGFQrX2g9dCDPILgIpP+NWgkXTMlr6HB9DJb/Stu9ufmJiTQYj3WKpUw/9qBUFwOQKsVYsWcBL262rBQjDkUCiH5HqySe0iIMMx9BP3/UFwSKXG0An+UdFtA8km3lgd/MRNF5w8jfsx0yMPSR9Qw3pKS3mHoe/YI9XH6Gj26NwGfNYtGmwEAmBbQ9ggb6wF4tfBV22O4f6CfRfd1A1kvAj3NJh6YE3q8bykeUTE6LBgThtr2Xbrs+HGgpcXwMACtwT6omTIG1RMSUJ0YjppIP1S79aBa17PeZ156c7ep/0txHDgEegSKJ+UivelKFwuLTlmBrsjf4TOHMX38dIcp8uewtFphLXtT86ubmga+v6+vcVKt+zkiwqmKcFFyYyWMCUuomZug93/jMBiOE4pbmlPJPTRUKCznwCguidToCvwdPnwY06dPl3SBP0q6LSDppJuG8RrQaIRcQ9cLfuSI8H5Px9UVuOaa3iR8/HgL3q/1T1QHS0AtTmLV1jmPOT8zOy/1cN0+IDTdvm0YCbRaYSjIpR5xHD0KnDwp3gMUHNy7ZJlu+bLQUHRpulDbXiu+JnpHjcG+uo46aC2MLW9X7wET876Ju4+bz2UPcxdbzi7KJwrr5623y3J2TqOnR/gEVKzHuqho8F7H8HDThcsCAkbMsF+e55GXl4ekpCTJvoF0St3dQhJuToJeV2f4xsIc3t7mFYoLCRE+ZJJSvPM8+MxMXDx5EmFpaZCnp9McPiIJjnK9pKTbApJNuh1hGC9jQ0xALyWhl9n72t3Vg5qLPaip7kFDbQ961D1QyC9tLj3wUPbA368Hft498PLsgQs3wOPaO1G1NU4OyFwBmULYOEXv9+b+3FkJ1P08+GN5xABJDwCxSwFPGv8/rHp6hPX6+ibiZ8+Kz42Nju5NxKdMEdbx8/MzeWpey6O+s37AKu5996n5AdY7FuEmdzN7mHuge6BR73VGdgYWfb4IrN81k7t0zdy+eDsl3gNpaxMSaLEe69LSgRMRuRyIjRXvsY6PBzxGdmE/4kB4Xqh+b06CXl098LruYlxdzU/Qg4JsmwCLVdWPigLWr7d/VX1CHAQl3RaQZNKt5YGvVYY93P25BgBprwGMv7xe0aEMPdb9bOEaxg6Hkw89QZW7Du1+lvxsyX2s8cl6dSawd/DlHAyEzARUy4HoRYBbwOW3gViusxM4fVpIwHXJeE6O+FrFo0YZJuJpaUNKmBhjaOluEe9B75ugX9rXqrasmruMkyHII0ifiAd7BuObvG/Qpm4TPZ4DhyifKBSvKh65Q80ZE3rxxIaAFxYKCcRA3N3Fh4AnJAgFzWipp0FptVpcuHABERERVCXaGTAmTPExJ0GvqTGaDjQomUxIvM0pFBcaKtRAMJdu/fj+fwdsuX48IRZwlOslJd0WkGTSPZTkRiouJ1EdcsJp3IPbwyuQk6fAsRMKHPlVgXM5wr4ejfBVrlBg4iQFrr5GgZnpCiSOUoCT9z2HC8BJ95fcLvQfBlXCeAQGAHCAewSQ+gxQug2o2d97k0wBhN8IqJYBkfMBF+r5squWFuDECcNEvLjY+DiZDBg71jARHzfO6gWsOns6RXvLxfbVd9Qb9Waba/X01bgt5TYkBybDV+mEaxFqtUKvlVjRssLCwd/0BwSIDwFPTATCwqQ1LNYB0dzZEa6z03CY+0AJel2d+AejA/H1NS9BDwoS5t9VmOjY4Tihx7u4mIaaE7txlOslJd0WkGTSXfIp8NOywY/zmwB4xtqmZ9TkOVwHOE66iWptreHa4FVVhrdHRwvzwG+4QaiOHkCdsuL00x4Aw8RbZNpDezlQ+ilQshVoOt17qIuXcEzsMiDsOiFuiP3V1RkOSz96VKii3p+rK3DFFb1zw6dMESoaDtObM41Wg7qOOoNe8535O7Ela4tF5wn3CkdKcApGB47G6CBhSwlOQaR3pLSXUOvuFt4Mi/VYFxcPPtw1Kkp87eqEhAGnF5DL5yhvIokEaDTCNdmcBL262nCtVWt5+22hSE5QkPTmohOn5yjXS0q6LSDJpNvcnm4qWDUkjAFZWb0F2Q4cEN7H6nCckEfoCrJdeSWNnDQgWuAvGpi0znSdgaZzQOlWIQFvL+ndrwwBYpYIQ9ADp9IfdSlhTFjSqW8SfuwY0NhofKyXFzBxomEiHh8/bP+fmSWZmP3R4NfMtLA0VLdX40Kr6aWqPBWevUl4UIr++8SARLi5WDB883K0tJheZqu8fOAeMIVCWE5LrMc6Ls7hKy07Mkd5E0kcDGPCKgFiybjYvjbxaTgDcnERKroHBRluwcHG+3Sbhwf9TSdD5ijXS0q6LSDJpNucYby0NJPVdHQABw8KCfgPPwh1qPry8QGuvVZIwOfOFXKJEU/LQ1u9H7VlZxAcMx6y0FnmxSJjQjG2ki1A2edAd13vbV4JwvBz1XLAJ9l2bSdDx5hQbKtvIn7iBNDebnxsQEBvEq77Ghlpk2bxWh6q9SpUtlSKDj3vP6e7uasZufW5yKnLQU5dDrLrspFTl4OChgJotCJF5wDIOTni/eP1SXjfpNzf3d+yBjMmvAE2tcxWXd3A9/f0ND0MPDqahoRKlFarRXFxMeLi4iQ9R5E4uZ07gRtvHPy4sDDh2t5qWc0NPaVy4KS8f9IeGGj1qUvEcTnK9ZKSbgtIMukGLBvGS6yqsrJ3GPru3UIh074SEnp7wWfPFpJyMgTaHqBqt5CAV3wF8B29t/lPFJLv2CWAh20SNWIlPA9kZxsOTT99WnyYc3i44fzwyZOFN1pWoKteDsAg8bakenkP34OixiJ9Et43KW/pNj0fOsQzxKhnfLRfImJaOMiKisV7rMU+qOgrONh04bKQEOpBIoQMDc8Lo2EqK8VHzfSf093dLXwQONBWW2v4vaVV3XV8fMzvSQ8KAvz96UNGYleUdFtAskk3MLRhvMSqeF5Y+ljXC/7TT4arL7m4ANOm9faCT5w4cq7/Vv0UUtMOVPxHGH5e9QPAdC8yB4TOFnrAo38LuPpdbrPJcOjuFpYq61uo7dw58WWn4uIME/GJE4V1b4dAbJ3uaJ9orJu37rKWC2OM4WLbRaOe8ZzabJS3ml5lwr0HSK4DRl/aUi59HVUPuPOc0Cst1mOdkECf5jkhR+m5ISOArno5YJh4W6N6OWPCh4qmknJTm6XrowNCsc+AAPN60nWbtzd9aOkAHOV6SUm3BSSddAOAlgd/MRNF5w8jfsx0yMPSaUi5HbW2Avv29SbhBQWGtwcEANdf31uULSrKPu0cDjabb9NVC5RvF3rAaw/37pe5AhG/EXrAI38DyJXWe0xie+3twidYfeeH5+cbH8dxQmG2von4hAnCUEUz8D1qZH79Fs5k/YLxqVch/ZYHIVdcxpDFxkbTy2xVVqLNFcgNBHKCerfsYCA/AFCb+LXgwEHlG4uUkDFGhdyCPIKG3lYiaY4yR5GMEGLrdEdHA+vWDf9yYVqtMC/dnJ503dbUNLTHUigs600PCqJaGHbgKNdLSrotIPmkG44TeCNRUVHvUPS9e41X5BkzprcXfObMIS15LFnDEpdtJZcqoG8BmvtMtlf4CD3fquVASDp9EOWoGhuB48cN54iLLWPj4iIsVdY3ER87Vtjfl9ibyKgoYP16028iGROWMxBbYquwEGhoGPg5+PiIDgHXxMWixLMHOY35yK691DNen4Ps2mw0dokUo7sk0D1QtJCbyk81ctcYdxL0t5xIDs+Dz8xE0eHDiJ8+HfL0dMcZrtfTI1yfB+tF73t7R8fg5xXj6WlZb3pgoPHfJ2IRR7leUtJtAUq6ibVoNMCRI7294EePGo6WcnMDZszo7QUfP96xRzgNa1wyBjSdFZLv0k+BjvLe29zDgZg7hCHoAZMc+0UlwjJl/ZcuEyss5u4OpKX1zg1vbBQS7v5/1nTx8NZbQlLcv7e6qEhYP3cgoaHiQ8ATE4U3VxbEHGMMtR21RnPGc+pyUNpUanINcje5G5ICk4wKuSUFJsHT1dPsxyf2Q3/LiRSNqLjs6BAK9Vgy9H2oy7H5+Znfkx4cLCzLJuFh1MPNUeKSkm4LOELSrdVqceHCBUREREh6XgMx1NAg9H7rkvDycsPbw8KEoehz5wpfQ0Ls086hsltcMi1Qe+hSBfQvAHWfXkPvpN4K6N6Jw9cmYjuMAWVlhkn48ePGw0ouh0wGxMaKFy6LjxeWRBsGHT0dyK/PNyrkllufiy5Nl8n7xfjGCIl4oDBEXZeUh3qGSnvN8RGG/pYTKaK4HABjwt8ac3vS6+qEN39DSa/kcvFl2QZK3D09nbajwVHikpJuCzhC0k0cH2NAbm5vAp6ZaTzKKS2tdyj61VcLPeNkELwaqNopFGCr/Brg+/RYBk4FYpcJFdDdw+zXRmJ9Wi2Ql9fbI75nD3D+/OD3i40V5of377GOjZX0UjW8lkdZc5lxIbe6HNR21Jq8n5/Sr7dnvE9CHu8fDxeZdHsOCCHEYfG8MPLK3J702tqhL8vm5mZeb7ru9sBAx3hzyfPCWr5VVcKqJzNmSHbaAyXdFnCEpJvneeTl5SEpKQlyiQYdsUx3N3D4cO988JMnDW/38ADS03uXJktOlt6HmZKLy55WYemxki3AxT0A44X9nAwIvU7o/Y6+TZgPTpzLp58Cy5YNftzWrcDSpbZvzzCq76gXHape3FQMLROvBqyQKZAYkCgk4X0KuY0OGg1vt6FVjieDk9w1kxBQXEpCd7fxsPeBkvbaWuE+Q+HtbX5PelCQUCF4OONiKLVZ7IiSbgs4QtLtKPMayNBVVwuddT/8ICTh1dWGt8fE9PaCX3edsDSlvUk6LjurgbLPhQS8/kjvfrkSiJwvJODh8wC5A3ziSwaXmQnMnj34cfv2CZ9mjQBdmi4UNBQYFHHTJeYdPaaLCUV6R4oWcovwjqCh6pdJ0tdMMmJRXDogxoThkoP1pPe9rb5e6EG2FMcJbzrN7U0PChIKjA7l74VuKTtTtVkuZyk7G6Gk2wKUdBOpYQw4c6Z3KPrBg4Ba3Xu7TCbUjtL1gl95pX2KZDpMXLYWCsPPS7cALbm9+139gehFwhzwkJlCjzhxTDwPqFRAZaX4XDqOEz4pLy6W7BC14aJlWlS0VPT2jNdm6xPyi20XTd7Py9XLKBEfHTQaiQGJcJVLd2i+lDjMNZOMKBSXI4RWCzQ3W1ZErtH0ShsDcnGxrDc9KEgY9q5Sia9gAkj27zgl3RagpJtIXUcHcOBAby94/6mrPj5C77cuCY+LG552OVxcMgY0nryUgH8KdF7ovc09ElAtFXrA/SZIbyw/GZzuE3LAMPGW8CfkUtPU1WQwVF23FTQUgGfiPSRyTo6EgATRhNxP6Te8T0DiHO6aSUYEiktikm5ZNkvWT29vH9pjubmZN2ReYiPWKOm2gCMk3VqtFnV1dQgKCpJ0BT8yPMrLgd27hSR8zx7jZYRHjepdlmz2bGH6ji04dFxqeaD2wKUK6NuBnube23xShORbtQzwGqZPMIh1iM0Fi44G1q2jhPsyqHk1ChsKRQu5tapNFwAK8wrTF3EbHdRbyC3KJwqyETiyxKGvmcRpUVwSq+rs7J2fbu4a6pYsyyax2iyUdFvAEZJuQkzheWH1JF1Btp9/FtYL13FxESqh63rBJ06kZSCN8F3Ahe+FBLzyG0Db55PWoGlCAh6zGFAG26+NxHwOVPXU0THGcKH1gmght8rWSpP381B4IDkw2aiQ26jAUVC6KIfxGRBCCLErxoTq7d98AyxfPvjx1NPtuBwh6eZ5HllZWUhNTaXKkmRALS3C9Ug3FL2w0PD2wEBhTXBdT3hk5NAfyynjUt0MlGcApVuB6h+FNcEBgJMDYTcIvd9RtwKK4Vm3mQyNU8amg2ntbkVufa5RIbf8+nz0aMV7NWScDHF+cQZD1HVD1gM9Aof5GVgfxSWRIopLIgkOWpvF3DySJm44CMYYOjs7QZ+RkMH4+AALFggbICTdul7wvXuFET/btgkbAIwd29sLPnMm4O5u/mM5ZVy6+gIJvxe2ziqg9DOhB7zhGFD1vbDJ3YGoBUIPeNgNABWRkhynjE0H4+3mjckRkzE5YrLB/h6+B8VNxUY949m12WjubkZhYyEKGwvxbf63BvcL8ggymjeeEpSCGN8YyGXSeQM2EIpLIkUUl0QS5HJhWbBFi4QEW6w2y7p1kkq4LUE93XCMnm4qckGsoacHOHKktxf86FHDa5qbm5B465YmS001XU+M54HMTB6HDxdh+vR4pKfLHfU6aJ6WXKDkUyEBbyvo3e8WCETfLiTgwVdTBXSJoGum42GMoaa9xmC+uC4pL2suM3k/pYsSSYFJRgl5UmASPBQew/gMBkdxSaSI4pJIioPVZqHh5RagpJuMVPX1Qu+3Lgnvv0pDeHjvMPTrrxdWewDEr4dRUcIHlBK8HloXY0Kvd8kWoHQb0NVnQXXPWCB2qTAE3W+c/dpI6JrpZNrV7cirzzMq4pZXn4duXrzaLQcOsX6xBoXcdMXcgj2C7bLmOMUlkSKKSyI5PA8+MxNFhw8jfvp0yNPTJdvDTUm3BRwh6WaMobm5Gb6+vnZ5o0CcH2NATk5vAp6ZKRSg7GviRCA2FvjyS+P7j8hVmbQaoHqfkICXZwCaPlWc/cYBscuEZcg8Y+3XxhGKrpkjA6/lUdJUYtQznl2XjYbOBpP381f6G80ZHx00GnH+cXCR2S7poLgkUkRxSaTIUeKSkm4LOELSTchw6+oCDh/uTcJPnx78PhwHREQApaWS/UDSdjSdwIVvhDXAL3wHaNW9twVfc6kC+u3CcHRCiM3VddTp54rrCrll12ajpKkEDOJvfVzlrhgVMMqokFtyUDK8XC+veCKv5XGw7CCqWqsQ7h2OGTEzHGYuOiGEEHGUdFvAEZJujUaDkydPIi0tjYb+ELu4eBHYsAF4+eXBj3VzE5LvkBAgNFTYTH3v72963rjDUjcCZTuEHvCa/YDuDT7nAoTPExLwqFsAF2nNN3UmdM0kpnT2dCK/Ib83Ib9UVT23Lhedmk6T94vyiTLoFdcl5GFeYYP2wmRkZ2DVzlWoaOmdkxPlE4X189ZjYcpIGRpEpIqul0SKHCUuqXq5E+J53t5NICNYWBgwzsxpyt3dwooOxcWDH+viIiTh5iToQUGAQnF5z2NYuPoDifcJW0eFMPe7ZAvQeEroDb/wDeDiCUTdJsz/DrsesOGQ1pGKrplEjLvCHeNDx2N86HiD/VqmRVlzmcFQdd1w9Zr2GlS0VKCipQK7i3Yb3M/Hzac3EQ8U5oyPDhqNBP8EKOQKZGRnYNHni4x61ytbKrHo80XYvng7Jd7E7uh6SaTImeKS3uURQswWHm7ecZ98AsTFATU1QHW1sIl939QEaDTAhQvCZo7AQMNkfKBk3UMKHckeUUDKY8LWfF4Yfl6yFWgvBko+ETa3YCB2iTAHPOgqJ+z6J0T6ZJwMKj8VVH4qzEucZ3BbQ2cDcutyjQq5FTYWoqW7Bb9W/opfK381uI+LzAXxfvEoaykTHc7OwMCBw8M7H8aC5AU01JwQQpwYJd2EELPNmCFUKa+sNFxqTIfjhNvvuMO8Od3d3UBtremkvO/3tbWAVitUXK+vB86fH/z8Xl7mJ+h+fsOQ6/qOASb8DRj/IlD3C1C6VVgHvLsWyHtb2DzjhN5v1XLAN8XGDSKEmCPAPQDToqdhWvQ0g/3dmm4UNBT09ozX984hb+9pR15D3oDnZWAobynHx2c+xp3j77RpETdCCCH2Q3O64Rhzuhlj6OzshLu7u6Qr+BHnl5EBLFokfN/36mHr6uU8DzQ0GCfjppL1bvFVhExydTUc5j5Qgh4UJAyLtwptD3BxrzD8vOJLQNPee5v/FULyHXuH0GNOzEbXTGJPjDFUtlbiX0f/hZcPmVEIA0IRt5SgFIwPHY9xIeMwLnQcxoWMQ4R3BMUwsSm6XhIpcpS4pEJqFnCUpJvnecjlckkHHhkZxNbpjo4G1q2TxnJhjAGtrQP3nPfd19Ji2fk5Tki8xRJzsX1KpZkn1rQDFf8VEvCqnQDT6B4RCJl1qQL6b4U542RAdM0kUpBZkonZH80e9DilixJdmi7R2wLcA4QkPGSckJCHjkNqSOplV1MnRIeul0SKHCUuKem2gCMk3RqNBseOHcPkyZMlXcGPjBw8D2Rm8jh8uAjTp8cjPV3usMuEdXUN3nOu+76uTnxo/UB8fMxP0H18Lo0a6K4Hyr4Q5n/XHuw9mcwViLhJGIIecTPg4m7V18JZ0DWTSAGv5aFar0JlS6XovG4OHKJ8olD4UCEqWipwpvoMztacFbbqs8itz4WWaUXPHecXZ9ArPj50PBIDEmmIOrEYXS+JFDlKXFL1ckKITcnlwKxZDJ6e9Zg8Oc5hE25A6ImOiRG2wWg0wpxycxL06mqgp0foSW9pAQoKBj+/m5suAQ9EaOifEBLyJyRHlWJ65KcY670V/tqzQMVXQMVXYC7e4KIXCj3godcCVIiJEEmRy+RYP289Fn2+CBw4g8Sbg9Bzs27eOijkCsT5xyHOPw4LRi/QH9Ol6UJ2bTbO1pztTcirz6KqrQrFTcUobirGf3L/oz/eTe6GMcFjhCQ8ZLx+iLo5y5oRQgixHUq6CSHEAi4uvb3Tg2EMaG42fx56W5swF728XNh6xQJYDWA1UqPPYtnVW7Hs6q2IDSoDij8Cij9CQ0cojlTfgZzO5VB7T0ZICGfUq+7mZpvXhBBi2sKUhdi+eLvoOt3r5q0bcLkwpYsSaeFpSAtPM9hf11GHs9W9PeJnas4gqyYLHT0dOHnxJE5ePGlwfJBHkH6Iuq5XfGzwWHi6elr3yRJCCBFFw8tBw8sJGSqKS+vq6Bg4Me+7r6FBi6tH/YTl07dg8ZWfI9C7QX+evKpR2PrTMmz9aRnyLybp9/v6Dr4Wuu57Ly/HXrmMYpNIDa/lkVmcicNnDmP6+OlIj0u36jJhWqZFcWOxUa94fkO+6BB1Dhzi/eONesUTAxJp+bIRhq6XRIocJS5pTrcFHCHpdpRiAmRkobi0H42md7m12mo15DW7EN69BQnK/8BV1qk/7lT5ZHx8YDm2/rQEF5vMXGgdgLu7eZXcQ0OBgABAJrPFsxwangcOHGCorNQiMlKGmTM5h57+QJyHPa6ZnT2dOF973qBX/Gz1WVS3V4ser3RRYmzwWH0Srps3HuplxvAe4pDobzmRIkeJS0q6LeAoSbcjlM0nIwvFpQT1tAlzvku2Ahd3AYwHADDI0O59LSrky5DduhAVNb4mh7l3dFj2kHI5EBxsXoIeHCwsz2YrYpX1o6KA9eulUVmfjGxSumbWttf29opfGqqeVZOFTk2n6PHBHsFGveJjQ8bCQ+ExzC0n1ialuCREx1HikpJuCzhC0u0oQyzIyEJxKXFdNZcqoG8B6n7u3S9zAyJvFgqwRdwEyA0ne7e3mz8PvbHR8mb5+5uXoIeGAp4WTDnVrSHf/6+ardeQJ8RcUr9m8loeRY1FRr3iBQ0FJquvJwYkGvWKx/vH0xB1ByL1uCQjk6PEJVUvJ4SQkU4ZAiQ9IGxtRUDJp0IC3pINlO8QNoUvELNISMCDZwIyOTw9gfh4YRuMWt07zH2weei1tcLQ78ZGYcvJGfz8Hh7mJehBQUIPt9jHyIwJiffDDwMLFoCGmhNiglwmx6jAURgVOMqgwFtHTwfO1ZzTJ+O6HvLajlrkN+QjvyEfGdkZ+uPdXdyRGpKqL9ymS8iDPYPt8bQIIcTuKOkmhJCRwCseSH0aGPtXoOm0kHyXfAp0VgKFHwibewQQu1RYA9w/zaxKaq6uQGSksA1GqwUaGsxfbq2rSxjqXlwsbJeDMaEi/J//DKSmCsl8383T03ifh4ewnJyER7URMiw8FB6YEjkFUyKnGOyvbqs26hU/V3sOnZpOHL1wFEcvHDU4PtQz1KhXfEzwGLgr3Ifz6RBCyLCjpNuByKl7hkgQxaWD4TjA/wphu+IVoOaAMP+77Aug8wKQ87qw+YwGYpcJCbh3glUeWiYTeqSDgoCxYwc+ljFhCTVzE/TmZvPasHGj5e0WS8bNSdgt2SQ8co5YmTNdM0O9QhHqFYo58XP0+3gtj4KGAqNe8aLGIlS3V6O6qBp7ivboj5dxMowKGKVPxnUJeZx/HGSchCo0OjlnikviPJwpLmlONxxjTjchhNgU3w1U7RR6wCv/C/BdvbcFXiUk37FLhCHrErRrFzB37uDHzZ0rLJ3W0THwplbbvs19uboOLVm3JOF3c6Nee2I/7ep2nKs9Z1C47Uz1GdR31ose76nwxNiQsQaF28aFjkOQR9Awt5wQQkyjQmoWcISkmzGG5uZm+Pr6SrqCHxlZKC6dVE8LUP6lkIBX7wV0a/xyciBsjjD/O+pWQOFt12b2xfOASgVUVorP6+Y4oYp5cbF5c7o1GqCzUzwhb28fPGkfbNOdYzhxnPV66E3d192d5sybolvKrrCwAwkJHrSUHYS/IRfbLhr1ip+vPY9uvlv0PuFe4UZD1FOCU6B0UQ5z650H/S0nUuQocUlJtwUcIel2lAp+ZGShuBwBOi8CpZ8BpVuB+l9798vdgchbhAQ8fC4gt+E6YGbSVS8HDBNvqVYvZ6x33vrlJO6DbT09w/u83NxsOyTf0xNQKByr156WsrOMRqtBQUOBUa94cZN4cQc5JxSA0yXhul5xlZ+Khqibgf6WEylylLikpNsClHQTMjQUlyNMS76QfJdsAVrze/e7BgAxtwtD0IOvAez4JlcsuYmOBtatG7nJTU+P7XvtO8WXdrYZudz6vfRivfYyK4QyLWVnPa3drThXe04o3FZ9RughrzmLhs4G0eO9XL30VdT1CXnoOAS4Bwxzy6WN/pYTKXKUuKSk2wKUdBMyNBSXIxRjQMPxSwXYtgGdVb23eURfqoC+HPAfb5fm8TyQmcnj8OEiTJ8ej/R0+YgfxmtrWq3te+3b24X/2+GkVF5eD71SCaxcCdSLT1u2eNoDMcYYQ1VblVGveHZdNtS8eHGGCO8Ig17x8aHjMTpoNNxc3Ia59dJAf8uJFDlKXFLSbQFHSLp5nkdWVhZSU1OdqpIfcWwUlwRaHqjJFHq/y3cI88F1fFMvFWBbCniphrVZFJvOqafH9vPsu7oGb4e1/fWvwK23AqNGAX5+w//4zqiH70F+Q75Rr3hJU4no8XJOjuSgZKNe8VjfWEnPJ7UGul4SKXKUuKSk2wKOkHQTQojk8V1A5bdCAn7hW0Dbp5cpeLrQ+x19O6Ck6sNEurRa08PxLe2xLykBsrMte/zgYCApqXcbNUr4mpgoDHknl6eluwVZNVkGveJna86iqatJ9HhvV2+j5czGhY6Dn9JvWNtNCJEmSrot4AhJt1arRV1dHYKCgiCzxiQzQqyA4pKYpG4Ser5LtgLV+wBc+lPDuQiF11TLgKgFgIunTR6eYpNIQWYmMHv24MeNHy+sO3/x4sDHxcT0JuF9k3KVSiguR4aGMYbK1kqjXvHs2mz0aMUrEUb5RBn1io8OGg1XCRSVtBRdL4nU8Foe+0v2I68qD0nhSZilmgW5TJq93ZR0W8ARkm5HmddARhaKS2KWjkqhAnrJFqDxRO9+uYew9JhqORB+PSCzXtZAsUmkwNKl7Fpbgfx8IC+v96tua2oy/TguLkB8vGHPuG6LiLBOQbiRqIfvQW59rlGveFlzmejxLjIXjA4abdQrHu0TLekh6nS9JFKSkZ2BVTtXoaKltyJqlE8U1s9bj4Up0qs6SUm3BSjpJmRoKC6JxZpzeiugtxX17ncLAmIWCwl40LTLXg+KYpNIhTWWsmNMKMbWNwnvm5wPVD3e3b03Ee+fkAcGOtbSa1LR3NWMrJosg17xM9Vn0NLdInq8r5uvwRB13fe+St9hbrk4ul4SqcjIzsCizxeBwTA95SBcqLYv3i65xJuSbgtQ0k3I0FBckiFjTFj3u2QLUPYZ0FXTe5un6lIBtmWA39ghnZ5ik0iJLZey02qFnvT+PeP5+UBREaDRmL6vn5/4/PFRowBv78tr10jDGEN5S7nREPWcuhxotOL/CTG+MUa94smByVDIh3euAF0viRTwWh6q9SqDHu6+OHCI8olC8apiSQ01p6TbAo6QdPM8j7y8PCQlJUm6gh8ZWSguiVVoNcDFvUIPeHkGoGnrvc1vQm8FdM9os09JsUmkRreU3cmTF5GWFjYsS9n19AjF3PoPV8/PB8rER0jrhYeLzx9PSADcRubKWkOi5tXIqcvRD1HX9YqbSiwUMgVSglMMesXHh45HpHekzYao0/WSWAOv5dHNd6Nb040uTRe6+UtfL/0stq/vz+drz+PDUx8O+jj7VuxDuird9k/ITJR0W8ARkm5CCBkRNB1A5X+FAmxV3wP6IkYcEDJTSMCjFwFuAabPoeWB2oPC+uHu4UDwDEBCn4oTIgUdHUBhofj88dpa0/eTyYDYWPGEPDaW1hs3V2Nno9EQ9bPVZ9GqbhU93k/pZ1S4LTUkFT5ul/e+ldfyOFh2EFWtVQj3DseMmBmS6kUkg9My7ZAT3UHvY8GxpkZ0WNvWhVuxdNzSYXksc1DSbQFHSLq1Wi0uXLiAiIgIqixJJIPikthUd/2lCuhbgJoDvftlCiD8RmH+d+TNgItH723lGcDxVUBHn14kjyhg0nogWlrzwMjI4yjXzKYm0wXdWsVzQgCAq6vQEy42fzwsjOaPD4YxhtLmUqPCbbl1ueAZL3oflZ/KqFc8KTAJLrLBh4k7WsEqqdElu5eT6IoeY0lSrOk2WWHfnjhwULoooXRRws3Frfd7uZvBvr4/N3Q04LuC7wY9N/V0OzBHSLppvg2RIopLMmzay4HST4Ue8KbTvftdvIRkOnYZ0NMCHF4CoP+ftUvv9Gdsp8Sb2JWjXzMZE5Y2EyvoVlAAdHebvq+Xl2Ei3vd7f//hew6OqFvTjZy6HKNe8crWStHjXeWuSAlKMegVHxcyDhHeEfoh6o5YsEpHy7RQ82q7Jrpdmi5JJ7vmJrp9f7b42AGOcZG5WDwdQjenu7Kl0igudc+N5nQ7OEq6CRkaiktiF03nhN7v0q1Ae2mfG2QAtCbuxAk93rcU01BzYjfOfM3keaFQnFhCXlwsFHwzJShIfLh6YiLg6Tl8z8HRNHQ2GPWKZ9VkoU3dJnp8gHsAxoWMw9jgsfg061M0djWKHmcquWGMGczZvexEV9ONLt6yRLeb74aaV9vk9bwcHLghJbrmJrHmJtJDSXalRPdhEACDxFvKHwZR0m0BSroJGRqKS2JXjAF1Pwm93yWfCD3dgwm/EfCMEYaocwrhq8Hmarx/sJ/NOUb3swO/GSKXScuDv5iJovOHET9mOuRh6SPmAyC1WqikLlZhvVK8s1YvKko8IY+LE4azE0NapkVpU6nRcmZ59XnQsgE++RAR7BEMAPrEV4rJLgDLk1crJ7puLm5QyBQOnexKidi0h2ifaKybt05yCTdASbdFHCHp1mq1KC4uRlxcnKTngZGRheKSSEbxx8DPd9m7FYPj5CYSd1fLkner/Ox6GedxoQ8QLEG1BkxqaxOGpotVWK+vN30/uVxIvMXmj0dFCQXfSK8uTReya7NxtuYsPjv3Gb7LH3zu7GAsTl7lliW65pyfkl3nxGt57C/ZjzNFZzA+fjxmqWZJakh5X5R0W8ARkm5CCCEDqM4E9s4e/LiE+wCPaKEqOusRvuo21gPwavH9Q/nZROEjp8G5DDHhv4xkf6gfNMgHGMHAyW37AUJ5BnBwEajWgOXq600XdOvoMH0/pVIYmi42fzw4mD4vyizJxOyPBr9e/vs3/8b0mOmiybCr3JWSXUJASbdFHCHpph5FIkUUl0QytDzwtQroqIRxcgPYZU430wprkFuUtKuHnuxfzgcEfR9f7BgLh6U6HJuNKnABCjYCGlMlv6nWwFAwBlRVGc8dz8sTlkHrGaC+la+veEG3UaOE20YCRy1YRUYWR3mPaW4eSZMwHYRWq0VtbS1iY2MlHXhkZKG4JJIhkwtDdQ8ugtCD2PeN5KXemEnrhjex4WRCDyucYOIp09o22bf2KIOBfhb7AEHbA6AHGPbBCQzoKAdOPyWsQe8z5lLMkIFwHBARIWzp6Ya3aTRAWZl4QbfSUqC5GTh2TNj6Cw01XdBNqRyWpzYs5DI51s9bj0WfLwIHTrRg1bp56yjhJnblbO8xKekmhBDiHKIXCkN1RefOrqMhvJeDkwFyN2FzdCY/QLBglIG5CX7jGeDCN4O3Kfs1YZO5An7jgYCJgP9E4avfOEDuRBmfjbm4APHxwjZvnuFtXV1CT7hYQbeLF4HqamE7dMjwfhwHxMSIzx+PjRUe09EsTFmI7Yu3i67TLdWCVYQ4Mge8TBBCCCEmRC8EIheM2CrRxAzD+QFCdaZ5Sbd/GtBWDPQ0AQ3HhE2HcwF8xwoJeMAkIRn3nwC4eNiq1U5LqQTGjhW2/lpaTM8fb24WeslLS4Hduw3vp1AICb7Y/PGICGnPH1+YshALkhcgszgTh88cxvTx05Eel0493ITYAM3phuPM6b5w4QIiIiKcYogFcQ4Ul0SqKDaJJFhSa4CTAe0lQMNxoOEE0HhC+L67TuRuMsAnpbc3PGAS4H8FoPC26dMZiRgD6urE54/n5wu956Z4eIjPH09KAgIDh+85DIaul0SKHCUuqZCaBRwh6SaEEEKIA9JXLwdEaw0MVL2cMWGqhC4B1yXjnVUiB3OA9yghAdcPT08DXP2t+GRIX1qtsM64WEJeVATwA9QICAgQnz8+ahTg5TV8z4EQcnko6baAIyTdPM8jLy8PSUlJkMtp2A+RBopLIlUUm0RSRNfpjh56rYHOKiEB79sj3lEufqxXfL8e8YmAMmhIT4OYr6cHKCkRL+hWbuK/SiciQnz+eHw84GrlOns8D2Rm8jh58iLS0sKQni4HXTKJFDjK33GqXu5kGGNobm4GfUZCpITikkgVxSaRFGvXGnAPByJ/I2w6XbVA40nDHvG2ot6tfHvvsR7RvQm4Lhl3D7usp0gMKRS9Pde/+Y3hbR0dQkE3sYS8tha4cEHYMjMN7yeTASqV+HD16GhYnCxnZACrVgEVFXIAkQCAqChg/XpgIdVRI3bmbH/HKekmhBBCCLE1mRwsZBbqyzwRFzLZ+sX9lMFA+A3CpqNuBBpOGg5Pb80TesU7yoGKr3qPdQ837hH3iJJ2JTAH5eEBjBsnbP01NgoJuFiF9dZWYdh6URGwc6fh/dzcgIQE8YQ8NNT4vzEjA1i0SJjB0FdlpbB/+3ZKvAmxJkq6CSGEEEKckas/EHatsOn0tACNpwyHp7dkC0PWO78FLnzbe6xbsOHyZQGTAE8VJeI25O8PTJ0qbH0xJixnJjZ/vKAA6O4Gzp8Xtv68vQ2T8MRE4LHHjBNu3eNwHPDww8CCBZb3nhNCxNGcbjjGnG6tVou6ujoEBQVJuoIfGVkoLolUUWwSKZJsXGrahTXF+/aIN58DmMb4WIWfYW94wETAO1GoqE7sgueFeeJiCXlJiVDwbSg2bgRuugkIDhaGyxMynCR7veyHCqlZwBGSbkIIIYSQYcN3AU1nDYu1NZ0FtGrjY128hUrpfXvEvZOtP4SeWKy7GyguNhyqfugQkJ1t2XkCA4GQEGGouu6rqe89aAl5MoJQ0m0BR0i6eZ5HVlYWUlNTJV3Bj4wsFJdEqig2iRQ5fFzyaqDlfG9veMMJoOmUkKD3J/cA/CcY9oj7jgFk1GVqb5mZwOzZgx/n7w+0tAy89JkYT8+Bk/K+3/v50WwFIs5RrpdUvdzJMMbQ2dnpNBX8iHOguCRSRbFJpMjh41LuCvhfIWwJ9wr7tBqgJcewR7zxpDBkve5nYdORuQF+4y/1hl/qEfdNBeRu9ng2I9aMGUKV8spK8XndHCfcXlwsfN/QIMwnr6kRvg70fVcX0N7eW/BtMAqF+T3oQUGAC2UuI4OWB6oz4VF7GKiuAy5ntQeJoNAlhBBCCCFDI3MB/FKFDXcJ+7Q80FZguHxZwwmgpxloOCpsOtyl+/ftEfebALi42+XpjARyubAs2KJFQlLdN/HW9Tqvbk4GyQAAKjFJREFUW9dbRC0oSNjGjh34vIwBbW3mJ+jNzcJ65pWVwjYYjhOGuZuToIeEAO4UQo6pPAM4vgryjgqMAoAaCCspTFovLL/ooCjpJoQQQggh1iOTAz7JwqZaJuxjWqCt2LBYW8NxQN0gVFNvPAXgA+FYTg74pBgWbPO/AlB42ef5OKGFC4VlwYR1unv3R0UJCfdQlgvjOKFSure3UCF9MN3dQhJuToJeVycUhKurE7Zz5wY/v7e3eQl6aCjg40PD3CWhPAM4uAhAvyEYHZXC/hnbHTbxpjndcIw53boF4n19fcHRVYFIBMUlkSqKTSJFFJf9MAZ0lPXOD284DjQeB7pqRA7mAJ8kwH9S7/B0/zTA1W+4W+1UeB44cIChsLADCQkemDmTk+QyYTwP1Nebl6BXVwNqkXp/A3FzE5JwcxL0wEBaSs0mtDzwtQroqDBxACf0eN9SLKmh5lRIzQKOkHQTQgghhDg9xoQ1w/v2iDeeMP1G3CvBeAkzt8DhbTORFMaEAnB9k/GBkvWWFsvOL5MJw+3NSdBDQoSEnvTR0yr8jndeuPS1CuiqAhpOAdV7Br//dfuA0HRbt9JslHRbwBGSbo1Gg5MnTyItLQ0uVEWCSATFJZEqik0iRRSXl6GzWijQ1jcZby8RP9YztjcB97+UkLuHDmtzHclIj8vOTtPD3Pvvq6sTLz43EF9f8xN0b28HHebOGKBu7E2gdcl038Rad5um/fIe6+qtgGqpddptBVS93Anxlq7ZQMgwoLgkUkWxSaSI4nKI3EMB93lAxLzefd0NvUXadMPT2wqA9lJhq/iyz/0jehNw3fB090gHzXCsbyTHpbs7EBsrbIPRaITE25wEvbpaKBTX3Cxs+fmDn1+pNK9InG6Yu0x2+c9/QEwLdNeJJ9EGyXUVoO02/7wuXsLvpHu4sCnDAU0HUPju4Pd1Dx/687EjSroJIYQQQojjcQsAwuYIm466+VJhtj494i05l5KFC8CFb3qPVYb09ojrhqd7xlIiTkxycQHCwoRtMIwBTU2Dz0PXfW1rE5ZcKysTtsHIZEBwsHkJekgI4Ora585aDdBVbSKB7ptYVwNMY/4L5Orfm0TrEur+ybV7uHhRRC0PVH0rFE3rX0gNgH5Od/AM89sjIZR0E0IIIYQQ5+DqC4TOEjadnjag6bThWuLN54WCbVU7hU1//4A+w9IvffVOADhbdykSZ8NxgL+/sCUnD358R4f5CXp9vVDNXXe7jqtLN8L8LiLcrwrhflWI8L+g/z4muAqRAVUI9a2Cv3sNZJwF4+Tdgg2TZ9HEOgyQKy1/oXRkcmFZsIOLwMCB65N4Cz8DmLROUkXULEFzuuEYc7oZY+js7IS7uztVPCWSQXFJpIpik0gRxaWEaDqBprNCtXTd8PTms4C2x/hYhY9QKb3v8HTvJId9898fxaUD0LQbDOXm26vQ2VAFdXMVtB1VcFFfgBurgruswfxT8nJUN4eiqincYLvQGIGGjnCo5eHQKsPh4hmKoBCFyd50f3/rDnP/5YsMxNSuQoRfb/HEyqZolAevw1W3S2+5MCqkZgFHSbp5nodcLqcLIpEMiksiVRSbRIooLiWOVwPNWYY94o2nxeeqyj2EtcP1c8QnCWuLyxxvECnFpZ0wBvS0DDK8+9LXHgtKrMtcAWWYvgeaKcPRyYWjqTscdW3huNgcjvLacJRcDEZ1jdyoN72jw7Kn4eLSO8x9sPnowcGAQmH6XBkZwKJFAAceM0YfRLhfFaqawnEodwa0TI7t24e2hrwtUdJtAUdIujUaDY4dO4bJkyePyMqSRJooLolUUWwSKaK4dEDaHmFOeN/lyxpOArxIZiJXAn7jDXvEfccCcmmvGUVxaWWMAeoG09W7++7nO80/r9xdfH50/3nTrgGXVZegvX3wtdB13zc2Wn7+gADxpDw4GHj6aWHovBiOA6KigOJiaa2TTtXLCSGEEEIIuRwyBeA3Ttji7xb2aXmgNa+3YrqugrqmFaj/Vdj63t93XG/FdP9Jwrlc3O3ydMhl0PJAd63pBFq//yKgVZt/XoVPvyTaxNxphc+wFPnz9ATi44VtMGo1UFtrXoJeWwvwPNDQIGzZ2Za1izGgvBw4eBBITx/SU7MrSroJIYQQQggxl0wO+KYIW9xyYR/TAq2FvQm4bni6ulH4vvEEUHjp/pwc8B1j2CPuN0G8ojOxPW1Pn0re/RJofXJ9QSi8xyxYWs01YIDiY332u3jY7rnZmKsrEBkpbIPRaoVk21RSfuIEcPLk4Oepqrr8dtsDJd2EEEIIIYRcDk4G+IwSttglwj7GhPXC+y5f1nBc6C1tOitsxR/pTgD4jO5TOX2SMGfc1ddez8jx8V0mEuh+yXV3HcSXqBLDCUvNDTS82z1cmFMt8WkFw00mA4KChG3sWOPbMzOB2bMHP0+4Yy7TTXO6AceY001FLogUUVwSqaLYJFJEcUnAGNBZ2VsxXTc8vfOC+PFeiX2KtV1KyN0CrNwkB4vLnrZBhndf+qq2YMIxJzcoPmayd1oZ4pDF8hwBzwMqFVBZKfya9EdzusmwUavVcHenOUBEWiguiVRRbBIporgc4TgO8IgStqhbevd3XuwzLP1SMt5RBrQVCFvZZ73HeqoMe8QDJgrJ4FBoeaDmAPiWUsh9YoGQmfZZCo0xoKd54OHdup81beafV+Y2+PBu93DALYjWYrczuRxYv/5S9XLOMPHWfRa0bp20Em5LUE83HKOnmypLEimiuCRSRbFJpIjiklikqw5oPGk4PL2tUPxY98jeBFyXjLuHD1x4qzwDOL4K6OhdDxkeUcCk9UC0ldZlYlqgu950At13P99l/nldPE0n0H2Ta1f/YSk+RqwnIwNYtQqo6BOW0dFCwi215cIA6ukmhBBCCCHEcSmDgPDrhU1H3SQk4rrh6Y3HgZY8Ych6ZSVQ+XWf+4ca9oYHTAQ8YoQktDwDOLgIRnOZOyqF/TO2D5x4a3mgu2aAnmld8bFqoVCZuRS+5hUfU3ibf07iUBYuBBYsADIzeRw+XITp0+ORni532B5uHUq6CSGEEEIIcQSufkDobGHT6WkFGk8bLl/Wcl5IeKu+FzYdt0DALw2oPwLx4mEMAAf8+hdhfG93jfi86e4aoRfbXG5BAw/v1t1GS6kRCEPIZ81i8PSsx+TJcQ6fcAOUdDsUuTNEHHE6FJdEqig2iRRRXBKrU3gDIdcIm46mA2g6Y7h8WVOWMNS7es8gJ2RAdzVwaNHAh3EywC1kgOHdl/YrQwG562U/TTLyONP1kuZ0wzHmdBNCCCGEEDJkfDfQnAXk/y9Q+MHgx3slAH6pAxQfC7FP0TVCJITmdDsZxhiam5vh6+vrGMs5kBGB4pJIFcUmkSKKS2JXcjdhfrfqTvOS7ivfB0LTbd4sQsQ42/WSauM7CJ7nkZOTA57n7d0UQvQoLolUUWwSKaK4JJIQPEOoUg5TiQwHeEQLxxFiJ852vaSkmxBCCCGEkJFCJheWBQNgnHhf+nnSOho6TogVUdJNCCGEEELISBK9UFgWzCPScL9H1ODLhRFCLEZzuh0Ex3Fwd3d3ijkNxHlQXBKpotgkUkRxSSQleiEQuQB8dSYq8o8iatQUyEPTqYebSIKzXS+pejmoejkhhBBCCCGEEMuYm0fS8HIHodVqUVNTA61Wa++mEKJHcUmkimKTSBHFJZEiiksiRc4Wl5R0OwitVouioiKnCTziHCguiVRRbBIporgkUkRxSaTI2eKSkm5CCCGEEEIIIcRGKOkmhBBCCCGEEEJshJJuB8FxHHx9fZ2mgh9xDhSXRKooNokUUVwSKaK4JFLkbHFJ1ctB1csJIYQQQgghhFiGqpc7Ga1Wi4qKCqcpJkCcA8UlkSqKTSJFFJdEiiguiRQ5W1xS0u0gnC3wiHOguCRSRbFJpIjikkgRxSWRImeLS0q6CSGEEEIIIYQQG6GkmxBCCCGEEEIIsRFKuh2ETCZDcHAwZDL6LyPSQXFJpIpik0gRxSWRIopLIkXOFpdUvRxUvZwQQgghhBBCiGWoermT0Wq1KCwsdJpiAsQ5UFwSqaLYJFJEcUmkiOKSSJGzxSUl3Q5Cq9WitrbWaQKPOAeKSyJVFJtEiiguiRRRXBIpcra4pKSbEEIIIYQQQgixERd7N0AKdNPaW1pa7NwS0zQaDdrb29HS0gIXF/pvI9JAcUmkimKTSBHFJZEiiksiRY4Sl7r8cbAyadJ9BsOotbUVABAdHW3nlhBCCCGEEEIIcSStra3w9fU1eTtVL4cwZ+DChQvw9vYGx3H2bo6olpYWREdHo7y8nCqsE8mguCRSRbFJpIjikkgRxSWRIkeJS8YYWltbERERMeDyZtTTDWEduKioKHs3wyw+Pj6SDjwyMlFcEqmi2CRSRHFJpIjikkiRI8TlQD3cOlRIjRBCCCGEEEIIsRFKugkhhBBCCCGEEBuhpNtBuLm5Yc2aNXBzc7N3UwjRo7gkUkWxSaSI4pJIEcUlkSJni0sqpEYIIYQQQgghhNgI9XQTQgghhBBCCCE2Qkk3IYQQQgghhBBiI5R0E0IIIYQQQgghNkJJt4S88847UKlUUCqVuPLKK/Hrr7+aPHbz5s3gOM5gUyqVw9haMlJYEpcA0NTUhAceeADh4eFwc3NDUlISvvvuu2FqLRlJLInN9PR0o2smx3H4zW9+M4wtJiOBpdfMdevWITk5Ge7u7oiOjsYjjzyCrq6uYWotGSksicuenh688MILSEhIgFKpxIQJE7Bz585hbC0ZCQ4cOID58+cjIiICHMfhq6++GvQ+mZmZmDhxItzc3JCYmIjNmzfbvJ3WQkm3RHz22Wd49NFHsWbNGpw4cQITJkzA3LlzUVNTY/I+Pj4+qKqq0m+lpaXD2GIyElgal2q1Gtdffz1KSkqwfft25ObmYuPGjYiMjBzmlhNnZ2lsZmRkGFwvs7KyIJfLcfvttw9zy4kzszQut27ditWrV2PNmjXIzs7GBx98gM8++wx//etfh7nlxJlZGpfPPPMM3n33Xbz11ls4f/48/vSnP+G2227DyZMnh7nlxJm1t7djwoQJeOedd8w6vri4GL/5zW8we/ZsnDp1Cg8//DDuu+8+/PDDDzZuqZUwIglTp05lDzzwgP5nnudZREQEe/nll0WP37RpE/P19R2m1pGRytK4/N///V8WHx/P1Gr1cDWRjFCWxmZ/b775JvP29mZtbW22aiIZgSyNywceeIBde+21BvseffRRNn36dJu2k4wslsZleHg4e/vttw32LVy4kC1fvtym7SQjFwD25ZdfDnjME088wcaOHWuwb8mSJWzu3Lk2bJn1UE+3BKjVahw/fhxz5szR75PJZJgzZw5+/vlnk/dra2tDbGwsoqOjsWDBApw7d244mktGiKHE5ddff41p06bhgQceQGhoKFJTU/H3v/8dPM8PV7PJCDDUa2ZfH3zwAe644w54enraqplkhBlKXF599dU4fvy4fqhvUVERvvvuO9x0003D0mbi/IYSl93d3UZTFt3d3XHo0CGbtpWQgfz8888GcQwAc+fONfvvvr1R0i0BdXV14HkeoaGhBvtDQ0Nx8eJF0fskJyfjww8/xH/+8x988skn0Gq1uPrqq1FRUTEcTSYjwFDisqioCNu3bwfP8/juu+/w7LPP4vXXX8ff/va34WgyGSGGEpt9/frrr8jKysJ9991nqyaSEWgocbls2TK88MILuOaaa6BQKJCQkID09HQaXk6sZihxOXfuXLzxxhvIz8+HVqvF7t279VN0CLGXixcvisZxS0sLOjs77dQq81HS7aCmTZuGu+66C1dccQVmzZqFjIwMBAcH491337V308gIptVqERISgvfeew+TJk3CkiVL8PTTT+Pf//63vZtGiN4HH3yAcePGYerUqfZuChnhMjMz8fe//x3/+te/cOLECWRkZODbb7/Fiy++aO+mkRFs/fr1GDVqFEaPHg1XV1esXLkSv//97yGTUdpAyFC52LsBBAgKCoJcLkd1dbXB/urqaoSFhZl1DoVCgbS0NBQUFNiiiWQEGkpchoeHQ6FQQC6X6/elpKTg4sWLUKvVcHV1tWmbychwOdfM9vZ2bNu2DS+88IItm0hGoKHE5bPPPovf/e53+lEX48aNQ3t7O/7whz/g6aefpiSHXLahxGVwcDC++uordHV1ob6+HhEREVi9ejXi4+OHo8mEiAoLCxONYx8fH7i7u9upVeajq7kEuLq6YtKkSdi7d69+n1arxd69ezFt2jSzzsHzPM6ePYvw8HBbNZOMMEOJy+nTp6OgoABarVa/Ly8vD+Hh4ZRwE6u5nGvmF198ge7ubtx55522biYZYYYSlx0dHUaJte5DS8aY7RpLRozLuV4qlUpERkZCo9Fgx44dWLBgga2bS4hJ06ZNM4hjANi9e7fZuZLd2buSGxFs27aNubm5sc2bN7Pz58+zP/zhD8zPz49dvHiRMcbY7373O7Z69Wr98WvXrmU//PADKywsZMePH2d33HEHUyqV7Ny5c/Z6CsQJWRqXZWVlzNvbm61cuZLl5uayb775hoWEhLC//e1v9noKxElZGps611xzDVuyZMlwN5eMEJbG5Zo1a5i3tzf79NNPWVFREdu1axdLSEhgixcvttdTIE7I0rj85Zdf2I4dO1hhYSE7cOAAu/baa1lcXBxrbGy00zMgzqi1tZWdPHmSnTx5kgFgb7zxBjt58iQrLS1ljDG2evVq9rvf/U5/fFFREfPw8GCPP/44y87OZu+88w6Ty+Vs586d9noKFqHh5RKxZMkS1NbW4rnnnsPFixdxxRVXYOfOnfqCAWVlZQafhjc2NuL+++/HxYsX4e/vj0mTJuGnn37CmDFj7PUUiBOyNC6jo6Pxww8/4JFHHsH48eMRGRmJVatW4cknn7TXUyBOytLYBIDc3FwcOnQIu3btskeTyQhgaVw+88wz4DgOzzzzDCorKxEcHIz58+fjpZdestdTIE7I0rjs6urCM888g6KiInh5eeGmm27Cxx9/DD8/Pzs9A+KMjh07htmzZ+t/fvTRRwEAK1aswObNm1FVVYWysjL97XFxcfj222/xyCOPYP369YiKisL777+PuXPnDnvbh4JjjMYvEUIIIYQQQgghtkBzugkhhBBCCCGEEBuhpJsQQgghhBBCCLERSroJIYQQQgghhBAboaSbEEIIIYQQQgixEUq6CSGEEEIIIYQQG6GkmxBCCCGEEEIIsRFKugkhhBBCCCGEEBuhpJsQQgghhBBCCLERSroJIcTGVCoV1q1bd1nn2Lx5M/z8/AY85vnnn8cVV1yh//nuu+/Grbfeqv85PT0dDz/88GW1QwxjDH/4wx8QEBAAjuNw6tQpqz9Gf/2fmyMz5/92qKTwOtny+VlL/9+doSgpKRm2+Lc3a1zTLCWFWCaEkKGipJsQQpzEY489hr1795q8PSMjAy+++KL+Z2u9cd65cyc2b96Mb775BlVVVUhNTb3sc+o4WyJjq2TF1Ou0fv16bN682eqPZ4klS5YgLy/PovuY+wGRPZI/R2CtD9gc4QOT4VBVVYVly5YhKSkJMpnMJh9eEkKcm4u9G0AIIY5KrVbD1dXV3s3Q8/LygpeXl8nbAwICbPK4hYWFCA8Px9VXXz3kczDGwPM8XFzoz5I1+fr62rsJcHd3h7u7u72bQciQdXd3Izg4GM888wzefPNNezeHEOKAqKebEEIg9AytXLkSK1euhK+vL4KCgvDss8+CMaY/RqVS4cUXX8Rdd90FHx8f/OEPfwAA7NixA2PHjoWbmxtUKhVef/11o/O3trZi6dKl8PT0RGRkJN555x2D29944w2MGzcOnp6eiI6Oxl/+8he0tbUZneerr77CqFGjoFQqMXfuXJSXl+tvG2yIbN/er/T0dJSWluKRRx4Bx3HgOA7t7e3w8fHB9u3bjR7T09MTra2tRue8++678eCDD6KsrAwcx0GlUgEQ3qQ+9NBDCAkJgVKpxDXXXIOjR4/q75eZmQmO4/D9999j0qRJcHNzw6FDh4zOHxcXBwBIS0sDx3FIT083uP2f//wnwsPDERgYiAceeAA9PT3627q7u/HYY48hMjISnp6euPLKK5GZmWny9WGM4fnnn0dMTAzc3NwQERGBhx56CADwwgsviPbgX3HFFXj22Wf1r8Wtt95qsk1ir3lfP/zwA1JSUuDl5YV58+ahqqrK4Pb3338fKSkpUCqVGD16NP71r38N+jr1H5Kr1Wrx6quvIjExEW5uboiJicFLL71k8jUx5/eisbERd911F/z9/eHh4YEbb7wR+fn5+tv795bq4vTjjz+GSqWCr68v7rjjDn183X333di/fz/Wr1+vf51KSkpE22bq9TTnd1LMu+++i+joaHh4eGDx4sVobm42uH2g/wMx+/fvx9SpU+Hm5obw8HCsXr0aGo3G4Dk89NBDeOKJJxAQEICwsDA8//zzBufIycnBNddcA6VSiTFjxmDPnj3gOA5fffWV6GMO9PoN1p6+MjMz8fvf/x7Nzc368/RtW0dHB+655x54e3sjJiYG7733nsH9y8vLsXjxYvj5+SEgIAALFiwQ/X/s69y5c7j55pvh4+MDb29vzJgxA4WFhaLH7ty5E9dccw38/PwQGBiIm2++2eBYtVqNlStXIjw8HEqlErGxsXj55ZcBDPy7LkalUmH9+vW46667JPFBFiHEATFCCCFs1qxZzMvLi61atYrl5OSwTz75hHl4eLD33ntPf0xsbCzz8fFh//znP1lBQQErKChgx44dYzKZjL3wwgssNzeXbdq0ibm7u7NNmzYZ3M/b25u9/PLLLDc3l23YsIHJ5XK2a9cu/TFvvvkm+/HHH1lxcTHbu3cvS05OZn/+85/1t2/atIkpFAo2efJk9tNPP7Fjx46xqVOnsquvvlp/zJo1a9iECRP0P69YsYItWLDA4DmuWrWKMcZYfX09i4qKYi+88AKrqqpiVVVVjDHG7r//fnbTTTcZvDa33HILu+uuu0Rft6amJvbCCy+wqKgoVlVVxWpqahhjjD300EMsIiKCfffdd+zcuXNsxYoVzN/fn9XX1zPGGNu3bx8DwMaPH8927drFCgoK9Lf19euvvzIAbM+ePayqqkp/zIoVK5iPjw/705/+xLKzs9l///tfo/+v++67j1199dXswIEDrKCggL322mvMzc2N5eXliT6XL774gvn4+LDvvvuOlZaWsiNHjujPV15ezmQyGfv111/1x584cYJxHMcKCwvNapOp11z3fztnzhx29OhRdvz4cZaSksKWLVumf6xPPvmEhYeHsx07drCioiK2Y8cOFhAQwDZv3jzo69Q3Bp544gnm7+/PNm/ezAoKCtjBgwfZxo0bRV8Pxsz7vbjllltYSkoKO3DgADt16hSbO3cuS0xMZGq1Wv/8fH199cevWbOGeXl5sYULF7KzZ8+yAwcOsLCwMPbXv/6VMSbE1LRp09j999+vf500Go1R20y9nub8Tva3Zs0a5unpya699lp28uRJtn//fpaYmGjR/0FxcTEDwE6ePMkYY6yiooJ5eHiwv/zlLyw7O5t9+eWXLCgoiK1Zs8bg9fXx8WHPP/88y8vLYx999BHjOE5/bdBoNCw5OZldf/317NSpU+zgwYNs6tSpDAD78ssvRZ+LqdfPnPb01d3dzdatW8d8fHz052ltbWWMCde0gIAA9s4777D8/Hz28ssvM5lMxnJychhjjKnVapaSksLuuecedubMGXb+/Hm2bNkylpyczLq7u0Ufr6KiggUEBLCFCxeyo0ePstzcXPbhhx/qz9k/lrdv38527NjB8vPz2cmTJ9n8+fPZuHHjGM/zjDHGXnvtNRYdHc0OHDjASkpK2MGDB9nWrVsZYwP/rg+m73WUEELMRUk3IYQw4Y1USkoK02q1+n1PPvkkS0lJ0f8cGxvLbr31VoP7LVu2jF1//fUG+x5//HE2ZswYg/vNmzfP4JglS5awG2+80WR7vvjiCxYYGKj/edOmTQwA++WXX/T7srOzGQB25MgRxphlSbeuXW+++abB4x45coTJ5XJ24cIFxhhj1dXVzMXFhWVmZpps65tvvsliY2P1P7e1tTGFQsG2bNmi36dWq1lERAR79dVXGWO9SfdXX31l8ryMGScyfZ9bbGysQTJ2++23syVLljDGGCstLWVyuZxVVlYa3O+6665jTz31lOhjvf766ywpKUmfLPZ34403GnwQ8uCDD7L09HSz28SY+Guu+78tKCjQ73vnnXdYaGio/ueEhAR9wqDz4osvsmnTpjHGBn6ddDHQ0tLC3NzcBkyy+xvs9yIvL48BYIcPH9bfXldXx9zd3dnnn3+uf379k24PDw/W0tKi3/f444+zK6+80uBxzUlsxF5Pc34n+1uzZg2Ty+WsoqJCv+/7779nMplMn8xb+n/w17/+lSUnJxu8du+88w7z8vLSJ4azZs1i11xzjcE5p0yZwp588kl9G1xcXPRtYIyx3bt3D5h0687b//Uzpz399f+/04mNjWV33nmn/metVstCQkLY//7v/zLGGPv444+NHqu7u5u5u7uzH374QfSxnnrqKRYXF2fy96//9ay/2tpaBoCdPXuWMSb8fl577bUGbdAZ7Hd9IJR0E0KGgoaXE0LIJVdddZXBENVp06YhPz8fPM/r902ePNngPtnZ2Zg+fbrBvunTpxvdb9q0aQbHTJs2DdnZ2fqf9+zZg+uuuw6RkZHw9vbG7373O9TX16Ojo0N/jIuLC6ZMmaL/efTo0fDz8zM4z+WaOnUqxo4di48++ggA8MknnyA2NhYzZ840+xyFhYXo6ekxeF0UCgWmTp1q1Nb+r6clxo4dC7lcrv85PDwcNTU1AICzZ8+C53kkJSXp57p7eXlh//79Joer3n777ejs7ER8fDzuv/9+fPnllwZDb++//358+umn6OrqglqtxtatW3HPPfeY3aaBeHh4ICEhQfR+7e3tKCwsxL333mvwXP72t7+ZfC5isrOz0d3djeuuu87s+wAD/15kZ2fDxcUFV155pf72wMBAJCcnDxiXKpUK3t7e+p/NfZ3MYe7vZH8xMTGIjIzU/zxt2jRotVrk5uYO6f8gOzsb06ZNM3jtpk+fjra2NlRUVOj3jR8/3uB+fV+L3NxcREdHIywsTH/71KlTzXgVht4ec/VtN8dxCAsL07f79OnTKCgogLe3t/61CggIQFdXl8nX69SpU5gxYwYUCoVZj5+fn4+lS5ciPj4ePj4++qktZWVlAIRh9qdOnUJycjIeeugh7Nq1S3/fwX7XCSHE2qhiDSGEWMDT09Pq5ywpKcHNN9+MP//5z3jppZcQEBCAQ4cO4d5774VarYaHh4fVH3Mg9913H9555x2sXr0amzZtwu9//3uj+cfWcjmvZ/835xzHQavVAgDa2togl8tx/PhxgyQYgMlic9HR0cjNzcWePXuwe/du/OUvf8Frr72G/fv3Q6FQYP78+XBzc8OXX34JV1dX9PT0YNGiRWa3ydLnwi7Nm9bN7d+4caNBcgvA6LkNRErFzIb6OtmLtf4PxDjaa6Ez2O/fpEmTsGXLFqP7BQcHi57P0vicP38+YmNjsXHjRkRERECr1SI1NRVqtRoAMHHiRBQXF+P777/Hnj17sHjxYsyZMwfbt28f9HedEEKsjXq6CSHkkiNHjhj8/Msvv2DUqFEDvqlOSUnB4cOHDfYdPnwYSUlJBvf75ZdfjM6dkpICADh+/Di0Wi1ef/11XHXVVUhKSsKFCxeMHkuj0eDYsWP6n3Nzc9HU1KQ/j6VcXV1Fe/7uvPNOlJaWYsOGDTh//jxWrFhh0XkTEhLg6upq8Lr09PTg6NGjGDNmjMVtBDBgD6WYtLQ08DyPmpoaJCYmGmx9ew37c3d3x/z587FhwwZkZmbi559/xtmzZwEIIw1WrFiBTZs2YdOmTbjjjjssThRMveYDCQ0NRUREBIqKioyei66Amjmv06hRo+Du7j7gsnJiBvq9SElJgUajMTimvr4eubm5Fv9f92Xu6yR2nLm/k/2VlZUZ/N798ssvkMlkSE5ONuv/oL+UlBT8/PPPBkXnDh8+DG9vb0RFRQ363AAgOTkZ5eXlqK6u1u/rW5DQFFOvi6XtGUq8AkLCm5+fj5CQEKPXy1QhsvHjx+PgwYMGxRBN0cXYM888g+uuuw4pKSlobGw0Os7HxwdLlizBxo0b8dlnn2HHjh1oaGgAMPDvOiGEWBsl3YQQcklZWRkeffRR5Obm4tNPP8Vbb72FVatWDXif//mf/8HevXvx4osvIi8vDx999BHefvttPPbYYwbHHT58GK+++iry8vLwzjvv4IsvvtCfOzExET09PXjrrbdQVFSEjz/+GP/+97+NHkuhUODBBx/EkSNHcPz4cdx999246qqrhjzcVKVS4cCBA6isrERdXZ1+v7+/PxYuXIjHH38cN9xwg9kJgo6npyf+/Oc/4/HHH8fOnTtx/vx53H///ejo6MC9995r0blCQkLg7u6OnTt3orq62qiatClJSUlYvnw57rrrLmRkZKC4uBi//vorXn75ZXz77bei99m8eTM++OADZGVloaioCJ988gnc3d0RGxurP+a+++7Djz/+iJ07dxoNLTeHqdd8MGvXrsXLL7+MDRs2IC8vD2fPnsWmTZvwxhtvADDvdVIqlXjyySfxxBNP4P/+7/9QWFiIX375BR988MGAjz3Q78WoUaOwYMEC3H///Th06BBOnz6NO++8E5GRkViwYIEFr4whlUqFI0eOoKSkBHV1dSZ7fsVeT3N/J/+/vXsJiXKN4zj+P4IzXmpscIhRKMUQuoDOJhLGG2S1lKAiiBpaRDKkkhtRoggqIlF042LaJVEQNUSboIwBkTYRo4vyMiAVZGAoltQi4ncW4hzn4qUDg57j9wMudB6c//u8z/uOf338TbKcnBwLBAI2MjJiQ0ND1tLSYqdOnYr/kmatc5AsGAzap0+frLm52cbGxuzp06d27do1a2trs6ys9f34deTIEduzZ48FAgEbHR214eFhu3LlipnZqrtP0s3fv6mntLTUFhYWbHBw0L5+/Zrw7y6rOXPmjHk8HmtsbLShoSGbmpqySCRiLS0tK25lv3Tpkn379s1Onz5tb968scnJSRsYGLDx8fGUsW632woLCy0UClksFrNXr15ZW1tbwpienh578OCBjY2N2cTEhD169Mi8Xq/t2LFjXdd6smg0atFo1BYWFmxmZsai0ai9e/duXfMBAASpAYAWw3GCwaCamprkcrnkdrvV2dmZEMKTLrRJWkzR3b9/v7Kzs7V79251dXUlPF5SUqLr16/r5MmTysvLk9frVV9fX8KYnp4eFRUVKTc3V8eOHdO9e/dkZpqbm5P0T6DR48ePVVZWJqfTqYaGBn348CH+Pf40SO3169eqqKiQ0+lU8svB4OCgzCwehrWa5CA1Sfr586eam5vl8XjkdDrl9/sTkr+XgtSWjm81d+/e1a5du5SVlaW6urq0xyZJra2t8celxfC2q1evqrS0VNnZ2SoqKtLx48c1Ojqa9nnC4bAOHTokl8ul/Px8VVVV6eXLlynjampqdODAgZSvr6emdHOeLqwqHA6nnJP79+/L5/PJ4XDI7XartrZWT548+aN5+v37t27cuKGSkpL4er1161ba+ZDWd13Mzs7q7NmzKigoiK/f5Qnx6YLUlq9TKXUNjY+Pq6qqSrm5uTIzTU1Npa1vpTW81jWZbKmm/v5+FRcXKycnRydOnNDs7GzCuNXOQbowu0gkooMHD8rhcMjr9aq9vV2/fv1KmN/kUK7GxkYFAoH45+/fv5ff75fD4dDevXv17NkzmZmeP3++4vGsNH9r1ZNOU1OTCgsLZWbxpPN098LKysqEJPTp6WmdO3cufg8oKyvThQsXND8/v+JzjYyM6OjRo8rLy9P27dtVU1OT8O4Ay9fyixcvtG/fPjmdTlVUVCgSiSQEzIVCIfl8PuXn58vlcunw4cN6+/atpPVf68uZWcpH8n0PAFbyl7RsnxEAbFH19fXm8/mst7d3o0vZFAYGBuzy5cv2+fPn+NZlLL6/b3l5uQWDwZS/rP0fcV1sPsPDw1ZdXW2xWCwhfA8AsHkRpAYAiPvx44dNT0/b7du37eLFizTcy8zMzNjDhw/ty5cvdv78+Y0uB1tEOBy2bdu2WXl5ucViMWttbTW/30/DDQD/ITTdAIC4O3fu2M2bN622ttY6Ojo2upxNZefOnebxeCwUCpnb7d7ocrBFfP/+3drb2+3jx4/m8XisoaHBuru7N7osAMAfYHs5AAAAAAAZQno5AAAAAAAZQtMNAAAAAECG0HQDAAAAAJAhNN0AAAAAAGQITTcAAAAAABlC0w0AAAAAQIbQdAMAAAAAkCE03QAAAAAAZAhNNwAAAAAAGfI3g5DvoZBlAv4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creazione del grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "p =[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "# Linea per i falsi positivi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(p, falsi_negativi_2K_fp_5sub, marker='o', label='False Negatives 2K  ', color='black')\n",
    "plt.plot(p, falsi_negativi_3K_fp_5sub, marker='o', label='False Negatives 3K  ', color='red')\n",
    "plt.plot(p, falsi_negativi_4K_fp_5sub, marker='o', label='False Negatives 4K  ', color='green')\n",
    "plt.plot(p, falsi_negativi_5K_fp_5sub, marker='o', label='False Negatives 5K  ', color='blue')\n",
    "plt.plot(p, falsi_negativi_6K_fp_5sub, marker='o', label='False Negatives 6K  ', color='orange')\n",
    "\n",
    "\n",
    "plt.axhline(y=falsi_negativi_5K_fp_5sub_before, color='purple', linestyle='--', label='Initial False Negatives')\n",
    "\n",
    "# Etichette e titolo\n",
    "plt.xlabel('probability for the synthetic point to belong to the class 1')\n",
    "plt.ylabel('Count False Negaitives')\n",
    "plt.title(f'False Negatives, fn, #subgroups = {K} on {filtered_instances}, support = {min_sup}, pruning = {epsilon}')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "plt.yticks(range(550, 660, 25))\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3070, 365)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_0, count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
