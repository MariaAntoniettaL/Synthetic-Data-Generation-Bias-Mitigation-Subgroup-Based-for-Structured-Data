{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ANALISI CONDOTTA CON LA FEATURE error rate (PASSATA A BOOLEAN OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_for_adult import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import torch\n",
    "\n",
    "      \n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv(\"adult.data\", header = None, names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = 0.10\n",
    "percentage = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosità precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GDecisioN tree predictions\n",
    "X_train = df_train_enc.drop(columns = 'income', axis = 1)\n",
    "y_train = df_train_enc['income']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'income', axis = 1)\n",
    "y_test = df_test_enc['income']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'income', axis = 1)\n",
    "y_val = df_val_enc['income']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'income', axis = 1)\n",
    "y_holdout = df_holdout_enc['income']\n",
    "\n",
    "classifier_train = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.865     0.681                0.050   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.402              247              630   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       6508  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione è giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>2</td>\n",
       "      <td>0.077</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0</td>\n",
       "      <td>0.284</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass  fnlwgt  education  marital-status  occupation  relationship  \\\n",
       "18761          2   0.077          3               0           4             1   \n",
       "27582          3   0.048          3               1           4             0   \n",
       "30911          2   0.174          3               3           4             4   \n",
       "11128          0   0.012          2               1           2             0   \n",
       "683            0   0.284          3               3           2             4   \n",
       "\n",
       "       race  sex  capital-gain  capital-loss  native-country  age_group  \\\n",
       "18761     4    0         0.000         0.000               5          2   \n",
       "27582     4    1         0.000         0.000               5          5   \n",
       "30911     2    0         0.039         0.000               5          1   \n",
       "11128     2    1         0.000         0.507               5          3   \n",
       "683       2    1         0.000         0.000               5          0   \n",
       "\n",
       "       edu_num_group  hours_per_week_group  y_val_true  y_pred  \n",
       "18761              1                     1           0       0  \n",
       "27582              1                     2           1       0  \n",
       "30911              1                     1           0       0  \n",
       "11128              4                     1           1       1  \n",
       "683                1                     1           0       0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set\n",
    "y_pred_val_dt = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val_dt\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.077</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>Self-emp</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>65-100</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.174</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.012</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>45-54</td>\n",
       "      <td>14 Master's Degree</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.284</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        workclass  fnlwgt        education marital-status    occupation  \\\n",
       "18761     Private   0.077    Non Graduated       Divorced  Self-emp-occ   \n",
       "27582    Self-emp   0.048    Non Graduated        Married  Self-emp-occ   \n",
       "30911     Private   0.174    Non Graduated      Separated  Self-emp-occ   \n",
       "11128  Government   0.012  Master's Degree        Married   Private-occ   \n",
       "683    Government   0.284    Non Graduated      Separated   Private-occ   \n",
       "\n",
       "         relationship    race      sex  capital-gain  capital-loss  \\\n",
       "18761   Not-in-family   White   Female         0.000         0.000   \n",
       "27582         Husband   White     Male         0.000         0.000   \n",
       "30911       Unmarried   Black   Female         0.039         0.000   \n",
       "11128         Husband   Black     Male         0.000         0.507   \n",
       "683         Unmarried   Black     Male         0.000         0.000   \n",
       "\n",
       "      native-country  income age_group       edu_num_group  \\\n",
       "18761  United-States       0     35-44          10 College   \n",
       "27582  United-States       1    65-100          10 College   \n",
       "30911  United-States       0     25-34          10 College   \n",
       "11128  United-States       1     45-54  14 Master's Degree   \n",
       "683    United-States       0     17-24          10 College   \n",
       "\n",
       "      hours_per_week_group  y_pred  error  \n",
       "18761             Overtime       0      0  \n",
       "27582            Part-time       0      1  \n",
       "30911             Overtime       0      0  \n",
       "11128             Overtime       1      0  \n",
       "683               Overtime       0      0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione è giusta 0 se la predizione è sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['error'] = (df_val_class['y_val_true'] != df_val_class['y_pred']).astype(int)\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>error</th>\n",
       "      <th>error_div</th>\n",
       "      <th>error_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101</td>\n",
       "      <td>(capital-gain=0.0, education=Bachelor's Degree, marital-status=Married)</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.207</td>\n",
       "      <td>10.959</td>\n",
       "      <td>3</td>\n",
       "      <td>659.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.159</td>\n",
       "      <td>(sex= Male, capital-gain=0.0, workclass=Private, hours_per_week_group=Overtime, capital-loss=0.0, race= White, relationship= Husband, native-country=United-States)</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.200</td>\n",
       "      <td>13.164</td>\n",
       "      <td>8</td>\n",
       "      <td>1034.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.159</td>\n",
       "      <td>(sex= Male, capital-gain=0.0, workclass=Private, marital-status=Married, hours_per_week_group=Overtime, capital-loss=0.0, race= White, relationship= Husband, native-country=United-States)</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.200</td>\n",
       "      <td>13.164</td>\n",
       "      <td>9</td>\n",
       "      <td>1034.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159</td>\n",
       "      <td>(capital-gain=0.0, workclass=Private, marital-status=Married, hours_per_week_group=Overtime, capital-loss=0.0, race= White, relationship= Husband, native-country=United-States)</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.200</td>\n",
       "      <td>13.164</td>\n",
       "      <td>8</td>\n",
       "      <td>1034.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.159</td>\n",
       "      <td>(capital-gain=0.0, workclass=Private, hours_per_week_group=Overtime, capital-loss=0.0, race= White, relationship= Husband, native-country=United-States)</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.200</td>\n",
       "      <td>13.164</td>\n",
       "      <td>7</td>\n",
       "      <td>1034.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.101   \n",
       "1    0.159   \n",
       "2    0.159   \n",
       "3    0.159   \n",
       "4    0.159   \n",
       "\n",
       "                                                                                                                                                                                       itemset  \\\n",
       "0                                                                                                                      (capital-gain=0.0, education=Bachelor's Degree, marital-status=Married)   \n",
       "1                          (sex= Male, capital-gain=0.0, workclass=Private, hours_per_week_group=Overtime, capital-loss=0.0, race= White, relationship= Husband, native-country=United-States)   \n",
       "2  (sex= Male, capital-gain=0.0, workclass=Private, marital-status=Married, hours_per_week_group=Overtime, capital-loss=0.0, race= White, relationship= Husband, native-country=United-States)   \n",
       "3             (capital-gain=0.0, workclass=Private, marital-status=Married, hours_per_week_group=Overtime, capital-loss=0.0, race= White, relationship= Husband, native-country=United-States)   \n",
       "4                                     (capital-gain=0.0, workclass=Private, hours_per_week_group=Overtime, capital-loss=0.0, race= White, relationship= Husband, native-country=United-States)   \n",
       "\n",
       "   error  error_div  error_t  length  support_count  \n",
       "0  0.340      0.207   10.959       3        659.000  \n",
       "1  0.334      0.200   13.164       8       1034.000  \n",
       "2  0.334      0.200   13.164       9       1034.000  \n",
       "3  0.334      0.200   13.164       8       1034.000  \n",
       "4  0.334      0.200   13.164       7       1034.000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_diver = DivergenceExplorer(df_val)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"error_div\", \"error_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "      <th>error</th>\n",
       "      <th>error_div</th>\n",
       "      <th>error_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101</td>\n",
       "      <td>(capital-gain=0.0, education=Bachelor's Degree, marital-status=Married)</td>\n",
       "      <td>3</td>\n",
       "      <td>659.000</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.207</td>\n",
       "      <td>10.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.172</td>\n",
       "      <td>(capital-gain=0.0, workclass=Private, capital-loss=0.0, race= White, relationship= Husband, native-country=United-States)</td>\n",
       "      <td>6</td>\n",
       "      <td>1122.000</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.193</td>\n",
       "      <td>13.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.197</td>\n",
       "      <td>(capital-gain=0.0, workclass=Private, marital-status=Married, capital-loss=0.0, race= White, native-country=United-States)</td>\n",
       "      <td>6</td>\n",
       "      <td>1285.000</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.187</td>\n",
       "      <td>13.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.185</td>\n",
       "      <td>(capital-gain=0.0, workclass=Private, capital-loss=0.0, relationship= Husband, native-country=United-States)</td>\n",
       "      <td>5</td>\n",
       "      <td>1206.000</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.181</td>\n",
       "      <td>12.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.116</td>\n",
       "      <td>(age_group=35-44, capital-loss=0.0, capital-gain=0.0, marital-status=Married)</td>\n",
       "      <td>4</td>\n",
       "      <td>752.000</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.181</td>\n",
       "      <td>10.393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support  \\\n",
       "0     0.101   \n",
       "7     0.172   \n",
       "23    0.197   \n",
       "44    0.185   \n",
       "46    0.116   \n",
       "\n",
       "                                                                                                                       itemset  \\\n",
       "0                                                      (capital-gain=0.0, education=Bachelor's Degree, marital-status=Married)   \n",
       "7    (capital-gain=0.0, workclass=Private, capital-loss=0.0, race= White, relationship= Husband, native-country=United-States)   \n",
       "23  (capital-gain=0.0, workclass=Private, marital-status=Married, capital-loss=0.0, race= White, native-country=United-States)   \n",
       "44                (capital-gain=0.0, workclass=Private, capital-loss=0.0, relationship= Husband, native-country=United-States)   \n",
       "46                                               (age_group=35-44, capital-loss=0.0, capital-gain=0.0, marital-status=Married)   \n",
       "\n",
       "    length  support_count  error  error_div  error_t  \n",
       "0        3        659.000  0.340      0.207   10.959  \n",
       "7        6       1122.000  0.326      0.193   13.228  \n",
       "23       6       1285.000  0.321      0.187   13.717  \n",
       "44       5       1206.000  0.314      0.181   12.941  \n",
       "46       4        752.000  0.314      0.181   10.393  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = error_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "df_pruned_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 247\n",
      "total problematic 193\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_error)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_error[(df_pruned_error['error_div'] > 0) & (df_pruned_error['error_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (3793, 7)\n",
      "Dim pruned th_redundancy  (247, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_error.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset_and_or li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3363\n"
     ]
    }
   ],
   "source": [
    "print(len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "TRAIN SET MITIGATED ROWS:  16377\n",
      "VALIDATION SET ROWS:  6508\n",
      "FILTERED DF holdout ROWS:  3363\n",
      "TEST SET FILTERED ROWS:  6507\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'income', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['income']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "#cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3363\n",
      "verifica : 3363\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['income']\n",
    "\n",
    "classifier_train_mitigated_random = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.397</td>\n",
       "      <td>240</td>\n",
       "      <td>623</td>\n",
       "      <td>16377</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.399</td>\n",
       "      <td>246</td>\n",
       "      <td>625</td>\n",
       "      <td>16377</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.865     0.681                0.050   \n",
       "After Mitigation(K=5, fp)     0.867     0.687                0.049   \n",
       "After RANDOM mitigation       0.866     0.684                0.050   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.402              247   \n",
       "After Mitigation(K=5, fp)                0.397              240   \n",
       "After RANDOM mitigation                  0.399              246   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      630       13014       6508  \n",
       "After Mitigation(K=5, fp)              623       16377       6508  \n",
       "After RANDOM mitigation                625       16377       6508  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance su sottogruppi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.390</td>\n",
       "      <td>236</td>\n",
       "      <td>524</td>\n",
       "      <td>13014</td>\n",
       "      <td>3369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.386</td>\n",
       "      <td>230</td>\n",
       "      <td>518</td>\n",
       "      <td>16377</td>\n",
       "      <td>3369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.386</td>\n",
       "      <td>237</td>\n",
       "      <td>519</td>\n",
       "      <td>16377</td>\n",
       "      <td>3369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                         Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                    0.774     0.683   \n",
       "After Mitigation(K=5, on subgroups, fp)            0.778     0.688   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)     0.776     0.686   \n",
       "\n",
       "Metrics                                         False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                               0.116   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.114   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.117   \n",
       "\n",
       "Metrics                                         False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                               0.390   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.386   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.386   \n",
       "\n",
       "Metrics                                         False Positives  \\\n",
       "Before Mitigation, on subgroups                             236   \n",
       "After Mitigation(K=5, on subgroups, fp)                     230   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              237   \n",
       "\n",
       "Metrics                                         False Negatives  Train Size  \\\n",
       "Before Mitigation, on subgroups                             524       13014   \n",
       "After Mitigation(K=5, on subgroups, fp)                     518       16377   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              519       16377   \n",
       "\n",
       "Metrics                                         Test Size  \n",
       "Before Mitigation, on subgroups                      3369  \n",
       "After Mitigation(K=5, on subgroups, fp)              3369  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)       3369  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered_fp = K_subgroups_dataset_and_or(df_pruned_error, df_test, K)\n",
    "inutile, df_test_filtered_enc_fp, inutile2, inutile3 = encoding_funct(df_train, df_test_filtered_fp, df_holdout, df_val)\n",
    "\n",
    "X_test_filtered_fp = df_test_filtered_enc_fp.drop(columns='income', axis = 1)\n",
    "y_true_test_filtered_fp = df_test_filtered_enc_fp['income']\n",
    "\n",
    "y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after = classifier_train_mitigated.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_random = classifier_train_mitigated_random.predict(X_test_filtered_fp)\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after )\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_random)\n",
    "\n",
    "\n",
    "metrics_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after, len(y_train_mitigated), len(y_pred_test_filtered_fp_after)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(y_train_mitigated_random), len(y_pred_test_filtered_fp_after_random)]\n",
    "})\n",
    "metrics_after_fp_sottogruppi = metrics_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi[metric] = metrics_after_fp_sottogruppi[metric].astype(int)\n",
    "\n",
    "metrics_after_fp\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp\")\n",
    "metrics_after_fp_sottogruppi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE\n",
    "\n",
    "\n",
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.152</td>\n",
       "      <td>3363.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.155</td>\n",
       "      <td>3363.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.865     0.681             0.063   \n",
       "After Mitigation(K=5 fp)            0.867     0.687             0.064   \n",
       "After RANDOM Mitigation(K=5 fp)     0.866     0.684             0.065   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.195               0.176   \n",
       "After Mitigation(K=5 fp)           0.195               0.179   \n",
       "After RANDOM Mitigation(K=5 fp)    0.195               0.181   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.164               0.149   \n",
       "After Mitigation(K=5 fp)                      0.168               0.152   \n",
       "After RANDOM Mitigation(K=5 fp)               0.170               0.155   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)              3363.000  \n",
       "After RANDOM Mitigation(K=5 fp)       3363.000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_no_mitigation  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_no_mitigation\n",
    "\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_baseline1  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_baseline1\n",
    "\n",
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_random_per_confrontare_con_baseline1  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_random_per_confrontare_con_baseline1\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_error_div_list_no_mitigation = np.nanmean(error_div_list_no_mitigation)\n",
    "media_error_div_list_nomitigation_primi10 = np.nanmean(error_div_list_no_mitigation[:10])\n",
    "media_error_div_list_nomitigation_primi20 = np.nanmean(error_div_list_no_mitigation[:20])\n",
    "media_error_div_list_nomitigation_primi40 = np.nanmean(error_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_error_div_no_mitigation = max(abs(x) for x in error_div_list_no_mitigation)\n",
    "\n",
    "media_error_div_list_baseline1 = np.nanmean(error_div_list_baseline1)\n",
    "media_error_div_list_baseline1_primi10 = np.nanmean(error_div_list_baseline1[:10])\n",
    "media_error_div_list_baseline1_primi20 = np.nanmean(error_div_list_baseline1[:20])\n",
    "media_error_div_list_baseline1_primi40 = np.nanmean(error_div_list_baseline1[:40])\n",
    "error_div_massimo_valore_assoluto_error_div_baseline1 = max(abs(x) for x in error_div_list_baseline1)\n",
    "\n",
    "media_error_div_list_random_per_confrontare_con_baseline1 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1)\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_error_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in error_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_correctness_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_error_div_list_no_mitigation, massimo_valore_assoluto_error_div_no_mitigation,\n",
    "        media_error_div_list_nomitigation_primi10, media_error_div_list_nomitigation_primi20, media_error_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_error_div_list_baseline1, error_div_massimo_valore_assoluto_error_div_baseline1,\n",
    "        media_error_div_list_baseline1_primi10, media_error_div_list_baseline1_primi20, media_error_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_error_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_error_div_random_per_confrontare_con_baseline1, media_error_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_error_div_list_random_per_confrontare_con_baseline1_primi20, media_error_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_correctness_sottogruppi = divergence_after_correctness_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_correctness_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SIMULANDO DATI ATTRAVERSO SMOTE\n",
    "\n",
    "SEGUE CODICE USANDO SMOTE \n",
    "DIVIDO IN TRAIN, TEST E VALIDATION -- ora uso quelli gia esistenti\n",
    "DIV EXPLORER SUL VALIDATION  -- già fatto \n",
    "GENERO NUOVI DATI CON SMOTE a partire dai dati di divexplorer sul validation\n",
    "INSERISCO QUESTI NUOVI DATI NEL TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 3569\n",
      "numero di dati simulati con smotenc 4440\n",
      "income\n",
      "1    2220\n",
      "0    2220\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['error', 'y_pred', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]\n",
    "\n",
    "smote_nc = SMOTENC( categorical_features=categorical_features, random_state=seed)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "\n",
    "print(\"numero di dati simulati con smotenc\",len(y_resampled))\n",
    "\n",
    "class_counts = y_resampled.value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17454\n"
     ]
    }
   ],
   "source": [
    "X_train_mitigated_SMOTE = pd.concat([X_train, X_resampled], ignore_index=True)\n",
    "y_train_mitigated_SMOTE = pd.concat([y_train, y_resampled], ignore_index=True)\n",
    "print(len(X_train_mitigated_SMOTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_train_mitigated_SMOTE = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_SMOTE.fit(X_train_mitigated_SMOTE, y_train_mitigated_SMOTE)\n",
    "y_mitigated_SMOTE_pred = classifier_train_mitigated_SMOTE.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#vediamo che succede se prendo lo stesso numero di righe ma random da holdout\\nprint(len(X_resampled))\\nn_random_smote = len(X_resampled)\\n\\ndf_holdout_smote_sampled = df_holdout_enc.sample(n=n_random_smote, random_state=seed)\\nprint(\"verifica :\", len(df_holdout_smote_sampled)) #verifica\\n\\ndf_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\\ndf_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\\n\\nX_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\\ny_train_mitigated_random_smote = df_train_mitigated_random_smote[\\'income\\']\\n\\nclassifier_train_mitigated_random_smote = GradientBoostingClassifier(random_state=seed)\\n\\nclassifier_train_mitigated_random_smote.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\\ny_mitigated_pred_random_smote = classifier_train_mitigated_random_smote.predict(X_test)\\n\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#vediamo che succede se prendo lo stesso numero di righe ma random da holdout\n",
    "print(len(X_resampled))\n",
    "n_random_smote = len(X_resampled)\n",
    "\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=n_random_smote, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_smote_sampled)) #verifica\n",
    "\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random_smote.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote = classifier_train_mitigated_random_smote.predict(X_test)\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_SMOTE_pred )\\naccuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote )\\n\\n\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\\n    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\\n    'After SMOTE fp mitigation' : [accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_mitigated_SMOTE_pred)],\\n    'After RANDOM mitigation' : [accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random, len(y_train_mitigated_random_smote), len(y_mitigated_pred_random_smote)]\\n    \\n})\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\\nmetrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n    \\nmetrics_after_fp_SMOTE\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_SMOTE_pred )\n",
    "accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote )\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After SMOTE fp mitigation' : [accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_mitigated_SMOTE_pred)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random, len(y_train_mitigated_random_smote), len(y_mitigated_pred_random_smote)]\n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "    \n",
    "metrics_after_fp_SMOTE'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A QUESTO PUNTO POSSIAMO VEDERE LE PERFORMANCE SUI SOTTOGRUPPI PRIMA E DOPO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \\ny_pred_test_filtered_fp_after_SMOTE = classifier_train_mitigated_SMOTE.predict(X_test_filtered_fp)\\ny_pred_RANDOM_subgroups = classifier_train_mitigated_random_smote.predict(X_test_filtered_fp)\\n\\n\\n#accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\\naccuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE )\\naccuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_RANDOM_subgroups )\\n\\nmetrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\\n    \\'Metrics\\' : [\\'Accuracy\\', \\'F1 Score\\', \\'False Positive Rate\\', \\'False Negative Rate\\', \\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\'],\\n    \\'Before Mitigation, on subgroups\\' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\\n    \\'After RANDOM mitigation, on subgroups\\' : [accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE, len(y_train), len(y_pred_RANDOM_subgroups)],\\n    \\'After Mitigation(K=5, on subgroups, fp and SMOTE)\\': [accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_pred_test_filtered_fp_after_SMOTE)],\\n})\\nmetrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index(\\'Metrics\\').T\\n\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\']\\n\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\\n\\nmetrics_after_fp_SMOTE\\n\\n\\nprint(\"Subgroups Decision Tree performance when boolean outcomes = correctness e SMOTE \")\\nmetrics_after_fp_sottogruppi_SMOTE'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "y_pred_test_filtered_fp_after_SMOTE = classifier_train_mitigated_SMOTE.predict(X_test_filtered_fp)\n",
    "y_pred_RANDOM_subgroups = classifier_train_mitigated_random_smote.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "#accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE )\n",
    "accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_RANDOM_subgroups )\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM mitigation, on subgroups' : [accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE, len(y_train), len(y_pred_RANDOM_subgroups)],\n",
    "    'After Mitigation(K=5, on subgroups, fp and SMOTE)': [accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_pred_test_filtered_fp_after_SMOTE)],\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = correctness e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p è la probabilità che il campione simulato sia di classe 0 qui (perchè voglio diminuire il numero di falsi positivi)\n",
    "- FISSO p VARIA N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 3569\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = [ 'y_pred', 'error', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1349, 2220)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered['income'].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0=0\n",
    "p1 = 0.1\n",
    "p2 = 0.2\n",
    "p3 = 0.3 \n",
    "p4 = 0.4\n",
    "p5 = 0.5\n",
    "p6 = 0.6\n",
    "p7 = 0.7\n",
    "p8 = 0.8\n",
    "p9 = 0.9\n",
    "p10 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df_holdout_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.155</td>\n",
       "      <td>3363.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3363.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.151</td>\n",
       "      <td>3363.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.166</td>\n",
       "      <td>3363.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3363.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.866     0.684             0.065   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.855     0.711             0.062   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.865     0.692             0.062   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.861     0.649             0.074   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.854     0.611             0.080   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.195               0.176   \n",
       "After RANDOM Mitigation(K=5 fp)            0.195               0.181   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.201               0.189   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.195               0.173   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.218               0.192   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.220               0.196   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.164   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.170   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.183   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.164   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.180   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.185   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.149          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.155       3363.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.174       3363.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.151       3363.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.166       3363.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.174       3363.000  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_2K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.154</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.156</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.153</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.162</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.176</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.866     0.684             0.066   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.860     0.704             0.062   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.867     0.692             0.062   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.862     0.654             0.072   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.856     0.623             0.080   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.195               0.176   \n",
       "After RANDOM Mitigation(K=5 fp)            0.195               0.180   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.186               0.174   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.195               0.179   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.200               0.184   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.220               0.200   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.164   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.169   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.167   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.167   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.174   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.189   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.149          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.154       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.156       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.153       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.162       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.176       2000.000  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 2000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_2K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.402</td>\n",
       "      <td>237</td>\n",
       "      <td>631</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.253</td>\n",
       "      <td>560</td>\n",
       "      <td>397</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.1</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.286</td>\n",
       "      <td>481</td>\n",
       "      <td>448</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.2</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.311</td>\n",
       "      <td>422</td>\n",
       "      <td>488</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.3</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.336</td>\n",
       "      <td>368</td>\n",
       "      <td>527</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.4</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.363</td>\n",
       "      <td>301</td>\n",
       "      <td>569</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.378</td>\n",
       "      <td>274</td>\n",
       "      <td>593</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.405</td>\n",
       "      <td>242</td>\n",
       "      <td>635</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.418</td>\n",
       "      <td>220</td>\n",
       "      <td>656</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.456</td>\n",
       "      <td>186</td>\n",
       "      <td>715</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.479</td>\n",
       "      <td>163</td>\n",
       "      <td>751</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.506</td>\n",
       "      <td>142</td>\n",
       "      <td>794</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.867     0.683                0.048   \n",
       "After SMOTE N = 5000 p_class 0 = 0       0.853     0.710                0.113   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1     0.857     0.707                0.097   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2     0.860     0.704                0.085   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3     0.862     0.699                0.074   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4     0.866     0.697                0.061   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.867     0.692                0.055   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.865     0.680                0.049   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.865     0.676                0.045   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.862     0.654                0.038   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.860     0.641                0.033   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.856     0.623                0.029   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.402              237   \n",
       "After SMOTE N = 5000 p_class 0 = 0                  0.253              560   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1                0.286              481   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2                0.311              422   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3                0.336              368   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4                0.363              301   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.378              274   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.405              242   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.418              220   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.456              186   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.479              163   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.506              142   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  631       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0                397       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.1              448       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.2              488       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.3              527       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.4              569       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              593       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              635       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              656       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              715       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              751       15014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                794       15014       6508  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.155</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.168</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.149</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.165</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.176</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.866     0.684             0.067   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.855     0.704             0.059   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.866     0.691             0.059   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.859     0.643             0.073   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.856     0.620             0.078   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.195               0.176   \n",
       "After RANDOM Mitigation(K=5 fp)            0.194               0.179   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.195               0.184   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.193               0.176   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.215               0.189   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.224               0.202   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.164   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.169   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.177   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.165   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.178   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.191   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.149          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.155       3000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.168       3000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.149       3000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.165       3000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.176       3000.000  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 3000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_3K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.398</td>\n",
       "      <td>242</td>\n",
       "      <td>624</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.227</td>\n",
       "      <td>639</td>\n",
       "      <td>356</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.1</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.251</td>\n",
       "      <td>582</td>\n",
       "      <td>393</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.2</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.286</td>\n",
       "      <td>494</td>\n",
       "      <td>448</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.3</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.316</td>\n",
       "      <td>421</td>\n",
       "      <td>495</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.4</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.337</td>\n",
       "      <td>360</td>\n",
       "      <td>529</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.377</td>\n",
       "      <td>284</td>\n",
       "      <td>591</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.408</td>\n",
       "      <td>244</td>\n",
       "      <td>640</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.436</td>\n",
       "      <td>196</td>\n",
       "      <td>684</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.474</td>\n",
       "      <td>174</td>\n",
       "      <td>743</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.489</td>\n",
       "      <td>153</td>\n",
       "      <td>767</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.511</td>\n",
       "      <td>138</td>\n",
       "      <td>802</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.867     0.686                0.049   \n",
       "After SMOTE N = 5000 p_class 0 = 0       0.847     0.709                0.129   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1     0.850     0.707                0.118   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2     0.855     0.704                0.100   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3     0.859     0.701                0.085   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4     0.863     0.700                0.073   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.866     0.691                0.057   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.864     0.677                0.049   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.865     0.668                0.040   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.859     0.643                0.035   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.859     0.635                0.031   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.856     0.620                0.028   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.398              242   \n",
       "After SMOTE N = 5000 p_class 0 = 0                  0.227              639   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1                0.251              582   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2                0.286              494   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3                0.316              421   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4                0.337              360   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.377              284   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.408              244   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.436              196   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.474              174   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.489              153   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.511              138   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  624       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0                356       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.1              393       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.2              448       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.3              495       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.4              529       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              591       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              640       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              684       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              743       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              767       16014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                802       16014       6508  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.160</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.174</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.155</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.162</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.213</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.866     0.684             0.069   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.853     0.711             0.065   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.863     0.690             0.065   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.860     0.642             0.069   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.851     0.591             0.100   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.195               0.176   \n",
       "After RANDOM Mitigation(K=5 fp)            0.207               0.185   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.198               0.189   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.193               0.177   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.213               0.189   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.264               0.237   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.164   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.174   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.183   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.168   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.176   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.227   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.149          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.160       4000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.174       4000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.155       4000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.162       4000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.213       4000.000  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 4000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_4K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 5000 p changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.156</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.184</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.147</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.164</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.215</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.866     0.684             0.065   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.851     0.712             0.056   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.864     0.699             0.056   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.859     0.638             0.071   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.848     0.579             0.094   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.195               0.176   \n",
       "After RANDOM Mitigation(K=5 fp)            0.205               0.184   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.208               0.199   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.189               0.169   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.212               0.191   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.280               0.244   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.164   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.172   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.192   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.160   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.178   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.231   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.149          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.156       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.184       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.147       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.164       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.215       5000.000  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 5000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_5K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.410</td>\n",
       "      <td>231</td>\n",
       "      <td>643</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.182</td>\n",
       "      <td>831</td>\n",
       "      <td>285</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.1</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.200</td>\n",
       "      <td>748</td>\n",
       "      <td>314</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.2</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.236</td>\n",
       "      <td>601</td>\n",
       "      <td>370</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.3</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.275</td>\n",
       "      <td>508</td>\n",
       "      <td>431</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.4</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.323</td>\n",
       "      <td>392</td>\n",
       "      <td>506</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.346</td>\n",
       "      <td>341</td>\n",
       "      <td>542</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.399</td>\n",
       "      <td>255</td>\n",
       "      <td>626</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.429</td>\n",
       "      <td>212</td>\n",
       "      <td>673</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.485</td>\n",
       "      <td>158</td>\n",
       "      <td>760</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.523</td>\n",
       "      <td>129</td>\n",
       "      <td>820</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.565</td>\n",
       "      <td>104</td>\n",
       "      <td>886</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.866     0.679                0.047   \n",
       "After SMOTE N = 5000 p_class 0 = 0       0.829     0.697                0.168   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1     0.837     0.703                0.151   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2     0.851     0.712                0.122   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3     0.856     0.708                0.103   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4     0.862     0.703                0.079   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.864     0.699                0.069   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.865     0.681                0.052   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.864     0.669                0.043   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.859     0.638                0.032   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.854     0.612                0.026   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.848     0.579                0.021   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.410              231   \n",
       "After SMOTE N = 5000 p_class 0 = 0                  0.182              831   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1                0.200              748   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2                0.236              601   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3                0.275              508   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4                0.323              392   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.346              341   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.399              255   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.429              212   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.485              158   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.523              129   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.565              104   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  643       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0                285       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.1              314       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.2              370       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.3              431       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.4              506       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              542       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              626       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              673       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              760       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              820       18014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                886       18014       6508  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 6000 p changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.153</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.213</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.149</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.172</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.230</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.866     0.684             0.064   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.844     0.705             0.061   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.864     0.701             0.061   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.858     0.631             0.077   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.845     0.560             0.099   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.195               0.176   \n",
       "After RANDOM Mitigation(K=5 fp)            0.198               0.177   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.243               0.229   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.187               0.171   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.220               0.198   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.282               0.260   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.164   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.167   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.222   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.162   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.186   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.248   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.149          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.153       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.213       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.149       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.172       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.230       6000.000  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 6000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_6K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.152</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.223</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.148</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.176</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.231</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.866     0.684             0.064   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.839     0.702             0.059   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.864     0.699             0.059   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.856     0.624             0.078   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.845     0.560             0.100   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.195               0.176   \n",
       "After RANDOM Mitigation(K=5 fp)            0.195               0.176   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.252               0.239   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.187               0.172   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.223               0.203   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.284               0.262   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.164   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.165   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.231   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.162   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.191   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.249   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.149          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.152       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.223       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.148       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.176       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.231       7000.000  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 7000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_6K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.150</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.246</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.151</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.172</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.253</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.866     0.684             0.062   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.837     0.701             0.059   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.862     0.695             0.059   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.857     0.626             0.078   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.838     0.521             0.110   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.195               0.176   \n",
       "After RANDOM Mitigation(K=5 fp)            0.191               0.173   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.277               0.263   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.189               0.173   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.221               0.199   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.347               0.299   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.164   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.164   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.255   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.164   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.186   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.278   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.149          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.150       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.246       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.151       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.172       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.253       8000.000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 8000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_6K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.156</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.252</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.153</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.174</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.255</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.866     0.684             0.066   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.834     0.698             0.063   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.862     0.696             0.063   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.856     0.622             0.076   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.837     0.517             0.110   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.195               0.176   \n",
       "After RANDOM Mitigation(K=5 fp)            0.199               0.182   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.283               0.268   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.194               0.177   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.224               0.203   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.349               0.302   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.164   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.171   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.261   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.166   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.189   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.280   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.149          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.156       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.252       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.153       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.174       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.255       9000.000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 9000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_6K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creazione del grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "p =[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "# Linea per i falsi positivi\n",
    "\n",
    "plt.plot(p, errors_after_2K, marker='o', label='Error 2K ', color='black')\n",
    "plt.plot(p, errors_after_3K, marker='o', label='Error 3K ', color='red')\n",
    "plt.plot(p, errors_after_4K, marker='o', label='Error 4K ', color='green')\n",
    "plt.plot(p, errors_after_5K, marker='o', label='Error 5K ', color='blue')\n",
    "plt.plot(p, errors_after_6K,  marker='o', label='Error 6K ', color='orange')\n",
    "\n",
    "\n",
    "plt.axhline(y=errors_before, color='purple', linestyle='--', label='Initial Errors')\n",
    "\n",
    "# Etichette e titolo\n",
    "plt.xlabel('probability for the synthetic point to belong to the class 0')\n",
    "plt.ylabel('Count Errors')\n",
    "plt.title(f'Errors, err, #subgroups = {K}, support = {min_sup} on {filtered_instances}, redundancy = 0.01')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.yticks(range(1175, 1350, 25))\n",
    "plt.xticks(np.arange(0, 1.1, 0.1)) \n",
    "# Mostra il grafico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1349, 2220)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
