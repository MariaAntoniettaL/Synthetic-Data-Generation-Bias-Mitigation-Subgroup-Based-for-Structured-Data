{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_for_adult import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "\n",
    "from divexplorer.outcomes import get_false_negative_rate_outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv(\"adult.data\", header = None, names = col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = 0.25\n",
    "percentage =  35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosità precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GDecisioN tree predictions\n",
    "X_train = df_train_enc.drop(columns = 'income', axis = 1)\n",
    "y_train = df_train_enc['income']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'income', axis = 1)\n",
    "y_test = df_test_enc['income']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'income', axis = 1)\n",
    "y_val = df_val_enc['income']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'income', axis = 1)\n",
    "y_holdout = df_holdout_enc['income']\n",
    "\n",
    "classifier_train = RandomForestClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.381</td>\n",
       "      <td>426</td>\n",
       "      <td>598</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.843     0.655                0.086   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.381              426              598   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       6508  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione è giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>2</td>\n",
       "      <td>0.077</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0</td>\n",
       "      <td>0.284</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass  fnlwgt  education  marital-status  occupation  relationship  \\\n",
       "18761          2   0.077          3               0           4             1   \n",
       "27582          3   0.048          3               1           4             0   \n",
       "30911          2   0.174          3               3           4             4   \n",
       "11128          0   0.012          2               1           2             0   \n",
       "683            0   0.284          3               3           2             4   \n",
       "\n",
       "       race  sex  capital-gain  capital-loss  native-country  age_group  \\\n",
       "18761     4    0         0.000         0.000               5          2   \n",
       "27582     4    1         0.000         0.000               5          5   \n",
       "30911     2    0         0.039         0.000               5          1   \n",
       "11128     2    1         0.000         0.507               5          3   \n",
       "683       2    1         0.000         0.000               5          0   \n",
       "\n",
       "       edu_num_group  hours_per_week_group  y_val_true  y_pred  \n",
       "18761              1                     1           0       0  \n",
       "27582              1                     2           1       0  \n",
       "30911              1                     1           0       0  \n",
       "11128              4                     1           1       1  \n",
       "683                1                     1           0       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set\n",
    "y_pred_val_dt = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val_dt\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>fn</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.077</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>Self-emp</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>65-100</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.174</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.012</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>45-54</td>\n",
       "      <td>14 Master's Degree</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.284</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        workclass  fnlwgt        education marital-status    occupation  \\\n",
       "18761     Private   0.077    Non Graduated       Divorced  Self-emp-occ   \n",
       "27582    Self-emp   0.048    Non Graduated        Married  Self-emp-occ   \n",
       "30911     Private   0.174    Non Graduated      Separated  Self-emp-occ   \n",
       "11128  Government   0.012  Master's Degree        Married   Private-occ   \n",
       "683    Government   0.284    Non Graduated      Separated   Private-occ   \n",
       "\n",
       "         relationship    race      sex  capital-gain  capital-loss  \\\n",
       "18761   Not-in-family   White   Female         0.000         0.000   \n",
       "27582         Husband   White     Male         0.000         0.000   \n",
       "30911       Unmarried   Black   Female         0.039         0.000   \n",
       "11128         Husband   Black     Male         0.000         0.507   \n",
       "683         Unmarried   Black     Male         0.000         0.000   \n",
       "\n",
       "      native-country  income age_group       edu_num_group  \\\n",
       "18761  United-States       0     35-44          10 College   \n",
       "27582  United-States       1    65-100          10 College   \n",
       "30911  United-States       0     25-34          10 College   \n",
       "11128  United-States       1     45-54  14 Master's Degree   \n",
       "683    United-States       0     17-24          10 College   \n",
       "\n",
       "      hours_per_week_group    fn  y_pred  accuracy  \n",
       "18761             Overtime   NaN       0         1  \n",
       "27582            Part-time 1.000       0         0  \n",
       "30911             Overtime   NaN       0         1  \n",
       "11128             Overtime 0.000       1         1  \n",
       "683               Overtime   NaN       0         1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]\n",
    "\n",
    "df_val_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_val['fn'] = df_val_class['fn']\n",
    "\n",
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione è giusta 0 se la predizione è sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['accuracy'] = (df_val_class['y_val_true']==df_val_class['y_pred']).astype(int)\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_div</th>\n",
       "      <th>fn_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.271</td>\n",
       "      <td>(native-country=United-States, capital-gain=0.0, marital-status=Never-married, capital-loss=0.0)</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.435</td>\n",
       "      <td>7.485</td>\n",
       "      <td>4</td>\n",
       "      <td>1764.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300</td>\n",
       "      <td>(capital-gain=0.0, marital-status=Never-married, capital-loss=0.0)</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.419</td>\n",
       "      <td>7.118</td>\n",
       "      <td>3</td>\n",
       "      <td>1952.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.288</td>\n",
       "      <td>(capital-gain=0.0, education=Non Graduated, edu_num_group=9 High School Graduate, capital-loss=0.0)</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.404</td>\n",
       "      <td>13.956</td>\n",
       "      <td>4</td>\n",
       "      <td>1872.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288</td>\n",
       "      <td>(capital-gain=0.0, edu_num_group=9 High School Graduate, capital-loss=0.0)</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.404</td>\n",
       "      <td>13.956</td>\n",
       "      <td>3</td>\n",
       "      <td>1872.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.264</td>\n",
       "      <td>(native-country=United-States, capital-gain=0.0, edu_num_group=9 High School Graduate, capital-loss=0.0)</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.394</td>\n",
       "      <td>13.114</td>\n",
       "      <td>4</td>\n",
       "      <td>1718.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.271   \n",
       "1    0.300   \n",
       "2    0.288   \n",
       "3    0.288   \n",
       "4    0.264   \n",
       "\n",
       "                                                                                                    itemset  \\\n",
       "0          (native-country=United-States, capital-gain=0.0, marital-status=Never-married, capital-loss=0.0)   \n",
       "1                                        (capital-gain=0.0, marital-status=Never-married, capital-loss=0.0)   \n",
       "2       (capital-gain=0.0, education=Non Graduated, edu_num_group=9 High School Graduate, capital-loss=0.0)   \n",
       "3                                (capital-gain=0.0, edu_num_group=9 High School Graduate, capital-loss=0.0)   \n",
       "4  (native-country=United-States, capital-gain=0.0, edu_num_group=9 High School Graduate, capital-loss=0.0)   \n",
       "\n",
       "     fn  fn_div   fn_t  length  support_count  \n",
       "0 0.804   0.435  7.485       4       1764.000  \n",
       "1 0.788   0.419  7.118       3       1952.000  \n",
       "2 0.773   0.404 13.956       4       1872.000  \n",
       "3 0.773   0.404 13.956       3       1872.000  \n",
       "4 0.763   0.394 13.114       4       1718.000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_diver = DivergenceExplorer(df_val)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_div</th>\n",
       "      <th>fn_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.271</td>\n",
       "      <td>(native-country=United-States, capital-gain=0.0, marital-status=Never-married, capital-loss=0.0)</td>\n",
       "      <td>4</td>\n",
       "      <td>1764.000</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.435</td>\n",
       "      <td>7.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300</td>\n",
       "      <td>(capital-gain=0.0, marital-status=Never-married, capital-loss=0.0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1952.000</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.419</td>\n",
       "      <td>7.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288</td>\n",
       "      <td>(capital-gain=0.0, edu_num_group=9 High School Graduate, capital-loss=0.0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1872.000</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.404</td>\n",
       "      <td>13.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.311</td>\n",
       "      <td>(capital-gain=0.0, marital-status=Never-married)</td>\n",
       "      <td>2</td>\n",
       "      <td>2021.000</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.385</td>\n",
       "      <td>6.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.453</td>\n",
       "      <td>(capital-gain=0.0, education=Non Graduated, capital-loss=0.0, workclass=Private)</td>\n",
       "      <td>4</td>\n",
       "      <td>2945.000</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.359</td>\n",
       "      <td>13.260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.271   \n",
       "1    0.300   \n",
       "3    0.288   \n",
       "7    0.311   \n",
       "9    0.453   \n",
       "\n",
       "                                                                                            itemset  \\\n",
       "0  (native-country=United-States, capital-gain=0.0, marital-status=Never-married, capital-loss=0.0)   \n",
       "1                                (capital-gain=0.0, marital-status=Never-married, capital-loss=0.0)   \n",
       "3                        (capital-gain=0.0, edu_num_group=9 High School Graduate, capital-loss=0.0)   \n",
       "7                                                  (capital-gain=0.0, marital-status=Never-married)   \n",
       "9                  (capital-gain=0.0, education=Non Graduated, capital-loss=0.0, workclass=Private)   \n",
       "\n",
       "   length  support_count    fn  fn_div   fn_t  \n",
       "0       4       1764.000 0.804   0.435  7.485  \n",
       "1       3       1952.000 0.788   0.419  7.118  \n",
       "3       3       1872.000 0.773   0.404 13.956  \n",
       "7       2       2021.000 0.754   0.385  6.755  \n",
       "9       4       2945.000 0.729   0.359 13.260  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 87\n",
      "total problematic 62\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_fp)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_fp[(df_pruned_fp['fn_div'] > 0) & (df_pruned_fp['fn_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (509, 7)\n",
      "Dim pruned th_redundancy  (87, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_fp.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset3 li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prima 4994\n",
      "dopo 684\n"
     ]
    }
   ],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "print('prima', len(df_holdout_filtered))\n",
    "df_holdout_filtered_solo1 = df_holdout_filtered[df_holdout_filtered['income']==1]\n",
    "\n",
    "\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered_solo1, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "df_holdout_filtered = df_holdout_filtered_solo1 \n",
    "\n",
    "print(\"dopo\", len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "TRAIN SET MITIGATED ROWS:  13698\n",
      "VALIDATION SET ROWS:  6508\n",
      "FILTERED DF holdout ROWS:  684\n",
      "TEST SET FILTERED ROWS:  6507\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'income', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['income']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "verifica : 684\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['income']\n",
    "\n",
    "classifier_train_mitigated_random = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Gradient Boosting performance when boolean outcomes = fn \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.381</td>\n",
       "      <td>426</td>\n",
       "      <td>598</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.323</td>\n",
       "      <td>553</td>\n",
       "      <td>507</td>\n",
       "      <td>13698</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.379</td>\n",
       "      <td>429</td>\n",
       "      <td>595</td>\n",
       "      <td>13698</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.843     0.655                0.086   \n",
       "After Mitigation(K=5, fp)     0.837     0.667                0.112   \n",
       "After RANDOM mitigation       0.843     0.655                0.087   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.381              426   \n",
       "After Mitigation(K=5, fp)                0.323              553   \n",
       "After RANDOM mitigation                  0.379              429   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      598       13014       6508  \n",
       "After Mitigation(K=5, fp)              507       13698       6508  \n",
       "After RANDOM mitigation                595       13698       6508  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "print(\"Overall Gradient Boosting performance when boolean outcomes = fn \")\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.658</td>\n",
       "      <td>250</td>\n",
       "      <td>439</td>\n",
       "      <td>13014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.520</td>\n",
       "      <td>379</td>\n",
       "      <td>347</td>\n",
       "      <td>13698</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.642</td>\n",
       "      <td>258</td>\n",
       "      <td>428</td>\n",
       "      <td>13698</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                         Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                    0.862     0.398   \n",
       "After Mitigation(K=5, on subgroups, fp)            0.855     0.469   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)     0.863     0.411   \n",
       "\n",
       "Metrics                                         False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                               0.058   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.087   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.060   \n",
       "\n",
       "Metrics                                         False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                               0.658   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.520   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.642   \n",
       "\n",
       "Metrics                                         False Positives  \\\n",
       "Before Mitigation, on subgroups                             250   \n",
       "After Mitigation(K=5, on subgroups, fp)                     379   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              258   \n",
       "\n",
       "Metrics                                         False Negatives  Train Size  \\\n",
       "Before Mitigation, on subgroups                             439       13014   \n",
       "After Mitigation(K=5, on subgroups, fp)                     347       13698   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              428       13698   \n",
       "\n",
       "Metrics                                         Test Size  \n",
       "Before Mitigation, on subgroups                      5002  \n",
       "After Mitigation(K=5, on subgroups, fp)              5002  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)       5002  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered_fp = K_subgroups_dataset_and_or(df_pruned_fp, df_test, K)\n",
    "inutile, df_test_filtered_enc_fp, inutile2, inutile3 = encoding_funct(df_train, df_test_filtered_fp, df_holdout, df_val)\n",
    "\n",
    "X_test_filtered_fp = df_test_filtered_enc_fp.drop(columns='income', axis = 1)\n",
    "y_true_test_filtered_fp = df_test_filtered_enc_fp['income']\n",
    "\n",
    "y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after = classifier_train_mitigated.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_random = classifier_train_mitigated_random.predict(X_test_filtered_fp)\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after )\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_random)\n",
    "\n",
    "\n",
    "metrics_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after, len(y_train_mitigated), len(y_pred_test_filtered_fp_after)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(y_train_mitigated_random), len(y_pred_test_filtered_fp_after_random)]\n",
    "})\n",
    "metrics_after_fp_sottogruppi = metrics_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi[metric] = metrics_after_fp_sottogruppi[metric].astype(int)\n",
    "\n",
    "metrics_after_fp\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fn\")\n",
    "metrics_after_fp_sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values([\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fn_div_list_no_mitigation  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fn_div_list_no_mitigation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fn_div_list_baseline1  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fn_div_list_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values([\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fn_div_list_random_per_confrontare_con_baseline1  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fn_div_list_random_per_confrontare_con_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.198</td>\n",
       "      <td>684.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.284</td>\n",
       "      <td>684.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.843     0.655             0.127   \n",
       "After Mitigation(K=5 fp)            0.837     0.667             0.114   \n",
       "After RANDOM Mitigation(K=5 fp)     0.843     0.655             0.144   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.490               0.373   \n",
       "After Mitigation(K=5 fp)           0.477               0.316   \n",
       "After RANDOM Mitigation(K=5 fp)    0.493               0.406   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.328               0.268   \n",
       "After Mitigation(K=5 fp)                      0.259               0.198   \n",
       "After RANDOM Mitigation(K=5 fp)               0.347               0.284   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)               684.000  \n",
       "After RANDOM Mitigation(K=5 fp)        684.000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fn_div_list_no_mitigation = np.nanmean(fn_div_list_no_mitigation)\n",
    "media_fn_div_list_nomitigation_primi10 = np.nanmean(fn_div_list_no_mitigation[:10])\n",
    "media_fn_div_list_nomitigation_primi20 = np.nanmean(fn_div_list_no_mitigation[:20])\n",
    "media_fn_div_list_nomitigation_primi40 = np.nanmean(fn_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fn_div_no_mitigation = max(abs(x) for x in fn_div_list_no_mitigation)\n",
    "\n",
    "media_fn_div_list_baseline1 = np.nanmean(fn_div_list_baseline1)\n",
    "media_fn_div_list_baseline1_primi10 = np.nanmean(fn_div_list_baseline1[:10])\n",
    "media_fn_div_list_baseline1_primi20 = np.nanmean(fn_div_list_baseline1[:20])\n",
    "media_fn_div_list_baseline1_primi40 = np.nanmean(fn_div_list_baseline1[:40])\n",
    "fn_div_massimo_valore_assoluto_fn_div_baseline1 = max(abs(x) for x in fn_div_list_baseline1)\n",
    "\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fn_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fn_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fn_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fn_div_list_no_mitigation, massimo_valore_assoluto_fn_div_no_mitigation,\n",
    "        media_fn_div_list_nomitigation_primi10, media_fn_div_list_nomitigation_primi20, media_fn_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_fn_div_list_baseline1, fn_div_massimo_valore_assoluto_fn_div_baseline1,\n",
    "        media_fn_div_list_baseline1_primi10, media_fn_div_list_baseline1_primi20, media_fn_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fn_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fn_div_random_per_confrontare_con_baseline1, media_fn_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fn_div_list_random_per_confrontare_con_baseline1_primi20, media_fn_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fn_sottogruppi = divergence_after_fn_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fn_sottogruppi\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUI INIZIA SMOTE come si deve DA METTERE NEL REPORT\n",
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p è la probabilità che il campione simulato sia di classe 0 qui (perchè voglio diminuire il numero di falsi negativi)\n",
    "- FISSO p VARIA N , aumento il numero di 0 per diminuire il numero di falsi negativi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 4961\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['fn', 'y_pred', 'accuracy', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(649, 4312)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered['income'].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUI MODIFICO FACENDO SMOTE SU DF_VAL_FILTERED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smote_nc = SMOTENC(categorical_features=categorical_features,random_state=seed)\\nX_to_SMOTE, y_to_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\ncount_1 = y_to_SMOTE.sum()\\ncount_0 = len(y_to_SMOTE)-count_1\\ncount_0, count_1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''smote_nc = SMOTENC(categorical_features=categorical_features,random_state=seed)\n",
    "X_to_SMOTE, y_to_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "count_1 = y_to_SMOTE.sum()\n",
    "count_0 = len(y_to_SMOTE)-count_1\n",
    "count_0, count_1'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.381</td>\n",
       "      <td>426</td>\n",
       "      <td>598</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.379</td>\n",
       "      <td>429</td>\n",
       "      <td>595</td>\n",
       "      <td>13698</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.357</td>\n",
       "      <td>462</td>\n",
       "      <td>560</td>\n",
       "      <td>13698</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.371</td>\n",
       "      <td>453</td>\n",
       "      <td>582</td>\n",
       "      <td>13698</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.372</td>\n",
       "      <td>448</td>\n",
       "      <td>583</td>\n",
       "      <td>13698</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.372</td>\n",
       "      <td>438</td>\n",
       "      <td>583</td>\n",
       "      <td>13698</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.387</td>\n",
       "      <td>437</td>\n",
       "      <td>607</td>\n",
       "      <td>13698</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.389</td>\n",
       "      <td>418</td>\n",
       "      <td>610</td>\n",
       "      <td>13698</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.843     0.655                0.086   \n",
       "After RANDOM mitigation N = 5000         0.843     0.655                0.087   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.843     0.664                0.094   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.841     0.656                0.092   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.842     0.656                0.091   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.843     0.659                0.089   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.840     0.648                0.088   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.842     0.651                0.085   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.381              426   \n",
       "After RANDOM mitigation N = 5000                    0.379              429   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.357              462   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.371              453   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.372              448   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.372              438   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.387              437   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.389              418   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 598       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  595       13698       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              560       13698       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              582       13698       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              583       13698       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              583       13698       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              607       13698       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                610       13698       6508  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + int(N*0.5), 0: count_0 + int(N*0.5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + int(N*0.6), 1: count_1 + int(N*0.4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + int(N*0.7), 1: count_1 + int(N*0.3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 +int(N*0.8), 1: count_1 + int(N*0.2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + int(N*0.9), 1: count_1 + int(N*0.1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + int(N*1), 1: count_1 + int(N*0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.284</td>\n",
       "      <td>684.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=0.5)</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.257</td>\n",
       "      <td>684.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=0.8)</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.277</td>\n",
       "      <td>684.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=1)</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.287</td>\n",
       "      <td>684.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.843     0.655             0.127   \n",
       "After RANDOM Mitigation(K=5 fp)             0.843     0.655             0.144   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)     0.841     0.656             0.123   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)     0.843     0.659             0.138   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)       0.842     0.651             0.133   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.490               0.373   \n",
       "After RANDOM Mitigation(K=5 fp)            0.493               0.406   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)    0.461               0.366   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)    0.465               0.395   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)      0.502               0.389   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.328   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.347   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)               0.309   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)               0.341   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)                 0.343   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.268          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.284        684.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)               0.257        684.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)               0.277        684.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)                 0.287        684.000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 2K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 2K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 2K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.381</td>\n",
       "      <td>426</td>\n",
       "      <td>598</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.379</td>\n",
       "      <td>420</td>\n",
       "      <td>594</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.5</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.351</td>\n",
       "      <td>508</td>\n",
       "      <td>551</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.6</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.339</td>\n",
       "      <td>526</td>\n",
       "      <td>531</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.7</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.339</td>\n",
       "      <td>542</td>\n",
       "      <td>532</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.8</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.332</td>\n",
       "      <td>541</td>\n",
       "      <td>520</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.9</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.330</td>\n",
       "      <td>564</td>\n",
       "      <td>517</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 1</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.319</td>\n",
       "      <td>594</td>\n",
       "      <td>500</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.843     0.655                0.086   \n",
       "After RANDOM mitigation N = 5000         0.844     0.658                0.085   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5     0.837     0.658                0.103   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6     0.838     0.662                0.106   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7     0.835     0.659                0.110   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8     0.837     0.664                0.110   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9     0.834     0.660                0.114   \n",
       "After SMOTE N = 2000 p_class 0 = 1       0.832     0.661                0.120   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.381              426   \n",
       "After RANDOM mitigation N = 5000                    0.379              420   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5                0.351              508   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6                0.339              526   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7                0.339              542   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8                0.332              541   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9                0.330              564   \n",
       "After SMOTE N = 2000 p_class 0 = 1                  0.319              594   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 598       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  594       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.5              551       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.6              531       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.7              532       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.8              520       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.9              517       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 1                500       15014       6508  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 2000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 1000, 0: count_0 + 1000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 1200, 0: count_0 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 1400, 0: count_0 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 1600, 0: count_0 + 400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 1800, 0: count_0 + 200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 2000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 2000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1= metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.301</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=0.5)</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.237</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=0.8)</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.249</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=1)</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.222</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.843     0.655             0.127   \n",
       "After RANDOM Mitigation(K=5 fp)             0.843     0.655             0.146   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)     0.838     0.662             0.120   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)     0.837     0.664             0.125   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)       0.832     0.661             0.100   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.490               0.373   \n",
       "After RANDOM Mitigation(K=5 fp)            0.494               0.413   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)    0.423               0.299   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)    0.459               0.319   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)      0.439               0.297   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.328   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.362   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)               0.270   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)               0.281   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)                 0.256   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.268          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.301       2000.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)               0.237       2000.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)               0.249       2000.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)                 0.222       2000.000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 2K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 2K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 2K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.381</td>\n",
       "      <td>426</td>\n",
       "      <td>598</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.386</td>\n",
       "      <td>435</td>\n",
       "      <td>606</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.341</td>\n",
       "      <td>526</td>\n",
       "      <td>535</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.339</td>\n",
       "      <td>535</td>\n",
       "      <td>532</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.321</td>\n",
       "      <td>569</td>\n",
       "      <td>504</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.320</td>\n",
       "      <td>585</td>\n",
       "      <td>501</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.312</td>\n",
       "      <td>593</td>\n",
       "      <td>490</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.309</td>\n",
       "      <td>623</td>\n",
       "      <td>485</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.843     0.655                0.086   \n",
       "After RANDOM mitigation N = 5000         0.840     0.649                0.088   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.837     0.661                0.106   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.836     0.660                0.108   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.835     0.665                0.115   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.833     0.663                0.118   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.834     0.666                0.120   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.830     0.662                0.126   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.381              426   \n",
       "After RANDOM mitigation N = 5000                    0.386              435   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.341              526   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.339              535   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.321              569   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.320              585   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.312              593   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.309              623   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 598       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  606       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              535       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              532       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              504       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              501       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              490       16014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                485       16014       6508  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 3000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 1500, 0: count_0 + 1500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 1800, 0: count_0 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 2100, 0: count_0 + 900}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 2400, 0: count_0 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 2700, 0: count_0 + 300}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 3000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_3K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_3K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_3K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_3K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1= metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.275</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=0.5)</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.247</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=0.8)</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.215</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=1)</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.216</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.843     0.655             0.127   \n",
       "After RANDOM Mitigation(K=5 fp)             0.843     0.655             0.153   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)     0.836     0.660             0.123   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)     0.833     0.663             0.105   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)       0.830     0.662             0.110   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.490               0.373   \n",
       "After RANDOM Mitigation(K=5 fp)            0.504               0.415   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)    0.433               0.300   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)    0.439               0.289   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)      0.481               0.307   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.328   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.348   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)               0.273   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)               0.246   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)                 0.254   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.268          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.275       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)               0.247       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)               0.215       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)                 0.216       3000.000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 3K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 3K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 3K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.381</td>\n",
       "      <td>426</td>\n",
       "      <td>598</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.379</td>\n",
       "      <td>438</td>\n",
       "      <td>594</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.342</td>\n",
       "      <td>564</td>\n",
       "      <td>536</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.330</td>\n",
       "      <td>561</td>\n",
       "      <td>518</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.328</td>\n",
       "      <td>588</td>\n",
       "      <td>515</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.320</td>\n",
       "      <td>614</td>\n",
       "      <td>501</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.320</td>\n",
       "      <td>633</td>\n",
       "      <td>501</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.305</td>\n",
       "      <td>641</td>\n",
       "      <td>478</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.843     0.655                0.086   \n",
       "After RANDOM mitigation N = 5000         0.841     0.654                0.089   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.831     0.652                0.114   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.834     0.661                0.114   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.831     0.656                0.119   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.829     0.657                0.124   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.826     0.653                0.128   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.828     0.661                0.130   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.381              426   \n",
       "After RANDOM mitigation N = 5000                    0.379              438   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.342              564   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.330              561   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.328              588   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.320              614   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.320              633   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.305              641   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 598       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  594       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              536       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              518       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              515       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              501       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              501       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                478       17014       6508  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 4000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 2000, 0: count_0 + 2000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 2400, 0: count_0 + 1600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 2800, 0: count_0 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 3200, 0: count_0 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 3600, 0: count_0 + 400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 4000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_4K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_4K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_4K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_4K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1= metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.277</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=0.5)</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.249</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=0.8)</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.218</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=1)</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.206</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.843     0.655             0.127   \n",
       "After RANDOM Mitigation(K=5 fp)             0.843     0.655             0.132   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)     0.834     0.661             0.132   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)     0.829     0.657             0.104   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)       0.828     0.661             0.085   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.490               0.373   \n",
       "After RANDOM Mitigation(K=5 fp)            0.476               0.404   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)    0.476               0.335   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)    0.439               0.296   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)      0.453               0.308   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.328   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.346   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)               0.286   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)               0.252   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)                 0.251   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.268          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.277       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)               0.249       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)               0.218       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)                 0.206       4000.000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 4K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 4K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 4K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.381</td>\n",
       "      <td>426</td>\n",
       "      <td>598</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.375</td>\n",
       "      <td>456</td>\n",
       "      <td>588</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.349</td>\n",
       "      <td>538</td>\n",
       "      <td>548</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.333</td>\n",
       "      <td>595</td>\n",
       "      <td>522</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.318</td>\n",
       "      <td>592</td>\n",
       "      <td>499</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.318</td>\n",
       "      <td>620</td>\n",
       "      <td>498</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.312</td>\n",
       "      <td>637</td>\n",
       "      <td>490</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.314</td>\n",
       "      <td>650</td>\n",
       "      <td>492</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.843     0.655                0.086   \n",
       "After RANDOM mitigation N = 5000         0.840     0.652                0.092   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.833     0.653                0.109   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.828     0.652                0.120   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.832     0.662                0.120   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.828     0.657                0.126   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.827     0.657                0.129   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.825     0.653                0.132   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.381              426   \n",
       "After RANDOM mitigation N = 5000                    0.375              456   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.349              538   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.333              595   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.318              592   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.318              620   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.312              637   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.314              650   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 598       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  588       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              548       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              522       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              499       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              498       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              490       18014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                492       18014       6508  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 5000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 2500, 0: count_0 + 2500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 3000, 0: count_0 + 2000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 3500, 0: count_0 + 1500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 4000, 0: count_0 + 1000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 4500, 0: count_0 + 500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 5000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_5K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOTTOGRUPPI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.658</td>\n",
       "      <td>250</td>\n",
       "      <td>439</td>\n",
       "      <td>13014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.627</td>\n",
       "      <td>273</td>\n",
       "      <td>418</td>\n",
       "      <td>18014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.571</td>\n",
       "      <td>356</td>\n",
       "      <td>381</td>\n",
       "      <td>18014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.535</td>\n",
       "      <td>407</td>\n",
       "      <td>357</td>\n",
       "      <td>18014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.507</td>\n",
       "      <td>415</td>\n",
       "      <td>338</td>\n",
       "      <td>18014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.498</td>\n",
       "      <td>440</td>\n",
       "      <td>332</td>\n",
       "      <td>18014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.487</td>\n",
       "      <td>453</td>\n",
       "      <td>325</td>\n",
       "      <td>18014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.483</td>\n",
       "      <td>475</td>\n",
       "      <td>322</td>\n",
       "      <td>18014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.862     0.398   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.862     0.419   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.853     0.437   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.847     0.448   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.849     0.466   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.846     0.465   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.844     0.468   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.841     0.464   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.058   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.063   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.082   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.094   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.096   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.101   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.104   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.110   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.658   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.627   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.571   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.535   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.507   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.498   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.487   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.483   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                     250   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      273   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              356   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              407   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              415   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              440   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              453   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                475   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     439   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      418   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              381   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              357   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              338   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              332   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              325   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                322   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       5002  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               18014       5002  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       18014       5002  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       18014       5002  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       18014       5002  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       18014       5002  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       18014       5002  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         18014       5002  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.265</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.247</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.207</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.194</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.843     0.655             0.127   \n",
       "After RANDOM Mitigation(K=5 fp)             0.843     0.655             0.118   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.828     0.652             0.111   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.828     0.657             0.083   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.825     0.653             0.064   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.490               0.373   \n",
       "After RANDOM Mitigation(K=5 fp)            0.461               0.386   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.505               0.327   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.440               0.293   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.444               0.299   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.328   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.335   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.283   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.246   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.242   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.268          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.265       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.247       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.207       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.194       5000.000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 6000, p changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.381</td>\n",
       "      <td>426</td>\n",
       "      <td>598</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.374</td>\n",
       "      <td>457</td>\n",
       "      <td>586</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.5</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.344</td>\n",
       "      <td>552</td>\n",
       "      <td>539</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.6</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.331</td>\n",
       "      <td>601</td>\n",
       "      <td>519</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.7</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.326</td>\n",
       "      <td>595</td>\n",
       "      <td>511</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.8</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.320</td>\n",
       "      <td>632</td>\n",
       "      <td>501</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.9</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.321</td>\n",
       "      <td>648</td>\n",
       "      <td>503</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 1</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.302</td>\n",
       "      <td>688</td>\n",
       "      <td>474</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.843     0.655                0.086   \n",
       "After RANDOM mitigation N = 6000         0.840     0.653                0.093   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5     0.832     0.654                0.112   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6     0.828     0.652                0.122   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7     0.830     0.657                0.120   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8     0.826     0.653                0.128   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9     0.823     0.649                0.131   \n",
       "After SMOTE N = 6000 p_class 0 = 1       0.821     0.653                0.139   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.381              426   \n",
       "After RANDOM mitigation N = 6000                    0.374              457   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5                0.344              552   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6                0.331              601   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7                0.326              595   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8                0.320              632   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9                0.321              648   \n",
       "After SMOTE N = 6000 p_class 0 = 1                  0.302              688   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 598       13014       6508  \n",
       "After RANDOM mitigation N = 6000                  586       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.5              539       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.6              519       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.7              511       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.8              501       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.9              503       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 1                474       19014       6508  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 6000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 3000, 0: count_0 + 3000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 3600, 0: count_0 + 2400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 4100, 0: count_0 + 1800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 4800, 0: count_0 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 5400, 0: count_0 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1+ 6000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 6000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 6000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_6K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_6K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_6K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_6K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOTTOGRUPPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.658</td>\n",
       "      <td>250</td>\n",
       "      <td>439</td>\n",
       "      <td>13014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.642</td>\n",
       "      <td>279</td>\n",
       "      <td>428</td>\n",
       "      <td>19014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.565</td>\n",
       "      <td>371</td>\n",
       "      <td>377</td>\n",
       "      <td>19014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.532</td>\n",
       "      <td>419</td>\n",
       "      <td>355</td>\n",
       "      <td>19014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.519</td>\n",
       "      <td>421</td>\n",
       "      <td>346</td>\n",
       "      <td>19014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.505</td>\n",
       "      <td>451</td>\n",
       "      <td>337</td>\n",
       "      <td>19014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.505</td>\n",
       "      <td>473</td>\n",
       "      <td>337</td>\n",
       "      <td>19014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.457</td>\n",
       "      <td>502</td>\n",
       "      <td>305</td>\n",
       "      <td>19014</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.862     0.398   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.859     0.403   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.850     0.437   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.845     0.446   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.847     0.456   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.842     0.456   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.838     0.449   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.839     0.473   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.058   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.064   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.086   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.097   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.097   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.104   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.109   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.116   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.658   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.642   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.565   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.532   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.519   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.505   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.505   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.457   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                     250   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      279   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              371   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              419   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              421   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              451   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              473   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                502   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     439   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      428   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              377   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              355   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              346   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              337   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              337   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                305   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       5002  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               19014       5002  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       19014       5002  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       19014       5002  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       19014       5002  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       19014       5002  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       19014       5002  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         19014       5002  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_6K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_6K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_6K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_6K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.291</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.251</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.212</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.186</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.843     0.655             0.127   \n",
       "After RANDOM Mitigation(K=5 fp)             0.843     0.655             0.141   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.828     0.652             0.133   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.826     0.653             0.086   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.821     0.653             0.062   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.490               0.373   \n",
       "After RANDOM Mitigation(K=5 fp)            0.481               0.407   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.474               0.336   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.422               0.287   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.424               0.283   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.328   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.357   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.287   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.247   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.231   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.268          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.291       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.251       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.212       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.186       6000.000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 7000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.381</td>\n",
       "      <td>426</td>\n",
       "      <td>598</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.374</td>\n",
       "      <td>458</td>\n",
       "      <td>586</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.5</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.337</td>\n",
       "      <td>566</td>\n",
       "      <td>529</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.6</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.332</td>\n",
       "      <td>589</td>\n",
       "      <td>520</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.7</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.332</td>\n",
       "      <td>627</td>\n",
       "      <td>520</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.8</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.319</td>\n",
       "      <td>630</td>\n",
       "      <td>500</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.9</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.312</td>\n",
       "      <td>662</td>\n",
       "      <td>490</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 1</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.301</td>\n",
       "      <td>701</td>\n",
       "      <td>472</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.843     0.655                0.086   \n",
       "After RANDOM mitigation N = 5000         0.840     0.653                0.093   \n",
       "After SMOTE N = 8000 p_class 0 = 0.5     0.832     0.655                0.115   \n",
       "After SMOTE N = 8000 p_class 0 = 0.6     0.830     0.654                0.119   \n",
       "After SMOTE N = 8000 p_class 0 = 0.7     0.824     0.646                0.127   \n",
       "After SMOTE N = 8000 p_class 0 = 0.8     0.826     0.654                0.128   \n",
       "After SMOTE N = 8000 p_class 0 = 0.9     0.823     0.652                0.134   \n",
       "After SMOTE N = 8000 p_class 0 = 1       0.820     0.651                0.142   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.381              426   \n",
       "After RANDOM mitigation N = 5000                    0.374              458   \n",
       "After SMOTE N = 8000 p_class 0 = 0.5                0.337              566   \n",
       "After SMOTE N = 8000 p_class 0 = 0.6                0.332              589   \n",
       "After SMOTE N = 8000 p_class 0 = 0.7                0.332              627   \n",
       "After SMOTE N = 8000 p_class 0 = 0.8                0.319              630   \n",
       "After SMOTE N = 8000 p_class 0 = 0.9                0.312              662   \n",
       "After SMOTE N = 8000 p_class 0 = 1                  0.301              701   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 598       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  586       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.5              529       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.6              520       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.7              520       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.8              500       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.9              490       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 1                472       21014       6508  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 8000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 4000, 0: count_0 + 4000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 4800, 0: count_0 + 3200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 5600, 0: count_0 + 2400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 6400, 0: count_0 + 1600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 7200, 0: count_0 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 8000, 0: count_0 }\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 8000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_8K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_8K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.238</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.232</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.207</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.185</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.843     0.655             0.127   \n",
       "After RANDOM Mitigation(K=5 fp)             0.843     0.655             0.140   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.830     0.654             0.104   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.826     0.654             0.084   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.820     0.651             0.048   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.490               0.373   \n",
       "After RANDOM Mitigation(K=5 fp)            0.481               0.390   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.453               0.308   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.455               0.307   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.489               0.325   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.328   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.319   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.266   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.251   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.246   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.268          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.238       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.232       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.207       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.185       8000.000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.381</td>\n",
       "      <td>426</td>\n",
       "      <td>598</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.372</td>\n",
       "      <td>465</td>\n",
       "      <td>583</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.5</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.339</td>\n",
       "      <td>565</td>\n",
       "      <td>532</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.6</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.334</td>\n",
       "      <td>630</td>\n",
       "      <td>523</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.7</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.337</td>\n",
       "      <td>618</td>\n",
       "      <td>528</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.8</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.320</td>\n",
       "      <td>643</td>\n",
       "      <td>501</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.9</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.309</td>\n",
       "      <td>688</td>\n",
       "      <td>485</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 1</th>\n",
       "      <td>0.817</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.302</td>\n",
       "      <td>718</td>\n",
       "      <td>473</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.843     0.655                0.086   \n",
       "After RANDOM mitigation N = 5000         0.839     0.653                0.094   \n",
       "After SMOTE N = 9000 p_class 0 = 0.5     0.831     0.654                0.114   \n",
       "After SMOTE N = 9000 p_class 0 = 0.6     0.823     0.644                0.128   \n",
       "After SMOTE N = 9000 p_class 0 = 0.7     0.824     0.645                0.125   \n",
       "After SMOTE N = 9000 p_class 0 = 0.8     0.824     0.651                0.130   \n",
       "After SMOTE N = 9000 p_class 0 = 0.9     0.820     0.649                0.139   \n",
       "After SMOTE N = 9000 p_class 0 = 1       0.817     0.648                0.145   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.381              426   \n",
       "After RANDOM mitigation N = 5000                    0.372              465   \n",
       "After SMOTE N = 9000 p_class 0 = 0.5                0.339              565   \n",
       "After SMOTE N = 9000 p_class 0 = 0.6                0.334              630   \n",
       "After SMOTE N = 9000 p_class 0 = 0.7                0.337              618   \n",
       "After SMOTE N = 9000 p_class 0 = 0.8                0.320              643   \n",
       "After SMOTE N = 9000 p_class 0 = 0.9                0.309              688   \n",
       "After SMOTE N = 9000 p_class 0 = 1                  0.302              718   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 598       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  583       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.5              532       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.6              523       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.7              528       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.8              501       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.9              485       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 1                473       22014       6508  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 9000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 4500, 0: count_0 + 4500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 5400, 0: count_0 + 2600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 6300, 0: count_0 + 2700}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 7200, 0: count_0 + 1800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 8100, 0: count_0 + 900}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 9000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 9000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_9K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_9K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.252</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.237</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.206</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.817</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.190</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.843     0.655             0.127   \n",
       "After RANDOM Mitigation(K=5 fp)             0.843     0.655             0.138   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.823     0.644             0.109   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.824     0.651             0.077   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.817     0.648             0.045   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.490               0.373   \n",
       "After RANDOM Mitigation(K=5 fp)            0.501               0.393   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.497               0.327   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.455               0.301   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.426               0.314   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.328   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.327   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.275   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.248   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.244   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.268          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.252       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.237       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.206       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.190       9000.000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT: andamento di falsi positivi e di falsi negativi al variare di N e p di appartenere alla classe 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creazione del grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "p =[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "# Linea per i falsi positivi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(p, falsi_negativi_2K_fp_5sub, marker='o', label='False Negatives 2K  ', color='black')\n",
    "plt.plot(p, falsi_negativi_3K_fp_5sub, marker='o', label='False Negatives 3K  ', color='red')\n",
    "plt.plot(p, falsi_negativi_4K_fp_5sub, marker='o', label='False Negatives 4K  ', color='green')\n",
    "plt.plot(p, falsi_negativi_5K_fp_5sub, marker='o', label='False Negatives 5K  ', color='blue')\n",
    "plt.plot(p, falsi_negativi_6K_fp_5sub, marker='o', label='False Negatives 6K  ', color='orange')\n",
    "\n",
    "\n",
    "plt.axhline(y=falsi_negativi_5K_fp_5sub_before, color='purple', linestyle='--', label='Initial False Negatives')\n",
    "\n",
    "# Etichette e titolo\n",
    "plt.xlabel('probability for the synthetic point to belong to the class 1')\n",
    "plt.ylabel('Count False Negaitives')\n",
    "plt.title(f'False Negatives, fn, #subgroups = {K} on {filtered_instances}, support = {min_sup}, pruning = {epsilon}')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "plt.yticks(range(550, 660, 25))\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4312, 649)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_0, count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
