{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_for_adult import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "\n",
    "from divexplorer.outcomes import get_false_negative_rate_outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv(\"adult.data\", header = None, names = col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = 0.25\n",
    "percentage =  15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosità precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GDecisioN tree predictions\n",
    "X_train = df_train_enc.drop(columns = 'income', axis = 1)\n",
    "y_train = df_train_enc['income']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'income', axis = 1)\n",
    "y_test = df_test_enc['income']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'income', axis = 1)\n",
    "y_val = df_val_enc['income']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'income', axis = 1)\n",
    "y_holdout = df_holdout_enc['income']\n",
    "\n",
    "classifier_train = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.803     0.593                0.130   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.407              641              638   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       6508  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione è giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>2</td>\n",
       "      <td>0.077</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0</td>\n",
       "      <td>0.284</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass  fnlwgt  education  marital-status  occupation  relationship  \\\n",
       "18761          2   0.077          3               0           4             1   \n",
       "27582          3   0.048          3               1           4             0   \n",
       "30911          2   0.174          3               3           4             4   \n",
       "11128          0   0.012          2               1           2             0   \n",
       "683            0   0.284          3               3           2             4   \n",
       "\n",
       "       race  sex  capital-gain  capital-loss  native-country  age_group  \\\n",
       "18761     4    0         0.000         0.000               5          2   \n",
       "27582     4    1         0.000         0.000               5          5   \n",
       "30911     2    0         0.039         0.000               5          1   \n",
       "11128     2    1         0.000         0.507               5          3   \n",
       "683       2    1         0.000         0.000               5          0   \n",
       "\n",
       "       edu_num_group  hours_per_week_group  y_val_true  y_pred  \n",
       "18761              1                     1           0       0  \n",
       "27582              1                     2           1       0  \n",
       "30911              1                     1           0       0  \n",
       "11128              4                     1           1       1  \n",
       "683                1                     1           0       0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set\n",
    "y_pred_val_dt = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val_dt\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>fn</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.077</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>Self-emp</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>65-100</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.174</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.012</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>45-54</td>\n",
       "      <td>14 Master's Degree</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.284</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        workclass  fnlwgt        education marital-status    occupation  \\\n",
       "18761     Private   0.077    Non Graduated       Divorced  Self-emp-occ   \n",
       "27582    Self-emp   0.048    Non Graduated        Married  Self-emp-occ   \n",
       "30911     Private   0.174    Non Graduated      Separated  Self-emp-occ   \n",
       "11128  Government   0.012  Master's Degree        Married   Private-occ   \n",
       "683    Government   0.284    Non Graduated      Separated   Private-occ   \n",
       "\n",
       "         relationship    race      sex  capital-gain  capital-loss  \\\n",
       "18761   Not-in-family   White   Female         0.000         0.000   \n",
       "27582         Husband   White     Male         0.000         0.000   \n",
       "30911       Unmarried   Black   Female         0.039         0.000   \n",
       "11128         Husband   Black     Male         0.000         0.507   \n",
       "683         Unmarried   Black     Male         0.000         0.000   \n",
       "\n",
       "      native-country  income age_group       edu_num_group  \\\n",
       "18761  United-States       0     35-44          10 College   \n",
       "27582  United-States       1    65-100          10 College   \n",
       "30911  United-States       0     25-34          10 College   \n",
       "11128  United-States       1     45-54  14 Master's Degree   \n",
       "683    United-States       0     17-24          10 College   \n",
       "\n",
       "      hours_per_week_group    fn  y_pred  accuracy  \n",
       "18761             Overtime   NaN       0         1  \n",
       "27582            Part-time 1.000       0         0  \n",
       "30911             Overtime   NaN       0         1  \n",
       "11128             Overtime 0.000       1         1  \n",
       "683               Overtime   NaN       0         1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]\n",
    "\n",
    "df_val_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_val['fn'] = df_val_class['fn']\n",
    "\n",
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione è giusta 0 se la predizione è sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['accuracy'] = (df_val_class['y_val_true']==df_val_class['y_pred']).astype(int)\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_div</th>\n",
       "      <th>fn_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.271</td>\n",
       "      <td>(native-country=United-States, capital-gain=0.0, capital-loss=0.0, marital-status=Never-married)</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.383</td>\n",
       "      <td>6.228</td>\n",
       "      <td>4</td>\n",
       "      <td>1764.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300</td>\n",
       "      <td>(capital-gain=0.0, capital-loss=0.0, marital-status=Never-married)</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.368</td>\n",
       "      <td>5.942</td>\n",
       "      <td>3</td>\n",
       "      <td>1952.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.264</td>\n",
       "      <td>(edu_num_group=9 High School Graduate, native-country=United-States, capital-gain=0.0, capital-loss=0.0)</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.352</td>\n",
       "      <td>11.347</td>\n",
       "      <td>4</td>\n",
       "      <td>1718.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.264</td>\n",
       "      <td>(education=Non Graduated, capital-gain=0.0, capital-loss=0.0, native-country=United-States, edu_num_group=9 High School Graduate)</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.352</td>\n",
       "      <td>11.347</td>\n",
       "      <td>5</td>\n",
       "      <td>1718.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.288</td>\n",
       "      <td>(edu_num_group=9 High School Graduate, education=Non Graduated, capital-gain=0.0, capital-loss=0.0)</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.352</td>\n",
       "      <td>11.636</td>\n",
       "      <td>4</td>\n",
       "      <td>1872.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.271   \n",
       "1    0.300   \n",
       "2    0.264   \n",
       "3    0.264   \n",
       "4    0.288   \n",
       "\n",
       "                                                                                                                             itemset  \\\n",
       "0                                   (native-country=United-States, capital-gain=0.0, capital-loss=0.0, marital-status=Never-married)   \n",
       "1                                                                 (capital-gain=0.0, capital-loss=0.0, marital-status=Never-married)   \n",
       "2                           (edu_num_group=9 High School Graduate, native-country=United-States, capital-gain=0.0, capital-loss=0.0)   \n",
       "3  (education=Non Graduated, capital-gain=0.0, capital-loss=0.0, native-country=United-States, edu_num_group=9 High School Graduate)   \n",
       "4                                (edu_num_group=9 High School Graduate, education=Non Graduated, capital-gain=0.0, capital-loss=0.0)   \n",
       "\n",
       "     fn  fn_div   fn_t  length  support_count  \n",
       "0 0.765   0.383  6.228       4       1764.000  \n",
       "1 0.750   0.368  5.942       3       1952.000  \n",
       "2 0.734   0.352 11.347       4       1718.000  \n",
       "3 0.734   0.352 11.347       5       1718.000  \n",
       "4 0.734   0.352 11.636       4       1872.000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_diver = DivergenceExplorer(df_val)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_div</th>\n",
       "      <th>fn_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.271</td>\n",
       "      <td>(native-country=United-States, capital-gain=0.0, capital-loss=0.0, marital-status=Never-married)</td>\n",
       "      <td>4</td>\n",
       "      <td>1764.000</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.383</td>\n",
       "      <td>6.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300</td>\n",
       "      <td>(capital-gain=0.0, capital-loss=0.0, marital-status=Never-married)</td>\n",
       "      <td>3</td>\n",
       "      <td>1952.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.368</td>\n",
       "      <td>5.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.288</td>\n",
       "      <td>(edu_num_group=9 High School Graduate, capital-gain=0.0, capital-loss=0.0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1872.000</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.352</td>\n",
       "      <td>11.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.281</td>\n",
       "      <td>(native-country=United-States, capital-gain=0.0, marital-status=Never-married)</td>\n",
       "      <td>3</td>\n",
       "      <td>1828.000</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.325</td>\n",
       "      <td>5.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.453</td>\n",
       "      <td>(education=Non Graduated, workclass=Private, capital-gain=0.0, capital-loss=0.0)</td>\n",
       "      <td>4</td>\n",
       "      <td>2945.000</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.323</td>\n",
       "      <td>11.669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support  \\\n",
       "0     0.271   \n",
       "1     0.300   \n",
       "5     0.288   \n",
       "6     0.281   \n",
       "10    0.453   \n",
       "\n",
       "                                                                                             itemset  \\\n",
       "0   (native-country=United-States, capital-gain=0.0, capital-loss=0.0, marital-status=Never-married)   \n",
       "1                                 (capital-gain=0.0, capital-loss=0.0, marital-status=Never-married)   \n",
       "5                         (edu_num_group=9 High School Graduate, capital-gain=0.0, capital-loss=0.0)   \n",
       "6                     (native-country=United-States, capital-gain=0.0, marital-status=Never-married)   \n",
       "10                  (education=Non Graduated, workclass=Private, capital-gain=0.0, capital-loss=0.0)   \n",
       "\n",
       "    length  support_count    fn  fn_div   fn_t  \n",
       "0        4       1764.000 0.765   0.383  6.228  \n",
       "1        3       1952.000 0.750   0.368  5.942  \n",
       "5        3       1872.000 0.734   0.352 11.636  \n",
       "6        3       1828.000 0.707   0.325  5.302  \n",
       "10       4       2945.000 0.705   0.323 11.669  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 72\n",
      "total problematic 49\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_fp)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_fp[(df_pruned_fp['fn_div'] > 0) & (df_pruned_fp['fn_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (509, 7)\n",
      "Dim pruned th_redundancy  (72, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_fp.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset3 li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prima 4572\n",
      "dopo 534\n"
     ]
    }
   ],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "print('prima', len(df_holdout_filtered))\n",
    "df_holdout_filtered_solo1 = df_holdout_filtered[df_holdout_filtered['income']==1]\n",
    "\n",
    "\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered_solo1, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "df_holdout_filtered = df_holdout_filtered_solo1 \n",
    "\n",
    "print(\"dopo\", len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "TRAIN SET MITIGATED ROWS:  13548\n",
      "VALIDATION SET ROWS:  6508\n",
      "FILTERED DF holdout ROWS:  534\n",
      "TEST SET FILTERED ROWS:  6507\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'income', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['income']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534\n",
      "verifica : 534\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['income']\n",
    "\n",
    "classifier_train_mitigated_random = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Gradient Boosting performance when boolean outcomes = fn \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.360</td>\n",
       "      <td>743</td>\n",
       "      <td>564</td>\n",
       "      <td>13548</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.393</td>\n",
       "      <td>643</td>\n",
       "      <td>616</td>\n",
       "      <td>13548</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.803     0.593                0.130   \n",
       "After Mitigation(K=5, fp)     0.799     0.606                0.150   \n",
       "After RANDOM mitigation       0.807     0.602                0.130   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.407              641   \n",
       "After Mitigation(K=5, fp)                0.360              743   \n",
       "After RANDOM mitigation                  0.393              643   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      638       13014       6508  \n",
       "After Mitigation(K=5, fp)              564       13548       6508  \n",
       "After RANDOM mitigation                616       13548       6508  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "print(\"Overall Gradient Boosting performance when boolean outcomes = fn \")\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.710</td>\n",
       "      <td>394</td>\n",
       "      <td>372</td>\n",
       "      <td>13014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.595</td>\n",
       "      <td>490</td>\n",
       "      <td>312</td>\n",
       "      <td>13548</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.702</td>\n",
       "      <td>386</td>\n",
       "      <td>368</td>\n",
       "      <td>13548</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                         Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                    0.833     0.284   \n",
       "After Mitigation(K=5, on subgroups, fp)            0.825     0.346   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)     0.836     0.293   \n",
       "\n",
       "Metrics                                         False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                               0.097   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.121   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.095   \n",
       "\n",
       "Metrics                                         False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                               0.710   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.595   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.702   \n",
       "\n",
       "Metrics                                         False Positives  \\\n",
       "Before Mitigation, on subgroups                             394   \n",
       "After Mitigation(K=5, on subgroups, fp)                     490   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              386   \n",
       "\n",
       "Metrics                                         False Negatives  Train Size  \\\n",
       "Before Mitigation, on subgroups                             372       13014   \n",
       "After Mitigation(K=5, on subgroups, fp)                     312       13548   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              368       13548   \n",
       "\n",
       "Metrics                                         Test Size  \n",
       "Before Mitigation, on subgroups                      4590  \n",
       "After Mitigation(K=5, on subgroups, fp)              4590  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)       4590  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered_fp = K_subgroups_dataset_and_or(df_pruned_fp, df_test, K)\n",
    "inutile, df_test_filtered_enc_fp, inutile2, inutile3 = encoding_funct(df_train, df_test_filtered_fp, df_holdout, df_val)\n",
    "\n",
    "X_test_filtered_fp = df_test_filtered_enc_fp.drop(columns='income', axis = 1)\n",
    "y_true_test_filtered_fp = df_test_filtered_enc_fp['income']\n",
    "\n",
    "y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after = classifier_train_mitigated.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_random = classifier_train_mitigated_random.predict(X_test_filtered_fp)\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after )\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_random)\n",
    "\n",
    "\n",
    "metrics_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after, len(y_train_mitigated), len(y_pred_test_filtered_fp_after)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(y_train_mitigated_random), len(y_pred_test_filtered_fp_after_random)]\n",
    "})\n",
    "metrics_after_fp_sottogruppi = metrics_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi[metric] = metrics_after_fp_sottogruppi[metric].astype(int)\n",
    "\n",
    "metrics_after_fp\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fn\")\n",
    "metrics_after_fp_sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values([\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fn_div_list_no_mitigation  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fn_div_list_no_mitigation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fn_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fn_div_list_baseline1  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fn_div_list_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values([\"fn_div\", \"fn_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fn_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fn_div_list_random_per_confrontare_con_baseline1  = df_pruned_fp[\"fn_div\"].tolist()\n",
    "#fn_div_list_random_per_confrontare_con_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.165</td>\n",
       "      <td>534.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.219</td>\n",
       "      <td>534.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.803     0.593             0.111   \n",
       "After Mitigation(K=5 fp)            0.799     0.606             0.095   \n",
       "After RANDOM Mitigation(K=5 fp)     0.807     0.602             0.128   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.444               0.329   \n",
       "After Mitigation(K=5 fp)           0.422               0.277   \n",
       "After RANDOM Mitigation(K=5 fp)    0.437               0.339   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.255               0.189   \n",
       "After Mitigation(K=5 fp)                      0.225               0.165   \n",
       "After RANDOM Mitigation(K=5 fp)               0.291               0.219   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)               534.000  \n",
       "After RANDOM Mitigation(K=5 fp)        534.000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fn_div_list_no_mitigation = np.nanmean(fn_div_list_no_mitigation)\n",
    "media_fn_div_list_nomitigation_primi10 = np.nanmean(fn_div_list_no_mitigation[:10])\n",
    "media_fn_div_list_nomitigation_primi20 = np.nanmean(fn_div_list_no_mitigation[:20])\n",
    "media_fn_div_list_nomitigation_primi40 = np.nanmean(fn_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fn_div_no_mitigation = max(abs(x) for x in fn_div_list_no_mitigation)\n",
    "\n",
    "media_fn_div_list_baseline1 = np.nanmean(fn_div_list_baseline1)\n",
    "media_fn_div_list_baseline1_primi10 = np.nanmean(fn_div_list_baseline1[:10])\n",
    "media_fn_div_list_baseline1_primi20 = np.nanmean(fn_div_list_baseline1[:20])\n",
    "media_fn_div_list_baseline1_primi40 = np.nanmean(fn_div_list_baseline1[:40])\n",
    "fn_div_massimo_valore_assoluto_fn_div_baseline1 = max(abs(x) for x in fn_div_list_baseline1)\n",
    "\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fn_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fn_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fn_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fn_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fn_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fn_div_list_no_mitigation, massimo_valore_assoluto_fn_div_no_mitigation,\n",
    "        media_fn_div_list_nomitigation_primi10, media_fn_div_list_nomitigation_primi20, media_fn_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_fn_div_list_baseline1, fn_div_massimo_valore_assoluto_fn_div_baseline1,\n",
    "        media_fn_div_list_baseline1_primi10, media_fn_div_list_baseline1_primi20, media_fn_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fn_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fn_div_random_per_confrontare_con_baseline1, media_fn_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fn_div_list_random_per_confrontare_con_baseline1_primi20, media_fn_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fn_sottogruppi = divergence_after_fn_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fn_sottogruppi\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUI INIZIA SMOTE come si deve DA METTERE NEL REPORT\n",
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p è la probabilità che il campione simulato sia di classe 0 qui (perchè voglio diminuire il numero di falsi negativi)\n",
    "- FISSO p VARIA N , aumento il numero di 0 per diminuire il numero di falsi negativi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 4583\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['fn', 'y_pred', 'accuracy', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(542, 4041)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered['income'].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUI MODIFICO FACENDO SMOTE SU DF_VAL_FILTERED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smote_nc = SMOTENC(categorical_features=categorical_features,random_state=seed)\\nX_to_SMOTE, y_to_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\ncount_1 = y_to_SMOTE.sum()\\ncount_0 = len(y_to_SMOTE)-count_1\\ncount_0, count_1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''smote_nc = SMOTENC(categorical_features=categorical_features,random_state=seed)\n",
    "X_to_SMOTE, y_to_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "count_1 = y_to_SMOTE.sum()\n",
    "count_0 = len(y_to_SMOTE)-count_1\n",
    "count_0, count_1'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.393</td>\n",
       "      <td>643</td>\n",
       "      <td>616</td>\n",
       "      <td>13548</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.384</td>\n",
       "      <td>637</td>\n",
       "      <td>602</td>\n",
       "      <td>13548</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.394</td>\n",
       "      <td>665</td>\n",
       "      <td>618</td>\n",
       "      <td>13548</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.397</td>\n",
       "      <td>636</td>\n",
       "      <td>622</td>\n",
       "      <td>13548</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.401</td>\n",
       "      <td>619</td>\n",
       "      <td>629</td>\n",
       "      <td>13548</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.402</td>\n",
       "      <td>617</td>\n",
       "      <td>631</td>\n",
       "      <td>13548</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.398</td>\n",
       "      <td>608</td>\n",
       "      <td>624</td>\n",
       "      <td>13548</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 5000         0.807     0.602                0.130   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.810     0.609                0.129   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.803     0.597                0.135   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.807     0.601                0.129   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.808     0.601                0.125   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.808     0.600                0.125   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.811     0.605                0.123   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 5000                    0.393              643   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.384              637   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.394              665   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.397              636   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.401              619   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.402              617   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.398              608   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  616       13548       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              602       13548       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              618       13548       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              622       13548       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              629       13548       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              631       13548       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                624       13548       6508  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + int(N*0.5), 0: count_0 + int(N*0.5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + int(N*0.6), 1: count_1 + int(N*0.4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + int(N*0.7), 1: count_1 + int(N*0.3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 +int(N*0.8), 1: count_1 + int(N*0.2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + int(N*0.9), 1: count_1 + int(N*0.1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + int(N*1), 1: count_1 + int(N*0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.219</td>\n",
       "      <td>534.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=0.5)</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.203</td>\n",
       "      <td>534.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=0.8)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.238</td>\n",
       "      <td>534.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=1)</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.218</td>\n",
       "      <td>534.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.111   \n",
       "After RANDOM Mitigation(K=5 fp)             0.807     0.602             0.128   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)     0.803     0.597             0.099   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)     0.808     0.601             0.135   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)       0.811     0.605             0.132   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.444               0.329   \n",
       "After RANDOM Mitigation(K=5 fp)            0.437               0.339   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)    0.467               0.345   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)    0.492               0.373   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)      0.496               0.375   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.255   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.291   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)               0.273   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)               0.308   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)                 0.296   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.189          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.219        534.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)               0.203        534.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)               0.238        534.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)                 0.218        534.000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 2K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 2K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 2K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.390</td>\n",
       "      <td>664</td>\n",
       "      <td>611</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.5</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.367</td>\n",
       "      <td>731</td>\n",
       "      <td>576</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.6</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.357</td>\n",
       "      <td>740</td>\n",
       "      <td>560</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.7</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.360</td>\n",
       "      <td>720</td>\n",
       "      <td>564</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.8</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.355</td>\n",
       "      <td>739</td>\n",
       "      <td>556</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.9</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.344</td>\n",
       "      <td>777</td>\n",
       "      <td>539</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 1</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.334</td>\n",
       "      <td>807</td>\n",
       "      <td>524</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 5000         0.804     0.600                0.134   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5     0.799     0.603                0.148   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6     0.800     0.608                0.150   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7     0.803     0.610                0.146   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8     0.801     0.610                0.150   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9     0.798     0.610                0.157   \n",
       "After SMOTE N = 2000 p_class 0 = 1       0.795     0.611                0.163   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 5000                    0.390              664   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5                0.367              731   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6                0.357              740   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7                0.360              720   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8                0.355              739   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9                0.344              777   \n",
       "After SMOTE N = 2000 p_class 0 = 1                  0.334              807   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  611       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.5              576       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.6              560       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.7              564       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.8              556       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.9              539       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 1                524       15014       6508  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 2000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 1000, 0: count_0 + 1000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 1200, 0: count_0 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 1400, 0: count_0 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 1600, 0: count_0 + 400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 1800, 0: count_0 + 200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 2000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 2000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 2000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1= metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.233</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=0.5)</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.212</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=0.8)</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.196</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 2K, p=1)</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.184</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.111   \n",
       "After RANDOM Mitigation(K=5 fp)             0.807     0.602             0.121   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)     0.800     0.608             0.091   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)     0.801     0.610             0.094   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)       0.795     0.611             0.079   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.444               0.329   \n",
       "After RANDOM Mitigation(K=5 fp)            0.320               0.302   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)    0.378               0.301   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)    0.387               0.254   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)      0.375               0.280   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.255   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.282   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)               0.257   \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)               0.224   \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)                 0.226   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.189          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.233       2000.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.5)               0.212       2000.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=0.8)               0.196       2000.000  \n",
       "After Mitigation(K=5 fp, N = 2K, p=1)                 0.184       2000.000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 2K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 2K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 2K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.395</td>\n",
       "      <td>622</td>\n",
       "      <td>620</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.353</td>\n",
       "      <td>720</td>\n",
       "      <td>554</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.342</td>\n",
       "      <td>742</td>\n",
       "      <td>537</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.358</td>\n",
       "      <td>799</td>\n",
       "      <td>561</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.348</td>\n",
       "      <td>802</td>\n",
       "      <td>545</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.331</td>\n",
       "      <td>801</td>\n",
       "      <td>519</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.335</td>\n",
       "      <td>836</td>\n",
       "      <td>525</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 5000         0.809     0.604                0.126   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.804     0.614                0.146   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.803     0.617                0.150   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.791     0.597                0.162   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.793     0.603                0.162   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.797     0.614                0.162   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.791     0.605                0.169   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 5000                    0.395              622   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.353              720   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.342              742   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.358              799   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.348              802   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.331              801   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.335              836   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  620       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              554       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              537       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              561       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              545       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              519       16014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                525       16014       6508  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 3000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 1500, 0: count_0 + 1500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 1800, 0: count_0 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 2100, 0: count_0 + 900}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 2400, 0: count_0 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 2700, 0: count_0 + 300}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 3000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_3K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_3K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_3K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_3K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1= metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.223</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=0.5)</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.182</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=0.8)</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.177</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=1)</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.175</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.111   \n",
       "After RANDOM Mitigation(K=5 fp)             0.807     0.602             0.147   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)     0.803     0.617             0.080   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)     0.793     0.603             0.074   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)       0.791     0.605             0.097   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.444               0.329   \n",
       "After RANDOM Mitigation(K=5 fp)            0.434               0.343   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)    0.410               0.297   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)    0.394               0.242   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)      0.356               0.270   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.255   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.285   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)               0.244   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)               0.208   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)                 0.224   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.189          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.223       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)               0.182       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)               0.177       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)                 0.175       3000.000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 3K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 3K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 3K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.388</td>\n",
       "      <td>634</td>\n",
       "      <td>609</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.358</td>\n",
       "      <td>745</td>\n",
       "      <td>562</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.347</td>\n",
       "      <td>757</td>\n",
       "      <td>544</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.340</td>\n",
       "      <td>783</td>\n",
       "      <td>533</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.335</td>\n",
       "      <td>800</td>\n",
       "      <td>525</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.789</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.348</td>\n",
       "      <td>825</td>\n",
       "      <td>545</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.337</td>\n",
       "      <td>862</td>\n",
       "      <td>528</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 5000         0.809     0.607                0.128   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.799     0.606                0.151   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.800     0.612                0.153   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.798     0.611                0.159   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.796     0.612                0.162   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.789     0.599                0.167   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.786     0.599                0.174   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 5000                    0.388              634   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.358              745   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.347              757   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.340              783   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.335              800   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.348              825   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.337              862   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  609       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              562       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              544       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              533       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              525       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              545       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                528       17014       6508  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 4000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 2000, 0: count_0 + 2000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 2400, 0: count_0 + 1600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 2800, 0: count_0 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 3200, 0: count_0 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 3600, 0: count_0 + 400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 4000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_4K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_4K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_4K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_4K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1= metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.168</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=0.5)</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.194</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=0.8)</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.174</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=1)</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.138</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.111   \n",
       "After RANDOM Mitigation(K=5 fp)             0.807     0.602             0.125   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)     0.800     0.612             0.060   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)     0.796     0.612             0.085   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)       0.786     0.599             0.060   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.444               0.329   \n",
       "After RANDOM Mitigation(K=5 fp)            0.441               0.311   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)    0.387               0.281   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)    0.392               0.255   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)      0.405               0.234   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.255   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.240   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)               0.231   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)               0.210   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)                 0.185   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.189          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.168       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)               0.194       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)               0.174       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)                 0.138       4000.000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 4K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 4K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 4K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.402</td>\n",
       "      <td>654</td>\n",
       "      <td>631</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.354</td>\n",
       "      <td>746</td>\n",
       "      <td>555</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.357</td>\n",
       "      <td>788</td>\n",
       "      <td>559</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.358</td>\n",
       "      <td>847</td>\n",
       "      <td>562</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.342</td>\n",
       "      <td>775</td>\n",
       "      <td>537</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.342</td>\n",
       "      <td>850</td>\n",
       "      <td>537</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.339</td>\n",
       "      <td>884</td>\n",
       "      <td>531</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 5000         0.803     0.593                0.132   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.800     0.609                0.151   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.793     0.600                0.160   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.783     0.588                0.171   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.798     0.611                0.157   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.787     0.598                0.172   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.783     0.594                0.179   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 5000                    0.402              654   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.354              746   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.357              788   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.358              847   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.342              775   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.342              850   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.339              884   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  631       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              555       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              559       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              562       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              537       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              537       18014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                531       18014       6508  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 5000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 2500, 0: count_0 + 2500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 3000, 0: count_0 + 2000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 3500, 0: count_0 + 1500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 4000, 0: count_0 + 1000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 4500, 0: count_0 + 500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 5000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_5K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOTTOGRUPPI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.710</td>\n",
       "      <td>394</td>\n",
       "      <td>372</td>\n",
       "      <td>13014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.697</td>\n",
       "      <td>395</td>\n",
       "      <td>365</td>\n",
       "      <td>18014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.573</td>\n",
       "      <td>491</td>\n",
       "      <td>300</td>\n",
       "      <td>18014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.540</td>\n",
       "      <td>522</td>\n",
       "      <td>283</td>\n",
       "      <td>18014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.576</td>\n",
       "      <td>559</td>\n",
       "      <td>302</td>\n",
       "      <td>18014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.523</td>\n",
       "      <td>502</td>\n",
       "      <td>274</td>\n",
       "      <td>18014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.517</td>\n",
       "      <td>594</td>\n",
       "      <td>271</td>\n",
       "      <td>18014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.481</td>\n",
       "      <td>607</td>\n",
       "      <td>252</td>\n",
       "      <td>18014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.833     0.284   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.834     0.295   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.828     0.362   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.825     0.375   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.812     0.340   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.831     0.392   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.812     0.369   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.813     0.388   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.097   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.097   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.121   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.128   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.137   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.123   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.146   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.149   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.710   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.697   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.573   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.540   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.576   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.523   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.517   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.481   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                     394   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      395   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              491   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              522   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              559   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              502   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              594   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                607   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     372   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      365   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              300   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              283   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              302   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              274   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              271   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                252   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       4590  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               18014       4590  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       18014       4590  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       18014       4590  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       18014       4590  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       18014       4590  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       18014       4590  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         18014       4590  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.158</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.186</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.149</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.138</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.111   \n",
       "After RANDOM Mitigation(K=5 fp)             0.807     0.602             0.111   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.793     0.600             0.084   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.798     0.611             0.072   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.783     0.594             0.067   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.444               0.329   \n",
       "After RANDOM Mitigation(K=5 fp)            0.372               0.275   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.392               0.265   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.385               0.238   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.339               0.240   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.255   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.218   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.226   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.193   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.181   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.189          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.158       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.186       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.149       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.138       5000.000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(['fn_div', 'fn_t'], ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 6000, p changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.386</td>\n",
       "      <td>651</td>\n",
       "      <td>606</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.5</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.362</td>\n",
       "      <td>785</td>\n",
       "      <td>567</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.6</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.337</td>\n",
       "      <td>779</td>\n",
       "      <td>528</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.7</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.345</td>\n",
       "      <td>777</td>\n",
       "      <td>541</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.8</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.344</td>\n",
       "      <td>810</td>\n",
       "      <td>540</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.9</th>\n",
       "      <td>0.779</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.353</td>\n",
       "      <td>883</td>\n",
       "      <td>553</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 1</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.351</td>\n",
       "      <td>934</td>\n",
       "      <td>550</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 6000         0.807     0.605                0.132   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5     0.792     0.597                0.159   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6     0.799     0.614                0.158   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7     0.797     0.609                0.157   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8     0.793     0.604                0.164   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9     0.779     0.586                0.179   \n",
       "After SMOTE N = 6000 p_class 0 = 1       0.772     0.578                0.189   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 6000                    0.386              651   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5                0.362              785   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6                0.337              779   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7                0.345              777   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8                0.344              810   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9                0.353              883   \n",
       "After SMOTE N = 6000 p_class 0 = 1                  0.351              934   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 6000                  606       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.5              567       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.6              528       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.7              541       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.8              540       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.9              553       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 1                550       19014       6508  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 6000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 3000, 0: count_0 + 3000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 3600, 0: count_0 + 2400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 4100, 0: count_0 + 1800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 4800, 0: count_0 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 5400, 0: count_0 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1+ 6000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 6000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 6000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_6K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_6K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_6K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_6K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOTTOGRUPPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.710</td>\n",
       "      <td>394</td>\n",
       "      <td>372</td>\n",
       "      <td>13014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.687</td>\n",
       "      <td>384</td>\n",
       "      <td>360</td>\n",
       "      <td>19014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.567</td>\n",
       "      <td>528</td>\n",
       "      <td>297</td>\n",
       "      <td>19014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.555</td>\n",
       "      <td>501</td>\n",
       "      <td>291</td>\n",
       "      <td>19014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.544</td>\n",
       "      <td>523</td>\n",
       "      <td>285</td>\n",
       "      <td>19014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.500</td>\n",
       "      <td>549</td>\n",
       "      <td>262</td>\n",
       "      <td>19014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.510</td>\n",
       "      <td>602</td>\n",
       "      <td>267</td>\n",
       "      <td>19014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.504</td>\n",
       "      <td>650</td>\n",
       "      <td>264</td>\n",
       "      <td>19014</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.833     0.284   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.838     0.306   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.820     0.355   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.827     0.370   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.824     0.372   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.823     0.393   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.811     0.372   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.801     0.363   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.097   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.094   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.130   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.123   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.129   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.135   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.148   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.160   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.710   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.687   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.567   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.555   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.544   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.500   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.510   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.504   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                     394   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      384   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              528   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              501   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              523   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              549   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              602   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                650   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     372   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      360   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              297   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              291   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              285   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              262   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              267   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                264   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       4590  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               19014       4590  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       19014       4590  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       19014       4590  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       19014       4590  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       19014       4590  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       19014       4590  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         19014       4590  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_6K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_6K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_6K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_6K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.200</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.184</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.130</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.160</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.111   \n",
       "After RANDOM Mitigation(K=5 fp)             0.807     0.602             0.125   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.799     0.614             0.105   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.793     0.604             0.048   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.772     0.578             0.037   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.444               0.329   \n",
       "After RANDOM Mitigation(K=5 fp)            0.388               0.329   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.366               0.249   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.383               0.245   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.413               0.316   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.255   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.267   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.214   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.187   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.223   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.189          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.200       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.184       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.130       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.160       6000.000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 7000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.383</td>\n",
       "      <td>653</td>\n",
       "      <td>601</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.5</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.353</td>\n",
       "      <td>768</td>\n",
       "      <td>554</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.6</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.345</td>\n",
       "      <td>781</td>\n",
       "      <td>541</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.7</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.353</td>\n",
       "      <td>812</td>\n",
       "      <td>554</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.8</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.356</td>\n",
       "      <td>889</td>\n",
       "      <td>558</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.9</th>\n",
       "      <td>0.780</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.351</td>\n",
       "      <td>883</td>\n",
       "      <td>551</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 1</th>\n",
       "      <td>0.777</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.350</td>\n",
       "      <td>902</td>\n",
       "      <td>549</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 5000         0.807     0.607                0.132   \n",
       "After SMOTE N = 8000 p_class 0 = 0.5     0.797     0.605                0.155   \n",
       "After SMOTE N = 8000 p_class 0 = 0.6     0.797     0.608                0.158   \n",
       "After SMOTE N = 8000 p_class 0 = 0.7     0.790     0.598                0.164   \n",
       "After SMOTE N = 8000 p_class 0 = 0.8     0.778     0.583                0.180   \n",
       "After SMOTE N = 8000 p_class 0 = 0.9     0.780     0.587                0.179   \n",
       "After SMOTE N = 8000 p_class 0 = 1       0.777     0.584                0.183   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 5000                    0.383              653   \n",
       "After SMOTE N = 8000 p_class 0 = 0.5                0.353              768   \n",
       "After SMOTE N = 8000 p_class 0 = 0.6                0.345              781   \n",
       "After SMOTE N = 8000 p_class 0 = 0.7                0.353              812   \n",
       "After SMOTE N = 8000 p_class 0 = 0.8                0.356              889   \n",
       "After SMOTE N = 8000 p_class 0 = 0.9                0.351              883   \n",
       "After SMOTE N = 8000 p_class 0 = 1                  0.350              902   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  601       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.5              554       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.6              541       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.7              554       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.8              558       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.9              551       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 1                549       21014       6508  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 8000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 4000, 0: count_0 + 4000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 4800, 0: count_0 + 3200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 5600, 0: count_0 + 2400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 6400, 0: count_0 + 1600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 7200, 0: count_0 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 8000, 0: count_0 }\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 8000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_8K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_8K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.218</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.167</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.143</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.777</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.155</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.111   \n",
       "After RANDOM Mitigation(K=5 fp)             0.807     0.602             0.134   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.797     0.608             0.086   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.778     0.583             0.053   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.777     0.584             0.038   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.444               0.329   \n",
       "After RANDOM Mitigation(K=5 fp)            0.423               0.329   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.374               0.239   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.353               0.239   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.436               0.285   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.255   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.276   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.201   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.182   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.213   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.189          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.218       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.167       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.143       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.155       8000.000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.392</td>\n",
       "      <td>652</td>\n",
       "      <td>614</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.5</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.371</td>\n",
       "      <td>746</td>\n",
       "      <td>581</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.6</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.357</td>\n",
       "      <td>790</td>\n",
       "      <td>559</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.7</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.357</td>\n",
       "      <td>862</td>\n",
       "      <td>560</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.8</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.361</td>\n",
       "      <td>895</td>\n",
       "      <td>566</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 0.9</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.349</td>\n",
       "      <td>897</td>\n",
       "      <td>547</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 9000 p_class 0 = 1</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.351</td>\n",
       "      <td>907</td>\n",
       "      <td>550</td>\n",
       "      <td>22014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 5000         0.805     0.601                0.132   \n",
       "After SMOTE N = 9000 p_class 0 = 0.5     0.796     0.598                0.151   \n",
       "After SMOTE N = 9000 p_class 0 = 0.6     0.793     0.599                0.160   \n",
       "After SMOTE N = 9000 p_class 0 = 0.7     0.781     0.586                0.174   \n",
       "After SMOTE N = 9000 p_class 0 = 0.8     0.776     0.578                0.181   \n",
       "After SMOTE N = 9000 p_class 0 = 0.9     0.778     0.586                0.182   \n",
       "After SMOTE N = 9000 p_class 0 = 1       0.776     0.583                0.184   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 5000                    0.392              652   \n",
       "After SMOTE N = 9000 p_class 0 = 0.5                0.371              746   \n",
       "After SMOTE N = 9000 p_class 0 = 0.6                0.357              790   \n",
       "After SMOTE N = 9000 p_class 0 = 0.7                0.357              862   \n",
       "After SMOTE N = 9000 p_class 0 = 0.8                0.361              895   \n",
       "After SMOTE N = 9000 p_class 0 = 0.9                0.349              897   \n",
       "After SMOTE N = 9000 p_class 0 = 1                  0.351              907   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  614       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.5              581       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.6              559       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.7              560       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.8              566       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 0.9              547       22014       6508  \n",
       "After SMOTE N = 9000 p_class 0 = 1                550       22014       6508  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 9000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {1: count_1 + 4500, 0: count_0 + 4500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {1: count_1 + 5400, 0: count_0 + 2600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {1: count_1 + 6300, 0: count_0 + 2700}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {1: count_1 + 7200, 0: count_0 + 1800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {1: count_1 + 8100, 0: count_0 + 900}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {1: count_1 + 9000, 0: count_0}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 9000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 9000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_9K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_9K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.173</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.173</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.151</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.168</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.111   \n",
       "After RANDOM Mitigation(K=5 fp)             0.807     0.602             0.105   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.793     0.599             0.081   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.776     0.578             0.048   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.776     0.583             0.025   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.444               0.329   \n",
       "After RANDOM Mitigation(K=5 fp)            0.301               0.268   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.429               0.270   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.384               0.292   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.377               0.298   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.255   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.223   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.212   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.214   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.248   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.189          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.173       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.173       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.151       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.168       9000.000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_negative_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = np.nanmean(fp_div_list_baseline2_p1_5K)\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = np.nanmean(fp_div_list_baseline2_p1_5K[:10])\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = np.nanmean(fp_div_list_baseline2_p1_5K[:20])\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = np.nanmean(fp_div_list_baseline2_p1_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = np.nanmean(fp_div_list_baseline2_p4_5K)\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = np.nanmean(fp_div_list_baseline2_p4_5K[:10])\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = np.nanmean(fp_div_list_baseline2_p4_5K[:20])\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = np.nanmean(fp_div_list_baseline2_p4_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = np.nanmean(fp_div_list_baseline2_p6_5K)\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = np.nanmean(fp_div_list_baseline2_p6_5K[:10])\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = np.nanmean(fp_div_list_baseline2_p6_5K[:20])\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = np.nanmean(fp_div_list_baseline2_p6_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT: andamento di falsi positivi e di falsi negativi al variare di N e p di appartenere alla classe 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creazione del grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "p =[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "# Linea per i falsi positivi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(p, falsi_negativi_2K_fp_5sub, marker='o', label='False Negatives 2K  ', color='black')\n",
    "plt.plot(p, falsi_negativi_3K_fp_5sub, marker='o', label='False Negatives 3K  ', color='red')\n",
    "plt.plot(p, falsi_negativi_4K_fp_5sub, marker='o', label='False Negatives 4K  ', color='green')\n",
    "plt.plot(p, falsi_negativi_5K_fp_5sub, marker='o', label='False Negatives 5K  ', color='blue')\n",
    "plt.plot(p, falsi_negativi_6K_fp_5sub, marker='o', label='False Negatives 6K  ', color='orange')\n",
    "\n",
    "\n",
    "plt.axhline(y=falsi_negativi_5K_fp_5sub_before, color='purple', linestyle='--', label='Initial False Negatives')\n",
    "\n",
    "# Etichette e titolo\n",
    "plt.xlabel('probability for the synthetic point to belong to the class 1')\n",
    "plt.ylabel('Count False Negaitives')\n",
    "plt.title(f'False Negatives, fn, #subgroups = {K} on {filtered_instances}, support = {min_sup}, pruning = {epsilon}')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "plt.yticks(range(550, 660, 25))\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4041, 542)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_0, count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
