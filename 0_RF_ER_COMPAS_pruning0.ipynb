{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ANALISI CONDOTTA CON LA FEATURE error (PASSATA A BOOLEAN OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_compas import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il CSV\n",
    "df = pd.read_csv(\"cox-violent-parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning = 0.00\n",
    "epsilon = pruning\n",
    "min_sup = 0.1\n",
    "percentage = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "VALIDATION SET ROWS:  2439\n",
      "HOLDOUT SET ROWS:  2440\n",
      "TEST SET ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) \n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0])\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "VALIDATION SET ROWS:  2439\n",
      "HOLDOUT SET ROWS:  2440\n",
      "TEST SET ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosit√† precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) \n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) \n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAGvCAYAAADCGAZiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACdHUlEQVR4nOzdeVzM2/8H8NdM+56UFqKSKBVlL7uIS2RJiCzh2q4lW+4lsmWLuLi4riWyXBGuiESW7CpkKbKEW5ZbpKJtzu+PvuZnzMSkz0w07+fj8Xk86sz5fN7nM5Y5cz7nvA+PMcZACCGEEIXDr+wGEEIIIaRyUCeAEEIIUVDUCSCEEEIUFHUCCCGEEAVFnQBCCCFEQVEngBBCCFFQ1AkghBBCFBR1AgghhBAFRZ0AQgghREFRJ4AQQghRUNQJIIQQQmTg7Nmz8PDwgJmZGXg8Hg4ePPjVc+Li4uDs7Aw1NTVYW1tj27ZtMm0jdQIIIYQQGcjLy0OjRo2wbt06qeo/evQI3bt3R4cOHZCUlITJkydj5MiROH78uMzayKMNhAghhBDZ4vF4iIyMhKenZ5l1Zs6ciaioKCQnJwvLBgwYgDdv3iA6Olom7aKRAEIIIUQKBQUFyMnJETkKCgo4u/7Fixfh5uYmUubu7o6LFy9yFuNzyjK7MiHfiSiV+nKNl3/urtxiGWgVyi0WALx6pya3WDaGWXKLBQDpb/XlGs9I673cYv2XryG3WACgr/FBbrHaNtSq0Pnl+f/h6m8DERQUJFI2d+5czJs3r0Jt+CgzMxPGxsYiZcbGxsjJycH79++hocH9nyN1AgghhCgsngpP6rqzZs2Cv7+/SJmamvw6xrJAnQBCCCEKS0lDSeq6ampqMv3QNzExwYsXL0TKXrx4AV1dXZmMAgDUCSCEEKLA+MrSjwTIWqtWrXD06FGRspiYGLRq1UpmMWliICGEEIXFU+FJfZRXbm4ukpKSkJSUBKB0CWBSUhLS09MBlD5e8PX1FdYfM2YMHj58iBkzZuDevXtYv349/v77b0yZMoWTe5WERgIIIYQoLFmOBFy7dg0dOnQQ/v5xPsHQoUOxbds2ZGRkCDsEAGBpaYmoqChMmTIFq1evRq1atbB582a4u7vLrI3UCSCEEKKwvuUbvrTat2+PL6XikZQNsH379khMTJRZmz5HnQBCCCEK63uaE1AZqBNACCFEYfGUFLsTQBMDiVxERETAwcEBGhoaqF69Otzc3JCXlwcA2Lx5M2xtbaGuro4GDRpg/fr1wvNGjBgBR0dHYVauwsJCODk5iUymIYSQb8VX4kl9VEXUCSAyl5GRgYEDB2LEiBG4e/cu4uLi0KdPHzDGEB4ejsDAQCxatAh3797F4sWLMWfOHGzfvh0AsGbNGuTl5SEgIAAA8Ntvv+HNmzdYu3ZtZd4SIaSK4PF5Uh9VET0OIDKXkZGB4uJi9OnTB3Xq1AEAODg4AChNuRkSEoI+ffoAKJ0de+fOHWzcuBFDhw6FtrY2du7ciXbt2kFHRwehoaE4ffo0dHV1K+1+CCFVB09Jsb8LUyeAyFyjRo3QqVMnODg4wN3dHV26dEG/fv2gqqqKtLQ0+Pn5YdSoUcL6xcXF0NPTE/7eqlUrTJs2DQsWLMDMmTPRunXrMmMVFBSIbehRxARQ4Sn2P3RCiGRKKor9f4Ni3z2RCyUlJcTExODYsWOws7PD77//jvr16wu3y/zzzz+FCTWSkpKQnJyMS5cuCc8XCASIj4+HkpISHjx48MVYwcHB0NPTEzn+Fsh3IxpCyI+D5gQQIgc8Hg+urq4ICgpCYmIiVFVVER8fDzMzMzx8+BDW1tYih6WlpfDc5cuX4969ezhz5gyio6OxdevWMuPMmjULb9++FTn68w3kcYuEkB8QT4kn9VEV0eMAInOXL19GbGwsunTpgho1auDy5ct49eoVbG1tERQUhIkTJ0JPTw9du3ZFQUEBrl27huzsbPj7+yMxMRGBgYGIiIiAq6srVq5ciUmTJqFdu3awsrISiyVpgw96FEAIKQuPr9j/P1AngMicrq4uzp49i9DQUOTk5KBOnToICQlBt27dAACamppYvnw5pk+fDi0tLTg4OGDy5Mn48OEDBg8ejGHDhsHDwwMAMHr0aERFRWHIkCE4e/YslJSk3wGMEEI+V1Vn/UuLx76U05CQKiBKpb5c4+Wfuyu3WAZahXKLBQCv3slv73QbQ/nO5Uh/qy/XeEZa7+UW67982WxDWxZ9jQ9yi9W2oVaFzk/q0kbquo1PnKtQrO8RjQQQQghRWIo+EkCdAEIIIQqL5gQQQgghCopGAgghhBAFpejJgqgTQAghRGHR4wBCCCFEQdHjAEIIIURBUSeAkCpOnuv2AUCzja3cYh1ecU1usQDAu0uR3GL9faZi67/Ly9VZvilT7vyrLbdYzrXlm3MhIV1+qbrbNqzY+YreCVDshyGEEEIUGo/Pl/r4FuvWrYOFhQXU1dXRokULXLly5Yv1Q0NDUb9+fWhoaMDc3BxTpkzBhw+yS75EIwGEEEIUlix3B9y7dy/8/f2xYcMGtGjRAqGhoXB3d0dKSgpq1KghVn/Xrl0ICAjAli1b4OLigtTUVAwbNgw8Hg8rV66USRtpJIAQQojC4vF5Uh8FBQXIyckROQoKCsq89sqVKzFq1CgMHz4cdnZ22LBhAzQ1NbFlyxaJ9S9cuABXV1cMGjQIFhYW6NKlCwYOHPjV0YOKoE4AIYQQhVWexwHBwcHQ09MTOYKDgyVet7CwENevX4ebm5uwjM/nw83NDRcvXpR4jouLC65fvy780H/48CGOHj2Kn376ifsb/x96HEAIIURh8ZWl/y48a9Ys+Pv7i5R9vnX5R69fv0ZJSQmMjY1Fyo2NjXHv3j2J5wwaNAivX79G69atwRhDcXExxowZg19//VXqNpYXjQQQQghRWOUZCVBTU4Ourq7IUVYn4FvExcVh8eLFWL9+PRISEnDgwAFERUVhwYIFnMX4HI0EEEIIUViyWiJoaGgIJSUlvHjxQqT8xYsXMDExkXjOnDlzMGTIEIwcORIA4ODggLy8PIwePRq//fYb+DLIbkgjAYQQQhSWrJYIqqqqokmTJoiNjRWWCQQCxMbGolWrVhLPyc/PF/ugV1JSAgAwJps8FjQSQGSisLAQqqqqld0MQgj5Mp7slgj6+/tj6NChaNq0KZo3b47Q0FDk5eVh+PDhAABfX1/UrFlTOLnQw8MDK1euhJOTE1q0aIEHDx5gzpw58PDwEHYGuEYjAYQT7du3x4QJEzB58mQYGhrC3d0dK1euhIODA7S0tGBubo5x48YhNzdX5Lz4+Hi0b98empqaqFatGtzd3ZGdnQ2gtNccHBwMS0tLaGhooFGjRoiIiKiM2yOEVFHlWSJYXt7e3lixYgUCAwPRuHFjJCUlITo6WjhZMD09HRkZGcL6s2fPxtSpUzF79mzY2dnBz88P7u7u2LhxI2f3+zkaCSCc2b59O8aOHYv4+HgAwLFjx7BmzRpYWlri4cOHGDduHGbMmIH169cDAJKSktCpUyeMGDECq1evhrKyMk6fPo2SkhIAQHBwMHbu3IkNGzagXr16OHv2LAYPHgwjIyO0a9eu0u6TEFJ1yHoXwQkTJmDChAkSX4uLixP5XVlZGXPnzsXcuXNl2iaRmHKLRKq8evXqYdmyZcLf69evL/zZwsICCxcuxJgxY4SdgGXLlqFp06bC3wGgYcPSROAFBQVYvHgxTp48KXx+ZmVlhfPnz2Pjxo1ldgIKCgrEkncUFapARZW7GbyEkKqD9g4ghCNNmjQR+f3kyZPo1KkTatasCR0dHQwZMgT//fcf8vPzAfz/SIAkDx48QH5+Pjp37gxtbW3hERYWhrS0tDLbICmZR2TYEu5ukhBSpch674DvHY0EEM5oaf3/rm+PHz9Gjx49MHbsWCxatAgGBgY4f/48/Pz8UFhYCE1NTWhoaJR5rY9zB6KiolCzZk2R1760LldSMo8jSSrfcjuEEAVQnmRBVRF1AohMXL9+HQKBACEhIcIlL3///bdIHUdHR8TGxiIoKEjsfDs7O6ipqSE9Pb1cz//V1NTEOgkqqoJvuANCiEKoot/wpUWdACIT1tbWKCoqwu+//w4PDw/Ex8djw4YNInVmzZoFBwcHjBs3DmPGjIGqqipOnz4NLy8vGBoaYtq0aZgyZQoEAgFat26Nt2/fIj4+Hrq6uhg6dGgl3RkhpCrhyXCJ4I9AsbtARGYaNWqElStXYunSpbC3t0d4eLjYRhs2NjY4ceIEbty4gebNm6NVq1Y4dOgQlJVL+6YLFizAnDlzEBwcDFtbW3Tt2hVRUVGwtLSsjFsihFRBij4ngMdklYaIkO/EvkvyfRyg2cZWbrFOrLgmt1gA4N1FfrEOn5fvXA5XZ/kOjGZmyy+ec+0sucUCgIR0A7nFGuX29Tpf8t+8kVLXrT5vc8WCfYfocQAhhBDFVUW/4UuLOgGEEEIUlqLnCaBOACGEEIXF49FIACGEEKKYaCSAEEIIUUxVdda/tKgTQAghRGHxZLRF74+COgGEEEIUFk0MJKSKM9AqlGu8w3Jcu99lWlO5xQKA8ODLcov161Pp129z4XKj3XKN16NWktxiBUaYyy0WAMztlyzHaPYVO50eBxBCCCGKSdHTBlMngBBCiOKikQBCCCFEMSn6nADF7gIRQghRbDy+9Mc3WLduHSwsLKCuro4WLVrgypUrX6z/5s0bjB8/HqamplBTU4ONjQ2OHj36TbGlQSMBhBBCFJcMRwL27t0Lf39/bNiwAS1atEBoaCjc3d2RkpKCGjVqiNUvLCxE586dUaNGDURERKBmzZp48uQJ9PX1ZdZG6gQQQghRWLJMG7xy5UqMGjUKw4cPBwBs2LABUVFR2LJlCwICAsTqb9myBVlZWbhw4QJUVEp30bSwsJBZ+wB6HCBXw4YNg6en5xfrtG/fHpMnTxb+bmFhgdDQUKljfH7+90ia9+Fb6hJCSHnxlJWkPgoKCpCTkyNyFBQUSLxuYWEhrl+/Dje3/9/rmM/nw83NDRcvXpR4zuHDh9GqVSuMHz8exsbGsLe3x+LFi1FSUiKTeweoEyBi2LBh4PF44PF4UFFRgaWlJWbMmIEPHz5wcv3Vq1dj27Zt5Trn6tWrGD16tNT1Dxw4gAULFpSzZdx4/Pix8P3j8XgwMDBAu3btcO7cOZF63/I+EEKITPB4Uh/BwcHQ09MTOYKDgyVe9vXr1ygpKYGxsbFIubGxMTIzMyWe8/DhQ0RERKCkpARHjx7FnDlzEBISgoULF3J+2x/R44DPdO3aFVu3bkVRURGuX7+OoUOHgsfjYenSpRW+tp6eXrnPMTIyKld9AwODcsfg2smTJ9GwYUO8fv0aixYtQo8ePZCamir8x/At7wMhhMhEOZYIzpoVAH9/f5EyNTU1zpoiEAhQo0YNbNq0CUpKSmjSpAmeP3+O5cuXY+7cuZzF+RSNBHxGTU0NJiYmMDc3h6enJ9zc3BATEwOg9A8oODgYlpaW0NDQQKNGjRARESFy/u3bt9GjRw/o6upCR0cHbdq0QVpaGgDxoe28vDz4+vpCW1sbpqamCAkJEWvPp48DBg0aBG9vb5HXi4qKYGhoiLCwMADijwPWr1+PevXqQV1dHcbGxujXr5/wtfbt2+OXX37B5MmTUa1aNRgbG+PPP/9EXl4ehg8fDh0dHVhbW+PYsWPleg+rV68OExMT2Nvb49dff0VOTg4uX/7/THOfvw8RERFwcHCAhoYGqlevDjc3N+Tl5Um89tWrV2FkZMRJp4wQQsozEqCmpgZdXV2Ro6xOgKGhIZSUlPDixQuR8hcvXsDExETiOaamprCxsYHSJ/sZ2NraIjMzE4WFssl8Sp2AL0hOTsaFCxegqqoKAAgODkZYWBg2bNiA27dvY8qUKRg8eDDOnDkDAHj+/Dnatm0LNTU1nDp1CtevX8eIESNQXFws8frTp0/HmTNncOjQIZw4cQJxcXFISEgosz0+Pj74559/kJubKyw7fvw48vPz0bt3b7H6165dw8SJEzF//nykpKQgOjoabdu2Famzfft2GBoa4sqVK/jll18wduxYeHl5wcXFBQkJCejSpQuGDBmC/Pz8cr9/79+/F3ZOPr6Hn8vIyMDAgQMxYsQI3L17F3FxcejTpw8YY2J1T506hc6dO2PRokWYOXNmudtDCCGf4/H5Uh/loaqqiiZNmiA2NlZYJhAIEBsbi1atWkk8x9XVFQ8ePIBAIBCWpaamwtTUtMz/QyuKHgd85siRI9DW1kZxcTEKCgrA5/Oxdu1aFBQUYPHixTh58qTwD9DKygrnz5/Hxo0b0a5dO6xbtw56enrYs2ePcGanjY2NxDi5ubn466+/sHPnTnTq1AlA6QdyrVq1ymybu7s7tLS0EBkZiSFDhgAAdu3ahZ49e0JHR0esfnp6OrS0tNCjRw/o6OigTp06cHJyEqnTqFEjzJ49GwAwa9YsLFmyBIaGhhg1ahQAIDAwEH/88Qdu3ryJli1bSvUeuri4gM/nIz8/H4wxNGnSRHiPn8vIyEBxcTH69OmDOnXqAAAcHBzE6kVGRsLX1xebN28WGw35VEFBgdhEncJCBlVV7obsCCFViAxXB/j7+2Po0KFo2rQpmjdvjtDQUOFIKwD4+vqiZs2awnkFY8eOxdq1azFp0iT88ssvuH//PhYvXoyJEyfKrI00EvCZDh06ICkpCZcvX8bQoUMxfPhw9O3bFw8ePEB+fj46d+4MbW1t4REWFiYc7k9KSkKbNm2EHYAvSUtLQ2FhIVq0aCEsMzAwQP369cs8R1lZGf3790d4eDiA0scJhw4dgo+Pj8T6nTt3Rp06dWBlZYUhQ4YgPDxc7Bu9o6Oj8GclJSVUr15d5EP443P8ly9ffvWePtq7dy8SExOxf/9+WFtbY9u2bWW+J40aNUKnTp3g4OAALy8v/Pnnn8jOzhapc/nyZXh5eWHHjh1f7AAAkDhxZ/fm5VK3nRCiYPg86Y9y8vb2xooVKxAYGIjGjRsjKSkJ0dHRwv9X09PTkZGRIaxvbm6O48eP4+rVq3B0dMTEiRMxadIkicsJuUIjAZ/R0tKCtbU1gNI1m40aNcJff/0Fe/vSnaqioqJQs2ZNkXM+PhPS0NCQeft8fHzQrl07vHz5EjExMdDQ0EDXrl0l1tXR0UFCQgLi4uJw4sQJBAYGYt68ebh69aow+cTnH84fV0Z8+jsAkeGprzE3N0e9evVQr149FBcXo3fv3khOTpb47ExJSQkxMTG4cOECTpw4gd9//x2//fYbLl++DEtLSwBA3bp1Ub16dWzZsgXdu3f/Yidr1qxZYhN34u+LP1oghBBAtnkCAGDChAmYMGGCxNfi4uLEylq1aoVLly7JtE2fopGAL+Dz+fj1118xe/Zs2NnZQU1NDenp6bC2thY5zM1Lt+l0dHTEuXPnUFRU9NVr161bFyoqKiIT5rKzs5GamvrF81xcXGBubo69e/ciPDwcXl5eX/xQVFZWhpubG5YtW4abN2/i8ePHOHXqlJTvQMX169cPysrKWL9+fZl1eDweXF1dERQUhMTERKiqqiIyMlL4uqGhIU6dOoUHDx6gf//+X3x/JU3coUcBhJAyyXAk4EdAnYCv8PLygpKSEjZu3Ihp06ZhypQp2L59O9LS0pCQkIDff/8d27dvB1Da48vJycGAAQNw7do13L9/Hzt27EBKSorYdbW1teHn54fp06fj1KlTSE5OxrBhw8CXYvLJoEGDsGHDBsTExJT5KAAond+wZs0aJCUl4cmTJwgLC4NAIPjiIweu8Xg8TJw4EUuWLJE4ufDy5ctYvHgxrl27hvT0dBw4cACvXr2Cra2tSL0aNWrg1KlTuHfvHgYOHFjmZEtCCCkXvpL0RxVEnYCvUFZWxoQJE7Bs2TLMmjULc+bMQXBwMGxtbdG1a1dERUUJh62rV6+OU6dOITc3F+3atUOTJk3w559/lvlNffny5WjTpg08PDzg5uaG1q1bo0mTJl9tk4+PD+7cuYOaNWvC1dW1zHr6+vo4cOAAOnbsCFtbW2zYsAG7d+9Gw4YNv+3N+EZDhw5FUVER1q5dK/aarq4uzp49i59++gk2NjaYPXs2QkJC0K1bN7G6JiYmOHXqFG7dugUfHx+ZZtEihCgIPl/6owriMUlrsQipQmJvcZPxUVqHT339cRBXukxrKrdYAHA0+PLXK3Hk16c/yy0WAFz22S3XeK10b8otVuABc7nFAoC5/TK+XokjtWzsK3T+hwOrpa6r3mdShWJ9j2hiICGEEMVVRZ/1S6tqjm8QmRgzZozI8shPjzFjxlR28wghpPx4fOmPKohGAojU5s+fj2nTpkl8TVdXV86tIYQQDvAUeySAOgFEajVq1ECNGjUquxmEEMKdKjrhT1rUCSCEEKK4aCSAEEIIUVBV9Fm/tKgTQAghRHEpVc0kQNKiTgCp8l69k2/aYO8u8ssTEC7HdfsA8NOsFl+vxJFVaxLlFgsARld/Jtd44Tccv16JIz49C75eiUOXsu3kFqtfRS9AIwGEEEKIgqI5AYQQQoiCotUBhBBCiGJiNBJACCGEKCiaE0AIIYQoKAXvBCj23VcRjx8/Bo/HQ1JSEqd1v0dxcXHg8Xh48+ZNZTeFEFIFMB5P6qMqok7AD2DYsGHg8Xjg8XhQUVGBpaUlZsyYgQ8fSrfINTc3R0ZGBuztK7alpjQsLCwQGhoq8ziEECIXCr6BUNW8qyqoa9euyMjIwMOHD7Fq1Sps3LgRc+fOBQAoKSnBxMQEysr0dIcQQsqFx5P++Abr1q2DhYUF1NXV0aJFC1y5ckWq8/bs2QMejwdPT89viist6gT8INTU1GBiYgJzc3N4enrCzc0NMTExAMSH+LOzs+Hj4wMjIyNoaGigXr162Lp1q8TrlpSUYMSIEWjQoAHS09Mr3M5Dhw7B2dkZ6urqsLKyQlBQEIqLiwEAgwYNgre3t0j9oqIiGBoaIiwsDAAgEAgQHBwMS0tLaGhooFGjRoiIiKhwuwghRBKmpCT1UV579+6Fv78/5s6di4SEBDRq1Aju7u54+fLlF897/Pgxpk2bhjZt2nzrbUmNOgE/oOTkZFy4cAGqqqoSX58zZw7u3LmDY8eO4e7du/jjjz9gaGgoVq+goABeXl5ISkrCuXPnULt27Qq169y5c/D19cWkSZNw584dbNy4Edu2bcOiRYsAAD4+Pvjnn3+Qm5srPOf48ePIz89H7969AQDBwcEICwvDhg0bcPv2bUyZMgWDBw/GmTNnKtQ2QgiRSIaPA1auXIlRo0Zh+PDhsLOzw4YNG6CpqYktW7aUeU5JSQl8fHwQFBQEKyurityZVGj8+Adx5MgRaGtro7i4GAUFBeDz+Vi7dq3Euunp6XByckLTpk0BlD7H/1xubi66d++OgoICnD59Gnp6ehVuY1BQEAICAjB06FAAgJWVFRYsWIAZM2Zg7ty5cHd3h5aWFiIjIzFkyBAAwK5du9CzZ0/o6OigoKAAixcvxsmTJ9GqVSvhNc6fP4+NGzeiXbt2FW4jIYR8ipXjw72goAAFBaIpmNXU1KCmJp6avLCwENevX8esWbOEZXw+H25ubrh48WKZMebPn48aNWrAz88P586dk7pt34o6AT+IDh064I8//kBeXh5WrVoFZWVl9O3bV2LdsWPHom/fvkhISECXLl3g6ekJFxcXkToDBw5ErVq1cOrUKWhoaHDSxhs3biA+Pl74zR8o7dV++PAB+fn50NTURP/+/REeHo4hQ4YgLy8Phw4dwp49ewAADx48QH5+Pjp37ixy3cLCQjg5OUnVBkn/SIsKVaGiKt/9AwghP4hyPOsPDg5GUFCQSNncuXMxb948sbqvX79GSUkJjI2NRcqNjY1x7949idc/f/48/vrrL7mu3qJOwA9CS0sL1tbWAIAtW7agUaNG+Ouvv+Dn5ydWt1u3bnjy5AmOHj2KmJgYdOrUCePHj8eKFSuEdX766Sfs3LkTFy9eRMeOHTlpY25uLoKCgtCnTx+x19TV1QGUPhJo164dXr58iZiYGGhoaKBr167C8wEgKioKNWvWFDlfUk9bEkn/SPuOCEQ/v3nlvR1CiAIoz0jArFmz4O/vL1Im7f9NX/Pu3TsMGTIEf/75p8THt7JCnYAfEJ/Px6+//gp/f38MGjRIYh0jIyMMHToUQ4cORZs2bTB9+nSRTsDYsWNhb2+Pnj17IioqipOhdmdnZ6SkpAg7K5K4uLjA3Nwce/fuxbFjx+Dl5QUVFRUAgJ2dHdTU1JCenv7N7ZH0j/RQguS5E4QQUp6RgLKG/iUxNDSEkpISXrx4IVL+4sULmJiYiNVPS0vD48eP4eHhISwTCAQAAGVlZaSkpKBu3bpSt1Va1An4QXl5eWH69OlYt24d+vUT3UwzMDAQTZo0QcOGDVFQUIAjR47A1tZW7Bq//PILSkpK0KNHDxw7dgytW7eWKvbz58/Fhqvq1KmDwMBA9OjRA7Vr10a/fv3A5/Nx48YNJCcnY+HChcK6gwYNwoYNG5CamorTp08Ly3V0dDBt2jRMmTIFAoEArVu3xtu3bxEfHw9dXV3hXIMvkfSPVEWVSXVfhBAFJKP1/6qqqmjSpAliY2OFy/wEAgFiY2MxYcIEsfoNGjTArVu3RMpmz56Nd+/eYfXq1TA3N5dJO6kT8INSVlbGhAkTsGzZMnTr1k3kNVVVVcyaNQuPHz+GhoYG2rRpI3zu/rnJkydDIBDgp59+QnR0tNjcAUlWrFghMqoAADt27MDgwYNx5MgRzJ8/H0uXLoWKigoaNGiAkSNHitT18fHBokWLUKdOHbi6uoq8tmDBAhgZGSE4OBgPHz6Evr4+nJ2d8euvv0rzthBCSLnIMhOgv78/hg4diqZNm6J58+YIDQ1FXl4ehg8fDgDw9fVFzZo1ERwcDHV1dbGEb/r6+gAg00RwPMYYfU0iVdqeC/L9K167Wu7XK3EkPKpEbrEA4KdZLeQW6/SaRLnFAoDRXV7LNd7hG7XkFqupTcHXK3HodZ78JuL2a1Gxb/I5CTFS19V17vz1Sp9Zu3Ytli9fjszMTDRu3Bhr1qxBixal/47at28PCwsLbNu2TeK5w4YNw5s3b3Dw4MFyx5UWjQQQQghRWAJe+ZMAlceECRMkDv8DpXuhfElZnQMuUbIgIhQeHg5tbW2JR8OGDSu7eYQQwj0F3zuARgKIUM+ePYXDVJ/7OIOfEEKqkqq6O6C0qBNAhHR0dKCjo1PZzSCEELkpT56Aqog6AYQQQhQXjQQQQgghiolGAgghhBAFxUAjAYRUaTaGWXKN9/cZLbnF+vXpyK9X4tAqOa7d7zBRuk2juHI5NkWu8Qbbye+97Dc9R26xAGBNiOyS24irXqGzaSSAEEIIUVQ0J4AQQghRTLJOFvS9o04AIYQQhUWPAwghhBAFRRMDCSGEEAVFIwGEEEKIglL0tMGcdoHmzZuHxo0bS13/8ePH4PF4SEpK4rIZ36Vt27YJ94Yuy+fv37Bhw+Dp6Sl1jPK+/5VBmvfhW+oSQsi3YOBJfVRFUncCPDw80LVrV4mvnTt3DjweD3369EFsbCxnjftWPB6vXPsvb9u2DTweDzweD3w+H6ampvD29kZ6ejpnbfL29kZqamq5zlm9enW5tpKcNm1apb7/FhYWwvdRU1MTDg4O2Lx5s0idb3kfCCFEVhiPL/VRFUl9V35+foiJicGzZ8/EXtu6dSuaNm0KR0dHVK9escQNlUVXVxcZGRl4/vw59u/fj5SUFHh5eXF2fQ0NDdSoUaNc5+jp6ZXrm7C2tnalv//z589HRkYGkpOTMXjwYIwaNQrHjh0Tvv4t7wMhhMgKjQRIqUePHjAyMhL7Zpqbm4t9+/bBz89PbDhaIBBg/vz5qFWrFtTU1NC4cWNER0d/MU5ycjK6desGbW1tGBsbY8iQIXj9+rXw9fbt22PixImYMWMGDAwMYGJignnz5glft7CwAAD07t0bPB5P+PvX8Hg8mJiYwNTUFC4uLvDz88OVK1eQk/P/mbYOHToEZ2dnqKurw8rKCkFBQSguLha+/ubNG/z8888wNjaGuro67O3tceTIEQCSh7aXLFkCY2Nj6OjowM/PDx8+fBB5/dPHAZs2bYKZmRkEAoFInV69emHEiBEAxB8HxMXFoXnz5tDS0oK+vj5cXV3x5MkTkbpbtmxB7dq1oa2tjXHjxqGkpATLli2DiYkJatSogUWLFkn1/n2ko6MDExMTWFlZYebMmTAwMEBMTIzw9c/fhxs3bqBDhw7Q0dGBrq4umjRpgmvXrkm89qtXr9C0aVP07t0bBQUF5WoXIYRIQiMBUlJWVoavry+2bdsGxpiwfN++fSgpKcHAgQPFzlm9ejVCQkKwYsUK3Lx5E+7u7ujZsyfu378vMcabN2/QsWNHODk54dq1a4iOjsaLFy/Qv39/kXrbt2+HlpYWLl++jGXLlmH+/PnCD5qrV68CKB2dyMjIEP5eHi9fvkRkZCSUlJSgpFSaSOLcuXPw9fXFpEmTcOfOHWzcuBHbtm0TfkgKBAJ069YN8fHx2LlzJ+7cuYMlS5YIz//c33//jXnz5mHx4sW4du0aTE1NsX79+jLb5OXlhf/++w+nT58WlmVlZSE6Oho+Pj5i9YuLi+Hp6Yl27drh5s2buHjxIkaPHg3eJ5Ng0tLScOzYMURHR2P37t3466+/0L17dzx79gxnzpzB0qVLMXv2bFy+fLnc76FAIMD+/fuRnZ0NVVXVMuv5+PigVq1auHr1Kq5fv46AgACoqKiI1Xv69CnatGkDe3t7REREQE1NrdxtIoSQzwl4SlIfVVG5VgeMGDECy5cvx5kzZ9C+fXsApR+2ffv2hZ6enlj9FStWYObMmRgwYAAAYOnSpTh9+jRCQ0Oxbt06sfpr166Fk5MTFi9eLCzbsmULzM3NkZqaChsbGwCAo6Mj5s6dCwCoV68e1q5di9jYWHTu3BlGRkYAAH19fZiYmEh9b2/fvoW2tjYYY8jPzwcATJw4EVpapXngg4KCEBAQgKFDhwIArKyssGDBAsyYMQNz587FyZMnceXKFdy9e1fYTisrqzLjhYaGws/PD35+fgCAhQsX4uTJk2KjAR9Vq1YN3bp1w65du9CpUycAQEREBAwNDdGhQwex+jk5OXj79i169OiBunXrAgBsbW1F6ggEAmzZsgU6Ojqws7NDhw4dkJKSgqNHj4LP56N+/frCP7MWLVpI9T7OnDkTs2fPRkFBAYqLi2FgYICRI8vOb5+eno7p06ejQYMGAEr/PD+XkpKCzp07o3fv3ggNDRXpyHyuoKBAbJSgsLAAqqrUaSCEiKuqw/zSKtf4RoMGDeDi4oItW7YAAB48eIBz584JP8g+lZOTg3///Reurq4i5a6urrh7967E69+4cQOnT5+Gtra28Pj44ZCWlias5+joKHKeqakpXr58WZ5bEaOjo4OkpCRcu3YNISEhcHZ2FhkKv3HjBubPny/StlGjRiEjIwP5+flISkpCrVq1hB2Ar7l7967YB2urVq2+eI6Pjw/2798v/JALDw/HgAEDwOeL/zEaGBhg2LBhcHd3h4eHB1avXo2MjAyROhYWFtDR0RH+bmxsDDs7O5HrGRsbl+u9nT59OpKSknDq1Cm0aNECq1atgrW1dZn1/f39MXLkSLi5uWHJkiUif84A8P79e7Rp0wZ9+vTB6tWrv9gBAIDg4GDo6emJHFs3hkrdfkKIYmE8ntTHt1i3bh0sLCygrq6OFi1a4MqVK2XW/fPPP9GmTRtUq1YN1apVg5ub2xfrc6HcDzn8/Pywf/9+vHv3Dlu3bkXdunXRrl07ThqTm5sLDw8PJCUliRz3799H27ZthfU+Hy7m8Xhiz8rLi8/nw9raGra2tvD390fLli0xduxYkbYFBQWJtOvWrVu4f/8+1NXVoaGhUaH40vDw8ABjDFFRUXj69CnOnTsn8VHAR1u3bsXFixfh4uKCvXv3wsbGBpcuXRK+Lul9rOh7a2hoCGtra7Rp0wb79u3DxIkTcefOnTLrz5s3D7dv30b37t1x6tQp2NnZITIyUvi6mpoa3NzccOTIETx//vyr8WfNmoW3b9+KHMN/nix1+wkhioUxntRHee3duxf+/v6YO3cuEhIS0KhRI7i7u5f5xSouLg4DBw7E6dOncfHiRZibm6NLly5S/d/3rcrdCejfvz/4fD527dqFsLAwjBgxQuK3M11dXZiZmSE+Pl6kPD4+HnZ2dhKv7ezsjNu3b8PCwgLW1tYix8dheWmoqKigpKSkfDf2mYCAAOzduxcJCQnCtqWkpIi1y9raGnw+H46Ojnj27JnUy99sbW3FnrV/+gEtibq6Ovr06YPw8HDs3r0b9evXh7Oz8xfPcXJywqxZs3DhwgXY29tj165dUrWPC+bm5vD29sasWbO+WM/GxgZTpkzBiRMn0KdPH2zdulX4Gp/Px44dO9CkSRN06NAB//777xevpaamBl1dXZGDHgUQQsrCwJf6KCgoQE5OjsjxpUnKK1euxKhRozB8+HDY2dlhw4YN0NTUFI6mfy48PBzjxo1D48aN0aBBA2zevBkCgUCmS7/L3QnQ1tYW/seekZGBYcOGlVl3+vTpWLp0Kfbu3YuUlBQEBAQgKSkJkyZNklh//PjxyMrKwsCBA3H16lWkpaXh+PHjGD58eLk+1C0sLBAbG4vMzExkZ2eX9xYBlH6A9e7dG4GBgQCAwMBAhIWFISgoCLdv38bdu3exZ88ezJ49GwDQrl07tG3bFn379kVMTAwePXoknHQnyaRJk7BlyxZs3boVqampmDt3Lm7fvv3Vdvn4+CAqKgpbtmz54ijAo0ePMGvWLFy8eBFPnjzBiRMncP/+fbF5AbI2adIk/PPPPxJn/L9//x4TJkxAXFwcnjx5gvj4eFy9elWsjUpKSggPD0ejRo3QsWNHZGZmyqv5hJAqrjxLBCU9bgwODpZ43cLCQly/fh1ubm7CMj6fDzc3N1y8eFGqtuXn56OoqAgGBgac3Ksk37Tmwc/PD9nZ2XB3d4eZmVmZ9SZOnAh/f39MnToVDg4OiI6OxuHDhyVO/gIgHDkoKSlBly5d4ODggMmTJ0NfX1/ic++yhISEICYmBubm5nBycir3/X00ZcoUREVF4cqVK3B3d8eRI0dw4sQJNGvWDC1btsSqVatQp04dYf39+/ejWbNmGDhwIOzs7DBjxowyOy/e3t6YM2cOZsyYgSZNmuDJkycijx/K0rFjRxgYGCAlJQWDBg0qs56mpibu3buHvn37wsbGBqNHj8b48ePx888/l/+NqAA7Ozt06dJF2Jn6lJKSEv777z/4+vrCxsYG/fv3R7du3RAUFCRWV1lZGbt370bDhg3RsWPHCs8BIYQQoHydAEmPG8sa6Xz9+jVKSkpgbGwsUm5sbCz1F5mZM2fCzMxMpCPBNR77dL0fIVVQQup/co339xnpH11V1C/JQ+UWCwBWNdj69Uoc6TDx2zvw3yIrNkWu8TrXSJRbrH7Tc75eiUNrQuzlFsvZpmIJ0u6liSfAK0uDurWkrvvvv/+iZs2auHDhgsik7xkzZuDMmTNfXXq9ZMkSLFu2DHFxcWKT4blEGwgRQghRWLJaImhoaAglJSW8ePFCpPzFixdfXb6+YsUKLFmyBCdPnpRpBwDgeAOh71XDhg1FlvZ9eoSHh1d2834I4eHhZb6HDRs2rOzmEULINxEwvtRHeaiqqqJJkyYik/o+TvL70nLwZcuWYcGCBYiOjkbTpk2/+b6kpRAjAUePHkVRUZHE1z5/XkMk69mzZ5kJgyRl+COEkB+BLJMF+fv7Y+jQoWjatCmaN2+O0NBQ5OXlYfjw4QAAX19f1KxZUzi5cOnSpQgMDMSuXbtgYWEhnDvw8QuXLChEJ+DTyXvk2+jo6IgkFiKEkKpAlp0Ab29vvHr1CoGBgcjMzBTun/Pxy2d6errIpPc//vgDhYWF6Nevn8h15s6dK7JHDpcUohNACCGESPItSYDKY8KECZgwYYLE1+Li4kR+f/z4sUzbIgl1AgghhCgsgYLvHUCdAEIIIQpL0TcQojwBpMo7eLViKaTLS4kvv39SRSXyXeBjX136NdUVdfl5bbnFAgCDTvXlGi8n7p7cYn0olO8HXXUd+f2b69m0Ylv8liePSEVzEnyPaCSAEEKIwlL0kQDqBBBCCFFYsp4Y+L2jTgAhhBCFRSMBhBBCiIIqoZEAQgghRDHR4wBCCCFEQSn64wCF2EBo3rx5aNy4sdT1Hz9+DB6Ph6SkJJm1iUsWFhYIDQ3lvO73iMfj4eDBg5XdDEJIFcEYT+qjKvrhOwEeHh7o2rWrxNfOnTsHHo+HPn36iOzkVFnK+wG2bds28Hg88Hg88Pl8mJqawtvbG+np6SL1rl69itGjR3PcWnHDhg2Dp6enzOMQQoi8MPCkPqqiH74T4Ofnh5iYGDx7Jp7EZOvWrWjatCkcHR1RvfqPmeRBV1cXGRkZeP78Ofbv34+UlBR4eXmJ1DEyMoKmpmYltZAQQn5cAib9URX98J2AHj16wMjICNu2bRMpz83Nxb59++Dn5yf2OEAgEGD+/PmoVasW1NTUhDs7fUlycjK6desGbW1tGBsbY8iQIXj9+rXw9fbt22PixImYMWMGDAwMYGJiIrLrk4WFBQCgd+/e4PF4wt+/hsfjwcTEBKampnBxcYGfnx+uXLmCnJwckWt/HOJnjGHevHmoXbs21NTUYGZmhokTJ5Z5/c2bN0NfX5+TkZIvvUebNm2CmZkZBAKByDm9evXCiBEjhL8fOnQIzs7OUFdXh5WVFYKCglBcXFzhthFCiCQ0EvCDU1ZWhq+vL7Zt24ZPMyDv27cPJSUlGDhwoNg5q1evRkhICFasWIGbN2/C3d0dPXv2xP379yXGePPmDTp27AgnJydcu3YN0dHRePHiBfr37y9Sb/v27dDS0sLly5exbNkyzJ8/HzExMQBKh+yB0tGJjIwM4e/l8fLlS0RGRkJJSQlKSpJTZe7fvx+rVq3Cxo0bcf/+fRw8eBAODg4S6y5btgwBAQE4ceIEOnXqVO72fOpr75GXlxf+++8/nD59WnhOVlYWoqOj4ePjA6D08Y2vry8mTZqEO3fuYOPGjdi2bRsWLVpUobYRQkhZFH1OQJVYHTBixAgsX74cZ86cQfv27QGUftj27dsXenp6YvVXrFiBmTNnYsCAAQCApUuX4vTp0wgNDcW6devE6q9duxZOTk5YvHixsGzLli0wNzdHamoqbGxsAACOjo6YO3cuAKBevXpYu3YtYmNj0blzZxgZGQEA9PX1YWJiIvW9vX37Ftra2mCMIT8/HwAwceJEaGlpSayfnp4OExMTuLm5QUVFBbVr10bz5s3F6s2cORM7duzAmTNn0LBhQ6nbUxZp3qNu3bph165dwg5HREQEDA0N0aFDBwBAUFAQAgICMHToUACAlZUVFixYgBkzZgjf168pKChAQUGBSFlRoTJUVNUqfI+EkKpH0XfP+eFHAgCgQYMGcHFxwZYtWwAADx48wLlz5+Dn5ydWNycnB//++y9cXV1Fyl1dXXH37l2J179x4wZOnz4NbW1t4dGgQQMAQFpamrCeo6OjyHmmpqZ4+fJlhe5NR0cHSUlJuHbtGkJCQuDs7PzFb8ZeXl54//49rKysMGrUKERGRooNp4eEhODPP//E+fPnOekAANK9Rz4+Pti/f7/wQzo8PBwDBgwAn88XXmP+/Pki1xg1ahQyMjKEHaCvCQ4Ohp6ensixf9sSTu6REFL1lDC+1EdVVGXuys/PD/v378e7d++wdetW1K1bF+3atePk2rm5ufDw8EBSUpLIcf/+fbRt21ZYT0VFReQ8Ho8n9gy8vPh8PqytrWFrawt/f3+0bNkSY8eOLbO+ubk5UlJSsH79emhoaGDcuHFo27YtioqKhHXatGmDkpIS/P333xVq26ekeY88PDzAGENUVBSePn2Kc+fOCR8FfLxGUFCQyPm3bt3C/fv3oa6uLlU7Zs2ahbdv34ocfYcFcHafhJCqhTHpj6qoSjwOAID+/ftj0qRJ2LVrF8LCwjB27FjweOLPcHR1dWFmZob4+HiRTkJ8fLzEYXMAcHZ2xv79+2FhYQFl5W9/y1RUVFBSUrEtNgMCAlC3bl1MmTIFzs7OEutoaGjAw8MDHh4eGD9+PBo0aIBbt24J6zdv3hwTJkxA165doaysjGnTplWoTYB075G6ujr69OmD8PBwPHjwAPXr1xe5B2dnZ6SkpMDa2vqb26GmpgY1NdGhfxVV+W4lTAj5cVTVCX/SqjIjAdra2vD29sasWbOQkZGBYcOGlVl3+vTpWLp0Kfbu3YuUlBQEBAQgKSkJkyZNklh//PjxyMrKwsCBA3H16lWkpaXh+PHjGD58eLk+1C0sLBAbG4vMzExkZ2eX9xYBlH7T7927NwIDAyW+vm3bNvz1119ITk7Gw4cPsXPnTmhoaKBOnToi9VxcXHD06FEEBQWVK3nQ27dvxb7tP336VOr3yMfHB1FRUdiyZYvIKAAABAYGIiwsDEFBQbh9+zbu3r2LPXv2YPbs2dK/QYQQUg6yXiK4bt06WFhYQF1dHS1atMCVK1e+WH/fvn1o0KAB1NXV4eDggKNHj35bYClVmU4AUPpIIDs7G+7u7jAzMyuz3sSJE+Hv74+pU6fCwcEB0dHROHz4MOrVqyex/seRg5KSEnTp0gUODg6YPHky9PX1hc+zpRESEoKYmBiYm5vDycmp3Pf30ZQpUxAVFSXxL5O+vj7+/PNPuLq6wtHRESdPnsQ///wjMU9C69atERUVhdmzZ+P333+XKnZcXBycnJxEjqCgIKnfo44dO8LAwAApKSkYNGiQyLXd3d1x5MgRnDhxAs2aNUPLli2xatUqsQ4MIYRwRZarA/bu3Qt/f3/MnTsXCQkJaNSoEdzd3cucK3bhwgUMHDgQfn5+SExMhKenJzw9PZGcnFzR2ywTj7Gq+qSDkFIHr8r3cYASX37/pIpK5NuPt68unpRLVi4/ry23WABg0Km+XOPlxN2TW6wPhfId8q6uI79/cz2bSl4uLa2jCUVfr/Q/PzmrfL3SJ1q0aIFmzZph7dq1AEpz1Jibm+OXX35BQID4XCVvb2/k5eXhyJEjwrKWLVuicePG2LBhQ7liS6tKjQQQQggh5SEAT+qjoKAAOTk5IsfnS5I/KiwsxPXr1+Hm5iYs4/P5cHNzw8WLFyWec/HiRZH6QOkIaVn1uUCdgErUsGFDkeVwnx7h4eFybUt6enqZbdHW1hbbr4AQQqqC8qwOkLQEOTg4WOJ1X79+jZKSEhgbG4uUGxsbIzMzU+I5mZmZ5arPhSqzOuBHdPToUZGle5/6/C+CrJmZmX1x18QvzbEghJAfVXme9c+aNQv+/v4iZZ+vRvrRUCegEn1PE96UlZUrtDSPEEJ+RCXlSOUiaQlyWQwNDaGkpIQXL16IlL948aLMrLEmJiblqs8FehxACCFEYclqAyFVVVU0adJEZHM2gUCA2NhYtGrVSuI5rVq1EtvMLSYmpsz6XKCRAEIIIQpLllsE+/v7Y+jQoWjatCmaN2+O0NBQ5OXlYfjw4QAAX19f1KxZUzivYNKkSWjXrh1CQkLQvXt37NmzB9euXcOmTZtk1kbqBBBCCFFYslwk7+3tjVevXiEwMBCZmZnCbes/zvlKT08XyaPi4uKCXbt2Yfbs2fj1119Rr149HDx4EPb29jJrI+UJIFVe/J1cuca786+23GL1qJUkt1gAEH7H8euVODLY7obcYgHA6f8ayzWebvsGcot1f7/8chIAQIt67+QWq5WtboXO//ui9JMC+reqek/QaSSAEEKIwhJ8QybAqoQ6AYQQQhSWoo+FUyeAEEKIwqJOACGEEKKgZLk64EdAnQBCCCEKSyBQ7DkBVW+q43ds3rx5aNy4sfD3YcOGwdPTs1LacvDgQVhbW0NJSQmTJ08us4wQQqoyAZP+qIqqbCegMj9gyzJt2jSxbFBc2759O5o1awZNTU3o6OigXbt2IttSfvTzzz+jX79+ePr0KRYsWFBmGSGEVGXl2UCoKqqynYDvkba2NqpXry6z60+bNg0///wzvL29cfPmTVy5cgWtW7dGr169hPtZA0Bubi5evnwJd3d3mJmZQUdHR2IZIYRUddQJUAAWFhYIDQ0VKWvcuDHmzZsHABg0aBC8vb1FXi8qKoKhoSHCwsIAlOZ8Dg4OhqWlJTQ0NNCoUSNEREQI68fFxYHH4yE2NhZNmzaFpqYmXFxckJKSIqzz+eOAz30txpdcunQJISEhWL58OaZNmwZra2vY2tpi0aJFmDx5Mvz9/fH06VPExcUJP+A7duwIHo9XZhkAnD9/Hm3atIGGhgbMzc0xceJE5OXliby3ixcvxogRI6Cjo4PatWuLpLgsLCzEhAkTYGpqCnV1ddSpU0dk6803b95g5MiRMDIygq6uLjp27IgbN/4/ScyNGzfQoUMH6OjoQFdXF02aNMG1a9ekek8IIeRr6HEAgY+PD/755x/k5v5/Zrnjx48jPz8fvXv3BlC6j3RYWBg2bNiA27dvY8qUKRg8eDDOnDkjcq3ffvsNISEhuHbtGpSVlTFixAip2yFtDEl2794NbW1t/Pzzz2KvTZ06FUVFRdi/f79Ix2T//v3IyMgosywtLQ1du3ZF3759cfPmTezduxfnz5/HhAkTRK4fEhKCpk2bIjExEePGjcPYsWOF11uzZg0OHz6Mv//+GykpKQgPD4eFhYXwXC8vL7x8+RLHjh3D9evX4ezsjE6dOiErKwtA6Z9NrVq1cPXqVVy/fh0BAQFQUVGR+j0lhJAvUfSRAFodAMDd3R1aWlqIjIzEkCFDAAC7du1Cz549oaOjg4KCAixevBgnT54U7uZkZWWF8+fPY+PGjWjXrp3wWosWLRL+HhAQgO7du+PDhw9QV1f/YhvKE0OS1NRU1K1bF6qqqmKvmZmZQVdXF6mpqVBVVUWNGjUAAAYGBsItKiWVBQcHw8fHRzhJsF69elizZg3atWuHP/74Q3hPP/30E8aNGwcAmDlzJlatWoXTp0+jfv36SE9PR7169dC6dWvweDyR7ZPPnz+PK1eu4OXLl8LtOVesWIGDBw8iIiICo0ePRnp6OqZPn44GDRoI20AIIVwRlGMr4aqIOgEAlJWV0b9/f4SHh2PIkCHIy8vDoUOHsGfPHgDAgwcPkJ+fj86dO4ucV1hYCCcnJ5EyR8f/z61uamoKAHj58iVq1679xTaUJ0ZZuN4G4saNG7h58ybCw8NFYggEAjx69Ai2trYARO+Zx+PBxMQEL1++BFA6QbNz586oX78+unbtih49eqBLly7C6+fm5orNk3j//j3S0tIAlO7CNXLkSOzYsQNubm7w8vJC3bp1y2xzQUEBCgoKRMoKC4ugqirdHuCEEMVSVb/hS0shOgF8Pl/sA7KoqEjkdx8fH7Rr1w4vX75ETEwMNDQ00LVrVwAQPiaIiopCzZo1Rc77+A32o0+Hqnm80vWnAim6muWJIYmNjQ3Onz+PwsJCsdGAf//9Fzk5ObCxsfnqdT5v088//4yJEyeKvfZpp+bz4Xkejye8Z2dnZzx69AjHjh3DyZMn0b9/f7i5uSEiIgK5ubkwNTUVzj/4lL6+PoDSeRSDBg1CVFQUjh07hrlz52LPnj3CxzSfCw4ORlBQkEjZ8HGz4Df+1/LcOiFEQVAnQAEYGRkhIyND+HtOTg4ePXokUsfFxQXm5ubYu3cvjh07Bi8vL+GHm52dHdTU1JCenv7VYflvVdEYAwYMwJo1a7Bx40b88ssvIq+tWLECKioq6Nu3b7mu6ezsjDt37sDa2rrc7fmUrq4uvL294e3tjX79+qFr167IysqCs7MzMjMzoaysLDJP4HM2NjawsbHBlClTMHDgQGzdurXMTsCsWbPg7+8vUnb9YZHEuoQQUlUn/ElLIToBHTt2xLZt2+Dh4QF9fX0EBgZCSUlJrN6gQYOwYcMGpKam4vTp08JyHR0dTJs2DVOmTIFAIEDr1q3x9u1bxMfHQ1dXF0OHDq1wGysao1WrVpg0aRKmT5+OwsJCeHp6oqioCDt37sTq1asRGhoKc3PzcrVp5syZaNmyJSZMmICRI0dCS0sLd+7cQUxMjMiSwy9ZuXIlTE1N4eTkBD6fj3379sHExAT6+vpwc3NDq1at4OnpiWXLlsHGxgb//vsvoqKi0Lt3bzRs2BDTp09Hv379YGlpiWfPnuHq1atf7MyoqamJjZyoqsp3K2FCyI9DUK5eQNXLLlhlOwECgQDKyqW3N2vWLDx69Ag9evSAnp4eFixYIDYSAJQ+Eli0aBHq1KkDV1dXkdcWLFgAIyMjBAcH4+HDh9DX14ezszN+/ZW7YeaKxggNDYWjoyPWr1+P2bNnQ0lJCc7Ozjh48CA8PDzK3R5HR0ecOXMGv/32G9q0aQPGGOrWrSu2nPJLdHR0sGzZMty/fx9KSkpo1qwZjh49Cj6/dGHK0aNH8dtvv2H48OF49eoVTExM0LZtWxgbG0NJSQn//fcffH198eLFCxgaGqJPnz5iw/2EEPKtFH1iII9xPZvsO9G1a1dYW1tL/Y2VVF3xd+Q7EnDnX225xepRK0lusQAg/I7j1ytxZLDdja9X4tDp/xrLNZ5u+wZyi3V//z25xQKAFvXeyS1WK1vdCp0felj6j8DJPaveSECVyxOQnZ2NI0eOIC4uDm5ubpXdHEIIId8xShZUxYwYMQJjxozB1KlT0atXr8puDmfGjBkDbW1ticeYMWMqu3mEEPJDomRBVUxkZGRlN0Em5s+fj2nTpkl8TVe3YsNhhBCiqNh3MDEwKysLv/zyC/755x/w+Xz07dsXq1evhra25EeLWVlZmDt3Lk6cOIH09HQYGRnB09MTCxYsgJ6eXrliV7lOQFVVo0YNYVY/Qggh3Pgehvl9fHyQkZGBmJgYFBUVYfjw4Rg9ejR27dolsf6///6Lf//9FytWrICdnR2ePHmCMWPG4N9//5V6v5mPqBNACCFEYVX2MP/du3cRHR2Nq1evomnTpgCA33//HT/99BNWrFgBMzMzsXPs7e2xf/9+4e9169bFokWLMHjwYBQXFwtXxkmjys0JIIQQQqQlEDCpj4KCAuTk5Igcn6cpL6+LFy9CX19f2AEAADc3N/D5fFy+fFnq67x9+xa6urrl6gAA1AkghBCiwAQC6Y/g4GDo6emJHJ9ujf4tMjMzxR71Kisrw8DAAJmZmVJd4/Xr11iwYAFGjx5d7vj0OIBUef/la8g1nnPtLLnFCowoXxbIivLpWbFvPeXRb3qO3GIBgJ+/fNeAv5Dj2v16feWXkwAACpMS5RqvIgTleB4gKS15WXu7BAQEYOnSpV+83t27d6WOXZacnBx0794ddnZ2mDdvXrnPp04AIYQQhcXKkTFQUlryskydOhXDhg37Yh0rKyuRXVc/Ki4uRlZWlnBb97K8e/cOXbt2hY6ODiIjI8U2c5MGdQIIIYQoLFklzTUyMoKRkdFX67Vq1Qpv3rzB9evX0aRJEwDAqVOnIBAI0KJFizLPy8nJgbu7O9TU1HD48GGoq6t/UztpTgAhhBCFVZ45AbJga2uLrl27YtSoUbhy5Qri4+MxYcIEDBgwQLgy4Pnz52jQoAGuXLkCoLQD0KVLF+Tl5eGvv/5CTk4OMjMzkZmZiZKSknLFp5EAQgghCut72D4nPDwcEyZMQKdOnYTJgtasWSN8vaioCCkpKcjPzwcAJCQkCFcOfL7V+6NHj764NfvnqBNACCFEYX0PyYIMDAzKTAwEABYWFiKdlfbt23PWeaFOACGEEIVVvrTBVQ91AgghhCis7+BpQKWiTgAhhBCFVVIioxl/PwjqBBDOFRYWQlVVtbKbQQghX1WePAFVES0R/M5FR0ejdevW0NfXR/Xq1dGjRw+kpaUJX79w4QIaN24MdXV1NG3aFAcPHgSPx0NSUpKwTnJyMrp16wZtbW0YGxtjyJAheP36tVTx3717Bx8fH2hpacHU1BSrVq1C+/btMXnyZGEdCwsLLFiwAL6+vtDV1RWmrty/fz8aNmwINTU1WFhYICQkROTaPB4PBw8eFCnT19fHtm3bAACPHz8Gj8fDnj174OLiAnV1ddjb2+PMmTPSv4GEEPIFAsakPqoi6gR85/Ly8uDv749r164hNjYWfD4fvXv3hkAgQE5ODjw8PODg4ICEhAQsWLAAM2fOFDn/zZs36NixI5ycnHDt2jVER0fjxYsX6N+/v1Tx/f39ER8fj8OHDyMmJgbnzp1DQkKCWL0VK1agUaNGSExMxJw5c3D9+nX0798fAwYMwK1btzBv3jzMmTNH+AFfHtOnT8fUqVORmJiIVq1awcPDA//991+5r0MIIZ9jjEl9VEX0OOA717dvX5Hft2zZAiMjI9y5cwfnz58Hj8fDn3/+CXV1ddjZ2eH58+cYNWqUsP7atWvh5OSExYsXi1zD3NwcqampsLGxKTP2u3fvsH37duzatQudOnUCAGzdulXi1pYdO3bE1KlThb/7+PigU6dOmDNnDgDAxsYGd+7cwfLly7+aSvNzEyZMEL4Pf/zxB6Kjo/HXX39hxowZYnULCgrEdvUqKlSGiqp0qT4JIYpFoOCrA2gk4Dt3//59DBw4EFZWVtDV1RUmgUhPT0dKSgocHR1F0kU2b95c5PwbN27g9OnT0NbWFh4NGpRuJvLpYwVJHj58iKKiIpFr6unpoX79+mJ1P90GEyjdGMPV1VWkzNXVFffv3y93RqtWrVoJf1ZWVkbTpk3L3HhD0i5fEduWlCseIURxMCb9URXRSMB3zsPDA3Xq1MGff/4JMzMzCAQC2Nvbo7CwUKrzc3Nz4eHhIXE3K1NTU87aqaWlVe5zeDye2BBbUVFRhdohaZevmGT6a04IkUzR8wTQSMB37L///kNKSgpmz56NTp06wdbWFtnZ2cLX69evj1u3bokMf1+9elXkGs7Ozrh9+zYsLCxgbW0tcnztg9vKygoqKioi13z79i1SU1O/2nZbW1vEx8eLlMXHx8PGxgZKSkoASjfYyMjIEL5+//59YVrMT126dEn4c3FxMa5fvw5bW1uJcdXU1KCrqyty0KMAQkhZaGIg+W5Vq1YN1atXx6ZNm/DgwQOcOnVK5FvuoEGDIBAIMHr0aNy9exfHjx/HihUrAJR+ywaA8ePHIysrCwMHDsTVq1eRlpaG48ePY/jw4V8dltfR0cHQoUMxffp0nD59Grdv34afnx/4fL7w+mWZOnUqYmNjsWDBAqSmpmL79u1Yu3Ytpk2bJqzTsWNHrF27FomJibh27RrGjBkjcSvMdevWITIyEvfu3cP48eORnZ2NESNGSP0+EkJIWZiASX1URdQJ+I7x+Xzs2bMH169fh729PaZMmYLly5cLX9fV1cU///yDpKQkNG7cGL/99hsCAwMBQDhPwMzMDPHx8SgpKUGXLl3g4OCAyZMnQ19fH3z+1//4V65ciVatWqFHjx5wc3ODq6srbG1tv7ptpbOzM/7++2/s2bMH9vb2CAwMxPz580UmBYaEhMDc3Bxt2rTBoEGDMG3aNGhqaopda8mSJViyZAkaNWqE8+fP4/DhwzA0NJTmLSSEkC8qKWFSH1URPSz9zrm5ueHOnTsiZZ8+R3dxccGNGzeEv4eHh0NFRQW1a9cWltWrVw8HDhz4pvg6OjoIDw8X/p6Xl4egoCBhLgCgdD2/JH379hVb3fApMzMzHD9+XKTszZs3YvVsbW2FO2YRQgiXquo3fGlRJ+AHFxYWBisrK9SsWRM3btzAzJkz0b9/f2hoaHBy/cTERNy7dw/NmzfH27dvMX/+fABAr169OLk+IYRUpqq6/l9a1An4wWVmZiIwMBCZmZkwNTWFl5cXFi1aJNW56enpsLOzK/P1jyMQK1asQEpKClRVVdGkSROcO3eOhuMJIVWCoucJoE7AD27GjBkSk+ZIw8zMTCS9sKTXa9eujevXr39j6yrm8z20CSGEa4r+fwx1AhSYsrIyrK2tK7sZhBBSaWhOACGEEKKgFL0TQEsECSGEKKzvIVlQVlYWfHx8oKurC319ffj5+SE3N1eqcxlj6Natm8RdWaVBnQBCCCEK63tIFuTj44Pbt28jJiYGR44cwdmzZ0WWYX9JaGjoV5O3fQk9DiBVnr7GB7nGS0g3kFusuf2S5RYLAC5ll72ahGtrQuzlFgsAnuWUb2Orimpgkie3WIVJiXKLBQC5jZ3kF6wopUKnV/bEwLt37yI6OhpXr14VbsT2+++/46effsKKFSsk7tr6UVJSEkJCQnDt2rVv3guGRgIIIYQorJJigdRHQUEBcnJyRI7Pty4vr4sXL0JfX19kJ1Y3Nzfw+fwvJknLz8/HoEGDsG7dOpiYmHxzfOoEEEIIUViMMakPSVuVBwcHVyh+ZmYmatSoIVKmrKwMAwMDZGZmlnnelClT4OLiUuHEbfQ4gBBCiMJiAoHUdSVtVa6mJnmX0oCAAIlbuH/q7t27Usf+1OHDh3Hq1CkkJlb8MQ91AgghhCis8mQMVFNTK/ND/3NTp04V2TBNEisrK5iYmODly5ci5cXFxcjKyipzmP/UqVNIS0uDvr6+SHnfvn3Rpk0bxMXFSdVGgDoBhBBCFJisJgYaGRnByMjoq/VatWqFN2/e4Pr162jSpAmA0g95gUCAFi1aSDwnICAAI0eOFClzcHDAqlWr4OHhUa52UieAEEKIwqrsZEG2trbo2rUrRo0ahQ0bNqCoqAgTJkzAgAEDhCsDnj9/jk6dOiEsLAzNmzeHiYmJxFGC2rVrw9LSslzxq8zEQAsLC4SGhlZ2M4Ty8/PRt29f6Orqgsfj4c2bNxLLCCGEVJ7vIU9AeHg4GjRogE6dOuGnn35C69atsWnTJuHrRUVFSElJQX5+Puexv8uRgGHDhmH79u0AABUVFdSuXRu+vr749ddfoawsuclXr16FlpaWzNv29OlTzJ07F9HR0Xj9+jVMTU3h6emJwMBAVK9eXVhv+/btOHfuHC5cuABDQ0Po6elhw4YNYmWEEEIqj4BJPzFQVgwMDLBr164yX5dmM7VvfazxXXYCAKBr167YunUrCgoKcPToUYwfPx4qKiqYNWuWSL3CwkKoqqpK9ezlSz5e50sePnyIVq1awcbGBrt374alpSVu376N6dOn49ixY7h06RIMDEoTxaSlpcHW1hb29v+f8ERSWVVUVFQEFRWVym4GIYR8VWU/Dqhs3+3jADU1NZiYmKBOnToYO3Ys3NzccPjwYQwbNgyenp5YtGgRzMzMUL9+fQDijwPS09PRq1cvaGtrQ1dXF/3798eLFy+Er8+bNw+NGzfG5s2bYWlpCXV19a+2afz48VBVVcWJEyfQrl071K5dG926dcPJkyfx/Plz/PbbbwCA9u3bIyQkBGfPngWPx0P79u0llgFAQUEBpk2bhpo1a0JLSwstWrQQmdm5bds26Ovr4/jx47C1tYW2tja6du2KjIwMYZ24uDg0b94cWlpa0NfXh6urK548eSJ8/dChQ3B2doa6ujqsrKwQFBSE4uJiAKW9x3nz5qF27dpQU1ODmZkZJk6cKDw3IyMD3bt3h4aGBiwtLbFr1y6x95rH4+GPP/5Az549oaWlhUWLFgEA/vjjD9StWxeqqqqoX78+duzYITzn8ePH4PF4IlsZv3nzBjweT3j/cXFx4PF4iIqKgqOjI9TV1dGyZUskJ8s3Sx4hpOoSlAikPqqi73Yk4HMaGhr477//AACxsbHQ1dVFTEyMxLoCgUDYAThz5gyKi4sxfvx4eHt7i3zAPnjwAPv378eBAwegpKT0xfhZWVk4fvw4Fi1aBA0NDZHXTExM4OPjg71792L9+vU4cOAAAgICkJycjAMHDghHGCSVTZgwAXfu3MGePXtgZmaGyMhIdO3aFbdu3UK9evUAlM4vWLFiBXbs2AE+n4/Bgwdj2rRpCA8PR3FxMTw9PTFq1Cjs3r0bhYWFuHLlijCX9Llz5+Dr64s1a9agTZs2SEtLE+aknjt3Lvbv349Vq1Zhz549aNiwITIzM3Hjxg3hvfn6+uL169eIi4uDiooK/P39xZazAKWdqiVLliA0NBTKysqIjIzEpEmTEBoaCjc3Nxw5cgTDhw9HrVq10KFDhy++15+bPn06Vq9eDRMTE/z666/w8PBAamoqjTYQQipMUI48AVXRd98JYIwhNjYWx48fxy+//IJXr15BS0sLmzdvLnP4PjY2Frdu3cKjR49gbm4OAAgLC0PDhg1x9epVNGvWDEDpI4CwsDCpHiXcv38fjDHY2tpKfN3W1hbZ2dl49eoVatSoAU1NTaiqqorM4Py8LD09HVu3bkV6erpwFui0adMQHR2NrVu3YvHixQBKh9c3bNiAunXrAijtOMyfPx8AkJOTg7dv36JHjx7C1z9tY1BQEAICAjB06FAApetSFyxYgBkzZmDu3LlIT0+HiYkJ3NzchPMvmjdvDgC4d+8eTp48KZLTevPmzcLOyacGDRqE4cOHC38fOHAghg0bhnHjxgEA/P39cenSJaxYsaLcnYC5c+eic+fOAErnWtSqVQuRkZHo37+/WN2CggKxNJ6FhcVQVZVubS8hRLHQ44Dv1JEjR6CtrQ11dXV069YN3t7emDdvHoDS9ZBfen5/9+5dmJubCzsAAGBnZwd9fX2RDE116tQp91wCLteU3rp1CyUlJbCxsYG2trbwOHPmDNLS0oT1NDU1hR/wAGBqair8Nm5gYIBhw4bB3d0dHh4eWL16tcijghs3bmD+/Pki1x81ahQyMjKQn58PLy8vvH//HlZWVhg1ahQiIyOFjwpSUlKgrKwMZ2dn4fWsra1RrVo1sXv5NO81UPpn4OrqKlLm6ur6TRmyWrVqJfzZwMAA9evXL/M6ktJ6hv+5otwxCSGKgTGB1EdV9N2OBHTo0AF//PEHVFVVYWZmJrIqgKtVAOW5jrW1NXg8Hu7evYvevXuLvX737l1Uq1atXJ2K3NxcKCkp4fr162KPI7S1tYU/fz7szePxRDojW7duxcSJExEdHY29e/di9uzZiImJQcuWLZGbm4ugoCD06dNHLL66ujrMzc2RkpKCkydPIiYmBuPGjcPy5ctx5swZqe8DKP+fCZ9f2v/89D6KiorKdQ1JJKX1vJJWXOHrEkKqJhoJ+E5paWnB2toatWvXLnNZYFlsbW3x9OlTPH36VFh2584dvHnzBnZ237YVavXq1dG5c2esX78e79+/F3ktMzMT4eHh8Pb2Lte+zk5OTigpKcHLly9hbW0tcpR3VygnJyfMmjULFy5cgL29vXC5ibOzM1JSUsSub21tLfwg1tDQgIeHB9asWYO4uDhcvHgRt27dQv369VFcXCySn/rBgwfIzs7+antsbW0RHx8vUhYfHy98/z92lj4dtfh0kuCnLl26JPw5OzsbqampZT6WUVNTg66urshBjwIIIWX5HvIEVKbvdiSgItzc3ODg4AAfHx+EhoaiuLgY48aNQ7t27cSGrctj7dq1cHFxgbu7OxYuXCiyRLBmzZrCWfHSsrGxgY+PD3x9fRESEgInJye8evUKsbGxcHR0RPfu3b96jUePHmHTpk3o2bMnzMzMkJKSgvv378PX1xcAEBgYiB49eqB27dro168f+Hw+bty4geTkZCxcuBDbtm1DSUkJWrRoAU1NTezcuRMaGhqoU6cOqlevDjc3N4wePRp//PEHVFRUMHXqVGhoaHy1szN9+nT0798fTk5OcHNzwz///IMDBw7g5MmTAEo7Hi1btsSSJUtgaWmJly9fYvbs2RKvNX/+fFSvXh3Gxsb47bffYGhoCE9Pz3K914QQIsn3kCegMn23IwEVwePxcOjQIVSrVg1t27aFm5sbrKyssHfv3gpdt169erh27RqsrKzQv39/1K1bF6NHj0aHDh1w8eJFYY6A8ti6dSt8fX0xdepU1K9fH56enrh69Spq164t1fmampq4d+8e+vbtCxsbG4wePRrjx4/Hzz//DABwd3fHkSNHcOLECTRr1gwtW7bEqlWrUKdOHQCAvr4+/vzzT7i6usLR0REnT57EP//8I0x8FBYWBmNjY7Rt2xa9e/fGqFGjoKOj89UllZ6enli9ejVWrFiBhg0bYuPGjdi6datwaSQAbNmyBcXFxWjSpAkmT56MhQsXSrzWkiVLMGnSJDRp0gSZmZn4559/vprTgRBCpKHoIwE8JqvdE0iV9OzZM5ibm+PkyZPo1KmTTGPFxcWhQ4cOyM7OFtstqzzO3s7jrlFSSMmQfebKj7rVlm/OhEvZ3/Y47VtYVfv6YycuPcvRl2s8Iy35/b0sFMh30De3sZPcYnUvSqnQ+Z19rktdNya8SYVifY+q5OMAwp1Tp04hNzcXDg4OyMjIwIwZM2BhYYG2bdtWdtMIIaTCBCUlld2ESkWdgP9JT0//4qTBO3fuSD1EX5UUFRXh119/xcOHD6GjowMXFxeEh4dToh5CSJUgqKLD/NKiTsD/mJmZlTk7/ePrisjd3R3u7u6VErt9+/Yy2+ubEEIAgFHGQAIAysrKsLa2ruxmEEIIkaOqOuFPWtQJIIQQorCqaiZAaVEngBBCiMKikQBCCCFEQSn6nAAwQoiYDx8+sLlz57IPHz5UuXh0bz9mPLo3IguULIgQCXJycqCnp4e3b99CV1e3SsWje/sx49G9EVmokmmDCSGEEPJ11AkghBBCFBR1AgghhBAFRZ0AQiRQU1PD3LlzoaamVuXi0b39mPHo3ogs0MRAQgghREHRSAAhhBCioKgTQAghhCgo6gQQQgghCoo6AYQQQoiCok4AIYQQoqCoE0CIFKr6Ipof9f6KiorKfO3169dybAn3EhIScOvWLeHvhw4dgqenJ3799VcUFhZWYstIVUJLBAn5n2HDhmHdunXQ0tISKX/8+DGGDBmCc+fOVVLLuLF8+XJMnz5drLykpASDBw/G7t27K6FVFdO3b19ERESAx+OJlL948QKdOnVCcnJyhWMcPnxY6ro9e/ascLyPmjVrhoCAAPTt2xcPHz5Ew4YN0bt3b1y9ehXdu3dHaGgoZ7E+lZ2djb/++gt3794FANja2mLEiBEwMDCQSTxSuagTQMj/ODk5IScnBzt37kSrVq0AANu3b8fEiRPRsWNHREZGch7z3Llz2LhxI9LS0hAREYGaNWtix44dsLS0ROvWrTmNVaNGDQQHB8PPz09YVlJSggEDBiA5OVn4n/63ysnJkbouV5vENGvWDI6Ojvjrr7+EZZmZmejQoQMaNmyIiIiICsfg86UbMOXxeCgpKalwvI/09PSQkJCAunXrYunSpTh16hSOHz+O+Ph4DBgwAE+fPuUs1kdnz55Fz549oauri6ZNmwIArl+/jjdv3uCff/5B27ZtOY9ZUlKCyMhIkU6Hp6cnlJVpp3u5qKztCwn53hQWFrJp06YxVVVVNmvWLObl5cW0tbXZpk2bZBIvIiKCaWhosJEjRzI1NTWWlpbGGGPs999/Z926deM83pUrV5i+vj7bt28fY4yxoqIi1rt3b2Zra8syMjIqfH0ej8f4fP4Xj491uPLy5UvWoEEDNmXKFMYYY8+fP2c2NjbMy8uLlZSUcBanMujo6LDU1FTGGGNubm4sNDSUMcbYkydPmLq6ukxi2tvbs1GjRrHi4mJhWXFxMRs9ejSzt7fnPF5ycjKzsrJimpqazMnJiTk5OTEtLS1mYWHBbt26xXk8Io5GAgj5zNy5c7FgwQIoKyvjzJkzwlEBrjk5OWHKlCnw9fWFjo4Obty4ASsrKyQmJqJbt27IzMzkPOapU6fg6emJnTt34q+//sKDBw9w6tQpGBsbV/jaZ86ckbpuu3btKhzvo6dPn6J169bo27cvjhw5AmdnZ4SHh0NJSYmzGJJ8+PAB6urqMrt+x44dYW5uDjc3N/j5+eHOnTuwtrbGmTNnMHToUDx+/JjzmBoaGkhKSkL9+vVFylNSUtC4cWO8f/+e03itWrWCkZERtm/fjmrVqgEofRwxbNgwvHr1ChcuXOA0HpGgsnshhHwvCgsLmb+/P1NTU2O//vora9u2LTMxMWFRUVEyiaehocEePXrEGGNMW1tbOBKQlpbG1NTUZBKTMcYiIyOZsrIyc3BwYK9evZJZHHlKSUlhNWrUYD4+PkwgEMgsTnFxMZs/fz4zMzNjSkpKwj+z2bNns82bN3Ma68aNG8ze3p7p6uqyefPmCcsnTJjABg4cyGmsj1xcXFhkZKRYeWRkJGvRogXn8dTV1VlycrJY+a1bt2Q22kFE0UMXQv6nadOmyM/PR1xcHFq2bAnGGJYtW4Y+ffpgxIgRWL9+PafxTExM8ODBA1hYWIiUnz9/HlZWVpzE6NOnj8RyIyMj6OvrY/To0cKyAwcOcBLzo4/zHR4+fIh9+/ZxNt+hWrVqYhMBASA/Px///PMPqlevLizLysr65jiSLFq0CNu3b8eyZcswatQoYbm9vT1CQ0NF5ltUlKOjo8jqgI+WL18us1GOiRMnYtKkSXjw4AFatmwJALh06RLWrVuHJUuW4ObNmyLtqygbGxu8ePECDRs2FCl/+fIlrK2tK3x98nXUCSDkf5o2bYo1a9YIVwfweDzMnDkTXbp0wZAhQziPN2rUKEyaNAlbtmwBj8fDv//+i4sXL2LatGmYM2cOJzH09PQklru7u3Ny/bLs378fQ4YMgY+PDxISElBQUAAAePv2LRYvXoyjR49+87VlNSteGmFhYdi0aRM6deqEMWPGCMsbNWqEe/fucR7vzZs3iIiIQFpaGqZPnw4DAwPcuXMHxsbGqFmzJufxBg4cCACYMWOGxNd4PB4YY5xNggwODsbEiRMxb948kU7H/PnzsXTpUpHJplxNJiWiaE4AIVIoKCjgfJtTxhgWL16M4OBg5OfnAyjdUnXatGlYsGABp7HkrTLmO8iDhoYG7t27hzp16ojc1507d9C8eXPk5uZyFuvmzZvo1KkT9PX18fjxY6SkpMDKygqzZ89Geno6wsLCOIv10ZMnT6SuW6dOnQrH+3TlxcfRnY8fSZ/+zvXKC/L/aCSAkE/s2LEDGzZswKNHj3Dx4kXUqVMHoaGhsLS0RK9evTiNxePx8Ntvv2H69Ol48OABcnNzYWdnB21tbU7jfPT+/XswxqCpqQmg9D/8yMhI2NnZoUuXLpzGSklJkbicTE9PD2/evOEsTkJCAlRUVODg4ACgNKHO1q1bYWdnh3nz5kFVVZWzWABgZ2eHc+fOiX0ARkREwMnJidNY/v7+GD58OJYtWwYdHR1h+U8//YRBgwZxGusjLj7Yy+P06dNyjUfEUSeAkP/5448/EBgYiMmTJ2PRokXCbx76+voIDQ3lvBPw9u1blJSUwMDAAHZ2dsLyrKwsKCsrcz782atXL/Tp0wdjxozBmzdv0Lx5c6iqquL169dYuXIlxo4dy1ksecx3AICff/4ZAQEBcHBwwMOHD+Ht7Y0+ffpg3759yM/P5/zRQWBgIIYOHYrnz59DIBDgwIEDSElJQVhYGI4cOcJprKtXr2Ljxo1i5TVr1pTZSMrXRhd8fX05jcflKhHyjSpvTiIh3xdbW1vhzOhPZ+vfunWLVa9enfN4Xbt2ZevWrRMr/+OPP2SSJ6B69erCmdh//vknc3R0ZCUlJezvv/9mDRo04DTW4sWLmZ2dHbt06RLT0dFh586dYzt37mRGRkZszZo1nMXR1dVlDx48YIwxtmTJEtalSxfGGGPnz59ntWrV4izOp86ePcvc3NyYkZER09DQYK6uruz48eOcxzEyMmIJCQmMMdG/jydOnJDZvenr64scWlpajMfjMTU1NVatWjXO4505c+aLB5E96gQQ8j/q6urs8ePHjDHR/3RTU1NlslypWrVq7M6dO2Lld+/eZQYGBpzH09DQYE+ePGGMMebl5SVcdpaens40NDQ4jSUQCNjChQuFHyI8Ho+pq6uz2bNncxqnMhLqyIufnx/z9PRkhYWFTFtbmz18+JA9efKEOTk5sUmTJsmtHampqaxTp04sOjqa82t//Lvx6fFpcikie7SBECH/Y2lpiaSkJLHy6Oho2Nrach6voKAAxcXFYuVFRUWcJ2UBAGtraxw8eBBPnz7F8ePHhfMAXr58yfmjh4/zHbKyspCcnIxLly7h1atXnE94bNq0KRYuXIgdO3bgzJkz6N69OwDg0aNHnCRA+tzIkSMRFxfH+XUlCQkJQW5uLmrUqIH379+jXbt2sLa2ho6ODhYtWiSXNgBAvXr1sGTJEkyaNInza2dnZ4scL1++RHR0NJo1a4YTJ05wHo9IUNm9EEK+F3/++SerWbMm27NnD9PS0mK7d+8WfpvdvXs35/Hat2/PJkyYIFY+btw41rp1a87j7du3j6moqDA+n886d+4sLF+8eDHr2rUrp7F27NjB8vLyOL2mJPJOqNOzZ0+mpqbGatWqxaZNm8YSExM5j/G58+fPs3Xr1rGlS5eymJgYmceTJDExkeno6MgtXlxcHHN2dpZbPEVGSwQJ+UR4eDjmzZuHtLQ0AKWTsObNm8dpEpiP4uPj4ebmhmbNmqFTp04AgNjYWFy9ehUnTpxAmzZtOI+ZmZmJjIwMNGrUSLg868qVK9DV1UWDBg04i2NkZIT379+jZ8+eGDx4MNzd3WWexvdTHz58gJKSElRUVDi/dnZ2Nvbt24ddu3bh3LlzaNCgAXx8fDBo0CCxiZBce/PmDfT19WV2/c93TGSMISMjA2vXroW5uTmOHTsms9ifunfvHpo2bcrpkksiGXUCCPmfT5fQ5efnIzk5GfHx8bCzs5NZcp2kpCQsX74cSUlJ0NDQgKOjI2bNmoV69erJJJ68FBcXIzo6Grt378ahQ4egqakJLy8v+Pj4wMXFpbKbx5lnz55h9+7d2LJlC+7fvy/x8c63Wrp0KSwsLODt7Q0A6N+/P/bv3w8TExMcPXoUjRo14izWR5/vmMjj8WBkZISOHTsiJCQEpqamnMb7NAMh8P+djiVLlqC4uBjnz5/nNB4RR50AQv6nS5cuIkvoGjRoABUVFZksoZOXPn36YNu2bdDV1S0zhfBHXKcN/ig/Px+RkZHYtWsXTp48iVq1aglHWr6FgYEBUlNTYWhoWGYK4Y+4Thv8qaKiIkRFRWHnzp2IioqCgYEBnj9/ztn1LS0tER4eDhcXF8TExKB///7Yu3cv/v77b6Snp1eJZ+Z8Pl+YhfBTLVu2xJYtWzgdnSKSUZ4AQv4nISEBq1atAlCa/MXY2BiJiYnYv38/AgMDZdoJ+PDhAwoLC0XKuJisp6enJ/yQLCuFsKxpamrC3d0d2dnZePLkiXDf+G+1atUqYfKcykghfPr0aezatQv79++HQCBAnz59cOTIEXTs2JHTOJmZmTA3NwcAHDlyBP3790eXLl1gYWGBFi1acBpLEvZZ5j5ZePTokcjvfD4fRkZGMt2dkXymkuYiEPLdkecSOsYYy8vLY+PHj2dGRkYiy6KqyvKovLw8tnPnTtatWzemqqrK6taty2bPns3u3r1b2U37ZmZmZkxdXZ15enqyffv2sQ8fPsgslqmpKYuPj2eMMWZjY8P+/vtvxhhj9+7dk+kkve3btzN7e3umpqbG1NTUmIODAwsLC5NZPFK5qBNAyP84ODiw1atXs/T0dKarq8suXLjAGGPs2rVrzNjYmPN448aNY7a2tiwiIoJpaGiwLVu2sAULFrBatWqxnTt3ch6vLO/fv2fLly/n9Jre3t5MS0uLGRkZsfHjxwvfS3m5fv066969O+fX3bRpE8vOzub8upKMHz+e1alTh7m5ubHq1auzd+/eMcYY2717N3NycpJJzJCQEKapqclmzJjBDh06xA4dOsSmT5/ONDU12cqVK2USMy4ujvXo0YPVrVuX1a1bl3l4eLCzZ8/KJBYRR50AQv5HnkvoGGPM3NycnT59mjFWmvTm/v37jDHGwsLCOM8Y+PLlS/bPP/+w48ePs+LiYsYYY4WFhSw0NJQZGxtznhFx0KBBLCoqShhLFqKjo9nUqVPZrFmzhImd7t69y3r16sX4fL5Msi5+dP/+fRYdHc3y8/MZY6XJkbhWWFjIli9fziZOnCjMHMgYYytXrmR//vkn5/EYY8zCwoJt375drHzbtm3MwsKC83g7duxgysrKrH///mz16tVs9erVrH///kxFRYWFh4dzHo+Io04AIZ/IyMhgCQkJrKSkRFh2+fJlmQxha2lpCR8/1KxZk12+fJkxxtjDhw+ZlpYWZ3HOnTvH9PT0hNnYmjdvzm7fvs3q1avHbG1t2R9//CH8MJOF9+/fc37NzZs3Mx6Px6pXr874fD4zMjJiO3bsYPr6+uznn3+WmImRC69fv2YdO3YUvpcfOx/Dhw9n/v7+MokpT2pqasLO6KdSU1OZmpoa5/EaNGggcYQhJCSE81TWRDLqBBBSSRwcHFhcXBxjjLFOnTqxqVOnMsYYW716NatZsyZncdq1a8cGDhzIbt26xaZNm8Z4PB6zsbFh+/bt4yzG50pKStj8+fOZmZkZU1JSEn5Yzp49m23evLnC13dwcGDLli1jjDEWERHBeDwea9WqFXv69GmFr/0lQ4YMYe7u7uzp06ciqaWjo6OZnZ0d5/FSU1PZxo0b2YIFC1hQUJDIIQsNGzZkixYtEitfsGABs7e35zyeqqqqxE7H/fv3ZdLpIOKoE0BIJVm5ciVbvXo1Y4yxmJgYpq6uztTU1BifzxfmwOeCgYEBu337NmOMsfz8fMbn89nBgwc5u74kQUFBzMrKiu3cuZNpaGgIPyz37NnDWrZsWeHra2pqskePHjHGSofiVVRU2Pnz5yt83a8xNjZmSUlJjDHR/SXS0tI4Hb1hrHT+gZKSEjM2NmaNGjVijRs3Fh6ymhMQERHBlJSUmLu7O5s/fz6bP38+c3d3Z8rKyuzAgQOcx6tbty7bsGGDWPkff/zBrK2tOY9HxNESQUIqQVFREY4cOYINGzYAANzc3HDv3j1cv34d1tbWcHR05CxWdnY2DA0NAQAaGhrQ1NSEvb09Z9eXJCwsDJs2bUKnTp0wZswYYXmjRo1w7969Cl///fv30NTUBFC6hE1NTY3zRDaS5OXlCeN+KisrC2pqapzGWrhwIRYtWoSZM2dyet0v6du3L65cuYKVK1fi4MGDAABbW1tcuXIFTk5OnMebOnUqJk6ciKSkJGESqfj4eGzbtg2rV6/mPB4RR50AQiqBioqKWLa0OnXqoE6dOjKJd+fOHeEe9IwxpKSkIC8vT6QOlx2P58+fw9raWqxcIBCgqKiIkxibN2+GtrY2gNIMhdu2bRN2dj6aOHEiJ7E+atOmDcLCwoQbIfF4PAgEAixbtgwdOnTgNFZ2dja8vLw4veaXFBUV4eeff8acOXOwc+dOucQcO3YsTExMEBISgr///htAaadj79696NWrl1zaoOgoYyAhlWTKlClQU1PDkiVLZBqnrKxsAITlPB4PJSUlnMVs0qQJpkyZgsGDB0NHRwc3btyAlZUV5s+fj5iYGJw7d65C17ewsPhqEhsej4eHDx9WKM7nkpOT0alTJzg7O+PUqVPo2bMnbt++jaysLMTHx6Nu3bqcxfLz80OzZs1ERlJkTU9PD0lJSbC0tJR5rOLiYixevBgjRoxArVq1ZB6PSEYjAYRUkuLiYmzZsgUnT55EkyZNoKWlJfL6ypUrOYnzeVY2eQgMDMTQoUPx/PlzCAQCHDhwACkpKQgLC8ORI0cqfP3Hjx9XvJHfwN7eHqmpqVi7di10dHSQm5uLPn36YPz48Zw/jrC2tsacOXNw6dIlODg4iG2GxPUoBwB4enri4MGDmDJlCufX/pyysjKWLVsGX19fmcciZaORAEIqyZeGj3k8Hk6dOiXH1vy/cePGYf78+WJD6+V17tw5zJ8/Hzdu3EBubi6cnZ0RGBiILl26cNRS6Tk4OODo0aPCNLxce/bsGebPn49NmzZxds0vfRuXxSgHUDoPISQkBJ06dZLYMeW649GrVy/06dMHQ4cO5fS6RHrUCSCEiNDV1UVSUhKsrKw4v/abN29w9OhRDBo0iPNrf8mnjyRk4caNG3B2dub0kUplkHfHY8OGDQgKCoKPj4/ETkfPnj05jUfEUSeAECJClh+YlfVh+SN3AgoLC/Ho0SPUrVsXyspV6wnu51sXf4rreSpEsrL/BAghhFSa/Px8+Pn5QVNTEw0bNkR6ejoA4JdffpH5ZFJ5EQgEZR7UAZCPqtWtJISQKmLWrFm4ceMG4uLi0LVrV2G5m5sb5s2bh4CAAM5j+vv7Syzn8XhQV1eHtbU1evXqBQMDA85jk8pBnQBCCPmKPn36fPH1N2/ecB7z4MGD2Lt3L1q2bCmyHLJhw4ZIS0vjPB4AJCYmIiEhASUlJahfvz4AIDU1FUpKSmjQoAHWr1+PqVOn4vz587Czs6twvDVr1kgs/7TT0bZtWygpKVU4FpGMOgGEEM6U9Z/6R8+fP5dTS7ilp6f31de5Xur26tUr1KhRQ6w8Ly/vqzkSvtXHb/lbt26Frq4uAODt27cYOXIkWrdujVGjRmHQoEGYMmUKjh8/XuF4q1atwqtXr5Cfn49q1aoBKE2SpKmpCW1tbbx8+RJWVlY4ffq0zFZ2KDqaGEgIETF27FgsWLDgm5YISptkRt65C3bt2oVevXqJzT6XlWfPnsHMzOyLE9++pm3btvDy8sIvv/wCHR0d3Lx5E5aWlvjll19w//59REdHc9jiUjVr1kRMTIzYt/zbt2+jS5cueP78ORISEtClSxe8fv26wvF2796NTZs2YfPmzcJESw8ePMDPP/+M0aNHw9XVFQMGDICJiQkiIiIqHI+Io04AIQrkw4cPuHnzJl6+fAmBQCDy2o+6HOvq1as4ffq0xHviKuFSeXGxzPL8+fPo1q0bBg8ejG3btuHnn3/GnTt3cOHCBZw5cwZNmjThsMWltLW1ceTIEbRv316kPC4uDh4eHnj37h0ePnyIxo0bIycnp8Lx6tati/3796Nx48Yi5YmJiejbty8ePnyICxcuoG/fvsjIyKhwPCKOHgcQoiCio6Ph6+sr8RtcZS3HqmgSn8WLF2P27NmoX78+jI2NRYbJZTVkLg0uvlu1bt0aSUlJWLJkCRwcHHDixAk4Ozvj4sWLcHBw4KCV4nr16oURI0YgJCQEzZo1A1DayZo2bRo8PT0BAFeuXIGNjQ0n8TIyMlBcXCxWXlxcLNzrwszMDO/eveMkHpFA/hsXEkIqg7W1NRs3bhzLzMys7KYIfbod77eoUaMG27p1K3cN4si33teUKVNYbm4uY4yxM2fOsKKiIq6b9kXv3r1jI0eOZKqqqozP5zM+n89UVVXZqFGjhO1KTExkiYmJnMT76aefmLOzM0tISBCWJSQksCZNmrDu3bszxhg7fPgws7e35yQeEUePAwhRELq6ukhMTOR0k5uKqmgSH1NTU5w9exb16tXjuGUV8633paKigmfPnsHY2BhKSkrIyMiQODlQ1nJzc4XZAa2srIS7NX7ExZwHAMjMzMSQIUMQGxsr3BuhuLgYnTp1wo4dO2BsbIzTp0+jqKioUtJNKwJ6HECIgujXrx/i4uK+q05ARU2ZMgXr1q1DaGhoZTeFExYWFlizZg26dOkCxhguXrwonDX/ubZt28qsHdra2l/cWtrOzo6T1NImJiaIiYlBSkoKUlJSAAD169cXLk8EvrzHBqk4GgkgREHk5+fDy8sLRkZGctuV7msqOhIgEAjQvXt3pKamws7OTuyeDhw4wEUzy+1bJwYePHgQY8aMwcuXL8vc/hmo/JS6skrDXFJSglu3bqFOnTpldn4It2gkgBAFsXv3bpw4cQLq6uqIi4sTm0RXGZ2Aipo4cSJOnz6NDh06oHr16pU6GfBT3/rdytPTE56ensjNzYWuri5SUlIq5XGAvEyePBkODg7w8/NDSUkJ2rVrhwsXLkBTU1PiKgUiA5U4H4EQIkfGxsZs0aJFrKSkpLKbIlTRiYHa2trsyJEjHLboy06dOlXma2vXrhX+nJ6ezoqLi8t9/U8nBsbFxcl9YqC0Kvrn9lHNmjXZ1atXGWOMRUZGMlNTU5aSksJmz57NXFxcKnx98nW0gRAhCqKwsBDe3t4VnswljWfPnpX52qVLl4Q/b9y4EcbGxt8cx8DAQK5zHPr06YPr16+Lla9evRqzZs0S/m5ubv5NqW5///135ObmAgA6duyIrKysb2/sD+D169cwMTEBABw9ehT9+/eHjY0NRowYgVu3blVy6xQDdQIIURBDhw7F3r175RKrS5cuEj/A4uPjRTbDGTRoUIWy+M2bNw9z585Ffn7+N1+jPJYvX45u3brh3r17wrKQkBAEBgYiKiqqwtf/ODHwzJkzwomBZ8+elXhUJq4euxgbG+POnTsoKSlBdHQ0OnfuDKB0/grtFyAfNCeAEAVRUlKCZcuW4fjx43B0dBSbRMdldr2WLVuiS5cuOH36NHR0dAAAZ8+ehYeHB+bNm8dZnDVr1iAtLQ3GxsawsLAQu6eEhATOYgHAyJEjkZWVBTc3N5w/fx579+7F4sWLcfToUbi6ulb4+suXL8eYMWMQHBwMHo+H3r17S6xX2RMDGUfzyYcPH47+/fvD1NQUPB4Pbm5uAIDLly+jQYMGnMQgX0arAwhREF9aasXj8XDq1CnOYgkEAvTr1w9ZWVk4fvw4Lly4gJ49e2LhwoWYNGkSZ3GCgoK++PrcuXM5i/WpmTNn4q+//kJJSQmOHTuGli1bcnp9aSYGfm1To4p48OAB0tLS0LZtW2hoaIAxJvLt/+nTpzAzM+Pk23pERASePn0KLy8v1KpVCwCwfft26Ovro1evXhW+Pvky6gQQQmSisLAQ3bt3R35+Pm7evIng4GBMmDChsptVbmXtjLhixQq0bdsWzZs3F5ZxucLizJkzcHV1hbKy/AZs//vvP3h7e+PUqVPg8Xi4f/8+rKysMGLECFSrVg0hISEyi/3hwweoq6vL7PpEMuoEEKKgcnJycOrUKTRo0ICTodebN2+Klb179w4DBw5E9+7dMXbsWGH5lxLRlMfTp0/B4/GE3yCvXLmCXbt2wc7ODqNHj+YkhrQ7I/J4PGGWPS48f/4c+/fvR2pqKgDAxsYGffv2Rc2aNTmL8TlfX1+8fPkSmzdvhq2trTAXwPHjx+Hv74/bt29zGq+kpASLFy/Ghg0b8OLFC6SmpsLKygpz5syBhYUF/Pz8OI1HJKi0dQmEELny8vJiv//+O2OMsfz8fFavXj2moqLClJWVWURERIWvz+PxGJ/PZzweT3h8+vvHn/l8foVjfdS6dWsWFhbGGGMsIyOD6ejosFatWjFDQ0MWFBTEWRx5W7duHVNTU2M8Ho/p6ekxPT09xuPxmJqaGlu3bp3M4hobG7OkpCTGmOgywLS0NKalpcV5vKCgIGZlZcV27tzJNDQ0hPH27NnDWrZsyXk8Io5WBxCiIM6ePYs2bdoAACIjI8EYw5s3b7BmzRosXLiwwtd/9OgRHj58iEePHgmPT3//+DOX35aTk5OFw/F///03HBwccOHCBYSHh2Pbtm2cxSlLSUkJkpKSkJ2dzdk1o6KiMHHiREyYMAHPnz/Hmzdv8ObNGzx//hzjxo3DpEmTcPToUc7ifSovLw+amppi5VlZWVBTU+M8XlhYGDZt2gQfHx+R+QWNGjUSWYFBZIdWBxCiIN6+fQsDAwMApdsK9+3bF5qamujevTumT59e4evXqVOnwtcor6KiIuGH08mTJ9GzZ08AQIMGDWSy//znGe7atm2Lixcvcprhbvny5QgICBDrmJmammLlypXQ1NTEsmXL8NNPP1U41ufatGmDsLAwLFiwAEDpIw6BQIBly5bJJIf/8+fPYW1tLVYuEAhQVFTEeTwijkYCCFEQ5ubmuHjxIvLy8hAdHS3clS07O5vzCVnbt28XWTc/Y8YM6Ovrw8XFBU+ePOEsTsOGDbFhwwacO3cOMTExwhwE//77L6pXr85ZnI8iIiLQqFEjAMA///yDx48f4969e5gyZQp+++03TmIkJCRgyJAhZb4+ZMgQzpc+frRs2TJs2rQJ3bp1Q2FhIWbMmAF7e3ucPXsWS5cu5TyenZ0dzp07J1YeEREBJycnzuMRcdQJIERBTJ48GT4+PqhVqxbMzMyE31rPnj0LBwcHTmMtXrwYGhoaAICLFy9i7dq1WLZsGQwNDTFlyhTO4ixduhQbN25E+/btMXDgQOEH9OHDh0Vm7XPl8wx3Xl5enGe4KykpEct38CkVFRWZ5Qiwt7dHamoqWrdujV69eiEvLw99+vSR2RbUgYGBmDBhApYuXQqBQIADBw5g1KhRWLRoEQIDAzmPRySo7EkJhBD5uXr1Kjtw4AB79+6dsOzIkSPs/PnznMbR0NBgT548YYwxNmPGDDZkyBDGGGPJycnM0NCQ01jFxcUsKytLpOzRo0fsxYsXnMZhjLHatWuz48ePs+LiYmZubi7ctyA5OZnp6+tzEqNZs2Zs5cqVZb4eEhLCmjVrxkms78HZs2eZm5sbMzIyYhoaGszV1ZUdP368spulMGhOACEKpGnTpmjatKlIWffu3TmPo62tjf/++w+1a9fGiRMn4O/vDwBQV1fH+/fvOY2lpKQktu2shYUFpzE+kkeGu/Hjx2Ps2LFQU1PD6NGjhXkCiouLsXHjRsyePRvr16/nJNbnJC3zBErnBqirq6N27dqcTxBs06YNYmJiOL0mkR51Agipwvz9/bFgwQJoaWkJP4jLwmXa4M6dO2PkyJFwcnJCamqqcBLb7du3K/wB7ezsjNjYWFSrVg1OTk5fzGPP9bPzefPmwd7eXpjh7uMHopKSEgICAjiJMXToUNy6dQsTJkzArFmzULduXTDG8PDhQ+Tm5mLixIkYNmwYJ7E+17hxY+H7yf6XQubT91dFRQXe3t7YuHEjJ/NI5JHngXwZdQIIqcISExOFs6wTExPLrMfVhjAfrVu3DrNnz8bTp0+xf/9+4SS969evY+DAgRW6dq9evYQfvr169eK87V/Tr18/sbKhQ4dyGmPFihXo168fdu/ejfv37wMA2rVrhwEDBnCeovhTkZGRmDlzJqZPny6cU3HlyhWEhIRg7ty5KC4uRkBAAGbPno0VK1ZUON6gQYMwevRoDBkyBJmZmXBzc4O9vT3Cw8ORmZlJ8wLkgDIGEkLIF6xZswajR4+Gurp6mSmEP+IybbC0xo0bh/nz58PQ0LDC12revDkWLFgAd3d3kfLjx49jzpw5uHLlCg4ePIipU6ciLS2twvGqVauGS5cuoX79+lizZg327t2L+Ph4nDhxAmPGjOE0pwSRjDoBhCiInTt3ok+fPhKTwXDh5s2bsLe3B5/PL/PZ8kdcpQ0eOXIkBg8ezMn6/LJYWlri2rVrqF69+hdTCHOdNlhaurq6SEpKgpWVVYWvpaGhgcTERLH5Dffu3YOTkxPev3+Px48fw87OjpPtm7W1tZGcnAwLCwv07NkTrq6umDlzJtLT01G/fn3O548QcdQJIERBGBkZ4f379+jZsycGDx4Md3d3Tvds5/P5yMzMRI0aNcDn88Hj8SRuOcvlNri9evXC8ePHYWRkhAEDBmDw4MHCZYKKQkdHR5jjv6KcnJzQqFEjbNq0CaqqqgBKEzKNGjUKN27cQGJiIuLj4zF48GA8evSowvFatGiBDh06oHv37ujSpQsuXbqERo0a4dKlS+jXrx+ePXtW4Rjky2hOACEKIiMjA9HR0di9ezf69+8PTU1NeHl5wcfHBy4uLhW+/qNHj2BkZCT8uSx5eXkVjvXRoUOHkJ2djX379mHXrl1YuXIlGjRoAB8fHwwaNEhmqwQkuXbtmtjKix/NunXr0LNnT9SqVUs4WnPr1i2UlJTgyJEjAICHDx9i3LhxnMRbunQpevfujeXLl2Po0KEyz/NAxNFIACEKKD8/H5GRkdi1axdOnjyJWrVqcfKM90sKCgqwbt06LFu2DJmZmTKJ8ezZM+zevRtbtmzB/fv3UVxczOn1c3NzoaSkJEyEBABJSUmYM2cOjh49KrMkPl/C5UgAULrzY3h4uHD3wvr162PQoEHQ0dHh5PqfKykpQU5Ojsgyz8ePH0NTUxM1atSQSUzy/yhjICEKSFNTE+7u7ujWrRvq1auHx48fc3LdgoICzJo1C02bNoWLiwsOHjwIANi6dSssLS2xatUqTjMGfqqoqAjXrl3D5cuX8fjxYxgbG3N27adPn6JVq1bQ09ODnp4e/P39kZ+fD19fX7Ro0QJaWlq4cOECZ/Eqk46ODtq2bYsuXbqgffv2MDU1xenTp3H48GGZxCsrzwN1AOSkkpIUEUIqQV5eHtu5cyfr1q0bU1VVZXXr1mWzZ89md+/e5eT6M2bMYHp6eqxv377M1NSUKSsrs1GjRjEHBwe2e/duVlxczEmcT506dYqNHDmSVatWjenp6bHhw4ezkydPMoFAwFkMb29v1rhxY/b777+zDh06MD6fz5o2bcrGjx/Pnj59ylmcb/Hplr8VlZaWxhwdHcW2fv54cC0zM5MNHjyYmZqaMiUlJZFYsohHxNGcAEIUxIABA3DkyBFoamqif//+mDNnDlq1asVpjH379iEsLAw9e/ZEcnIyHB0dUVxcjBs3bshkPX/NmjWRlZWFrl27YtOmTfDw8JDJlrdnz57FgQMH0LJlS/Tv3x8mJibw8fHB5MmTOY9VXoMHD4auri4n15o0aRIsLS0RGxsLS0tLXL58GVlZWZg6dSoneQE+N2zYMKSnp2POnDnCLIxEziq7F0IIkY9BgwaxqKgomXwb/0hFRYU9e/ZM+Lu6ujq7efOmzOJt2rSJZWdny+z6H/H5fJaZmSn8XUtLi927d0/mcc+ePct8fHxYy5Ythe9rWFgYO3funEziVa9end24cYMxxpiurq7wHmNjY1njxo05j6etrc0SExM5vy6RHs0JIERBhIeH46effuJ0WeDnSkpKhEvLAEBZWRna2toyizdq1Cjo6+vL7Pqf4vP5Ij9/ep+ysH//fri7uwvX7hcUFAAA3r59i8WLF8skZklJiXACoKGhIf79918AQJ06dZCSksJ5PHNzc4nLSIn80OMAQqoweWe7Y4xh2LBhwiH5Dx8+YMyYMdDS0hKpd+DAgW+O0adPH2zbtg26urro06fPF+tWJM6nGGOwsbERDlfn5ubCyclJpGMAAFlZWZzEA4CFCxdiw4YN8PX1xZ49e4Tlrq6uWLhwIWdxPmVvb48bN27A0tISLVq0wLJly6CqqopNmzZxtvrgU6GhoQgICMDGjRvlupyT/D/qBBBSha1atQo+Pj5QV1fHqlWryqzH4/E46QR8nkN/8ODBFb7m5/T09IQfxnp6epxfX5KtW7fKJc6nUlJS0LZtW7FyPT09vHnzRiYxZ8+eLczjMH/+fPTo0QNt2rRB9erVsXfvXs7jeXt7Iz8/H3Xr1oWmpiZUVFREXueyU0UkozwBhBDCsd27d6Nnz55iIyDlYWVlhU2bNsHNzU0kF0BYWBiWLFmCO3fucNjismVlZaFatWoymbS3ffv2L77O9cZMRBx1AgghhGNc5PMPDg7Gzp07sWXLFnTu3BlHjx7FkydPMGXKFMyZMwe//PILhy0miooeBxBShfn7+0tdd+XKlTJsCXecnJyk/laakJAg49ZIxsV3q4CAAAgEAnTq1An5+flo27Yt1NTUMG3atCrVAUhLS8PWrVuRlpaG1atXo0aNGjh27Bhq166Nhg0bVnbzqjzqBBBShSUmJor8npCQgOLiYtSvXx8AkJqaCiUlJTRp0qQymvdNPD09hT9/+PAB69evh52dnTDnwaVLl3D79m3O8ttXFh6Ph99++w3Tp0/HgwcPkJubCzs7O5mutpC3M2fOoFu3bnB1dcXZs2exaNEi1KhRAzdu3MBff/2FiIiIym5ilUedAEKqsNOnTwt/XrlyJXR0dLB9+3Zhmtbs7GwMHz4cbdq0qawmltvcuXOFP48cORITJ07EggULxOo8ffpU3k2TCVVVVdjZ2VV2M2QiICAACxcuhL+/v8jeBB07dsTatWsrsWWKg+YEEKIgatasiRMnTogNsSYnJ6NLly7CNeE/Ej09PVy7dg316tUTKb9//z6aNm2Kt2/fVkq7vnVTn68tefwUV8sfK5O2tjZu3boFS0tLkffs8ePHaNCgAT58+FDZTazyaCSAEAWRk5ODV69eiZW/evUK7969q4QWVZyGhgbi4+PFOgHx8fFQV1evpFZ9O3ktefxe6OvrIyMjA5aWliLliYmJqFmzZiW1SrFQJ4AQBdG7d28MHz4cISEhwr3aL1++jOnTp5frG+j3ZPLkyRg7diwSEhJE7mnLli2YM2dOpbWrTp06YmvepVEZ+Qgq04ABAzBz5kzs27cPPB4PAoEA8fHxmDZtGnx9fSu7eYqhsvIVE0LkKy8vj40dO5apqakJd2lTVVVlY8eOZbm5uZXdvG+2d+9e5uLiwqpVq8aqVavGXFxc2N69e2USy9LSkr1+/VqsPDs7m1laWsokZlVWUFDARo4cyZSVlRmPx2MqKiqMz+ezwYMHy3SPC/L/aE4AIQomLy8PaWlpAIC6detWKKGNouHz+cjMzBTb6/7FixeoXbu2ML//t3J2dkZsbCyqVav21aWQlbX8saJycnLEdj18+vQpbt26JUzH/PnjHSI79DiAEAWjpaUFR0fHym7GD+Xw4cPCn48fPy7y7L6kpASxsbGc5L7v1auXcN+FT5dCViXVqlVDRkYGatSogY4dO+LAgQMwNzeHubl5ZTdNIdFIACFVWGVstiNrBgYGSE1NhaGh4VfT2XKVe/7jRkE8Hk8sEZCKigosLCwQEhKCHj16cBKvKtPT08OlS5dga2sLPp+PFy9ewMjIqLKbpbBoJICQKqwyNtuRtVWrVgnXlK9atUomOe0/JxAIAACWlpa4evUqDA0NZR7zo8LCQrx8+VLYho9q164ttzZwyc3NDR06dICtrS2A0gmrZW3LfOrUKXk2TSHRSAAhhHyHUlNT4efnhwsXLoiUM8bA4/FQUlJSSS2rmPfv32P79u1IS0tDSEgIRo0aBU1NTYl1v7TzJeEGdQIIURCPHj1CcXGxxMQ6H4e0fzRHjx6FkpIS3N3dRcpPnDiBkpISdOvWjfOYsbGxiI2NlfjtfMuWLZzFcXV1hbKyMgICAmBqaio24tGoUSPOYsnTpxMDO3TogMjISOjr61duoxQYv7IbQAiRj2HDhol9qwRK19UPGzZM/g3iQEBAgMRvxAKBAAEBAZzHCwoKQpcuXRAbG4vXr18jOztb5OBSUlISNm7ciG7duqFx48Zo1KiRyPGjqlatGl6+fAkAcnmUQ76M5gQQoiASExPh6uoqVt6yZUtMmDChElpUcffv35eYV79BgwZ48OAB5/E2bNiAbdu2YciQIZxf+3N2dnZ4/fq1zOPIm7a2Nv777z/UqFEDZ86cQVFRUWU3SaFRJ4AQBcHj8SSmB3779u0P+3xZT08PDx8+FHuU8eDBA5nkPygsLISLiwvn15Vk6dKlmDFjBhYvXgwHBwexDISfr7X/UXw6MZAxRhMDKxnNCSBEQXh4eEBDQwO7d++GkpISgNI17t7e3sjLy8OxY8cquYXl9/PPP+PixYuIjIxE3bp1AZR2APr27YtmzZph8+bNnMabOXMmtLW15ZKS+NNliZ+iiYGES9QJIERB3LlzB23/r707j4qqfv8A/p6BOSxiSoIC7giZgJOQHhVDj7gAhbgl6tFEHbfERAyOW/hVM1MMj9vppBUgiLgglno6omDpSCWSgUtuA+SGaIWDgqLI3N8fHeYX4oozXO7M+/WXc+9tnkf/6D7zWZ5P375o3ry5/uhgtVqNO3fu4PDhw/Dy8hI5w5dXVlaGwMBA5Obmok2bNgCAa9euwc/PD+np6QZfcBYREYGkpCQolUoolco6v87XrFljsFhHjhx55v1+/foZLJZYuDBQfCwCiMxIcXExNm7ciPz8fNjY2ECpVGLWrFl4/fXXxU6t3gRBwKFDh2r9nfr27WuUWP3793/qPZlMxuHreqpZ+9CQ/RfoXywCiMgkVFZWwsrKyqRWnKvVamzatAmFhYXYtWsXWrdujeTkZHTs2BHvvPOO2Om9Eq1Wi0WLFmHHjh36nRX29vYYM2YMli9fztGBBsItgkRmRK1WY/z48fD19cX169cBAMnJyTh27JjImdWPTqfDp59+itatW8POzg5FRUUAgJiYGHz77bdGi6vRaJCRkYH79+8DQJ1Wwoawe/duBAQEwMbGBidPntQfTlRWVoYVK1YYPF5DKi0tRc+ePbFlyxaMHDkScXFxiIuL07e57t27t8G3XNJTNOSRhUQknrS0NMHGxkaYMmWKYGVlJRQUFAiCIAgbNmwQgoKCRM6ufpYuXSq4uroKW7duFWxsbPR/p+3btwu9evUyeLy///5b8Pf3F2QymSCXy/XxJk2aJMydO9egsbp16yZs2bJFEARBsLOz08c6efKk0KpVK4PGamgRERGCl5eXUFJSUufejRs3hK5duwpz5swRITPzw5EAIjOxfPlyfPXVV/j6669rLWjr06ePZI+lTUpKwubNmzFu3Dj9jgfg325658+fN3i8yMhIKBQKXLlypdaK9tGjR+PAgQMGjXXhwoUnrm1o1qwZtFqtQWM1tO+++w5ffPEFWrVqVeeek5MTYmNjsWfPHhEyMz/sE0BkJkzxpXL9+nW4ubnVua7T6YzShObgwYPIyMjQ70So4e7ujsuXLxs0lpOTEzQaTZ0eCMeOHYOrq6tBYzW0GzduwNPT86n3vby8UFJS0oAZmS+OBBCZiZqXyuOk/FLx8PCAWq2ucz0tLQ3e3t4Gj1dRUfHEPe2lpaWwsrIyaKypU6ciIiICx48fh0wmQ3FxMVJSUhAVFYUPP/zQoLEamoODA/7888+n3i8qKpL0jhUp4UgAkZmoeanEx8frXyq//PILPv74YyxevFjs9Opl8eLFCAsLw/Xr16HT6ZCeno4LFy4gKSkJ+/fvN3g8Pz8/JCUl4dNPPwXw77ZAnU6H2NjYZ24frI/58+dDp9NhwIABuHfvHvr27QsrKytERUXho48+MmishhYQEIBFixbh0KFDdboFPnjwADExMQgMDBQpO/PCLYJEZkIQBKxYsQKff/457t27BwCwsrJCdHQ0FixYABsbG5EzrB+1Wo1ly5YhPz8f5eXl8PHxweLFizF48GCDxzpz5gwGDBgAHx8fHD58GCEhITh79ixKS0uRnZ2t71poSA8fPoRGo0F5eTk8PDxgZ2dn8BgN7dq1a+jevTusrKwQHh6ON998E4Ig4Ny5c/jyyy/x4MED5Obmom3btmKnavJYBBCZmcdfKps2bcLq1atNbg42NzcX3bt3N/j3lpWV6Rsu1RQd4eHhcHZ2NmicrVu3YsSIEU9tqSt1RUVFmDlzJg4ePKjfYimTyTBo0CBs3LjxiWs9yPBYBBCZuAcPHmDJkiU4dOiQ/pf/sGHDkJCQgE8++QQWFhYIDw/HvHnzxE71pZWXl8PCwqLWKEZeXh5iYmLwww8/SLa/PgA4Ojri/v37CAkJwfjx4xEQEFBrB4SpuH37Ni5dugQAcHNze+JagGvXrsHFxUV/ngIZDosAIhM3b948bNq0CQMHDsTPP/+Mv/76C5MmTcKvv/6KhQsXYtSoUZJ7uVy9ehWhoaHIycmBhYUFZs2aheXLl2PGjBnYsWMHhg8fjsjISPTs2fOVY506deqFn1Uqla8cr8ajR49w4MABpKam4vvvv4etrS1GjRqFcePGNdhJho3Fa6+9hry8PMkuYG3MuDCQyMTt2rULSUlJCAkJwZkzZ6BUKvHo0SPk5+dLtsVudHQ0KisrsW7dOqSnp2PdunVQq9Xo2bMnCgoK6mzhexXdunWDTCZ7bldAQ5/sZ2lpieDgYAQHB+PevXvYs2cPtm3bhv79+6NNmzYoKCgwWKzGjr9VjYdFAJGJu3btGt5++20A/+6/trKyQmRkpGQLAAA4evQo0tPT0atXL4SGhsLJyQnjxo3DnDlzDB6rphWxmGxtbREQEIDbt2/j8uXLOHfunNgpkYlgEUBk4qqrq2ttw7K0tJT8CvObN2+iY8eOAICWLVvC1tYWQUFBRonVvn17o3zvi6gZAUhJSUFWVhbatm2LsWPHIi0tTbScyLSwCCAycYIgYOLEifpmNpWVlZgxYwaaNGlS67n09HQx0qu3/y4Sk8vldfabG0tBQQHWrl2r/zXu4eGBiIgIg28PHDNmDPbv3w9bW1uEhoYiJiYGvXv3NmgMIhYBRCYuLCys1ufx48eLlInhCIKAN954Qz+lUV5eDm9v7zqrx0tLSw0aNyMjAyEhIejWrRv69OkDAMjOzoanpyf27duHQYMGGSyWhYUFdu7cabK7Al6GlKeuGjvuDiAiydmyZcsLPfd4AfSqvL29ERAQgJUrV9a6Pn/+fBw8eFCyBzE1dk2bNkV+fj53BxgBiwAiMnmpqakICQmpMwXysqytrXH69Gm4u7vXun7x4kUolUpUVla+0vf/17Jly555X6qtnmtUVVXBxsYGeXl58PLyeuazV69ehYuLi9mPiBgDpwOIyORNnz4dPXv2fOVfko6OjsjLy6tTBOTl5aFly5av9N2Pe/wo3aqqKhQVFcHS0hKdOnWSfBGgUCjQrl27F9pWyfbBxsMigIhMnqEGPKdOnYpp06ahsLBQ37AnOzsbq1atwty5cw0So8bvv/9e59qdO3cwceJEDB8+3KCxxLJo0SIsXLgQycnJPDVQJJwOICKTZ6g5ZUEQsHbtWsTFxaG4uBgA4OLigujoaMyePbtBFrCdPn0aQ4YMeeZRvFLh7e0NjUaDqqoqtG/fvs50DddYGB9HAoiIXpBMJkNkZCQiIyNx9+5dAP8WGA2prKwMZWVlDRrTWIYNGyZ2CmaPRQARUT0Y++W/fv36Wp8FQcCNGzeQnJxstMZIDe1///uf2CmYPU4HEJHJe5XpAB8fH2RlZcHe3h7e3t7PHPI35PB1TUfEGnK5HI6OjvD398eCBQsafATCmH777Td98yVPT094e3uLnJH54EgAEZm89u3bQ6FQ1Ou/HTp0KIqLi2Fvb9+gw9eN4cwCY7t16xbGjBmDn376Cc2bNwcAaLVa9O/fH9u3b4ejo6O4CZoBjgQQkWS5urrixIkTaNGiRa3rWq0WPj4+KCwsNEgcuVyOHj16QKVSYezYsUb9FT5ixIjnPmNpaQknJycMGjQIQ4YMMVouxjZ69GgUFhYiKSkJXbp0AQD88ccfCAsLg5ubG1JTU0XO0PSxCCAiyZLL5SgpKamzR//mzZto164dHjx4YJA4arUaCQkJSEtLg06nw/vvvw+VSgU/Pz+DfP9/TZo06bnP6HQ63Lp1C0eOHEFUVNRzGws1Vs2aNUNmZiZ69OhR63pOTg4GDx4MrVYrTmJmhNMBRCQ5e/fu1f85IyMDzZo103+urq5GVlYWOnToYLB4fn5+8PPzw4YNG7Bz504kJiaiX79+cHNzg0qlQlhYGJycnAwSKyEh4YWf3b9/P2bOnCnZIkCn0z1xmkahUECn04mQkfnhSAARSU7NQUEymaxOIyCFQoEOHTogLi4OwcHBRstBo9EgISEBycnJKCkpQWBgYK3ipCFotVpMnjxZcidA1hg6dCi0Wi1SU1Ph4uICALh+/TrGjRsHe3v7Ol0TyfBYBBCRZHXs2BEnTpyAg4ODKPErKiqQkpKCBQsWQKvVvlALXPp/V69eRUhICM6ePatvDXz16lV4eXlh7969aNOmjcgZmj4WAUREL+no0aOIj4/H7t27IZfLERoaCpVKhV69eomdmuQIgoDMzEycP38eANClSxcMHDhQ5KzMB4sAIpK0rKwsZGVl4datW3XmkePj4w0Wp7i4GImJiUhMTIRGo4Gvry9UKhVCQ0Nf+XRCIrFwYSARSdbSpUuxbNkydO/eHc7Ozkbr3R8UFITMzEw4ODhgwoQJmDx5Mjp37myUWKZu/fr1mDZtGqytret0RXzc7NmzGygr88WRACKSLGdnZ8TGxuKDDz4wapyQkBCoVCoEBwfzTPtX1LFjR+Tm5qJFixZ1uiL+l0wmM1ifB3o6FgFEJFktWrRATk4OOnXqJHYqRJIkFzsBIqL6mjJlCrZt2yZ2GlQPVVVV6NSpk/7MABIH1wQQkWRVVlZi8+bNyMzMhFKprNN4Zs2aNSJlRs+jUChQWVkpdhpmj9MBRCRZ/fv3f+o9mUyGw4cPN2A29LJWrFiBixcv4ptvvoGlJX+TioFFABERiWL48OHIysqCnZ0dunbtWmerpVQ7IUoJSy8ikjyNRoOCggL07dsXNjY2EATBaNsFyXCaN2+OkSNHip2GWWMRQESS9c8//yA0NBQ//vgjZDIZLl26BFdXV6hUKtjb2yMuLk7sFOkJdDodVq9ejYsXL+Lhw4fw9/fHkiVLYGNjI3ZqZoe7A4hIsiIjI6FQKHDlyhXY2trqr48ePRoHDhwQMTN6ls8++wwLFy6EnZ0dWrdujfXr1yM8PFzstMwS1wQQkWQ5OTkhIyMDb731Fpo2bYr8/Hy4urqisLAQSqUS5eXlYqdIT+Du7o6oqChMnz4dAJCZmYn33nsP9+/f158QSQ2D/9pEJFkVFRW1RgBqlJaWwsrKSoSM6EVcuXIF7777rv7zwIEDIZPJUFxcLGJW5olFABFJlp+fH5KSkvSfZTIZdDodYmNjn7l9kMT16NEjWFtb17qmUChQVVUlUkbmi9MBRCRZZ86cwYABA+Dj44PDhw/rz6YvLS1FdnY22wk3UnK5HEFBQbVGa/bt2wd/f/9a2wS5RdD4WAQQkaSVlZVh48aNyM/PR3l5OXx8fBAeHg5nZ2exU6OnmDRp0gs9l5CQYORMiEUAERGRmWKfACKSlFOnTr3ws0ql0oiZEEkfRwKISFLkcjlkMhme978umUyG6urqBsqKSJo4EkBEklJUVCR2CkQmgyMBREREZoojAUQkaQUFBVi7di3OnTsHAPDw8EBERAS3BxK9ADYLIiLJysjIgIeHB3JycqBUKqFUKnH8+HF4enri0KFDYqdH1OhxOoCIJMvb2xsBAQFYuXJlrevz58/HwYMHcfLkSZEyI5IGFgFEJFnW1tY4ffo03N3da12/ePEilEolKisrRcqMSBo4HUBEkuXo6Ii8vLw61/Py8tCyZcuGT4hIYrgwkIgka+rUqZg2bRoKCwvh6+sLAMjOzsaqVaswd+5ckbMjavw4HUBEkiUIAtauXYu4uDj9MbQuLi6Ijo7G7NmzIZPJRM6QqHFjEUBEJuHu3bsAgKZNm4qcCZF0sAggIiIyU1wTQESS4uPjg6ysLNjb28Pb2/uZQ/7cIkj0bCwCiEhShg4diuLiYtjb22PYsGFip0MkaZwOICLJkcvl6NGjB1QqFcaOHct1AET1xD4BRCQ5R44cgaenJ6KiouDs7IyJEydCrVaLnRaR5HAkgIgkq6KiAjt37kRiYiLUajXc3NygUqkQFhYGJycnsdMjavRYBBCRSdBoNEhISEBycjJKSkoQGBiIvXv3ip0WUaPGIoCITEZFRQVSUlKwYMECaLVaVFdXi50SUaPG3QFEJHlHjx5FfHw8du/eDblcjtDQUKhUKrHTImr0OBJARJJUXFyMxMREJCYmQqPRwNfXFyqVCqGhoWjSpInY6RFJAkcCiEhygoKCkJmZCQcHB0yYMAGTJ09G586dxU6LSHJYBBCR5CgUCqSlpSE4OBgWFhZip0MkWZwOICIiMlNsFkRERGSmWAQQERGZKRYBREREZopFABERkZliEUBERGSmWAQQERGZKRYBREREZur/APfgjJ2CFGJEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_no_Violent_Recidivist = df_train_enc.drop(columns = 'Violent_Recidivist')\n",
    "plt.figure(figsize=(4, 3))\n",
    "g = sns.heatmap(df_train_no_Violent_Recidivist.corr(),\n",
    "                annot = False,\n",
    "                cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.747</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.934     0.359                0.012   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.747               28              133   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       2439  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_train = df_train_enc['Violent_Recidivist']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_test = df_test_enc['Violent_Recidivist']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_val = df_val_enc['Violent_Recidivist']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_holdout = df_holdout_enc['Violent_Recidivist']\n",
    "\n",
    "classifier_train = RandomForestClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()\n",
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione √® giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  race  Recidivism_Risk  Risk_Level  Violent_Recidivism_Risk  \\\n",
       "10676    1     0                4           1                        2   \n",
       "13123    1     2                1           1                        1   \n",
       "2611     1     0                8           0                        6   \n",
       "7945     1     2                1           1                        1   \n",
       "5727     1     2                6           2                        6   \n",
       "\n",
       "       Violent_Risk_Level  Juvenile_Offenses  age_group  Prior_Offensesgroup  \\\n",
       "10676                   1                  0          3                    7   \n",
       "13123                   1                  0          3                    0   \n",
       "2611                    2                  2          2                    1   \n",
       "7945                    1                  0          5                    0   \n",
       "5727                    2                  0          1                    0   \n",
       "\n",
       "       y_val_true  y_pred  \n",
       "10676           0       0  \n",
       "13123           0       0  \n",
       "2611            0       0  \n",
       "7945            0       0  \n",
       "5727            0       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set\n",
    "y_pred_val_dt = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val_dt\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Violent_Recidivist</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>6-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>35-44</td>\n",
       "      <td>11-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>65-100</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex              race  Recidivism_Risk  Violent_Recidivist Risk_Level  \\\n",
       "10676  Male  African-American                4                   0        Low   \n",
       "13123  Male         Caucasian                1                   0        Low   \n",
       "2611   Male  African-American                8                   0       High   \n",
       "7945   Male         Caucasian                1                   0        Low   \n",
       "5727   Male         Caucasian                6                   0     Medium   \n",
       "\n",
       "       Violent_Recidivism_Risk Violent_Risk_Level  Juvenile_Offenses  \\\n",
       "10676                        2                Low                  0   \n",
       "13123                        1                Low                  0   \n",
       "2611                         6             Medium                  2   \n",
       "7945                         1                Low                  0   \n",
       "5727                         6             Medium                  0   \n",
       "\n",
       "      age_group Prior_Offensesgroup  y_pred  error  \n",
       "10676     45-54                6-10       0      0  \n",
       "13123     45-54                 0-5       0      0  \n",
       "2611      35-44               11-15       0      0  \n",
       "7945     65-100                 0-5       0      0  \n",
       "5727      25-34                 0-5       0      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione √® giusta 0 se la predizione √® sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['error'] = (df_val_class['y_val_true'] != df_val_class['y_pred']).astype(int)\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['sex', 'race', 'Recidivism_Risk', 'Risk_Level', 'Violent_Recidivism_Risk', 'Violent_Risk_Level', 'Juvenile_Offenses', 'age_group', 'Prior_Offensesgroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>error</th>\n",
       "      <th>error_div</th>\n",
       "      <th>error_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107</td>\n",
       "      <td>(Risk_Level=High, age_group=25-34, sex=Male)</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.099</td>\n",
       "      <td>4.295</td>\n",
       "      <td>3</td>\n",
       "      <td>262.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.103</td>\n",
       "      <td>(Risk_Level=High, Violent_Risk_Level=High, sex=Male)</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.099</td>\n",
       "      <td>4.193</td>\n",
       "      <td>3</td>\n",
       "      <td>251.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.112</td>\n",
       "      <td>(Risk_Level=High, Violent_Risk_Level=High)</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.089</td>\n",
       "      <td>4.025</td>\n",
       "      <td>2</td>\n",
       "      <td>273.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.132</td>\n",
       "      <td>(Violent_Risk_Level=High, sex=Male)</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.078</td>\n",
       "      <td>3.908</td>\n",
       "      <td>2</td>\n",
       "      <td>321.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.123</td>\n",
       "      <td>(Risk_Level=High, age_group=25-34)</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.078</td>\n",
       "      <td>3.790</td>\n",
       "      <td>2</td>\n",
       "      <td>301.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support                                               itemset  error  \\\n",
       "0    0.107          (Risk_Level=High, age_group=25-34, sex=Male)  0.168   \n",
       "1    0.103  (Risk_Level=High, Violent_Risk_Level=High, sex=Male)  0.167   \n",
       "2    0.112            (Risk_Level=High, Violent_Risk_Level=High)  0.158   \n",
       "3    0.132                   (Violent_Risk_Level=High, sex=Male)  0.146   \n",
       "4    0.123                    (Risk_Level=High, age_group=25-34)  0.146   \n",
       "\n",
       "   error_div  error_t  length  support_count  \n",
       "0      0.099    4.295       3        262.000  \n",
       "1      0.099    4.193       3        251.000  \n",
       "2      0.089    4.025       2        273.000  \n",
       "3      0.078    3.908       2        321.000  \n",
       "4      0.078    3.790       2        301.000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_diver = DivergenceExplorer(df_val)\n",
    "FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"error_div\", \"error_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pruning \n",
    "error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = FP_fm\n",
    "df_pruned_error = FP_fm\n",
    "#df_pruned_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 351\n",
      "total problematic 30\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_error)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_error[(df_pruned_error['error_div'] > 0) & (df_pruned_error['error_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (351, 7)\n",
      "Dim pruned th_redundancy  (351, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_error.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset_and_or li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488\n"
     ]
    }
   ],
   "source": [
    "print(len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "TRAIN SET MITIGATED ROWS:  11463\n",
      "VALIDATION SET ROWS:  2439\n",
      "FILTERED DF holdout ROWS:  488\n",
      "TEST SET FILTERED ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['Violent_Recidivist']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "#cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488\n",
      "verifica : 488\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"Violent_Recidivist\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.747</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.747</td>\n",
       "      <td>25</td>\n",
       "      <td>133</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.747</td>\n",
       "      <td>30</td>\n",
       "      <td>133</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.934     0.359                0.012   \n",
       "After Mitigation(K=5, fp)     0.935     0.363                0.011   \n",
       "After RANDOM mitigation       0.933     0.356                0.013   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.747               28   \n",
       "After Mitigation(K=5, fp)                0.747               25   \n",
       "After RANDOM mitigation                  0.747               30   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      133       10975       2439  \n",
       "After Mitigation(K=5, fp)              133       11463       2439  \n",
       "After RANDOM mitigation                133       11463       2439  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE\n",
    "\n",
    "\n",
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.363</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.031</td>\n",
       "      <td>488.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.356</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.032</td>\n",
       "      <td>488.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.934     0.359            -0.009   \n",
       "After Mitigation(K=5 fp)            0.935     0.363            -0.008   \n",
       "After RANDOM Mitigation(K=5 fp)     0.933     0.356            -0.009   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.054               0.045   \n",
       "After Mitigation(K=5 fp)           0.059               0.047   \n",
       "After RANDOM Mitigation(K=5 fp)    0.057               0.047   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.040               0.031   \n",
       "After Mitigation(K=5 fp)                      0.040               0.031   \n",
       "After RANDOM Mitigation(K=5 fp)               0.041               0.032   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)               488.000  \n",
       "After RANDOM Mitigation(K=5 fp)        488.000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = FP_fm\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_no_mitigation  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_no_mitigation\n",
    "\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = FP_fm\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_baseline1  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_baseline1\n",
    "\n",
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = FP_fm\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_random_per_confrontare_con_baseline1  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_random_per_confrontare_con_baseline1\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_error_div_list_no_mitigation = np.nanmean(error_div_list_no_mitigation)\n",
    "media_error_div_list_nomitigation_primi10 = np.nanmean(error_div_list_no_mitigation[:10])\n",
    "media_error_div_list_nomitigation_primi20 = np.nanmean(error_div_list_no_mitigation[:20])\n",
    "media_error_div_list_nomitigation_primi40 = np.nanmean(error_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_error_div_no_mitigation = max(abs(x) for x in error_div_list_no_mitigation)\n",
    "\n",
    "media_error_div_list_baseline1 = np.nanmean(error_div_list_baseline1)\n",
    "media_error_div_list_baseline1_primi10 = np.nanmean(error_div_list_baseline1[:10])\n",
    "media_error_div_list_baseline1_primi20 = np.nanmean(error_div_list_baseline1[:20])\n",
    "media_error_div_list_baseline1_primi40 = np.nanmean(error_div_list_baseline1[:40])\n",
    "error_div_massimo_valore_assoluto_error_div_baseline1 = max(abs(x) for x in error_div_list_baseline1)\n",
    "\n",
    "media_error_div_list_random_per_confrontare_con_baseline1 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1)\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_error_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in error_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_correctness_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_error_div_list_no_mitigation, massimo_valore_assoluto_error_div_no_mitigation,\n",
    "        media_error_div_list_nomitigation_primi10, media_error_div_list_nomitigation_primi20, media_error_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_error_div_list_baseline1, error_div_massimo_valore_assoluto_error_div_baseline1,\n",
    "        media_error_div_list_baseline1_primi10, media_error_div_list_baseline1_primi20, media_error_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_error_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_error_div_random_per_confrontare_con_baseline1, media_error_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_error_div_list_random_per_confrontare_con_baseline1_primi20, media_error_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_correctness_sottogruppi = divergence_after_correctness_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_correctness_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SIMULANDO DATI ATTRAVERSO SMOTE\n",
    "\n",
    "SEGUE CODICE USANDO SMOTE \n",
    "DIVIDO IN TRAIN, TEST E VALIDATION -- ora uso quelli gia esistenti\n",
    "DIV EXPLORER SUL VALIDATION  -- gi√† fatto \n",
    "GENERO NUOVI DATI CON SMOTE a partire dai dati di divexplorer sul validation\n",
    "INSERISCO QUESTI NUOVI DATI NEL TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato 541\n",
      "numero di dati simulati con smotenc 912\n",
      "Violent_Recidivist\n",
      "0    456\n",
      "1    456\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_val, K)\n",
    "print(\"Righe del dataset filtrato\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['error', 'y_pred', 'Violent_Recidivist'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered[\"Violent_Recidivist\"]\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 1, 7, 8]\n",
    "\n",
    "smote_nc = SMOTENC( categorical_features=categorical_features, random_state=seed)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "\n",
    "print(\"numero di dati simulati con smotenc\",len(y_resampled))\n",
    "\n",
    "class_counts = y_resampled.value_counts()\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p √® la probabilit√† che il campione simulato sia di classe 0 qui (perch√® voglio diminuire il numero di falsi positivi)\n",
    "- FISSO p VARIA N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 456)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered['Violent_Recidivist'].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = np.arange(0.0, 1.05, 0.1)\n",
    "p_values = np.round(p_values, 2).tolist()\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = a targeted (holdout filtrato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.747</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 488</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.747</td>\n",
       "      <td>30</td>\n",
       "      <td>133</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 1 = 0.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.697</td>\n",
       "      <td>55</td>\n",
       "      <td>124</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 1 = 0.1</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.702</td>\n",
       "      <td>47</td>\n",
       "      <td>125</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 1 = 0.2</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.719</td>\n",
       "      <td>36</td>\n",
       "      <td>128</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 1 = 0.3</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.719</td>\n",
       "      <td>35</td>\n",
       "      <td>128</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 1 = 0.4</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.725</td>\n",
       "      <td>31</td>\n",
       "      <td>129</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 1 = 0.5</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.719</td>\n",
       "      <td>28</td>\n",
       "      <td>128</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 1 = 0.6</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.725</td>\n",
       "      <td>29</td>\n",
       "      <td>129</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 1 = 0.7</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.742</td>\n",
       "      <td>25</td>\n",
       "      <td>132</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 1 = 0.8</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.742</td>\n",
       "      <td>24</td>\n",
       "      <td>132</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 1 = 0.9</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.747</td>\n",
       "      <td>25</td>\n",
       "      <td>133</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 1 = 1.0</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.758</td>\n",
       "      <td>23</td>\n",
       "      <td>135</td>\n",
       "      <td>11463</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                              Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                       0.934     0.359                0.012   \n",
       "After RANDOM mitigation N = 488         0.933     0.356                0.013   \n",
       "After SMOTE N = 488 p_class 1 = 0.0     0.927     0.376                0.024   \n",
       "After SMOTE N = 488 p_class 1 = 0.1     0.929     0.381                0.021   \n",
       "After SMOTE N = 488 p_class 1 = 0.2     0.933     0.379                0.016   \n",
       "After SMOTE N = 488 p_class 1 = 0.3     0.933     0.380                0.015   \n",
       "After SMOTE N = 488 p_class 1 = 0.4     0.934     0.380                0.014   \n",
       "After SMOTE N = 488 p_class 1 = 0.5     0.936     0.391                0.012   \n",
       "After SMOTE N = 488 p_class 1 = 0.6     0.935     0.383                0.013   \n",
       "After SMOTE N = 488 p_class 1 = 0.7     0.936     0.369                0.011   \n",
       "After SMOTE N = 488 p_class 1 = 0.8     0.936     0.371                0.011   \n",
       "After SMOTE N = 488 p_class 1 = 0.9     0.935     0.363                0.011   \n",
       "After SMOTE N = 488 p_class 1 = 1.0     0.935     0.352                0.010   \n",
       "\n",
       "Metrics                              False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                  0.747               28   \n",
       "After RANDOM mitigation N = 488                    0.747               30   \n",
       "After SMOTE N = 488 p_class 1 = 0.0                0.697               55   \n",
       "After SMOTE N = 488 p_class 1 = 0.1                0.702               47   \n",
       "After SMOTE N = 488 p_class 1 = 0.2                0.719               36   \n",
       "After SMOTE N = 488 p_class 1 = 0.3                0.719               35   \n",
       "After SMOTE N = 488 p_class 1 = 0.4                0.725               31   \n",
       "After SMOTE N = 488 p_class 1 = 0.5                0.719               28   \n",
       "After SMOTE N = 488 p_class 1 = 0.6                0.725               29   \n",
       "After SMOTE N = 488 p_class 1 = 0.7                0.742               25   \n",
       "After SMOTE N = 488 p_class 1 = 0.8                0.742               24   \n",
       "After SMOTE N = 488 p_class 1 = 0.9                0.747               25   \n",
       "After SMOTE N = 488 p_class 1 = 1.0                0.758               23   \n",
       "\n",
       "Metrics                              False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                133       10975       2439  \n",
       "After RANDOM mitigation N = 488                  133       11463       2439  \n",
       "After SMOTE N = 488 p_class 1 = 0.0              124       11463       2439  \n",
       "After SMOTE N = 488 p_class 1 = 0.1              125       11463       2439  \n",
       "After SMOTE N = 488 p_class 1 = 0.2              128       11463       2439  \n",
       "After SMOTE N = 488 p_class 1 = 0.3              128       11463       2439  \n",
       "After SMOTE N = 488 p_class 1 = 0.4              129       11463       2439  \n",
       "After SMOTE N = 488 p_class 1 = 0.5              128       11463       2439  \n",
       "After SMOTE N = 488 p_class 1 = 0.6              129       11463       2439  \n",
       "After SMOTE N = 488 p_class 1 = 0.7              132       11463       2439  \n",
       "After SMOTE N = 488 p_class 1 = 0.8              132       11463       2439  \n",
       "After SMOTE N = 488 p_class 1 = 0.9              133       11463       2439  \n",
       "After SMOTE N = 488 p_class 1 = 1.0              135       11463       2439  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df_holdout_filtered)\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = RandomForestClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = FP_fm\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>161</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 488</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.356</td>\n",
       "      <td>30</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 0 = 0.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.376</td>\n",
       "      <td>55</td>\n",
       "      <td>124</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 0 = 0.1</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.381</td>\n",
       "      <td>47</td>\n",
       "      <td>125</td>\n",
       "      <td>172</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 0 = 0.2</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.379</td>\n",
       "      <td>36</td>\n",
       "      <td>128</td>\n",
       "      <td>164</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 0 = 0.3</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.380</td>\n",
       "      <td>35</td>\n",
       "      <td>128</td>\n",
       "      <td>163</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 0 = 0.4</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.380</td>\n",
       "      <td>31</td>\n",
       "      <td>129</td>\n",
       "      <td>160</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 0 = 0.5</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.391</td>\n",
       "      <td>28</td>\n",
       "      <td>128</td>\n",
       "      <td>156</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 0 = 0.6</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.383</td>\n",
       "      <td>29</td>\n",
       "      <td>129</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 0 = 0.7</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.369</td>\n",
       "      <td>25</td>\n",
       "      <td>132</td>\n",
       "      <td>157</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 0 = 0.8</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.371</td>\n",
       "      <td>24</td>\n",
       "      <td>132</td>\n",
       "      <td>156</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 0 = 0.9</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.363</td>\n",
       "      <td>25</td>\n",
       "      <td>133</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 488 p_class 0 = 1.0</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.352</td>\n",
       "      <td>23</td>\n",
       "      <td>135</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                              Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                       0.934     0.359               28   \n",
       "After RANDOM mitigation N = 488         0.933     0.356               30   \n",
       "After SMOTE N = 488 p_class 0 = 0.0     0.927     0.376               55   \n",
       "After SMOTE N = 488 p_class 0 = 0.1     0.929     0.381               47   \n",
       "After SMOTE N = 488 p_class 0 = 0.2     0.933     0.379               36   \n",
       "After SMOTE N = 488 p_class 0 = 0.3     0.933     0.380               35   \n",
       "After SMOTE N = 488 p_class 0 = 0.4     0.934     0.380               31   \n",
       "After SMOTE N = 488 p_class 0 = 0.5     0.936     0.391               28   \n",
       "After SMOTE N = 488 p_class 0 = 0.6     0.935     0.383               29   \n",
       "After SMOTE N = 488 p_class 0 = 0.7     0.936     0.369               25   \n",
       "After SMOTE N = 488 p_class 0 = 0.8     0.936     0.371               24   \n",
       "After SMOTE N = 488 p_class 0 = 0.9     0.935     0.363               25   \n",
       "After SMOTE N = 488 p_class 0 = 1.0     0.935     0.352               23   \n",
       "\n",
       "Metrics                              False Negatives  Total Errors  \\\n",
       "Before Mitigation                                133           161   \n",
       "After RANDOM mitigation N = 488                  133           163   \n",
       "After SMOTE N = 488 p_class 0 = 0.0              124           179   \n",
       "After SMOTE N = 488 p_class 0 = 0.1              125           172   \n",
       "After SMOTE N = 488 p_class 0 = 0.2              128           164   \n",
       "After SMOTE N = 488 p_class 0 = 0.3              128           163   \n",
       "After SMOTE N = 488 p_class 0 = 0.4              129           160   \n",
       "After SMOTE N = 488 p_class 0 = 0.5              128           156   \n",
       "After SMOTE N = 488 p_class 0 = 0.6              129           158   \n",
       "After SMOTE N = 488 p_class 0 = 0.7              132           157   \n",
       "After SMOTE N = 488 p_class 0 = 0.8              132           156   \n",
       "After SMOTE N = 488 p_class 0 = 0.9              133           158   \n",
       "After SMOTE N = 488 p_class 0 = 1.0              135           158   \n",
       "\n",
       "Metrics                              Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                             -0.009           0.054   \n",
       "After RANDOM mitigation N = 488               -0.009           0.057   \n",
       "After SMOTE N = 488 p_class 0 = 0.0           -0.012           0.093   \n",
       "After SMOTE N = 488 p_class 0 = 0.1           -0.011           0.061   \n",
       "After SMOTE N = 488 p_class 0 = 0.2           -0.009           0.059   \n",
       "After SMOTE N = 488 p_class 0 = 0.3           -0.009           0.057   \n",
       "After SMOTE N = 488 p_class 0 = 0.4           -0.009           0.061   \n",
       "After SMOTE N = 488 p_class 0 = 0.5           -0.008           0.052   \n",
       "After SMOTE N = 488 p_class 0 = 0.6           -0.008           0.051   \n",
       "After SMOTE N = 488 p_class 0 = 0.7           -0.008           0.055   \n",
       "After SMOTE N = 488 p_class 0 = 0.8           -0.008           0.052   \n",
       "After SMOTE N = 488 p_class 0 = 0.9           -0.008           0.051   \n",
       "After SMOTE N = 488 p_class 0 = 1.0           -0.008           0.050   \n",
       "\n",
       "Metrics                              Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                         0.045       0.040       0.031  \n",
       "After RANDOM mitigation N = 488           0.047       0.041       0.032  \n",
       "After SMOTE N = 488 p_class 0 = 0.0       0.077       0.065       0.044  \n",
       "After SMOTE N = 488 p_class 0 = 0.1       0.055       0.049       0.036  \n",
       "After SMOTE N = 488 p_class 0 = 0.2       0.046       0.041       0.031  \n",
       "After SMOTE N = 488 p_class 0 = 0.3       0.046       0.041       0.032  \n",
       "After SMOTE N = 488 p_class 0 = 0.4       0.044       0.038       0.030  \n",
       "After SMOTE N = 488 p_class 0 = 0.5       0.039       0.034       0.028  \n",
       "After SMOTE N = 488 p_class 0 = 0.6       0.039       0.034       0.027  \n",
       "After SMOTE N = 488 p_class 0 = 0.7       0.039       0.034       0.027  \n",
       "After SMOTE N = 488 p_class 0 = 0.8       0.037       0.032       0.027  \n",
       "After SMOTE N = 488 p_class 0 = 0.9       0.041       0.036       0.029  \n",
       "After SMOTE N = 488 p_class 0 = 1.0       0.041       0.036       0.029  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_confronto = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_confronto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.747</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 500</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.742</td>\n",
       "      <td>28</td>\n",
       "      <td>132</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.0</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.680</td>\n",
       "      <td>54</td>\n",
       "      <td>121</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.1</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.702</td>\n",
       "      <td>39</td>\n",
       "      <td>125</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.2</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.719</td>\n",
       "      <td>35</td>\n",
       "      <td>128</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.3</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.725</td>\n",
       "      <td>34</td>\n",
       "      <td>129</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.4</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.725</td>\n",
       "      <td>36</td>\n",
       "      <td>129</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.5</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.725</td>\n",
       "      <td>27</td>\n",
       "      <td>129</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.6</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.725</td>\n",
       "      <td>25</td>\n",
       "      <td>129</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.7</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.736</td>\n",
       "      <td>24</td>\n",
       "      <td>131</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.8</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.730</td>\n",
       "      <td>25</td>\n",
       "      <td>130</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.9</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.758</td>\n",
       "      <td>24</td>\n",
       "      <td>135</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 1.0</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.758</td>\n",
       "      <td>23</td>\n",
       "      <td>135</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                              Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                       0.934     0.359                0.012   \n",
       "After RANDOM mitigation N = 500         0.934     0.365                0.012   \n",
       "After SMOTE N = 500 p_class 1 = 0.0     0.928     0.394                0.024   \n",
       "After SMOTE N = 500 p_class 1 = 0.1     0.933     0.393                0.017   \n",
       "After SMOTE N = 500 p_class 1 = 0.2     0.933     0.380                0.015   \n",
       "After SMOTE N = 500 p_class 1 = 0.3     0.933     0.375                0.015   \n",
       "After SMOTE N = 500 p_class 1 = 0.4     0.932     0.373                0.016   \n",
       "After SMOTE N = 500 p_class 1 = 0.5     0.936     0.386                0.012   \n",
       "After SMOTE N = 500 p_class 1 = 0.6     0.937     0.389                0.011   \n",
       "After SMOTE N = 500 p_class 1 = 0.7     0.936     0.378                0.011   \n",
       "After SMOTE N = 500 p_class 1 = 0.8     0.936     0.382                0.011   \n",
       "After SMOTE N = 500 p_class 1 = 0.9     0.935     0.351                0.011   \n",
       "After SMOTE N = 500 p_class 1 = 1.0     0.935     0.352                0.010   \n",
       "\n",
       "Metrics                              False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                  0.747               28   \n",
       "After RANDOM mitigation N = 500                    0.742               28   \n",
       "After SMOTE N = 500 p_class 1 = 0.0                0.680               54   \n",
       "After SMOTE N = 500 p_class 1 = 0.1                0.702               39   \n",
       "After SMOTE N = 500 p_class 1 = 0.2                0.719               35   \n",
       "After SMOTE N = 500 p_class 1 = 0.3                0.725               34   \n",
       "After SMOTE N = 500 p_class 1 = 0.4                0.725               36   \n",
       "After SMOTE N = 500 p_class 1 = 0.5                0.725               27   \n",
       "After SMOTE N = 500 p_class 1 = 0.6                0.725               25   \n",
       "After SMOTE N = 500 p_class 1 = 0.7                0.736               24   \n",
       "After SMOTE N = 500 p_class 1 = 0.8                0.730               25   \n",
       "After SMOTE N = 500 p_class 1 = 0.9                0.758               24   \n",
       "After SMOTE N = 500 p_class 1 = 1.0                0.758               23   \n",
       "\n",
       "Metrics                              False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                133       10975       2439  \n",
       "After RANDOM mitigation N = 500                  132       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.0              121       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.1              125       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.2              128       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.3              129       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.4              129       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.5              129       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.6              129       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.7              131       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.8              130       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.9              135       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 1.0              135       11475       2439  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 500\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = RandomForestClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = FP_fm\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>161</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 500</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.365</td>\n",
       "      <td>28</td>\n",
       "      <td>132</td>\n",
       "      <td>160</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.0</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.394</td>\n",
       "      <td>54</td>\n",
       "      <td>121</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.1</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.393</td>\n",
       "      <td>39</td>\n",
       "      <td>125</td>\n",
       "      <td>164</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.2</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.380</td>\n",
       "      <td>35</td>\n",
       "      <td>128</td>\n",
       "      <td>163</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.3</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.375</td>\n",
       "      <td>34</td>\n",
       "      <td>129</td>\n",
       "      <td>163</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.4</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.373</td>\n",
       "      <td>36</td>\n",
       "      <td>129</td>\n",
       "      <td>165</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.5</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.386</td>\n",
       "      <td>27</td>\n",
       "      <td>129</td>\n",
       "      <td>156</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.6</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.389</td>\n",
       "      <td>25</td>\n",
       "      <td>129</td>\n",
       "      <td>154</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.7</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.378</td>\n",
       "      <td>24</td>\n",
       "      <td>131</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.8</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.382</td>\n",
       "      <td>25</td>\n",
       "      <td>130</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.9</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.351</td>\n",
       "      <td>24</td>\n",
       "      <td>135</td>\n",
       "      <td>159</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 1.0</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.352</td>\n",
       "      <td>23</td>\n",
       "      <td>135</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                              Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                       0.934     0.359               28   \n",
       "After RANDOM mitigation N = 500         0.934     0.365               28   \n",
       "After SMOTE N = 500 p_class 0 = 0.0     0.928     0.394               54   \n",
       "After SMOTE N = 500 p_class 0 = 0.1     0.933     0.393               39   \n",
       "After SMOTE N = 500 p_class 0 = 0.2     0.933     0.380               35   \n",
       "After SMOTE N = 500 p_class 0 = 0.3     0.933     0.375               34   \n",
       "After SMOTE N = 500 p_class 0 = 0.4     0.932     0.373               36   \n",
       "After SMOTE N = 500 p_class 0 = 0.5     0.936     0.386               27   \n",
       "After SMOTE N = 500 p_class 0 = 0.6     0.937     0.389               25   \n",
       "After SMOTE N = 500 p_class 0 = 0.7     0.936     0.378               24   \n",
       "After SMOTE N = 500 p_class 0 = 0.8     0.936     0.382               25   \n",
       "After SMOTE N = 500 p_class 0 = 0.9     0.935     0.351               24   \n",
       "After SMOTE N = 500 p_class 0 = 1.0     0.935     0.352               23   \n",
       "\n",
       "Metrics                              False Negatives  Total Errors  \\\n",
       "Before Mitigation                                133           161   \n",
       "After RANDOM mitigation N = 500                  132           160   \n",
       "After SMOTE N = 500 p_class 0 = 0.0              121           175   \n",
       "After SMOTE N = 500 p_class 0 = 0.1              125           164   \n",
       "After SMOTE N = 500 p_class 0 = 0.2              128           163   \n",
       "After SMOTE N = 500 p_class 0 = 0.3              129           163   \n",
       "After SMOTE N = 500 p_class 0 = 0.4              129           165   \n",
       "After SMOTE N = 500 p_class 0 = 0.5              129           156   \n",
       "After SMOTE N = 500 p_class 0 = 0.6              129           154   \n",
       "After SMOTE N = 500 p_class 0 = 0.7              131           155   \n",
       "After SMOTE N = 500 p_class 0 = 0.8              130           155   \n",
       "After SMOTE N = 500 p_class 0 = 0.9              135           159   \n",
       "After SMOTE N = 500 p_class 0 = 1.0              135           158   \n",
       "\n",
       "Metrics                              Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                             -0.009           0.054   \n",
       "After RANDOM mitigation N = 500               -0.009           0.057   \n",
       "After SMOTE N = 500 p_class 0 = 0.0           -0.011           0.086   \n",
       "After SMOTE N = 500 p_class 0 = 0.1           -0.009           0.060   \n",
       "After SMOTE N = 500 p_class 0 = 0.2           -0.009           0.064   \n",
       "After SMOTE N = 500 p_class 0 = 0.3           -0.009           0.057   \n",
       "After SMOTE N = 500 p_class 0 = 0.4           -0.010           0.059   \n",
       "After SMOTE N = 500 p_class 0 = 0.5           -0.008           0.052   \n",
       "After SMOTE N = 500 p_class 0 = 0.6           -0.007           0.053   \n",
       "After SMOTE N = 500 p_class 0 = 0.7           -0.007           0.048   \n",
       "After SMOTE N = 500 p_class 0 = 0.8           -0.007           0.048   \n",
       "After SMOTE N = 500 p_class 0 = 0.9           -0.008           0.051   \n",
       "After SMOTE N = 500 p_class 0 = 1.0           -0.008           0.050   \n",
       "\n",
       "Metrics                              Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                         0.045       0.040       0.031  \n",
       "After RANDOM mitigation N = 500           0.047       0.041       0.032  \n",
       "After SMOTE N = 500 p_class 0 = 0.0       0.074       0.061       0.042  \n",
       "After SMOTE N = 500 p_class 0 = 0.1       0.051       0.045       0.035  \n",
       "After SMOTE N = 500 p_class 0 = 0.2       0.050       0.043       0.033  \n",
       "After SMOTE N = 500 p_class 0 = 0.3       0.045       0.040       0.031  \n",
       "After SMOTE N = 500 p_class 0 = 0.4       0.044       0.039       0.031  \n",
       "After SMOTE N = 500 p_class 0 = 0.5       0.039       0.034       0.027  \n",
       "After SMOTE N = 500 p_class 0 = 0.6       0.039       0.034       0.028  \n",
       "After SMOTE N = 500 p_class 0 = 0.7       0.037       0.032       0.026  \n",
       "After SMOTE N = 500 p_class 0 = 0.8       0.037       0.032       0.026  \n",
       "After SMOTE N = 500 p_class 0 = 0.9       0.042       0.037       0.030  \n",
       "After SMOTE N = 500 p_class 0 = 1.0       0.041       0.036       0.029  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.747</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.747</td>\n",
       "      <td>26</td>\n",
       "      <td>133</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.0</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.669</td>\n",
       "      <td>84</td>\n",
       "      <td>119</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.1</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.680</td>\n",
       "      <td>69</td>\n",
       "      <td>121</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.2</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.691</td>\n",
       "      <td>68</td>\n",
       "      <td>123</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.3</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.691</td>\n",
       "      <td>62</td>\n",
       "      <td>123</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.4</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.702</td>\n",
       "      <td>41</td>\n",
       "      <td>125</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.5</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.708</td>\n",
       "      <td>36</td>\n",
       "      <td>126</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.6</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.730</td>\n",
       "      <td>30</td>\n",
       "      <td>130</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.7</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.725</td>\n",
       "      <td>27</td>\n",
       "      <td>129</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.8</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.736</td>\n",
       "      <td>25</td>\n",
       "      <td>131</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.9</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.758</td>\n",
       "      <td>23</td>\n",
       "      <td>135</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 1.0</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.764</td>\n",
       "      <td>22</td>\n",
       "      <td>136</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.934     0.359                0.012   \n",
       "After RANDOM mitigation N = 1000         0.935     0.361                0.011   \n",
       "After SMOTE N = 1000 p_class 1 = 0.0     0.917     0.368                0.037   \n",
       "After SMOTE N = 1000 p_class 1 = 0.1     0.922     0.375                0.031   \n",
       "After SMOTE N = 1000 p_class 1 = 0.2     0.922     0.365                0.030   \n",
       "After SMOTE N = 1000 p_class 1 = 0.3     0.924     0.373                0.027   \n",
       "After SMOTE N = 1000 p_class 1 = 0.4     0.932     0.390                0.018   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5     0.934     0.391                0.016   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6     0.934     0.375                0.013   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7     0.936     0.386                0.012   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8     0.936     0.376                0.011   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9     0.935     0.352                0.010   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0     0.935     0.347                0.010   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.747               28   \n",
       "After RANDOM mitigation N = 1000                    0.747               26   \n",
       "After SMOTE N = 1000 p_class 1 = 0.0                0.669               84   \n",
       "After SMOTE N = 1000 p_class 1 = 0.1                0.680               69   \n",
       "After SMOTE N = 1000 p_class 1 = 0.2                0.691               68   \n",
       "After SMOTE N = 1000 p_class 1 = 0.3                0.691               62   \n",
       "After SMOTE N = 1000 p_class 1 = 0.4                0.702               41   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5                0.708               36   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6                0.730               30   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7                0.725               27   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8                0.736               25   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9                0.758               23   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0                0.764               22   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 133       10975       2439  \n",
       "After RANDOM mitigation N = 1000                  133       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.0              119       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.1              121       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.2              123       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.3              123       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.4              125       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.5              126       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.6              130       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.7              129       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.8              131       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.9              135       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 1.0              136       11975       2439  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = RandomForestClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = FP_fm\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>161</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.361</td>\n",
       "      <td>26</td>\n",
       "      <td>133</td>\n",
       "      <td>159</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.0</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.368</td>\n",
       "      <td>84</td>\n",
       "      <td>119</td>\n",
       "      <td>203</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.1</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.375</td>\n",
       "      <td>69</td>\n",
       "      <td>121</td>\n",
       "      <td>190</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.2</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.365</td>\n",
       "      <td>68</td>\n",
       "      <td>123</td>\n",
       "      <td>191</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.3</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.373</td>\n",
       "      <td>62</td>\n",
       "      <td>123</td>\n",
       "      <td>185</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.4</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.390</td>\n",
       "      <td>41</td>\n",
       "      <td>125</td>\n",
       "      <td>166</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.5</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.391</td>\n",
       "      <td>36</td>\n",
       "      <td>126</td>\n",
       "      <td>162</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.6</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.375</td>\n",
       "      <td>30</td>\n",
       "      <td>130</td>\n",
       "      <td>160</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.7</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.386</td>\n",
       "      <td>27</td>\n",
       "      <td>129</td>\n",
       "      <td>156</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.8</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.376</td>\n",
       "      <td>25</td>\n",
       "      <td>131</td>\n",
       "      <td>156</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.9</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.352</td>\n",
       "      <td>23</td>\n",
       "      <td>135</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 1.0</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.347</td>\n",
       "      <td>22</td>\n",
       "      <td>136</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.934     0.359               28   \n",
       "After RANDOM mitigation N = 1000         0.935     0.361               26   \n",
       "After SMOTE N = 1000 p_class 0 = 0.0     0.917     0.368               84   \n",
       "After SMOTE N = 1000 p_class 0 = 0.1     0.922     0.375               69   \n",
       "After SMOTE N = 1000 p_class 0 = 0.2     0.922     0.365               68   \n",
       "After SMOTE N = 1000 p_class 0 = 0.3     0.924     0.373               62   \n",
       "After SMOTE N = 1000 p_class 0 = 0.4     0.932     0.390               41   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5     0.934     0.391               36   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6     0.934     0.375               30   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7     0.936     0.386               27   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8     0.936     0.376               25   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9     0.935     0.352               23   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0     0.935     0.347               22   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 133           161   \n",
       "After RANDOM mitigation N = 1000                  133           159   \n",
       "After SMOTE N = 1000 p_class 0 = 0.0              119           203   \n",
       "After SMOTE N = 1000 p_class 0 = 0.1              121           190   \n",
       "After SMOTE N = 1000 p_class 0 = 0.2              123           191   \n",
       "After SMOTE N = 1000 p_class 0 = 0.3              123           185   \n",
       "After SMOTE N = 1000 p_class 0 = 0.4              125           166   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5              126           162   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6              130           160   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7              129           156   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8              131           156   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9              135           158   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0              136           158   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                              -0.009           0.054   \n",
       "After RANDOM mitigation N = 1000               -0.009           0.057   \n",
       "After SMOTE N = 1000 p_class 0 = 0.0           -0.015           0.133   \n",
       "After SMOTE N = 1000 p_class 0 = 0.1           -0.013           0.104   \n",
       "After SMOTE N = 1000 p_class 0 = 0.2           -0.013           0.122   \n",
       "After SMOTE N = 1000 p_class 0 = 0.3           -0.013           0.106   \n",
       "After SMOTE N = 1000 p_class 0 = 0.4           -0.009           0.062   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5           -0.009           0.057   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6           -0.009           0.057   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7           -0.008           0.052   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8           -0.008           0.048   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9           -0.008           0.051   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0           -0.008           0.054   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.045       0.040       0.031  \n",
       "After RANDOM mitigation N = 1000           0.047       0.041       0.032  \n",
       "After SMOTE N = 1000 p_class 0 = 0.0       0.114       0.095       0.066  \n",
       "After SMOTE N = 1000 p_class 0 = 0.1       0.090       0.077       0.054  \n",
       "After SMOTE N = 1000 p_class 0 = 0.2       0.100       0.081       0.058  \n",
       "After SMOTE N = 1000 p_class 0 = 0.3       0.086       0.072       0.049  \n",
       "After SMOTE N = 1000 p_class 0 = 0.4       0.048       0.043       0.035  \n",
       "After SMOTE N = 1000 p_class 0 = 0.5       0.049       0.043       0.034  \n",
       "After SMOTE N = 1000 p_class 0 = 0.6       0.042       0.036       0.030  \n",
       "After SMOTE N = 1000 p_class 0 = 0.7       0.038       0.033       0.028  \n",
       "After SMOTE N = 1000 p_class 0 = 0.8       0.037       0.031       0.027  \n",
       "After SMOTE N = 1000 p_class 0 = 0.9       0.041       0.036       0.029  \n",
       "After SMOTE N = 1000 p_class 0 = 1.0       0.040       0.035       0.029  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_1000 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.747</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1500</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.736</td>\n",
       "      <td>29</td>\n",
       "      <td>131</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.0</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.629</td>\n",
       "      <td>118</td>\n",
       "      <td>112</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.1</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.674</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.2</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.674</td>\n",
       "      <td>88</td>\n",
       "      <td>120</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.3</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.691</td>\n",
       "      <td>71</td>\n",
       "      <td>123</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.4</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.691</td>\n",
       "      <td>60</td>\n",
       "      <td>123</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.708</td>\n",
       "      <td>52</td>\n",
       "      <td>126</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.6</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.713</td>\n",
       "      <td>36</td>\n",
       "      <td>127</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.7</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.725</td>\n",
       "      <td>29</td>\n",
       "      <td>129</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.8</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.747</td>\n",
       "      <td>24</td>\n",
       "      <td>133</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.9</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.753</td>\n",
       "      <td>24</td>\n",
       "      <td>134</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 1.0</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.764</td>\n",
       "      <td>21</td>\n",
       "      <td>136</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.934     0.359                0.012   \n",
       "After RANDOM mitigation N = 1500         0.934     0.370                0.013   \n",
       "After SMOTE N = 1500 p_class 1 = 0.0     0.906     0.365                0.052   \n",
       "After SMOTE N = 1500 p_class 1 = 0.1     0.911     0.349                0.042   \n",
       "After SMOTE N = 1500 p_class 1 = 0.2     0.915     0.358                0.039   \n",
       "After SMOTE N = 1500 p_class 1 = 0.3     0.920     0.362                0.031   \n",
       "After SMOTE N = 1500 p_class 1 = 0.4     0.925     0.375                0.027   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5     0.927     0.369                0.023   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6     0.933     0.385                0.016   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7     0.935     0.383                0.013   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8     0.936     0.364                0.011   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9     0.935     0.358                0.011   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0     0.936     0.349                0.009   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.747               28   \n",
       "After RANDOM mitigation N = 1500                    0.736               29   \n",
       "After SMOTE N = 1500 p_class 1 = 0.0                0.629              118   \n",
       "After SMOTE N = 1500 p_class 1 = 0.1                0.674               96   \n",
       "After SMOTE N = 1500 p_class 1 = 0.2                0.674               88   \n",
       "After SMOTE N = 1500 p_class 1 = 0.3                0.691               71   \n",
       "After SMOTE N = 1500 p_class 1 = 0.4                0.691               60   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5                0.708               52   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6                0.713               36   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7                0.725               29   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8                0.747               24   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9                0.753               24   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0                0.764               21   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 133       10975       2439  \n",
       "After RANDOM mitigation N = 1500                  131       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.0              112       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.1              120       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.2              120       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.3              123       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.4              123       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.5              126       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.6              127       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.7              129       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.8              133       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.9              134       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 1.0              136       12475       2439  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1500\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = RandomForestClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = FP_fm\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 1500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>161</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1500</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.370</td>\n",
       "      <td>29</td>\n",
       "      <td>131</td>\n",
       "      <td>160</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.0</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.365</td>\n",
       "      <td>118</td>\n",
       "      <td>112</td>\n",
       "      <td>230</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.1</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.349</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>216</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.2</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.358</td>\n",
       "      <td>88</td>\n",
       "      <td>120</td>\n",
       "      <td>208</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.3</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.362</td>\n",
       "      <td>71</td>\n",
       "      <td>123</td>\n",
       "      <td>194</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.4</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.375</td>\n",
       "      <td>60</td>\n",
       "      <td>123</td>\n",
       "      <td>183</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.5</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.369</td>\n",
       "      <td>52</td>\n",
       "      <td>126</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.6</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.385</td>\n",
       "      <td>36</td>\n",
       "      <td>127</td>\n",
       "      <td>163</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.7</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.383</td>\n",
       "      <td>29</td>\n",
       "      <td>129</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.8</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.364</td>\n",
       "      <td>24</td>\n",
       "      <td>133</td>\n",
       "      <td>157</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.9</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.358</td>\n",
       "      <td>24</td>\n",
       "      <td>134</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 1.0</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.349</td>\n",
       "      <td>21</td>\n",
       "      <td>136</td>\n",
       "      <td>157</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.934     0.359               28   \n",
       "After RANDOM mitigation N = 1500         0.934     0.370               29   \n",
       "After SMOTE N = 1500 p_class 0 = 0.0     0.906     0.365              118   \n",
       "After SMOTE N = 1500 p_class 0 = 0.1     0.911     0.349               96   \n",
       "After SMOTE N = 1500 p_class 0 = 0.2     0.915     0.358               88   \n",
       "After SMOTE N = 1500 p_class 0 = 0.3     0.920     0.362               71   \n",
       "After SMOTE N = 1500 p_class 0 = 0.4     0.925     0.375               60   \n",
       "After SMOTE N = 1500 p_class 0 = 0.5     0.927     0.369               52   \n",
       "After SMOTE N = 1500 p_class 0 = 0.6     0.933     0.385               36   \n",
       "After SMOTE N = 1500 p_class 0 = 0.7     0.935     0.383               29   \n",
       "After SMOTE N = 1500 p_class 0 = 0.8     0.936     0.364               24   \n",
       "After SMOTE N = 1500 p_class 0 = 0.9     0.935     0.358               24   \n",
       "After SMOTE N = 1500 p_class 0 = 1.0     0.936     0.349               21   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 133           161   \n",
       "After RANDOM mitigation N = 1500                  131           160   \n",
       "After SMOTE N = 1500 p_class 0 = 0.0              112           230   \n",
       "After SMOTE N = 1500 p_class 0 = 0.1              120           216   \n",
       "After SMOTE N = 1500 p_class 0 = 0.2              120           208   \n",
       "After SMOTE N = 1500 p_class 0 = 0.3              123           194   \n",
       "After SMOTE N = 1500 p_class 0 = 0.4              123           183   \n",
       "After SMOTE N = 1500 p_class 0 = 0.5              126           178   \n",
       "After SMOTE N = 1500 p_class 0 = 0.6              127           163   \n",
       "After SMOTE N = 1500 p_class 0 = 0.7              129           158   \n",
       "After SMOTE N = 1500 p_class 0 = 0.8              133           157   \n",
       "After SMOTE N = 1500 p_class 0 = 0.9              134           158   \n",
       "After SMOTE N = 1500 p_class 0 = 1.0              136           157   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                              -0.009           0.054   \n",
       "After RANDOM mitigation N = 1500               -0.009           0.057   \n",
       "After SMOTE N = 1500 p_class 0 = 0.0           -0.018           0.176   \n",
       "After SMOTE N = 1500 p_class 0 = 0.1           -0.016           0.151   \n",
       "After SMOTE N = 1500 p_class 0 = 0.2           -0.015           0.135   \n",
       "After SMOTE N = 1500 p_class 0 = 0.3           -0.013           0.133   \n",
       "After SMOTE N = 1500 p_class 0 = 0.4           -0.012           0.103   \n",
       "After SMOTE N = 1500 p_class 0 = 0.5           -0.011           0.105   \n",
       "After SMOTE N = 1500 p_class 0 = 0.6           -0.008           0.056   \n",
       "After SMOTE N = 1500 p_class 0 = 0.7           -0.008           0.055   \n",
       "After SMOTE N = 1500 p_class 0 = 0.8           -0.008           0.051   \n",
       "After SMOTE N = 1500 p_class 0 = 0.9           -0.008           0.050   \n",
       "After SMOTE N = 1500 p_class 0 = 1.0           -0.008           0.055   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.045       0.040       0.031  \n",
       "After RANDOM mitigation N = 1500           0.047       0.041       0.032  \n",
       "After SMOTE N = 1500 p_class 0 = 0.0       0.146       0.121       0.092  \n",
       "After SMOTE N = 1500 p_class 0 = 0.1       0.123       0.102       0.076  \n",
       "After SMOTE N = 1500 p_class 0 = 0.2       0.110       0.092       0.071  \n",
       "After SMOTE N = 1500 p_class 0 = 0.3       0.106       0.086       0.063  \n",
       "After SMOTE N = 1500 p_class 0 = 0.4       0.081       0.069       0.050  \n",
       "After SMOTE N = 1500 p_class 0 = 0.5       0.082       0.068       0.046  \n",
       "After SMOTE N = 1500 p_class 0 = 0.6       0.046       0.041       0.034  \n",
       "After SMOTE N = 1500 p_class 0 = 0.7       0.043       0.038       0.030  \n",
       "After SMOTE N = 1500 p_class 0 = 0.8       0.039       0.033       0.027  \n",
       "After SMOTE N = 1500 p_class 0 = 0.9       0.040       0.035       0.028  \n",
       "After SMOTE N = 1500 p_class 0 = 1.0       0.040       0.035       0.029  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_1500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.747</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.730</td>\n",
       "      <td>26</td>\n",
       "      <td>130</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.0</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.612</td>\n",
       "      <td>142</td>\n",
       "      <td>109</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.1</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.635</td>\n",
       "      <td>123</td>\n",
       "      <td>113</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.2</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.657</td>\n",
       "      <td>112</td>\n",
       "      <td>117</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.3</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.685</td>\n",
       "      <td>91</td>\n",
       "      <td>122</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.4</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.680</td>\n",
       "      <td>77</td>\n",
       "      <td>121</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.5</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.702</td>\n",
       "      <td>66</td>\n",
       "      <td>125</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.6</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.713</td>\n",
       "      <td>46</td>\n",
       "      <td>127</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.7</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.719</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.8</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.730</td>\n",
       "      <td>23</td>\n",
       "      <td>130</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.9</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.758</td>\n",
       "      <td>22</td>\n",
       "      <td>135</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 1.0</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.764</td>\n",
       "      <td>22</td>\n",
       "      <td>136</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.934     0.359                0.012   \n",
       "After RANDOM mitigation N = 2000         0.936     0.381                0.011   \n",
       "After SMOTE N = 2000 p_class 1 = 0.0     0.897     0.355                0.063   \n",
       "After SMOTE N = 2000 p_class 1 = 0.1     0.903     0.355                0.054   \n",
       "After SMOTE N = 2000 p_class 1 = 0.2     0.906     0.348                0.050   \n",
       "After SMOTE N = 2000 p_class 1 = 0.3     0.913     0.345                0.040   \n",
       "After SMOTE N = 2000 p_class 1 = 0.4     0.919     0.365                0.034   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5     0.922     0.357                0.029   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6     0.929     0.371                0.020   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7     0.935     0.388                0.013   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8     0.937     0.386                0.010   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9     0.936     0.354                0.010   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0     0.935     0.347                0.010   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.747               28   \n",
       "After RANDOM mitigation N = 2000                    0.730               26   \n",
       "After SMOTE N = 2000 p_class 1 = 0.0                0.612              142   \n",
       "After SMOTE N = 2000 p_class 1 = 0.1                0.635              123   \n",
       "After SMOTE N = 2000 p_class 1 = 0.2                0.657              112   \n",
       "After SMOTE N = 2000 p_class 1 = 0.3                0.685               91   \n",
       "After SMOTE N = 2000 p_class 1 = 0.4                0.680               77   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5                0.702               66   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6                0.713               46   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7                0.719               30   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8                0.730               23   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9                0.758               22   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0                0.764               22   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 133       10975       2439  \n",
       "After RANDOM mitigation N = 2000                  130       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.0              109       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.1              113       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.2              117       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.3              122       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.4              121       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.5              125       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.6              127       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.7              128       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.8              130       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.9              135       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 1.0              136       12975       2439  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2000\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = RandomForestClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = FP_fm\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>161</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.381</td>\n",
       "      <td>26</td>\n",
       "      <td>130</td>\n",
       "      <td>156</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.0</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.355</td>\n",
       "      <td>142</td>\n",
       "      <td>109</td>\n",
       "      <td>251</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.1</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.355</td>\n",
       "      <td>123</td>\n",
       "      <td>113</td>\n",
       "      <td>236</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.2</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.348</td>\n",
       "      <td>112</td>\n",
       "      <td>117</td>\n",
       "      <td>229</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.3</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.345</td>\n",
       "      <td>91</td>\n",
       "      <td>122</td>\n",
       "      <td>213</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.4</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.365</td>\n",
       "      <td>77</td>\n",
       "      <td>121</td>\n",
       "      <td>198</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.5</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.357</td>\n",
       "      <td>66</td>\n",
       "      <td>125</td>\n",
       "      <td>191</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.6</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.371</td>\n",
       "      <td>46</td>\n",
       "      <td>127</td>\n",
       "      <td>173</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.7</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.388</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.8</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.386</td>\n",
       "      <td>23</td>\n",
       "      <td>130</td>\n",
       "      <td>153</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.9</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.354</td>\n",
       "      <td>22</td>\n",
       "      <td>135</td>\n",
       "      <td>157</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 1.0</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.347</td>\n",
       "      <td>22</td>\n",
       "      <td>136</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.934     0.359               28   \n",
       "After RANDOM mitigation N = 2000         0.936     0.381               26   \n",
       "After SMOTE N = 2000 p_class 0 = 0.0     0.897     0.355              142   \n",
       "After SMOTE N = 2000 p_class 0 = 0.1     0.903     0.355              123   \n",
       "After SMOTE N = 2000 p_class 0 = 0.2     0.906     0.348              112   \n",
       "After SMOTE N = 2000 p_class 0 = 0.3     0.913     0.345               91   \n",
       "After SMOTE N = 2000 p_class 0 = 0.4     0.919     0.365               77   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5     0.922     0.357               66   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6     0.929     0.371               46   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7     0.935     0.388               30   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8     0.937     0.386               23   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9     0.936     0.354               22   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0     0.935     0.347               22   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 133           161   \n",
       "After RANDOM mitigation N = 2000                  130           156   \n",
       "After SMOTE N = 2000 p_class 0 = 0.0              109           251   \n",
       "After SMOTE N = 2000 p_class 0 = 0.1              113           236   \n",
       "After SMOTE N = 2000 p_class 0 = 0.2              117           229   \n",
       "After SMOTE N = 2000 p_class 0 = 0.3              122           213   \n",
       "After SMOTE N = 2000 p_class 0 = 0.4              121           198   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5              125           191   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6              127           173   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7              128           158   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8              130           153   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9              135           157   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0              136           158   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                              -0.009           0.054   \n",
       "After RANDOM mitigation N = 2000               -0.009           0.057   \n",
       "After SMOTE N = 2000 p_class 0 = 0.0           -0.019           0.186   \n",
       "After SMOTE N = 2000 p_class 0 = 0.1           -0.016           0.146   \n",
       "After SMOTE N = 2000 p_class 0 = 0.2           -0.016           0.169   \n",
       "After SMOTE N = 2000 p_class 0 = 0.3           -0.016           0.156   \n",
       "After SMOTE N = 2000 p_class 0 = 0.4           -0.014           0.136   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5           -0.014           0.117   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6           -0.010           0.087   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7           -0.008           0.054   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8           -0.007           0.053   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9           -0.008           0.051   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0           -0.008           0.054   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.045       0.040       0.031  \n",
       "After RANDOM mitigation N = 2000           0.047       0.041       0.032  \n",
       "After SMOTE N = 2000 p_class 0 = 0.0       0.152       0.133       0.109  \n",
       "After SMOTE N = 2000 p_class 0 = 0.1       0.130       0.117       0.098  \n",
       "After SMOTE N = 2000 p_class 0 = 0.2       0.138       0.117       0.095  \n",
       "After SMOTE N = 2000 p_class 0 = 0.3       0.120       0.101       0.076  \n",
       "After SMOTE N = 2000 p_class 0 = 0.4       0.112       0.092       0.066  \n",
       "After SMOTE N = 2000 p_class 0 = 0.5       0.099       0.081       0.056  \n",
       "After SMOTE N = 2000 p_class 0 = 0.6       0.070       0.059       0.041  \n",
       "After SMOTE N = 2000 p_class 0 = 0.7       0.040       0.035       0.028  \n",
       "After SMOTE N = 2000 p_class 0 = 0.8       0.036       0.032       0.027  \n",
       "After SMOTE N = 2000 p_class 0 = 0.9       0.039       0.035       0.029  \n",
       "After SMOTE N = 2000 p_class 0 = 1.0       0.041       0.036       0.029  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_2000 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.747</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2500</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.742</td>\n",
       "      <td>26</td>\n",
       "      <td>132</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.0</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.607</td>\n",
       "      <td>158</td>\n",
       "      <td>108</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.1</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.629</td>\n",
       "      <td>149</td>\n",
       "      <td>112</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.2</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.640</td>\n",
       "      <td>126</td>\n",
       "      <td>114</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.3</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.663</td>\n",
       "      <td>104</td>\n",
       "      <td>118</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.4</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.669</td>\n",
       "      <td>86</td>\n",
       "      <td>119</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.5</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.685</td>\n",
       "      <td>69</td>\n",
       "      <td>122</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.6</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.708</td>\n",
       "      <td>60</td>\n",
       "      <td>126</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.7</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.713</td>\n",
       "      <td>39</td>\n",
       "      <td>127</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.8</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.730</td>\n",
       "      <td>26</td>\n",
       "      <td>130</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.9</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.753</td>\n",
       "      <td>22</td>\n",
       "      <td>134</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 1.0</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.764</td>\n",
       "      <td>21</td>\n",
       "      <td>136</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.934     0.359                0.012   \n",
       "After RANDOM mitigation N = 2500         0.935     0.368                0.011   \n",
       "After SMOTE N = 2500 p_class 1 = 0.0     0.891     0.345                0.070   \n",
       "After SMOTE N = 2500 p_class 1 = 0.1     0.893     0.336                0.066   \n",
       "After SMOTE N = 2500 p_class 1 = 0.2     0.902     0.348                0.056   \n",
       "After SMOTE N = 2500 p_class 1 = 0.3     0.909     0.351                0.046   \n",
       "After SMOTE N = 2500 p_class 1 = 0.4     0.916     0.365                0.038   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5     0.922     0.370                0.031   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6     0.924     0.359                0.027   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7     0.932     0.381                0.017   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8     0.936     0.381                0.011   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9     0.936     0.361                0.010   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0     0.936     0.349                0.009   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.747               28   \n",
       "After RANDOM mitigation N = 2500                    0.742               26   \n",
       "After SMOTE N = 2500 p_class 1 = 0.0                0.607              158   \n",
       "After SMOTE N = 2500 p_class 1 = 0.1                0.629              149   \n",
       "After SMOTE N = 2500 p_class 1 = 0.2                0.640              126   \n",
       "After SMOTE N = 2500 p_class 1 = 0.3                0.663              104   \n",
       "After SMOTE N = 2500 p_class 1 = 0.4                0.669               86   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5                0.685               69   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6                0.708               60   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7                0.713               39   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8                0.730               26   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9                0.753               22   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0                0.764               21   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 133       10975       2439  \n",
       "After RANDOM mitigation N = 2500                  132       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.0              108       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.1              112       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.2              114       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.3              118       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.4              119       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.5              122       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.6              126       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.7              127       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.8              130       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.9              134       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 1.0              136       13475       2439  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2500\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = RandomForestClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = FP_fm\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = RandomForestClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 2500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.359</td>\n",
       "      <td>28</td>\n",
       "      <td>133</td>\n",
       "      <td>161</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2500</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.368</td>\n",
       "      <td>26</td>\n",
       "      <td>132</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.0</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.345</td>\n",
       "      <td>158</td>\n",
       "      <td>108</td>\n",
       "      <td>266</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.1</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.336</td>\n",
       "      <td>149</td>\n",
       "      <td>112</td>\n",
       "      <td>261</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.2</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.348</td>\n",
       "      <td>126</td>\n",
       "      <td>114</td>\n",
       "      <td>240</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.3</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.351</td>\n",
       "      <td>104</td>\n",
       "      <td>118</td>\n",
       "      <td>222</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.4</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.365</td>\n",
       "      <td>86</td>\n",
       "      <td>119</td>\n",
       "      <td>205</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.5</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.370</td>\n",
       "      <td>69</td>\n",
       "      <td>122</td>\n",
       "      <td>191</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.6</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.359</td>\n",
       "      <td>60</td>\n",
       "      <td>126</td>\n",
       "      <td>186</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.7</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.381</td>\n",
       "      <td>39</td>\n",
       "      <td>127</td>\n",
       "      <td>166</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.8</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.381</td>\n",
       "      <td>26</td>\n",
       "      <td>130</td>\n",
       "      <td>156</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.9</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.361</td>\n",
       "      <td>22</td>\n",
       "      <td>134</td>\n",
       "      <td>156</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 1.0</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.349</td>\n",
       "      <td>21</td>\n",
       "      <td>136</td>\n",
       "      <td>157</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.934     0.359               28   \n",
       "After RANDOM mitigation N = 2500         0.935     0.368               26   \n",
       "After SMOTE N = 2500 p_class 0 = 0.0     0.891     0.345              158   \n",
       "After SMOTE N = 2500 p_class 0 = 0.1     0.893     0.336              149   \n",
       "After SMOTE N = 2500 p_class 0 = 0.2     0.902     0.348              126   \n",
       "After SMOTE N = 2500 p_class 0 = 0.3     0.909     0.351              104   \n",
       "After SMOTE N = 2500 p_class 0 = 0.4     0.916     0.365               86   \n",
       "After SMOTE N = 2500 p_class 0 = 0.5     0.922     0.370               69   \n",
       "After SMOTE N = 2500 p_class 0 = 0.6     0.924     0.359               60   \n",
       "After SMOTE N = 2500 p_class 0 = 0.7     0.932     0.381               39   \n",
       "After SMOTE N = 2500 p_class 0 = 0.8     0.936     0.381               26   \n",
       "After SMOTE N = 2500 p_class 0 = 0.9     0.936     0.361               22   \n",
       "After SMOTE N = 2500 p_class 0 = 1.0     0.936     0.349               21   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 133           161   \n",
       "After RANDOM mitigation N = 2500                  132           158   \n",
       "After SMOTE N = 2500 p_class 0 = 0.0              108           266   \n",
       "After SMOTE N = 2500 p_class 0 = 0.1              112           261   \n",
       "After SMOTE N = 2500 p_class 0 = 0.2              114           240   \n",
       "After SMOTE N = 2500 p_class 0 = 0.3              118           222   \n",
       "After SMOTE N = 2500 p_class 0 = 0.4              119           205   \n",
       "After SMOTE N = 2500 p_class 0 = 0.5              122           191   \n",
       "After SMOTE N = 2500 p_class 0 = 0.6              126           186   \n",
       "After SMOTE N = 2500 p_class 0 = 0.7              127           166   \n",
       "After SMOTE N = 2500 p_class 0 = 0.8              130           156   \n",
       "After SMOTE N = 2500 p_class 0 = 0.9              134           156   \n",
       "After SMOTE N = 2500 p_class 0 = 1.0              136           157   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                              -0.009           0.054   \n",
       "After RANDOM mitigation N = 2500               -0.009           0.057   \n",
       "After SMOTE N = 2500 p_class 0 = 0.0           -0.022           0.196   \n",
       "After SMOTE N = 2500 p_class 0 = 0.1           -0.020           0.201   \n",
       "After SMOTE N = 2500 p_class 0 = 0.2           -0.018           0.172   \n",
       "After SMOTE N = 2500 p_class 0 = 0.3           -0.016           0.141   \n",
       "After SMOTE N = 2500 p_class 0 = 0.4           -0.015           0.159   \n",
       "After SMOTE N = 2500 p_class 0 = 0.5           -0.013           0.119   \n",
       "After SMOTE N = 2500 p_class 0 = 0.6           -0.013           0.117   \n",
       "After SMOTE N = 2500 p_class 0 = 0.7           -0.009           0.059   \n",
       "After SMOTE N = 2500 p_class 0 = 0.8           -0.007           0.052   \n",
       "After SMOTE N = 2500 p_class 0 = 0.9           -0.008           0.048   \n",
       "After SMOTE N = 2500 p_class 0 = 1.0           -0.008           0.051   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.045       0.040       0.031  \n",
       "After RANDOM mitigation N = 2500           0.047       0.041       0.032  \n",
       "After SMOTE N = 2500 p_class 0 = 0.0       0.166       0.147       0.121  \n",
       "After SMOTE N = 2500 p_class 0 = 0.1       0.164       0.145       0.119  \n",
       "After SMOTE N = 2500 p_class 0 = 0.2       0.142       0.123       0.100  \n",
       "After SMOTE N = 2500 p_class 0 = 0.3       0.115       0.102       0.085  \n",
       "After SMOTE N = 2500 p_class 0 = 0.4       0.134       0.110       0.078  \n",
       "After SMOTE N = 2500 p_class 0 = 0.5       0.104       0.084       0.059  \n",
       "After SMOTE N = 2500 p_class 0 = 0.6       0.096       0.077       0.054  \n",
       "After SMOTE N = 2500 p_class 0 = 0.7       0.049       0.044       0.034  \n",
       "After SMOTE N = 2500 p_class 0 = 0.8       0.039       0.033       0.027  \n",
       "After SMOTE N = 2500 p_class 0 = 0.9       0.041       0.036       0.029  \n",
       "After SMOTE N = 2500 p_class 0 = 1.0       0.041       0.036       0.029  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_2500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2500\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dati salvati correttamente in error_K_compas.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"error_K_compas.json\"\n",
    "\n",
    "# 1Ô∏è‚É£ Controlla se il file esiste e carica i dati\n",
    "if os.path.exists(json_filename):\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        error_data = json.load(f)\n",
    "else:\n",
    "    error_data = {}\n",
    "\n",
    "# 2Ô∏è‚É£ Salvataggio dei parametri principali\n",
    "error_data[\"run6_parameters\"] = {\n",
    "    \"min_sup\": min_sup,\n",
    "    \"percentage\": percentage,\n",
    "    \"th_redundancy\": pruning,\n",
    "    \"K\": K,\n",
    "    \"L\": filtered_instances  # Supponiamo che sia la lunghezza di filtered_instances\n",
    "}\n",
    "\n",
    "# 3Ô∏è‚É£ Dizionario con i dataset da salvare\n",
    "metrics_dict = {\n",
    "    \"1K\": metrics_after_fp_SMOTE_500,\n",
    "    \"2K\": metrics_after_fp_SMOTE_1000,\n",
    "    \"3K\": metrics_after_fp_SMOTE_1500,\n",
    "    \"4K\": metrics_after_fp_SMOTE_2000,\n",
    "    \"5K\": metrics_after_fp_SMOTE_2500\n",
    "}\n",
    "\n",
    "# 4Ô∏è‚É£ Loop per salvare i valori di errore\n",
    "for J, metrics in metrics_dict.items():\n",
    "    run_name = f\"N={J}_run6\"  # Nome corretto della run\n",
    "    error_data[run_name] = {}  # Inizializziamo il dizionario per la run\n",
    "    \n",
    "    for key, val in metrics[\"Total Errors\"].items():\n",
    "        # Se √® \"Before Mitigation\", lo salviamo direttamente\n",
    "        if \"Before Mitigation\" in key:\n",
    "            json_key = \"Before Mitigation\"\n",
    "        else:\n",
    "            # Estrai p_class 0 se presente nella stringa\n",
    "            parts = key.split(\"p_class 0 = \")\n",
    "            if len(parts) > 1:\n",
    "                try:\n",
    "                    p_value = round(float(parts[1]), 2)\n",
    "                except ValueError:\n",
    "                    continue  # Se non √® un numero, lo ignoriamo\n",
    "            else:\n",
    "                p_value = \"unknown\"\n",
    "\n",
    "            json_key = f\"After SMOTE N = {J}000 p_class 0 = {p_value}\"\n",
    "\n",
    "        error_data[run_name][json_key] = val  # Salva il valore degli errori\n",
    "\n",
    "# 5Ô∏è‚É£ Salvare il JSON aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(error_data, f, indent=4)\n",
    "\n",
    "print(f\"‚úÖ Dati salvati correttamente in {json_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"error_K_compas.json\"\n",
    "\n",
    "# Caricare i dati dal file JSON\n",
    "with open(json_filename, \"r\") as f:\n",
    "    error_data = json.load(f)\n",
    "\n",
    "# Estrarre parametri dal JSON\n",
    "run6_params = error_data.get(\"run6_parameters\", {})\n",
    "min_sup = run6_params.get(\"min_sup\", \"N/A\")\n",
    "percentage = run6_params.get(\"percentage\", \"N/A\")\n",
    "th_redundancy = run6_params.get(\"th_redundancy\", \"N/A\")\n",
    "L = run6_params.get(\"L\", \"N/A\")\n",
    "K = int((percentage / 100) * L) if isinstance(percentage, (int, float)) and isinstance(L, int) else \"N/A\"\n",
    "\n",
    "# Lista dei valori di p da 0.0 a 1.0 con step 0.1\n",
    "p_values = np.round(np.arange(0.0, 1.05, 0.1), 2)\n",
    "\n",
    "# Definiamo i colori per ogni N\n",
    "colors = [\"blue\", \"red\", \"green\", \"orange\", \"brown\"]\n",
    "labels = [f\"N={n}K\" for n in range(500, 2501, 500)]\n",
    "\n",
    "# Creazione della figura\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig.suptitle(\"ERROR MITIGATION\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Disegniamo la linea tratteggiata \"Before Mitigation\"\n",
    "before_mitigation_values = [\n",
    "    error_data.get(f\"N={n}K_run6\", {}).get(\"Before Mitigation\", None) for n in range(1, 6)\n",
    "]\n",
    "before_mitigation_values = [val for val in before_mitigation_values if val is not None]\n",
    "\n",
    "# Se esistono valori di \"Before Mitigation\", tracciamo una linea media\n",
    "if before_mitigation_values:\n",
    "    avg_before_mitigation = np.mean(before_mitigation_values)\n",
    "    ax.axhline(y=avg_before_mitigation, color=\"purple\", linestyle=\"--\", linewidth=2, label=\"Before Mitigation\")\n",
    "\n",
    "# Loop sui vari N (da 1K a 5K)\n",
    "legend_handles = []\n",
    "for i, n in enumerate(range(1, 6)):\n",
    "    N_key = f\"N={n}K_run6\"\n",
    "    if N_key not in error_data:\n",
    "        continue\n",
    "\n",
    "    data = error_data[N_key]\n",
    "\n",
    "    # Estrarre i valori di errore\n",
    "    error_filtered = []\n",
    "    p_values_filtered = []\n",
    "    \n",
    "    for p in p_values:\n",
    "        key = f\"After SMOTE N = {n}K000 p_class 0 = {p}\"  # üõ†Ô∏è CORRETTA FORMATT.\n",
    "        if key in data:\n",
    "            error_filtered.append(data[key])\n",
    "            p_values_filtered.append(p)\n",
    "\n",
    "    # Se ci sono dati validi, plottiamo la linea corrispondente\n",
    "    if error_filtered:\n",
    "        line, = ax.plot(\n",
    "            p_values_filtered, error_filtered, \n",
    "            marker=\"o\", linestyle=\"-\", color=colors[i], label=labels[i]\n",
    "        )\n",
    "        legend_handles.append(line)\n",
    "\n",
    "# Impostazioni asse\n",
    "ax.set_title(f\"Minsup = {min_sup}, pruning = {th_redundancy}, K% = {percentage}, subgroups: {K}/{L}\")\n",
    "ax.set_xlabel(\"p_class 0\")\n",
    "ax.set_ylabel(\"Errors\")\n",
    "ax.grid()\n",
    "\n",
    "# Aggiungere la leggenda\n",
    "ax.legend(handles=legend_handles, loc=\"upper right\", fontsize=10, frameon=True, title=\"Legend\")\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
