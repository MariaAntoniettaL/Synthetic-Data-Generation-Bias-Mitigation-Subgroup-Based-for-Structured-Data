{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ANALISI CONDOTTA CON LA FEATURE error (PASSATA A BOOLEAN OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_for_adult import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "\n",
    "      \n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv(\"adult.data\", header = None, names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning = 0.01\n",
    "epsilon = pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = 0.15\n",
    "percentage = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosità precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GDecisioN tree predictions\n",
    "X_train = df_train_enc.drop(columns = 'income', axis = 1)\n",
    "y_train = df_train_enc['income']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'income', axis = 1)\n",
    "y_test = df_test_enc['income']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'income', axis = 1)\n",
    "y_val = df_val_enc['income']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'income', axis = 1)\n",
    "y_holdout = df_holdout_enc['income']\n",
    "\n",
    "classifier_train = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.803     0.593                0.130   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.407              641              638   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       6508  "
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione è giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>2</td>\n",
       "      <td>0.077</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0</td>\n",
       "      <td>0.284</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass  fnlwgt  education  marital-status  occupation  relationship  \\\n",
       "18761          2   0.077          3               0           4             1   \n",
       "27582          3   0.048          3               1           4             0   \n",
       "30911          2   0.174          3               3           4             4   \n",
       "11128          0   0.012          2               1           2             0   \n",
       "683            0   0.284          3               3           2             4   \n",
       "\n",
       "       race  sex  capital-gain  capital-loss  native-country  age_group  \\\n",
       "18761     4    0         0.000         0.000               5          2   \n",
       "27582     4    1         0.000         0.000               5          5   \n",
       "30911     2    0         0.039         0.000               5          1   \n",
       "11128     2    1         0.000         0.507               5          3   \n",
       "683       2    1         0.000         0.000               5          0   \n",
       "\n",
       "       edu_num_group  hours_per_week_group  y_val_true  y_pred  \n",
       "18761              1                     1           0       0  \n",
       "27582              1                     2           1       0  \n",
       "30911              1                     1           0       0  \n",
       "11128              4                     1           1       1  \n",
       "683                1                     1           0       0  "
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set\n",
    "y_pred_val_dt = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val_dt\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.077</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>Self-emp</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>65-100</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.174</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.012</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>45-54</td>\n",
       "      <td>14 Master's Degree</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.284</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        workclass  fnlwgt        education marital-status    occupation  \\\n",
       "18761     Private   0.077    Non Graduated       Divorced  Self-emp-occ   \n",
       "27582    Self-emp   0.048    Non Graduated        Married  Self-emp-occ   \n",
       "30911     Private   0.174    Non Graduated      Separated  Self-emp-occ   \n",
       "11128  Government   0.012  Master's Degree        Married   Private-occ   \n",
       "683    Government   0.284    Non Graduated      Separated   Private-occ   \n",
       "\n",
       "         relationship    race      sex  capital-gain  capital-loss  \\\n",
       "18761   Not-in-family   White   Female         0.000         0.000   \n",
       "27582         Husband   White     Male         0.000         0.000   \n",
       "30911       Unmarried   Black   Female         0.039         0.000   \n",
       "11128         Husband   Black     Male         0.000         0.507   \n",
       "683         Unmarried   Black     Male         0.000         0.000   \n",
       "\n",
       "      native-country  income age_group       edu_num_group  \\\n",
       "18761  United-States       0     35-44          10 College   \n",
       "27582  United-States       1    65-100          10 College   \n",
       "30911  United-States       0     25-34          10 College   \n",
       "11128  United-States       1     45-54  14 Master's Degree   \n",
       "683    United-States       0     17-24          10 College   \n",
       "\n",
       "      hours_per_week_group  y_pred  error  \n",
       "18761             Overtime       0      0  \n",
       "27582            Part-time       0      1  \n",
       "30911             Overtime       0      0  \n",
       "11128             Overtime       1      0  \n",
       "683               Overtime       0      0  "
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione è giusta 0 se la predizione è sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['error'] = (df_val_class['y_val_true'] != df_val_class['y_pred']).astype(int)\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>error</th>\n",
       "      <th>error_div</th>\n",
       "      <th>error_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(native-country=United-States, race= White, relationship= Husband, capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0)</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.209</td>\n",
       "      <td>15.616</td>\n",
       "      <td>6</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(native-country=United-States, race= White, relationship= Husband, capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0, marital-status=Married)</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.209</td>\n",
       "      <td>15.616</td>\n",
       "      <td>7</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(sex= Male, native-country=United-States, race= White, relationship= Husband, capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0)</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.209</td>\n",
       "      <td>15.616</td>\n",
       "      <td>7</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(sex= Male, native-country=United-States, race= White, relationship= Husband, capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0, marital-status=Married)</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.209</td>\n",
       "      <td>15.616</td>\n",
       "      <td>8</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.159</td>\n",
       "      <td>(sex= Male, native-country=United-States, workclass=Private, race= White, relationship= Husband, capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0, marital-status=Married)</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.208</td>\n",
       "      <td>12.999</td>\n",
       "      <td>9</td>\n",
       "      <td>1034.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.239   \n",
       "1    0.239   \n",
       "2    0.239   \n",
       "3    0.239   \n",
       "4    0.159   \n",
       "\n",
       "                                                                                                                                                                                       itemset  \\\n",
       "0                                                        (native-country=United-States, race= White, relationship= Husband, capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0)   \n",
       "1                                (native-country=United-States, race= White, relationship= Husband, capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0, marital-status=Married)   \n",
       "2                                             (sex= Male, native-country=United-States, race= White, relationship= Husband, capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0)   \n",
       "3                     (sex= Male, native-country=United-States, race= White, relationship= Husband, capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0, marital-status=Married)   \n",
       "4  (sex= Male, native-country=United-States, workclass=Private, race= White, relationship= Husband, capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0, marital-status=Married)   \n",
       "\n",
       "   error  error_div  error_t  length  support_count  \n",
       "0  0.406      0.209   15.616       6       1554.000  \n",
       "1  0.406      0.209   15.616       7       1554.000  \n",
       "2  0.406      0.209   15.616       7       1554.000  \n",
       "3  0.406      0.209   15.616       8       1554.000  \n",
       "4  0.405      0.208   12.999       9       1034.000  "
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_diver = DivergenceExplorer(df_val)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"error_div\", \"error_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "      <th>error</th>\n",
       "      <th>error_div</th>\n",
       "      <th>error_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.286</td>\n",
       "      <td>(native-country=United-States, capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0, marital-status=Married)</td>\n",
       "      <td>5</td>\n",
       "      <td>1859.000</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.204</td>\n",
       "      <td>16.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.288</td>\n",
       "      <td>(capital-loss=0.0, hours_per_week_group=Overtime, relationship= Husband, capital-gain=0.0)</td>\n",
       "      <td>4</td>\n",
       "      <td>1875.000</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.198</td>\n",
       "      <td>16.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.326</td>\n",
       "      <td>(marital-status=Married, capital-loss=0.0, hours_per_week_group=Overtime, capital-gain=0.0)</td>\n",
       "      <td>4</td>\n",
       "      <td>2119.000</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.193</td>\n",
       "      <td>16.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.336</td>\n",
       "      <td>(native-country=United-States, marital-status=Married, capital-loss=0.0, capital-gain=0.0)</td>\n",
       "      <td>4</td>\n",
       "      <td>2188.000</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.190</td>\n",
       "      <td>16.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.309</td>\n",
       "      <td>(native-country=United-States, marital-status=Married, hours_per_week_group=Overtime, capital-gain=0.0)</td>\n",
       "      <td>4</td>\n",
       "      <td>2010.000</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.187</td>\n",
       "      <td>15.670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     support  \\\n",
       "21     0.286   \n",
       "46     0.288   \n",
       "72     0.326   \n",
       "100    0.336   \n",
       "123    0.309   \n",
       "\n",
       "                                                                                                                       itemset  \\\n",
       "21   (native-country=United-States, capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0, marital-status=Married)   \n",
       "46                                  (capital-loss=0.0, hours_per_week_group=Overtime, relationship= Husband, capital-gain=0.0)   \n",
       "72                                 (marital-status=Married, capital-loss=0.0, hours_per_week_group=Overtime, capital-gain=0.0)   \n",
       "100                                 (native-country=United-States, marital-status=Married, capital-loss=0.0, capital-gain=0.0)   \n",
       "123                    (native-country=United-States, marital-status=Married, hours_per_week_group=Overtime, capital-gain=0.0)   \n",
       "\n",
       "     length  support_count  error  error_div  error_t  \n",
       "21        5       1859.000  0.401      0.204   16.496  \n",
       "46        4       1875.000  0.395      0.198   16.098  \n",
       "72        4       2119.000  0.390      0.193   16.507  \n",
       "100       4       2188.000  0.387      0.190   16.472  \n",
       "123       4       2010.000  0.384      0.187   15.670  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = error_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "df_pruned_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 133\n",
      "total problematic 77\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_error)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_error[(df_pruned_error['error_div'] > 0) & (df_pruned_error['error_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (1655, 7)\n",
      "Dim pruned th_redundancy  (133, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_error.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset_and_or li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031\n"
     ]
    }
   ],
   "source": [
    "print(len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "TRAIN SET MITIGATED ROWS:  16045\n",
      "VALIDATION SET ROWS:  6508\n",
      "FILTERED DF holdout ROWS:  3031\n",
      "TEST SET FILTERED ROWS:  6507\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'income', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['income']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "#cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031\n",
      "verifica : 3031\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['income']\n",
    "\n",
    "classifier_train_mitigated_random = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.398</td>\n",
       "      <td>601</td>\n",
       "      <td>624</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.395</td>\n",
       "      <td>623</td>\n",
       "      <td>620</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.803     0.593                0.130   \n",
       "After Mitigation(K=5, fp)     0.812     0.606                0.122   \n",
       "After RANDOM mitigation       0.809     0.604                0.126   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.407              641   \n",
       "After Mitigation(K=5, fp)                0.398              601   \n",
       "After RANDOM mitigation                  0.395              623   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      638       13014       6508  \n",
       "After Mitigation(K=5, fp)              624       16045       6508  \n",
       "After RANDOM mitigation                620       16045       6508  "
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance su sottogruppi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.673</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.379</td>\n",
       "      <td>495</td>\n",
       "      <td>509</td>\n",
       "      <td>13014</td>\n",
       "      <td>3075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.688</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.369</td>\n",
       "      <td>464</td>\n",
       "      <td>495</td>\n",
       "      <td>16045</td>\n",
       "      <td>3075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.683</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.368</td>\n",
       "      <td>481</td>\n",
       "      <td>494</td>\n",
       "      <td>16045</td>\n",
       "      <td>3075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                         Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                    0.673     0.624   \n",
       "After Mitigation(K=5, on subgroups, fp)            0.688     0.639   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)     0.683     0.635   \n",
       "\n",
       "Metrics                                         False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                               0.286   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.268   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.278   \n",
       "\n",
       "Metrics                                         False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                               0.379   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.369   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.368   \n",
       "\n",
       "Metrics                                         False Positives  \\\n",
       "Before Mitigation, on subgroups                             495   \n",
       "After Mitigation(K=5, on subgroups, fp)                     464   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              481   \n",
       "\n",
       "Metrics                                         False Negatives  Train Size  \\\n",
       "Before Mitigation, on subgroups                             509       13014   \n",
       "After Mitigation(K=5, on subgroups, fp)                     495       16045   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              494       16045   \n",
       "\n",
       "Metrics                                         Test Size  \n",
       "Before Mitigation, on subgroups                      3075  \n",
       "After Mitigation(K=5, on subgroups, fp)              3075  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)       3075  "
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered_fp = K_subgroups_dataset_and_or(df_pruned_error, df_test, K)\n",
    "inutile, df_test_filtered_enc_fp, inutile2, inutile3 = encoding_funct(df_train, df_test_filtered_fp, df_holdout, df_val)\n",
    "\n",
    "X_test_filtered_fp = df_test_filtered_enc_fp.drop(columns='income', axis = 1)\n",
    "y_true_test_filtered_fp = df_test_filtered_enc_fp['income']\n",
    "\n",
    "y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after = classifier_train_mitigated.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_random = classifier_train_mitigated_random.predict(X_test_filtered_fp)\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after )\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_random)\n",
    "\n",
    "\n",
    "metrics_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after, len(y_train_mitigated), len(y_pred_test_filtered_fp_after)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(y_train_mitigated_random), len(y_pred_test_filtered_fp_after_random)]\n",
    "})\n",
    "metrics_after_fp_sottogruppi = metrics_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi[metric] = metrics_after_fp_sottogruppi[metric].astype(int)\n",
    "\n",
    "metrics_after_fp\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp\")\n",
    "metrics_after_fp_sottogruppi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE\n",
    "\n",
    "\n",
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.155</td>\n",
       "      <td>3031.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.101</td>\n",
       "      <td>3031.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.803     0.593             0.049   \n",
       "After Mitigation(K=5 fp)            0.812     0.606             0.059   \n",
       "After RANDOM Mitigation(K=5 fp)     0.809     0.604             0.025   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.179               0.169   \n",
       "After Mitigation(K=5 fp)           0.183               0.174   \n",
       "After RANDOM Mitigation(K=5 fp)    0.167               0.147   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.163               0.144   \n",
       "After Mitigation(K=5 fp)                      0.167               0.155   \n",
       "After RANDOM Mitigation(K=5 fp)               0.131               0.101   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)              3031.000  \n",
       "After RANDOM Mitigation(K=5 fp)       3031.000  "
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_no_mitigation  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_no_mitigation\n",
    "\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_baseline1  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_baseline1\n",
    "\n",
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_random_per_confrontare_con_baseline1  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_random_per_confrontare_con_baseline1\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_error_div_list_no_mitigation = np.nanmean(error_div_list_no_mitigation)\n",
    "media_error_div_list_nomitigation_primi10 = np.nanmean(error_div_list_no_mitigation[:10])\n",
    "media_error_div_list_nomitigation_primi20 = np.nanmean(error_div_list_no_mitigation[:20])\n",
    "media_error_div_list_nomitigation_primi40 = np.nanmean(error_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_error_div_no_mitigation = max(abs(x) for x in error_div_list_no_mitigation)\n",
    "\n",
    "media_error_div_list_baseline1 = np.nanmean(error_div_list_baseline1)\n",
    "media_error_div_list_baseline1_primi10 = np.nanmean(error_div_list_baseline1[:10])\n",
    "media_error_div_list_baseline1_primi20 = np.nanmean(error_div_list_baseline1[:20])\n",
    "media_error_div_list_baseline1_primi40 = np.nanmean(error_div_list_baseline1[:40])\n",
    "error_div_massimo_valore_assoluto_error_div_baseline1 = max(abs(x) for x in error_div_list_baseline1)\n",
    "\n",
    "media_error_div_list_random_per_confrontare_con_baseline1 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1)\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_error_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in error_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_correctness_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_error_div_list_no_mitigation, massimo_valore_assoluto_error_div_no_mitigation,\n",
    "        media_error_div_list_nomitigation_primi10, media_error_div_list_nomitigation_primi20, media_error_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_error_div_list_baseline1, error_div_massimo_valore_assoluto_error_div_baseline1,\n",
    "        media_error_div_list_baseline1_primi10, media_error_div_list_baseline1_primi20, media_error_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_error_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_error_div_random_per_confrontare_con_baseline1, media_error_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_error_div_list_random_per_confrontare_con_baseline1_primi20, media_error_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_correctness_sottogruppi = divergence_after_correctness_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_correctness_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SIMULANDO DATI ATTRAVERSO SMOTE\n",
    "\n",
    "SEGUE CODICE USANDO SMOTE \n",
    "DIVIDO IN TRAIN, TEST E VALIDATION -- ora uso quelli gia esistenti\n",
    "DIV EXPLORER SUL VALIDATION  -- già fatto \n",
    "GENERO NUOVI DATI CON SMOTE a partire dai dati di divexplorer sul validation\n",
    "INSERISCO QUESTI NUOVI DATI NEL TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 3063\n",
      "numero di dati simulati con smotenc 3428\n",
      "income\n",
      "1    1714\n",
      "0    1714\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['error', 'y_pred', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]\n",
    "\n",
    "smote_nc = SMOTENC( categorical_features=categorical_features, random_state=seed)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "\n",
    "print(\"numero di dati simulati con smotenc\",len(y_resampled))\n",
    "\n",
    "class_counts = y_resampled.value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16442\n"
     ]
    }
   ],
   "source": [
    "X_train_mitigated_SMOTE = pd.concat([X_train, X_resampled], ignore_index=True)\n",
    "y_train_mitigated_SMOTE = pd.concat([y_train, y_resampled], ignore_index=True)\n",
    "print(len(X_train_mitigated_SMOTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_train_mitigated_SMOTE = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_SMOTE.fit(X_train_mitigated_SMOTE, y_train_mitigated_SMOTE)\n",
    "y_mitigated_SMOTE_pred = classifier_train_mitigated_SMOTE.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#vediamo che succede se prendo lo stesso numero di righe ma random da holdout\\nprint(len(X_resampled))\\nn_random_smote = len(X_resampled)\\n\\ndf_holdout_smote_sampled = df_holdout_enc.sample(n=n_random_smote, random_state=seed)\\nprint(\"verifica :\", len(df_holdout_smote_sampled)) #verifica\\n\\ndf_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\\ndf_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\\n\\nX_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\\ny_train_mitigated_random_smote = df_train_mitigated_random_smote[\\'income\\']\\n\\nclassifier_train_mitigated_random_smote = DecisionTreeClassifier(random_state=seed)\\n\\nclassifier_train_mitigated_random_smote.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\\ny_mitigated_pred_random_smote = classifier_train_mitigated_random_smote.predict(X_test)\\n\\n'"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#vediamo che succede se prendo lo stesso numero di righe ma random da holdout\n",
    "print(len(X_resampled))\n",
    "n_random_smote = len(X_resampled)\n",
    "\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=n_random_smote, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_smote_sampled)) #verifica\n",
    "\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random_smote.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote = classifier_train_mitigated_random_smote.predict(X_test)\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_SMOTE_pred )\\naccuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote )\\n\\n\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\\n    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\\n    'After SMOTE fp mitigation' : [accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_mitigated_SMOTE_pred)],\\n    'After RANDOM mitigation' : [accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random, len(y_train_mitigated_random_smote), len(y_mitigated_pred_random_smote)]\\n    \\n})\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\\nmetrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n    \\nmetrics_after_fp_SMOTE\""
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_SMOTE_pred )\n",
    "accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote )\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After SMOTE fp mitigation' : [accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_mitigated_SMOTE_pred)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random, len(y_train_mitigated_random_smote), len(y_mitigated_pred_random_smote)]\n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "    \n",
    "metrics_after_fp_SMOTE'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A QUESTO PUNTO POSSIAMO VEDERE LE PERFORMANCE SUI SOTTOGRUPPI PRIMA E DOPO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \\ny_pred_test_filtered_fp_after_SMOTE = classifier_train_mitigated_SMOTE.predict(X_test_filtered_fp)\\ny_pred_RANDOM_subgroups = classifier_train_mitigated_random_smote.predict(X_test_filtered_fp)\\n\\n\\n#accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\\naccuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE )\\naccuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_RANDOM_subgroups )\\n\\nmetrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\\n    \\'Metrics\\' : [\\'Accuracy\\', \\'F1 Score\\', \\'False Positive Rate\\', \\'False Negative Rate\\', \\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\'],\\n    \\'Before Mitigation, on subgroups\\' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\\n    \\'After RANDOM mitigation, on subgroups\\' : [accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE, len(y_train), len(y_pred_RANDOM_subgroups)],\\n    \\'After Mitigation(K=5, on subgroups, fp and SMOTE)\\': [accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_pred_test_filtered_fp_after_SMOTE)],\\n})\\nmetrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index(\\'Metrics\\').T\\n\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\']\\n\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\\n\\nmetrics_after_fp_SMOTE\\n\\n\\nprint(\"Subgroups Decision Tree performance when boolean outcomes = correctness e SMOTE \")\\nmetrics_after_fp_sottogruppi_SMOTE'"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "y_pred_test_filtered_fp_after_SMOTE = classifier_train_mitigated_SMOTE.predict(X_test_filtered_fp)\n",
    "y_pred_RANDOM_subgroups = classifier_train_mitigated_random_smote.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "#accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE )\n",
    "accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_RANDOM_subgroups )\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM mitigation, on subgroups' : [accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE, len(y_train), len(y_pred_RANDOM_subgroups)],\n",
    "    'After Mitigation(K=5, on subgroups, fp and SMOTE)': [accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_pred_test_filtered_fp_after_SMOTE)],\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = correctness e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p è la probabilità che il campione simulato sia di classe 0 qui (perchè voglio diminuire il numero di falsi positivi)\n",
    "- FISSO p VARIA N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 3063\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = [ 'y_pred', 'error', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1349, 1714)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered['income'].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = np.arange(0.0, 1.05, 0.1)\n",
    "p_values = np.round(p_values, 2).tolist()\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = a targeted (holdout filtrato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3031</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.395</td>\n",
       "      <td>623</td>\n",
       "      <td>620</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 1 = 0.0</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.341</td>\n",
       "      <td>801</td>\n",
       "      <td>535</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 1 = 0.1</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.350</td>\n",
       "      <td>785</td>\n",
       "      <td>549</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 1 = 0.2</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.343</td>\n",
       "      <td>756</td>\n",
       "      <td>538</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 1 = 0.3</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.376</td>\n",
       "      <td>736</td>\n",
       "      <td>589</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 1 = 0.4</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.380</td>\n",
       "      <td>709</td>\n",
       "      <td>596</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 1 = 0.5</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.384</td>\n",
       "      <td>686</td>\n",
       "      <td>602</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 1 = 0.6</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.413</td>\n",
       "      <td>612</td>\n",
       "      <td>648</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 1 = 0.7</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.425</td>\n",
       "      <td>594</td>\n",
       "      <td>667</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 1 = 0.8</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.427</td>\n",
       "      <td>601</td>\n",
       "      <td>670</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 1 = 0.9</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.446</td>\n",
       "      <td>552</td>\n",
       "      <td>700</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 1 = 1.0</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.439</td>\n",
       "      <td>545</td>\n",
       "      <td>689</td>\n",
       "      <td>16045</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 3031         0.809     0.604                0.126   \n",
       "After SMOTE N = 3031 p_class 1 = 0.0     0.795     0.607                0.162   \n",
       "After SMOTE N = 3031 p_class 1 = 0.1     0.795     0.604                0.159   \n",
       "After SMOTE N = 3031 p_class 1 = 0.2     0.801     0.614                0.153   \n",
       "After SMOTE N = 3031 p_class 1 = 0.3     0.796     0.596                0.149   \n",
       "After SMOTE N = 3031 p_class 1 = 0.4     0.799     0.598                0.144   \n",
       "After SMOTE N = 3031 p_class 1 = 0.5     0.802     0.600                0.139   \n",
       "After SMOTE N = 3031 p_class 1 = 0.6     0.806     0.594                0.124   \n",
       "After SMOTE N = 3031 p_class 1 = 0.7     0.806     0.588                0.120   \n",
       "After SMOTE N = 3031 p_class 1 = 0.8     0.805     0.586                0.122   \n",
       "After SMOTE N = 3031 p_class 1 = 0.9     0.808     0.581                0.112   \n",
       "After SMOTE N = 3031 p_class 1 = 1.0     0.810     0.588                0.110   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 3031                    0.395              623   \n",
       "After SMOTE N = 3031 p_class 1 = 0.0                0.341              801   \n",
       "After SMOTE N = 3031 p_class 1 = 0.1                0.350              785   \n",
       "After SMOTE N = 3031 p_class 1 = 0.2                0.343              756   \n",
       "After SMOTE N = 3031 p_class 1 = 0.3                0.376              736   \n",
       "After SMOTE N = 3031 p_class 1 = 0.4                0.380              709   \n",
       "After SMOTE N = 3031 p_class 1 = 0.5                0.384              686   \n",
       "After SMOTE N = 3031 p_class 1 = 0.6                0.413              612   \n",
       "After SMOTE N = 3031 p_class 1 = 0.7                0.425              594   \n",
       "After SMOTE N = 3031 p_class 1 = 0.8                0.427              601   \n",
       "After SMOTE N = 3031 p_class 1 = 0.9                0.446              552   \n",
       "After SMOTE N = 3031 p_class 1 = 1.0                0.439              545   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 3031                  620       16045       6508  \n",
       "After SMOTE N = 3031 p_class 1 = 0.0              535       16045       6508  \n",
       "After SMOTE N = 3031 p_class 1 = 0.1              549       16045       6508  \n",
       "After SMOTE N = 3031 p_class 1 = 0.2              538       16045       6508  \n",
       "After SMOTE N = 3031 p_class 1 = 0.3              589       16045       6508  \n",
       "After SMOTE N = 3031 p_class 1 = 0.4              596       16045       6508  \n",
       "After SMOTE N = 3031 p_class 1 = 0.5              602       16045       6508  \n",
       "After SMOTE N = 3031 p_class 1 = 0.6              648       16045       6508  \n",
       "After SMOTE N = 3031 p_class 1 = 0.7              667       16045       6508  \n",
       "After SMOTE N = 3031 p_class 1 = 0.8              670       16045       6508  \n",
       "After SMOTE N = 3031 p_class 1 = 0.9              700       16045       6508  \n",
       "After SMOTE N = 3031 p_class 1 = 1.0              689       16045       6508  "
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df_holdout_filtered)\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 3031\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3031</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.604</td>\n",
       "      <td>623</td>\n",
       "      <td>620</td>\n",
       "      <td>1243</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 0 = 0.0</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.607</td>\n",
       "      <td>801</td>\n",
       "      <td>535</td>\n",
       "      <td>1336</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 0 = 0.1</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.604</td>\n",
       "      <td>785</td>\n",
       "      <td>549</td>\n",
       "      <td>1334</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 0 = 0.2</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.614</td>\n",
       "      <td>756</td>\n",
       "      <td>538</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 0 = 0.3</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.596</td>\n",
       "      <td>736</td>\n",
       "      <td>589</td>\n",
       "      <td>1325</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 0 = 0.4</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.598</td>\n",
       "      <td>709</td>\n",
       "      <td>596</td>\n",
       "      <td>1305</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 0 = 0.5</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.600</td>\n",
       "      <td>686</td>\n",
       "      <td>602</td>\n",
       "      <td>1288</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 0 = 0.6</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.594</td>\n",
       "      <td>612</td>\n",
       "      <td>648</td>\n",
       "      <td>1260</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 0 = 0.7</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.588</td>\n",
       "      <td>594</td>\n",
       "      <td>667</td>\n",
       "      <td>1261</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 0 = 0.8</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.586</td>\n",
       "      <td>601</td>\n",
       "      <td>670</td>\n",
       "      <td>1271</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 0 = 0.9</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.581</td>\n",
       "      <td>552</td>\n",
       "      <td>700</td>\n",
       "      <td>1252</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3031 p_class 0 = 1.0</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.588</td>\n",
       "      <td>545</td>\n",
       "      <td>689</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.803     0.593              641   \n",
       "After RANDOM mitigation N = 3031         0.809     0.604              623   \n",
       "After SMOTE N = 3031 p_class 0 = 0.0     0.795     0.607              801   \n",
       "After SMOTE N = 3031 p_class 0 = 0.1     0.795     0.604              785   \n",
       "After SMOTE N = 3031 p_class 0 = 0.2     0.801     0.614              756   \n",
       "After SMOTE N = 3031 p_class 0 = 0.3     0.796     0.596              736   \n",
       "After SMOTE N = 3031 p_class 0 = 0.4     0.799     0.598              709   \n",
       "After SMOTE N = 3031 p_class 0 = 0.5     0.802     0.600              686   \n",
       "After SMOTE N = 3031 p_class 0 = 0.6     0.806     0.594              612   \n",
       "After SMOTE N = 3031 p_class 0 = 0.7     0.806     0.588              594   \n",
       "After SMOTE N = 3031 p_class 0 = 0.8     0.805     0.586              601   \n",
       "After SMOTE N = 3031 p_class 0 = 0.9     0.808     0.581              552   \n",
       "After SMOTE N = 3031 p_class 0 = 1.0     0.810     0.588              545   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 638          1279   \n",
       "After RANDOM mitigation N = 3031                  620          1243   \n",
       "After SMOTE N = 3031 p_class 0 = 0.0              535          1336   \n",
       "After SMOTE N = 3031 p_class 0 = 0.1              549          1334   \n",
       "After SMOTE N = 3031 p_class 0 = 0.2              538          1294   \n",
       "After SMOTE N = 3031 p_class 0 = 0.3              589          1325   \n",
       "After SMOTE N = 3031 p_class 0 = 0.4              596          1305   \n",
       "After SMOTE N = 3031 p_class 0 = 0.5              602          1288   \n",
       "After SMOTE N = 3031 p_class 0 = 0.6              648          1260   \n",
       "After SMOTE N = 3031 p_class 0 = 0.7              667          1261   \n",
       "After SMOTE N = 3031 p_class 0 = 0.8              670          1271   \n",
       "After SMOTE N = 3031 p_class 0 = 0.9              700          1252   \n",
       "After SMOTE N = 3031 p_class 0 = 1.0              689          1234   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.049           0.179   \n",
       "After RANDOM mitigation N = 3031                0.025           0.167   \n",
       "After SMOTE N = 3031 p_class 0 = 0.0            0.065           0.232   \n",
       "After SMOTE N = 3031 p_class 0 = 0.1            0.068           0.240   \n",
       "After SMOTE N = 3031 p_class 0 = 0.2            0.048           0.193   \n",
       "After SMOTE N = 3031 p_class 0 = 0.3            0.052           0.214   \n",
       "After SMOTE N = 3031 p_class 0 = 0.4            0.035           0.184   \n",
       "After SMOTE N = 3031 p_class 0 = 0.5            0.039           0.180   \n",
       "After SMOTE N = 3031 p_class 0 = 0.6            0.053           0.179   \n",
       "After SMOTE N = 3031 p_class 0 = 0.7            0.040           0.191   \n",
       "After SMOTE N = 3031 p_class 0 = 0.8            0.042           0.185   \n",
       "After SMOTE N = 3031 p_class 0 = 0.9            0.048           0.196   \n",
       "After SMOTE N = 3031 p_class 0 = 1.0            0.053           0.189   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.169       0.163       0.144  \n",
       "After RANDOM mitigation N = 3031           0.147       0.131       0.101  \n",
       "After SMOTE N = 3031 p_class 0 = 0.0       0.214       0.201       0.178  \n",
       "After SMOTE N = 3031 p_class 0 = 0.1       0.223       0.209       0.184  \n",
       "After SMOTE N = 3031 p_class 0 = 0.2       0.175       0.166       0.142  \n",
       "After SMOTE N = 3031 p_class 0 = 0.3       0.190       0.178       0.151  \n",
       "After SMOTE N = 3031 p_class 0 = 0.4       0.168       0.152       0.117  \n",
       "After SMOTE N = 3031 p_class 0 = 0.5       0.165       0.152       0.121  \n",
       "After SMOTE N = 3031 p_class 0 = 0.6       0.167       0.158       0.143  \n",
       "After SMOTE N = 3031 p_class 0 = 0.7       0.174       0.162       0.128  \n",
       "After SMOTE N = 3031 p_class 0 = 0.8       0.168       0.154       0.124  \n",
       "After SMOTE N = 3031 p_class 0 = 0.9       0.178       0.164       0.140  \n",
       "After SMOTE N = 3031 p_class 0 = 1.0       0.172       0.161       0.143  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_confronto = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_confronto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.389</td>\n",
       "      <td>652</td>\n",
       "      <td>610</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.0</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.362</td>\n",
       "      <td>736</td>\n",
       "      <td>567</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.1</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.374</td>\n",
       "      <td>703</td>\n",
       "      <td>586</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.2</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.377</td>\n",
       "      <td>667</td>\n",
       "      <td>591</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.3</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.370</td>\n",
       "      <td>697</td>\n",
       "      <td>580</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.4</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.377</td>\n",
       "      <td>653</td>\n",
       "      <td>591</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.5</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.395</td>\n",
       "      <td>631</td>\n",
       "      <td>620</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.6</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.403</td>\n",
       "      <td>624</td>\n",
       "      <td>632</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.7</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.398</td>\n",
       "      <td>620</td>\n",
       "      <td>624</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.8</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.415</td>\n",
       "      <td>617</td>\n",
       "      <td>651</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.9</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.423</td>\n",
       "      <td>604</td>\n",
       "      <td>663</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 1.0</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.441</td>\n",
       "      <td>560</td>\n",
       "      <td>691</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 1000         0.806     0.603                0.132   \n",
       "After SMOTE N = 1000 p_class 1 = 0.0     0.800     0.606                0.149   \n",
       "After SMOTE N = 1000 p_class 1 = 0.1     0.802     0.604                0.142   \n",
       "After SMOTE N = 1000 p_class 1 = 0.2     0.807     0.608                0.135   \n",
       "After SMOTE N = 1000 p_class 1 = 0.3     0.804     0.607                0.141   \n",
       "After SMOTE N = 1000 p_class 1 = 0.4     0.809     0.611                0.132   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5     0.808     0.602                0.128   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6     0.807     0.598                0.126   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7     0.809     0.603                0.126   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8     0.805     0.591                0.125   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9     0.805     0.588                0.122   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0     0.808     0.584                0.113   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 1000                    0.389              652   \n",
       "After SMOTE N = 1000 p_class 1 = 0.0                0.362              736   \n",
       "After SMOTE N = 1000 p_class 1 = 0.1                0.374              703   \n",
       "After SMOTE N = 1000 p_class 1 = 0.2                0.377              667   \n",
       "After SMOTE N = 1000 p_class 1 = 0.3                0.370              697   \n",
       "After SMOTE N = 1000 p_class 1 = 0.4                0.377              653   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5                0.395              631   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6                0.403              624   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7                0.398              620   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8                0.415              617   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9                0.423              604   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0                0.441              560   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 1000                  610       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.0              567       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.1              586       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.2              591       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.3              580       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.4              591       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.5              620       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.6              632       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.7              624       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.8              651       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 0.9              663       14014       6508  \n",
       "After SMOTE N = 1000 p_class 1 = 1.0              691       14014       6508  "
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.603</td>\n",
       "      <td>652</td>\n",
       "      <td>610</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.0</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.606</td>\n",
       "      <td>736</td>\n",
       "      <td>567</td>\n",
       "      <td>1303</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.1</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.604</td>\n",
       "      <td>703</td>\n",
       "      <td>586</td>\n",
       "      <td>1289</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.2</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.608</td>\n",
       "      <td>667</td>\n",
       "      <td>591</td>\n",
       "      <td>1258</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.3</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.607</td>\n",
       "      <td>697</td>\n",
       "      <td>580</td>\n",
       "      <td>1277</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.4</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.611</td>\n",
       "      <td>653</td>\n",
       "      <td>591</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.5</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.602</td>\n",
       "      <td>631</td>\n",
       "      <td>620</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.6</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.598</td>\n",
       "      <td>624</td>\n",
       "      <td>632</td>\n",
       "      <td>1256</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.7</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.603</td>\n",
       "      <td>620</td>\n",
       "      <td>624</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.8</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.591</td>\n",
       "      <td>617</td>\n",
       "      <td>651</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.9</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.588</td>\n",
       "      <td>604</td>\n",
       "      <td>663</td>\n",
       "      <td>1267</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 1.0</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.584</td>\n",
       "      <td>560</td>\n",
       "      <td>691</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.803     0.593              641   \n",
       "After RANDOM mitigation N = 1000         0.806     0.603              652   \n",
       "After SMOTE N = 1000 p_class 0 = 0.0     0.800     0.606              736   \n",
       "After SMOTE N = 1000 p_class 0 = 0.1     0.802     0.604              703   \n",
       "After SMOTE N = 1000 p_class 0 = 0.2     0.807     0.608              667   \n",
       "After SMOTE N = 1000 p_class 0 = 0.3     0.804     0.607              697   \n",
       "After SMOTE N = 1000 p_class 0 = 0.4     0.809     0.611              653   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5     0.808     0.602              631   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6     0.807     0.598              624   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7     0.809     0.603              620   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8     0.805     0.591              617   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9     0.805     0.588              604   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0     0.808     0.584              560   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 638          1279   \n",
       "After RANDOM mitigation N = 1000                  610          1262   \n",
       "After SMOTE N = 1000 p_class 0 = 0.0              567          1303   \n",
       "After SMOTE N = 1000 p_class 0 = 0.1              586          1289   \n",
       "After SMOTE N = 1000 p_class 0 = 0.2              591          1258   \n",
       "After SMOTE N = 1000 p_class 0 = 0.3              580          1277   \n",
       "After SMOTE N = 1000 p_class 0 = 0.4              591          1244   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5              620          1251   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6              632          1256   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7              624          1244   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8              651          1268   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9              663          1267   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0              691          1251   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.049           0.179   \n",
       "After RANDOM mitigation N = 1000                0.025           0.167   \n",
       "After SMOTE N = 1000 p_class 0 = 0.0            0.046           0.186   \n",
       "After SMOTE N = 1000 p_class 0 = 0.1            0.047           0.191   \n",
       "After SMOTE N = 1000 p_class 0 = 0.2            0.033           0.171   \n",
       "After SMOTE N = 1000 p_class 0 = 0.3            0.064           0.196   \n",
       "After SMOTE N = 1000 p_class 0 = 0.4            0.036           0.177   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5            0.033           0.174   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6            0.041           0.174   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7            0.047           0.175   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8            0.043           0.185   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9            0.046           0.186   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0            0.043           0.176   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.169       0.163       0.144  \n",
       "After RANDOM mitigation N = 1000           0.147       0.131       0.101  \n",
       "After SMOTE N = 1000 p_class 0 = 0.0       0.175       0.164       0.143  \n",
       "After SMOTE N = 1000 p_class 0 = 0.1       0.174       0.164       0.135  \n",
       "After SMOTE N = 1000 p_class 0 = 0.2       0.157       0.143       0.108  \n",
       "After SMOTE N = 1000 p_class 0 = 0.3       0.180       0.172       0.160  \n",
       "After SMOTE N = 1000 p_class 0 = 0.4       0.162       0.151       0.114  \n",
       "After SMOTE N = 1000 p_class 0 = 0.5       0.154       0.140       0.106  \n",
       "After SMOTE N = 1000 p_class 0 = 0.6       0.157       0.147       0.126  \n",
       "After SMOTE N = 1000 p_class 0 = 0.7       0.160       0.149       0.132  \n",
       "After SMOTE N = 1000 p_class 0 = 0.8       0.174       0.163       0.135  \n",
       "After SMOTE N = 1000 p_class 0 = 0.9       0.170       0.158       0.135  \n",
       "After SMOTE N = 1000 p_class 0 = 1.0       0.162       0.149       0.130  "
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_1K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.390</td>\n",
       "      <td>664</td>\n",
       "      <td>611</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.0</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.334</td>\n",
       "      <td>810</td>\n",
       "      <td>523</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.1</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.356</td>\n",
       "      <td>746</td>\n",
       "      <td>558</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.2</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.367</td>\n",
       "      <td>719</td>\n",
       "      <td>576</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.3</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.376</td>\n",
       "      <td>702</td>\n",
       "      <td>589</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.4</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.381</td>\n",
       "      <td>677</td>\n",
       "      <td>597</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.5</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.400</td>\n",
       "      <td>641</td>\n",
       "      <td>627</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.6</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.399</td>\n",
       "      <td>642</td>\n",
       "      <td>626</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.7</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.420</td>\n",
       "      <td>614</td>\n",
       "      <td>658</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.8</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.431</td>\n",
       "      <td>576</td>\n",
       "      <td>676</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.9</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.429</td>\n",
       "      <td>564</td>\n",
       "      <td>672</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 1.0</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.429</td>\n",
       "      <td>541</td>\n",
       "      <td>673</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 2000         0.804     0.600                0.134   \n",
       "After SMOTE N = 2000 p_class 1 = 0.0     0.795     0.611                0.164   \n",
       "After SMOTE N = 2000 p_class 1 = 0.1     0.800     0.608                0.151   \n",
       "After SMOTE N = 2000 p_class 1 = 0.2     0.801     0.605                0.146   \n",
       "After SMOTE N = 2000 p_class 1 = 0.3     0.802     0.603                0.142   \n",
       "After SMOTE N = 2000 p_class 1 = 0.4     0.804     0.604                0.137   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5     0.805     0.597                0.130   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6     0.805     0.598                0.130   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7     0.805     0.589                0.124   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8     0.808     0.588                0.117   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9     0.810     0.592                0.114   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0     0.813     0.596                0.110   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 2000                    0.390              664   \n",
       "After SMOTE N = 2000 p_class 1 = 0.0                0.334              810   \n",
       "After SMOTE N = 2000 p_class 1 = 0.1                0.356              746   \n",
       "After SMOTE N = 2000 p_class 1 = 0.2                0.367              719   \n",
       "After SMOTE N = 2000 p_class 1 = 0.3                0.376              702   \n",
       "After SMOTE N = 2000 p_class 1 = 0.4                0.381              677   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5                0.400              641   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6                0.399              642   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7                0.420              614   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8                0.431              576   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9                0.429              564   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0                0.429              541   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 2000                  611       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.0              523       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.1              558       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.2              576       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.3              589       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.4              597       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.5              627       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.6              626       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.7              658       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.8              676       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 0.9              672       15014       6508  \n",
       "After SMOTE N = 2000 p_class 1 = 1.0              673       15014       6508  "
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.600</td>\n",
       "      <td>664</td>\n",
       "      <td>611</td>\n",
       "      <td>1275</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.0</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.611</td>\n",
       "      <td>810</td>\n",
       "      <td>523</td>\n",
       "      <td>1333</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.1</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.608</td>\n",
       "      <td>746</td>\n",
       "      <td>558</td>\n",
       "      <td>1304</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.2</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.605</td>\n",
       "      <td>719</td>\n",
       "      <td>576</td>\n",
       "      <td>1295</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.3</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.603</td>\n",
       "      <td>702</td>\n",
       "      <td>589</td>\n",
       "      <td>1291</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.4</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.604</td>\n",
       "      <td>677</td>\n",
       "      <td>597</td>\n",
       "      <td>1274</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.5</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.597</td>\n",
       "      <td>641</td>\n",
       "      <td>627</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.6</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.598</td>\n",
       "      <td>642</td>\n",
       "      <td>626</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.7</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.589</td>\n",
       "      <td>614</td>\n",
       "      <td>658</td>\n",
       "      <td>1272</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.8</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.588</td>\n",
       "      <td>576</td>\n",
       "      <td>676</td>\n",
       "      <td>1252</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.9</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.592</td>\n",
       "      <td>564</td>\n",
       "      <td>672</td>\n",
       "      <td>1236</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 1.0</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.596</td>\n",
       "      <td>541</td>\n",
       "      <td>673</td>\n",
       "      <td>1214</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.803     0.593              641   \n",
       "After RANDOM mitigation N = 2000         0.804     0.600              664   \n",
       "After SMOTE N = 2000 p_class 0 = 0.0     0.795     0.611              810   \n",
       "After SMOTE N = 2000 p_class 0 = 0.1     0.800     0.608              746   \n",
       "After SMOTE N = 2000 p_class 0 = 0.2     0.801     0.605              719   \n",
       "After SMOTE N = 2000 p_class 0 = 0.3     0.802     0.603              702   \n",
       "After SMOTE N = 2000 p_class 0 = 0.4     0.804     0.604              677   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5     0.805     0.597              641   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6     0.805     0.598              642   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7     0.805     0.589              614   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8     0.808     0.588              576   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9     0.810     0.592              564   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0     0.813     0.596              541   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 638          1279   \n",
       "After RANDOM mitigation N = 2000                  611          1275   \n",
       "After SMOTE N = 2000 p_class 0 = 0.0              523          1333   \n",
       "After SMOTE N = 2000 p_class 0 = 0.1              558          1304   \n",
       "After SMOTE N = 2000 p_class 0 = 0.2              576          1295   \n",
       "After SMOTE N = 2000 p_class 0 = 0.3              589          1291   \n",
       "After SMOTE N = 2000 p_class 0 = 0.4              597          1274   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5              627          1268   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6              626          1268   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7              658          1272   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8              676          1252   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9              672          1236   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0              673          1214   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.049           0.179   \n",
       "After RANDOM mitigation N = 2000                0.025           0.167   \n",
       "After SMOTE N = 2000 p_class 0 = 0.0            0.065           0.217   \n",
       "After SMOTE N = 2000 p_class 0 = 0.1            0.054           0.212   \n",
       "After SMOTE N = 2000 p_class 0 = 0.2            0.048           0.190   \n",
       "After SMOTE N = 2000 p_class 0 = 0.3            0.054           0.194   \n",
       "After SMOTE N = 2000 p_class 0 = 0.4            0.049           0.187   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5            0.040           0.178   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6            0.033           0.173   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7            0.038           0.193   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8            0.055           0.184   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9            0.046           0.179   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0            0.054           0.186   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.169       0.163       0.144  \n",
       "After RANDOM mitigation N = 2000           0.147       0.131       0.101  \n",
       "After SMOTE N = 2000 p_class 0 = 0.0       0.198       0.189       0.175  \n",
       "After SMOTE N = 2000 p_class 0 = 0.1       0.192       0.180       0.150  \n",
       "After SMOTE N = 2000 p_class 0 = 0.2       0.174       0.164       0.143  \n",
       "After SMOTE N = 2000 p_class 0 = 0.3       0.180       0.171       0.155  \n",
       "After SMOTE N = 2000 p_class 0 = 0.4       0.171       0.164       0.147  \n",
       "After SMOTE N = 2000 p_class 0 = 0.5       0.166       0.155       0.128  \n",
       "After SMOTE N = 2000 p_class 0 = 0.6       0.149       0.135       0.110  \n",
       "After SMOTE N = 2000 p_class 0 = 0.7       0.177       0.160       0.124  \n",
       "After SMOTE N = 2000 p_class 0 = 0.8       0.172       0.162       0.146  \n",
       "After SMOTE N = 2000 p_class 0 = 0.9       0.162       0.148       0.126  \n",
       "After SMOTE N = 2000 p_class 0 = 1.0       0.168       0.159       0.142  "
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_2K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.395</td>\n",
       "      <td>622</td>\n",
       "      <td>620</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.0</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.325</td>\n",
       "      <td>810</td>\n",
       "      <td>509</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.1</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.335</td>\n",
       "      <td>788</td>\n",
       "      <td>525</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.2</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.360</td>\n",
       "      <td>748</td>\n",
       "      <td>565</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.3</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.375</td>\n",
       "      <td>726</td>\n",
       "      <td>588</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.4</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.393</td>\n",
       "      <td>696</td>\n",
       "      <td>617</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.5</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.399</td>\n",
       "      <td>684</td>\n",
       "      <td>626</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.6</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.401</td>\n",
       "      <td>652</td>\n",
       "      <td>628</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.7</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.413</td>\n",
       "      <td>585</td>\n",
       "      <td>648</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.8</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.433</td>\n",
       "      <td>591</td>\n",
       "      <td>679</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 0.9</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.425</td>\n",
       "      <td>553</td>\n",
       "      <td>666</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 1 = 1.0</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.450</td>\n",
       "      <td>549</td>\n",
       "      <td>706</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 3000         0.809     0.604                0.126   \n",
       "After SMOTE N = 3000 p_class 1 = 0.0     0.797     0.616                0.164   \n",
       "After SMOTE N = 3000 p_class 1 = 0.1     0.798     0.614                0.160   \n",
       "After SMOTE N = 3000 p_class 1 = 0.2     0.798     0.604                0.151   \n",
       "After SMOTE N = 3000 p_class 1 = 0.3     0.798     0.599                0.147   \n",
       "After SMOTE N = 3000 p_class 1 = 0.4     0.798     0.592                0.141   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5     0.799     0.590                0.138   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6     0.803     0.595                0.132   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7     0.811     0.599                0.118   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8     0.805     0.583                0.120   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9     0.813     0.597                0.112   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0     0.807     0.579                0.111   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 3000                    0.395              622   \n",
       "After SMOTE N = 3000 p_class 1 = 0.0                0.325              810   \n",
       "After SMOTE N = 3000 p_class 1 = 0.1                0.335              788   \n",
       "After SMOTE N = 3000 p_class 1 = 0.2                0.360              748   \n",
       "After SMOTE N = 3000 p_class 1 = 0.3                0.375              726   \n",
       "After SMOTE N = 3000 p_class 1 = 0.4                0.393              696   \n",
       "After SMOTE N = 3000 p_class 1 = 0.5                0.399              684   \n",
       "After SMOTE N = 3000 p_class 1 = 0.6                0.401              652   \n",
       "After SMOTE N = 3000 p_class 1 = 0.7                0.413              585   \n",
       "After SMOTE N = 3000 p_class 1 = 0.8                0.433              591   \n",
       "After SMOTE N = 3000 p_class 1 = 0.9                0.425              553   \n",
       "After SMOTE N = 3000 p_class 1 = 1.0                0.450              549   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 3000                  620       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.0              509       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.1              525       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.2              565       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.3              588       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.4              617       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.5              626       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.6              628       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.7              648       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.8              679       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 0.9              666       16014       6508  \n",
       "After SMOTE N = 3000 p_class 1 = 1.0              706       16014       6508  "
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3000\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.604</td>\n",
       "      <td>622</td>\n",
       "      <td>620</td>\n",
       "      <td>1242</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.0</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.616</td>\n",
       "      <td>810</td>\n",
       "      <td>509</td>\n",
       "      <td>1319</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.1</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.614</td>\n",
       "      <td>788</td>\n",
       "      <td>525</td>\n",
       "      <td>1313</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.2</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.604</td>\n",
       "      <td>748</td>\n",
       "      <td>565</td>\n",
       "      <td>1313</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.3</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.599</td>\n",
       "      <td>726</td>\n",
       "      <td>588</td>\n",
       "      <td>1314</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.4</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.592</td>\n",
       "      <td>696</td>\n",
       "      <td>617</td>\n",
       "      <td>1313</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.5</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.590</td>\n",
       "      <td>684</td>\n",
       "      <td>626</td>\n",
       "      <td>1310</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.6</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.595</td>\n",
       "      <td>652</td>\n",
       "      <td>628</td>\n",
       "      <td>1280</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.7</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.599</td>\n",
       "      <td>585</td>\n",
       "      <td>648</td>\n",
       "      <td>1233</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.8</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.583</td>\n",
       "      <td>591</td>\n",
       "      <td>679</td>\n",
       "      <td>1270</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.9</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.597</td>\n",
       "      <td>553</td>\n",
       "      <td>666</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 1.0</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.579</td>\n",
       "      <td>549</td>\n",
       "      <td>706</td>\n",
       "      <td>1255</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.803     0.593              641   \n",
       "After RANDOM mitigation N = 3000         0.809     0.604              622   \n",
       "After SMOTE N = 3000 p_class 0 = 0.0     0.797     0.616              810   \n",
       "After SMOTE N = 3000 p_class 0 = 0.1     0.798     0.614              788   \n",
       "After SMOTE N = 3000 p_class 0 = 0.2     0.798     0.604              748   \n",
       "After SMOTE N = 3000 p_class 0 = 0.3     0.798     0.599              726   \n",
       "After SMOTE N = 3000 p_class 0 = 0.4     0.798     0.592              696   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5     0.799     0.590              684   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6     0.803     0.595              652   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7     0.811     0.599              585   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8     0.805     0.583              591   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9     0.813     0.597              553   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0     0.807     0.579              549   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 638          1279   \n",
       "After RANDOM mitigation N = 3000                  620          1242   \n",
       "After SMOTE N = 3000 p_class 0 = 0.0              509          1319   \n",
       "After SMOTE N = 3000 p_class 0 = 0.1              525          1313   \n",
       "After SMOTE N = 3000 p_class 0 = 0.2              565          1313   \n",
       "After SMOTE N = 3000 p_class 0 = 0.3              588          1314   \n",
       "After SMOTE N = 3000 p_class 0 = 0.4              617          1313   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5              626          1310   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6              628          1280   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7              648          1233   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8              679          1270   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9              666          1219   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0              706          1255   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.049           0.179   \n",
       "After RANDOM mitigation N = 3000                0.025           0.167   \n",
       "After SMOTE N = 3000 p_class 0 = 0.0            0.060           0.222   \n",
       "After SMOTE N = 3000 p_class 0 = 0.1            0.072           0.206   \n",
       "After SMOTE N = 3000 p_class 0 = 0.2            0.066           0.205   \n",
       "After SMOTE N = 3000 p_class 0 = 0.3            0.045           0.190   \n",
       "After SMOTE N = 3000 p_class 0 = 0.4            0.059           0.196   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5            0.035           0.186   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6            0.040           0.186   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7            0.042           0.173   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8            0.043           0.182   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9            0.031           0.172   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0            0.043           0.182   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.169       0.163       0.144  \n",
       "After RANDOM mitigation N = 3000           0.147       0.131       0.101  \n",
       "After SMOTE N = 3000 p_class 0 = 0.0       0.201       0.190       0.171  \n",
       "After SMOTE N = 3000 p_class 0 = 0.1       0.186       0.178       0.167  \n",
       "After SMOTE N = 3000 p_class 0 = 0.2       0.192       0.184       0.171  \n",
       "After SMOTE N = 3000 p_class 0 = 0.3       0.175       0.165       0.142  \n",
       "After SMOTE N = 3000 p_class 0 = 0.4       0.180       0.172       0.159  \n",
       "After SMOTE N = 3000 p_class 0 = 0.5       0.171       0.153       0.114  \n",
       "After SMOTE N = 3000 p_class 0 = 0.6       0.170       0.158       0.122  \n",
       "After SMOTE N = 3000 p_class 0 = 0.7       0.159       0.147       0.128  \n",
       "After SMOTE N = 3000 p_class 0 = 0.8       0.167       0.156       0.129  \n",
       "After SMOTE N = 3000 p_class 0 = 0.9       0.152       0.133       0.106  \n",
       "After SMOTE N = 3000 p_class 0 = 1.0       0.163       0.151       0.126  "
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_3K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_3K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 4000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.388</td>\n",
       "      <td>634</td>\n",
       "      <td>609</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.0</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.322</td>\n",
       "      <td>826</td>\n",
       "      <td>505</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.1</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.339</td>\n",
       "      <td>784</td>\n",
       "      <td>531</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.2</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.345</td>\n",
       "      <td>777</td>\n",
       "      <td>541</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.3</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.370</td>\n",
       "      <td>717</td>\n",
       "      <td>580</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.4</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.384</td>\n",
       "      <td>703</td>\n",
       "      <td>602</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.5</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.388</td>\n",
       "      <td>694</td>\n",
       "      <td>609</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.6</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.404</td>\n",
       "      <td>630</td>\n",
       "      <td>634</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.7</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.415</td>\n",
       "      <td>593</td>\n",
       "      <td>650</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.8</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.421</td>\n",
       "      <td>597</td>\n",
       "      <td>660</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 0.9</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.440</td>\n",
       "      <td>546</td>\n",
       "      <td>690</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 1 = 1.0</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.455</td>\n",
       "      <td>535</td>\n",
       "      <td>714</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 4000         0.809     0.607                0.128   \n",
       "After SMOTE N = 4000 p_class 1 = 0.0     0.795     0.615                0.167   \n",
       "After SMOTE N = 4000 p_class 1 = 0.1     0.798     0.612                0.159   \n",
       "After SMOTE N = 4000 p_class 1 = 0.2     0.797     0.609                0.157   \n",
       "After SMOTE N = 4000 p_class 1 = 0.3     0.801     0.604                0.145   \n",
       "After SMOTE N = 4000 p_class 1 = 0.4     0.799     0.597                0.142   \n",
       "After SMOTE N = 4000 p_class 1 = 0.5     0.800     0.595                0.140   \n",
       "After SMOTE N = 4000 p_class 1 = 0.6     0.806     0.596                0.128   \n",
       "After SMOTE N = 4000 p_class 1 = 0.7     0.809     0.596                0.120   \n",
       "After SMOTE N = 4000 p_class 1 = 0.8     0.807     0.591                0.121   \n",
       "After SMOTE N = 4000 p_class 1 = 0.9     0.810     0.587                0.111   \n",
       "After SMOTE N = 4000 p_class 1 = 1.0     0.808     0.578                0.108   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 4000                    0.388              634   \n",
       "After SMOTE N = 4000 p_class 1 = 0.0                0.322              826   \n",
       "After SMOTE N = 4000 p_class 1 = 0.1                0.339              784   \n",
       "After SMOTE N = 4000 p_class 1 = 0.2                0.345              777   \n",
       "After SMOTE N = 4000 p_class 1 = 0.3                0.370              717   \n",
       "After SMOTE N = 4000 p_class 1 = 0.4                0.384              703   \n",
       "After SMOTE N = 4000 p_class 1 = 0.5                0.388              694   \n",
       "After SMOTE N = 4000 p_class 1 = 0.6                0.404              630   \n",
       "After SMOTE N = 4000 p_class 1 = 0.7                0.415              593   \n",
       "After SMOTE N = 4000 p_class 1 = 0.8                0.421              597   \n",
       "After SMOTE N = 4000 p_class 1 = 0.9                0.440              546   \n",
       "After SMOTE N = 4000 p_class 1 = 1.0                0.455              535   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 4000                  609       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.0              505       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.1              531       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.2              541       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.3              580       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.4              602       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.5              609       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.6              634       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.7              650       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.8              660       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 0.9              690       17014       6508  \n",
       "After SMOTE N = 4000 p_class 1 = 1.0              714       17014       6508  "
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4000\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 4000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 4000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.607</td>\n",
       "      <td>634</td>\n",
       "      <td>609</td>\n",
       "      <td>1243</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.0</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.615</td>\n",
       "      <td>826</td>\n",
       "      <td>505</td>\n",
       "      <td>1331</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.1</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.612</td>\n",
       "      <td>784</td>\n",
       "      <td>531</td>\n",
       "      <td>1315</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.2</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.609</td>\n",
       "      <td>777</td>\n",
       "      <td>541</td>\n",
       "      <td>1318</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.3</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.604</td>\n",
       "      <td>717</td>\n",
       "      <td>580</td>\n",
       "      <td>1297</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.4</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.597</td>\n",
       "      <td>703</td>\n",
       "      <td>602</td>\n",
       "      <td>1305</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.5</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.595</td>\n",
       "      <td>694</td>\n",
       "      <td>609</td>\n",
       "      <td>1303</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.6</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.596</td>\n",
       "      <td>630</td>\n",
       "      <td>634</td>\n",
       "      <td>1264</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.7</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.596</td>\n",
       "      <td>593</td>\n",
       "      <td>650</td>\n",
       "      <td>1243</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.8</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.591</td>\n",
       "      <td>597</td>\n",
       "      <td>660</td>\n",
       "      <td>1257</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.9</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.587</td>\n",
       "      <td>546</td>\n",
       "      <td>690</td>\n",
       "      <td>1236</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1.0</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.578</td>\n",
       "      <td>535</td>\n",
       "      <td>714</td>\n",
       "      <td>1249</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.803     0.593              641   \n",
       "After RANDOM mitigation N = 4000         0.809     0.607              634   \n",
       "After SMOTE N = 4000 p_class 0 = 0.0     0.795     0.615              826   \n",
       "After SMOTE N = 4000 p_class 0 = 0.1     0.798     0.612              784   \n",
       "After SMOTE N = 4000 p_class 0 = 0.2     0.797     0.609              777   \n",
       "After SMOTE N = 4000 p_class 0 = 0.3     0.801     0.604              717   \n",
       "After SMOTE N = 4000 p_class 0 = 0.4     0.799     0.597              703   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5     0.800     0.595              694   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6     0.806     0.596              630   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7     0.809     0.596              593   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8     0.807     0.591              597   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9     0.810     0.587              546   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0     0.808     0.578              535   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 638          1279   \n",
       "After RANDOM mitigation N = 4000                  609          1243   \n",
       "After SMOTE N = 4000 p_class 0 = 0.0              505          1331   \n",
       "After SMOTE N = 4000 p_class 0 = 0.1              531          1315   \n",
       "After SMOTE N = 4000 p_class 0 = 0.2              541          1318   \n",
       "After SMOTE N = 4000 p_class 0 = 0.3              580          1297   \n",
       "After SMOTE N = 4000 p_class 0 = 0.4              602          1305   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5              609          1303   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6              634          1264   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7              650          1243   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8              660          1257   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9              690          1236   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0              714          1249   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.049           0.179   \n",
       "After RANDOM mitigation N = 4000                0.025           0.167   \n",
       "After SMOTE N = 4000 p_class 0 = 0.0            0.070           0.228   \n",
       "After SMOTE N = 4000 p_class 0 = 0.1            0.062           0.215   \n",
       "After SMOTE N = 4000 p_class 0 = 0.2            0.060           0.204   \n",
       "After SMOTE N = 4000 p_class 0 = 0.3            0.058           0.195   \n",
       "After SMOTE N = 4000 p_class 0 = 0.4            0.024           0.180   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5            0.032           0.184   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6            0.044           0.188   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7            0.053           0.186   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8            0.063           0.192   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9            0.047           0.185   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0            0.045           0.190   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.169       0.163       0.144  \n",
       "After RANDOM mitigation N = 4000           0.147       0.131       0.101  \n",
       "After SMOTE N = 4000 p_class 0 = 0.0       0.208       0.198       0.181  \n",
       "After SMOTE N = 4000 p_class 0 = 0.1       0.197       0.186       0.169  \n",
       "After SMOTE N = 4000 p_class 0 = 0.2       0.186       0.177       0.163  \n",
       "After SMOTE N = 4000 p_class 0 = 0.3       0.185       0.178       0.166  \n",
       "After SMOTE N = 4000 p_class 0 = 0.4       0.164       0.140       0.104  \n",
       "After SMOTE N = 4000 p_class 0 = 0.5       0.168       0.148       0.114  \n",
       "After SMOTE N = 4000 p_class 0 = 0.6       0.172       0.159       0.133  \n",
       "After SMOTE N = 4000 p_class 0 = 0.7       0.171       0.162       0.144  \n",
       "After SMOTE N = 4000 p_class 0 = 0.8       0.174       0.165       0.151  \n",
       "After SMOTE N = 4000 p_class 0 = 0.9       0.169       0.157       0.136  \n",
       "After SMOTE N = 4000 p_class 0 = 1.0       0.170       0.155       0.131  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_4K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_4K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.402</td>\n",
       "      <td>654</td>\n",
       "      <td>631</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.0</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.311</td>\n",
       "      <td>846</td>\n",
       "      <td>487</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.1</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.326</td>\n",
       "      <td>766</td>\n",
       "      <td>511</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.2</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.353</td>\n",
       "      <td>772</td>\n",
       "      <td>553</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.3</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.360</td>\n",
       "      <td>728</td>\n",
       "      <td>564</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.4</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.395</td>\n",
       "      <td>693</td>\n",
       "      <td>620</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.5</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.390</td>\n",
       "      <td>684</td>\n",
       "      <td>611</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.6</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.411</td>\n",
       "      <td>636</td>\n",
       "      <td>644</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.7</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.422</td>\n",
       "      <td>617</td>\n",
       "      <td>661</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.8</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.431</td>\n",
       "      <td>584</td>\n",
       "      <td>676</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 0.9</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.439</td>\n",
       "      <td>545</td>\n",
       "      <td>688</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 1 = 1.0</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.465</td>\n",
       "      <td>515</td>\n",
       "      <td>729</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 5000         0.803     0.593                0.132   \n",
       "After SMOTE N = 5000 p_class 1 = 0.0     0.795     0.619                0.171   \n",
       "After SMOTE N = 5000 p_class 1 = 0.1     0.804     0.623                0.155   \n",
       "After SMOTE N = 5000 p_class 1 = 0.2     0.796     0.605                0.156   \n",
       "After SMOTE N = 5000 p_class 1 = 0.3     0.801     0.608                0.147   \n",
       "After SMOTE N = 5000 p_class 1 = 0.4     0.798     0.591                0.140   \n",
       "After SMOTE N = 5000 p_class 1 = 0.5     0.801     0.596                0.138   \n",
       "After SMOTE N = 5000 p_class 1 = 0.6     0.803     0.591                0.129   \n",
       "After SMOTE N = 5000 p_class 1 = 0.7     0.804     0.587                0.125   \n",
       "After SMOTE N = 5000 p_class 1 = 0.8     0.806     0.586                0.118   \n",
       "After SMOTE N = 5000 p_class 1 = 0.9     0.811     0.588                0.110   \n",
       "After SMOTE N = 5000 p_class 1 = 1.0     0.809     0.574                0.104   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 5000                    0.402              654   \n",
       "After SMOTE N = 5000 p_class 1 = 0.0                0.311              846   \n",
       "After SMOTE N = 5000 p_class 1 = 0.1                0.326              766   \n",
       "After SMOTE N = 5000 p_class 1 = 0.2                0.353              772   \n",
       "After SMOTE N = 5000 p_class 1 = 0.3                0.360              728   \n",
       "After SMOTE N = 5000 p_class 1 = 0.4                0.395              693   \n",
       "After SMOTE N = 5000 p_class 1 = 0.5                0.390              684   \n",
       "After SMOTE N = 5000 p_class 1 = 0.6                0.411              636   \n",
       "After SMOTE N = 5000 p_class 1 = 0.7                0.422              617   \n",
       "After SMOTE N = 5000 p_class 1 = 0.8                0.431              584   \n",
       "After SMOTE N = 5000 p_class 1 = 0.9                0.439              545   \n",
       "After SMOTE N = 5000 p_class 1 = 1.0                0.465              515   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  631       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.0              487       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.1              511       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.2              553       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.3              564       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.4              620       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.5              611       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.6              644       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.7              661       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.8              676       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 0.9              688       18014       6508  \n",
       "After SMOTE N = 5000 p_class 1 = 1.0              729       18014       6508  "
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>654</td>\n",
       "      <td>631</td>\n",
       "      <td>1285</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.0</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.619</td>\n",
       "      <td>846</td>\n",
       "      <td>487</td>\n",
       "      <td>1333</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.1</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.623</td>\n",
       "      <td>766</td>\n",
       "      <td>511</td>\n",
       "      <td>1277</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.2</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.605</td>\n",
       "      <td>772</td>\n",
       "      <td>553</td>\n",
       "      <td>1325</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.3</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.608</td>\n",
       "      <td>728</td>\n",
       "      <td>564</td>\n",
       "      <td>1292</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.4</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.591</td>\n",
       "      <td>693</td>\n",
       "      <td>620</td>\n",
       "      <td>1313</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.596</td>\n",
       "      <td>684</td>\n",
       "      <td>611</td>\n",
       "      <td>1295</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.591</td>\n",
       "      <td>636</td>\n",
       "      <td>644</td>\n",
       "      <td>1280</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.587</td>\n",
       "      <td>617</td>\n",
       "      <td>661</td>\n",
       "      <td>1278</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.586</td>\n",
       "      <td>584</td>\n",
       "      <td>676</td>\n",
       "      <td>1260</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.588</td>\n",
       "      <td>545</td>\n",
       "      <td>688</td>\n",
       "      <td>1233</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 1.0</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.574</td>\n",
       "      <td>515</td>\n",
       "      <td>729</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.803     0.593              641   \n",
       "After RANDOM mitigation N = 5000         0.803     0.593              654   \n",
       "After SMOTE N = 5000 p_class 0 = 0.0     0.795     0.619              846   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1     0.804     0.623              766   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2     0.796     0.605              772   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3     0.801     0.608              728   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4     0.798     0.591              693   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.801     0.596              684   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.803     0.591              636   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.804     0.587              617   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.806     0.586              584   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.811     0.588              545   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0     0.809     0.574              515   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 638          1279   \n",
       "After RANDOM mitigation N = 5000                  631          1285   \n",
       "After SMOTE N = 5000 p_class 0 = 0.0              487          1333   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1              511          1277   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2              553          1325   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3              564          1292   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4              620          1313   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              611          1295   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              644          1280   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              661          1278   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              676          1260   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              688          1233   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0              729          1244   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.049           0.179   \n",
       "After RANDOM mitigation N = 5000                0.025           0.167   \n",
       "After SMOTE N = 5000 p_class 0 = 0.0            0.082           0.231   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1            0.068           0.210   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2            0.051           0.210   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3            0.055           0.193   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4            0.037           0.196   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5            0.023           0.176   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6            0.037           0.183   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7            0.049           0.196   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8            0.037           0.181   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9            0.038           0.180   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0            0.041           0.187   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.169       0.163       0.144  \n",
       "After RANDOM mitigation N = 5000           0.147       0.131       0.101  \n",
       "After SMOTE N = 5000 p_class 0 = 0.0       0.216       0.208       0.193  \n",
       "After SMOTE N = 5000 p_class 0 = 0.1       0.194       0.185       0.172  \n",
       "After SMOTE N = 5000 p_class 0 = 0.2       0.193       0.182       0.149  \n",
       "After SMOTE N = 5000 p_class 0 = 0.3       0.179       0.171       0.152  \n",
       "After SMOTE N = 5000 p_class 0 = 0.4       0.176       0.159       0.120  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5       0.152       0.122       0.091  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6       0.166       0.151       0.117  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7       0.178       0.167       0.143  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8       0.164       0.148       0.120  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9       0.160       0.143       0.118  \n",
       "After SMOTE N = 5000 p_class 0 = 1.0       0.168       0.149       0.127  "
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_5K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_5K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.386</td>\n",
       "      <td>651</td>\n",
       "      <td>606</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.0</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.305</td>\n",
       "      <td>868</td>\n",
       "      <td>478</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.1</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.336</td>\n",
       "      <td>829</td>\n",
       "      <td>527</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.2</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.346</td>\n",
       "      <td>748</td>\n",
       "      <td>542</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.3</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.365</td>\n",
       "      <td>710</td>\n",
       "      <td>573</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.4</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.370</td>\n",
       "      <td>679</td>\n",
       "      <td>580</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.5</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.398</td>\n",
       "      <td>666</td>\n",
       "      <td>624</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.6</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.417</td>\n",
       "      <td>646</td>\n",
       "      <td>654</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.7</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.431</td>\n",
       "      <td>612</td>\n",
       "      <td>676</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.8</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.438</td>\n",
       "      <td>589</td>\n",
       "      <td>686</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 0.9</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.450</td>\n",
       "      <td>558</td>\n",
       "      <td>705</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 1 = 1.0</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.462</td>\n",
       "      <td>521</td>\n",
       "      <td>724</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 6000         0.807     0.605                0.132   \n",
       "After SMOTE N = 6000 p_class 1 = 0.0     0.793     0.618                0.176   \n",
       "After SMOTE N = 6000 p_class 1 = 0.1     0.792     0.606                0.168   \n",
       "After SMOTE N = 6000 p_class 1 = 0.2     0.802     0.614                0.151   \n",
       "After SMOTE N = 6000 p_class 1 = 0.3     0.803     0.608                0.144   \n",
       "After SMOTE N = 6000 p_class 1 = 0.4     0.807     0.611                0.137   \n",
       "After SMOTE N = 6000 p_class 1 = 0.5     0.802     0.594                0.135   \n",
       "After SMOTE N = 6000 p_class 1 = 0.6     0.800     0.584                0.131   \n",
       "After SMOTE N = 6000 p_class 1 = 0.7     0.802     0.581                0.124   \n",
       "After SMOTE N = 6000 p_class 1 = 0.8     0.804     0.580                0.119   \n",
       "After SMOTE N = 6000 p_class 1 = 0.9     0.806     0.577                0.113   \n",
       "After SMOTE N = 6000 p_class 1 = 1.0     0.809     0.576                0.105   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 6000                    0.386              651   \n",
       "After SMOTE N = 6000 p_class 1 = 0.0                0.305              868   \n",
       "After SMOTE N = 6000 p_class 1 = 0.1                0.336              829   \n",
       "After SMOTE N = 6000 p_class 1 = 0.2                0.346              748   \n",
       "After SMOTE N = 6000 p_class 1 = 0.3                0.365              710   \n",
       "After SMOTE N = 6000 p_class 1 = 0.4                0.370              679   \n",
       "After SMOTE N = 6000 p_class 1 = 0.5                0.398              666   \n",
       "After SMOTE N = 6000 p_class 1 = 0.6                0.417              646   \n",
       "After SMOTE N = 6000 p_class 1 = 0.7                0.431              612   \n",
       "After SMOTE N = 6000 p_class 1 = 0.8                0.438              589   \n",
       "After SMOTE N = 6000 p_class 1 = 0.9                0.450              558   \n",
       "After SMOTE N = 6000 p_class 1 = 1.0                0.462              521   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 6000                  606       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.0              478       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.1              527       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.2              542       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.3              573       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.4              580       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.5              624       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.6              654       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.7              676       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.8              686       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 0.9              705       19014       6508  \n",
       "After SMOTE N = 6000 p_class 1 = 1.0              724       19014       6508  "
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 6000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 6000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.605</td>\n",
       "      <td>651</td>\n",
       "      <td>606</td>\n",
       "      <td>1257</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.0</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.618</td>\n",
       "      <td>868</td>\n",
       "      <td>478</td>\n",
       "      <td>1346</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.1</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.606</td>\n",
       "      <td>829</td>\n",
       "      <td>527</td>\n",
       "      <td>1356</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.2</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.614</td>\n",
       "      <td>748</td>\n",
       "      <td>542</td>\n",
       "      <td>1290</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.3</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.608</td>\n",
       "      <td>710</td>\n",
       "      <td>573</td>\n",
       "      <td>1283</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.4</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.611</td>\n",
       "      <td>679</td>\n",
       "      <td>580</td>\n",
       "      <td>1259</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.5</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.594</td>\n",
       "      <td>666</td>\n",
       "      <td>624</td>\n",
       "      <td>1290</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.6</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.584</td>\n",
       "      <td>646</td>\n",
       "      <td>654</td>\n",
       "      <td>1300</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.7</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.581</td>\n",
       "      <td>612</td>\n",
       "      <td>676</td>\n",
       "      <td>1288</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.8</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.580</td>\n",
       "      <td>589</td>\n",
       "      <td>686</td>\n",
       "      <td>1275</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.9</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.577</td>\n",
       "      <td>558</td>\n",
       "      <td>705</td>\n",
       "      <td>1263</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 1.0</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.576</td>\n",
       "      <td>521</td>\n",
       "      <td>724</td>\n",
       "      <td>1245</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.803     0.593              641   \n",
       "After RANDOM mitigation N = 6000         0.807     0.605              651   \n",
       "After SMOTE N = 6000 p_class 0 = 0.0     0.793     0.618              868   \n",
       "After SMOTE N = 6000 p_class 0 = 0.1     0.792     0.606              829   \n",
       "After SMOTE N = 6000 p_class 0 = 0.2     0.802     0.614              748   \n",
       "After SMOTE N = 6000 p_class 0 = 0.3     0.803     0.608              710   \n",
       "After SMOTE N = 6000 p_class 0 = 0.4     0.807     0.611              679   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5     0.802     0.594              666   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6     0.800     0.584              646   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7     0.802     0.581              612   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8     0.804     0.580              589   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9     0.806     0.577              558   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0     0.809     0.576              521   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 638          1279   \n",
       "After RANDOM mitigation N = 6000                  606          1257   \n",
       "After SMOTE N = 6000 p_class 0 = 0.0              478          1346   \n",
       "After SMOTE N = 6000 p_class 0 = 0.1              527          1356   \n",
       "After SMOTE N = 6000 p_class 0 = 0.2              542          1290   \n",
       "After SMOTE N = 6000 p_class 0 = 0.3              573          1283   \n",
       "After SMOTE N = 6000 p_class 0 = 0.4              580          1259   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5              624          1290   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6              654          1300   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7              676          1288   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8              686          1275   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9              705          1263   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0              724          1245   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                               0.049           0.179   \n",
       "After RANDOM mitigation N = 6000                0.025           0.167   \n",
       "After SMOTE N = 6000 p_class 0 = 0.0            0.057           0.222   \n",
       "After SMOTE N = 6000 p_class 0 = 0.1            0.079           0.245   \n",
       "After SMOTE N = 6000 p_class 0 = 0.2            0.054           0.206   \n",
       "After SMOTE N = 6000 p_class 0 = 0.3            0.064           0.198   \n",
       "After SMOTE N = 6000 p_class 0 = 0.4            0.022           0.177   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5            0.036           0.190   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6            0.044           0.194   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7            0.045           0.192   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8            0.053           0.189   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9            0.043           0.186   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0            0.039           0.190   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.169       0.163       0.144  \n",
       "After RANDOM mitigation N = 6000           0.147       0.131       0.101  \n",
       "After SMOTE N = 6000 p_class 0 = 0.0       0.207       0.195       0.160  \n",
       "After SMOTE N = 6000 p_class 0 = 0.1       0.219       0.209       0.195  \n",
       "After SMOTE N = 6000 p_class 0 = 0.2       0.192       0.184       0.157  \n",
       "After SMOTE N = 6000 p_class 0 = 0.3       0.188       0.179       0.167  \n",
       "After SMOTE N = 6000 p_class 0 = 0.4       0.141       0.113       0.085  \n",
       "After SMOTE N = 6000 p_class 0 = 0.5       0.173       0.157       0.117  \n",
       "After SMOTE N = 6000 p_class 0 = 0.6       0.179       0.166       0.135  \n",
       "After SMOTE N = 6000 p_class 0 = 0.7       0.175       0.159       0.132  \n",
       "After SMOTE N = 6000 p_class 0 = 0.8       0.175       0.166       0.152  \n",
       "After SMOTE N = 6000 p_class 0 = 0.9       0.167       0.154       0.132  \n",
       "After SMOTE N = 6000 p_class 0 = 1.0       0.169       0.150       0.126  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se è \"SMOTE\", iteriamo su p_values, altrimenti è un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento è SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_6K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_6K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "salvo i dati che mi servono "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Before Mitigation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[463], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     error_data[run_name] \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# Inizializziamo il dizionario\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p, val \u001b[38;5;129;01min\u001b[39;00m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Errors\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 29\u001b[0m         p\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convertiamo p in un numero\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         error_data[run_name][\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter SMOTE N = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mJ[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m000 p_class 1 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(p,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Salviamo il JSON aggiornato\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Before Mitigation'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"error_K.json\"\n",
    "\n",
    "# Controlla se il file esiste già per evitare di sovrascrivere\n",
    "if os.path.exists(json_filename):\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        error_data = json.load(f)\n",
    "else:\n",
    "    error_data = {}\n",
    "\n",
    "# Lista dei diversi metrics_after_fp_SMOTE_XK\n",
    "metrics_dict = {\n",
    "    \"1K_run6\": metrics_after_fp_SMOTE_1K,\n",
    "    \"2K_run6\": metrics_after_fp_SMOTE_2K,\n",
    "    \"3K_run6\": metrics_after_fp_SMOTE_3K,\n",
    "    \"4K_run6\": metrics_after_fp_SMOTE_4K,\n",
    "    \"5K_run6\": metrics_after_fp_SMOTE_5K,\n",
    "    \"6K_run6\": metrics_after_fp_SMOTE_6K\n",
    "}\n",
    "\n",
    "for J, metrics in metrics_dict.items():\n",
    "    run_name = f\"N={J}_run6\"  # Aggiunta corretta del nome della run\n",
    "    error_data[run_name] = {}  # Inizializziamo il dizionario\n",
    "    \n",
    "    for p, val in metrics[\"Total Errors\"].items():\n",
    "        p= float(p)  # Convertiamo p in un numero\n",
    "        error_data[run_name][f\"After SMOTE N = {J[:-4]}000 p_class 1 = {round(p, 2)}\"] = val\n",
    "\n",
    "# Salviamo il JSON aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(error_data, f, indent=4)\n",
    "\n",
    "print(f\"Dati salvati in {json_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "#per i parametri # Nome del file JSON\n",
    "json_filename = \"error_K.json\"\n",
    "\n",
    "# Valori da salvare (sostituiscili con i tuoi valori reali)\n",
    "min_sup_run6 = min_sup\n",
    "percentage_run6 = percentage\n",
    "th_redundancy_run6 = pruning\n",
    "K_run6 = K\n",
    "L_run6 = filtered_instances  # Supponiamo sia la lunghezza di filtered_instances\n",
    "\n",
    "# 1️⃣ Caricare i dati esistenti (se il file esiste)\n",
    "try:\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        error_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    error_data = {}  # Se il file non esiste, inizializza un dizionario vuoto\n",
    "\n",
    "# 2️⃣ Aggiungere le nuove variabili sotto una chiave dedicata\n",
    "error_data[\"run6_parameters\"] = {\n",
    "    \"min_sup\": min_sup_run6,\n",
    "    \"percentage\": percentage_run6,\n",
    "    \"th_redundancy\": th_redundancy_run6,\n",
    "    \"K\": percentage,\n",
    "    \"L\": L_run6\n",
    "}\n",
    "\n",
    "# 3️⃣ Salvare il file aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(error_data, f, indent=4)\n",
    "\n",
    "print(\"✅ Variabili salvate con successo in\", json_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"error_K.json\"\n",
    "\n",
    "# Caricare i dati dal file JSON\n",
    "with open(json_filename, \"r\") as f:\n",
    "    error_data = json.load(f)\n",
    "\n",
    "# Estrarre parametri dal JSON\n",
    "run6_params = error_data.get(\"run6_parameters\", {})\n",
    "min_sup = run6_params.get(\"min_sup\", \"N/A\")\n",
    "percentage = run6_params.get(\"percentage\", \"N/A\")\n",
    "th_redundancy = run6_params.get(\"th_redundancy\", \"N/A\")\n",
    "L = run6_params.get(\"L\", \"N/A\")\n",
    "K = int((percentage / 100) * L)  # K rappresenta il numero di sottogruppi\n",
    "\n",
    "# Lista dei valori di p da 0.5 a 1.0 con step 0.05\n",
    "p_values = np.arange(0.0, 1.05, 0.1)\n",
    "\n",
    "# Definiamo i colori per ogni N\n",
    "colors = [\"blue\", \"red\", \"green\", \"orange\", \"brown\", \"pink\"]\n",
    "labels = [f\"N={k}K\" for k in range(1, 7)]\n",
    "\n",
    "# Creazione della figura\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig.suptitle(\"ERROR MITIGATION\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Disegniamo la linea tratteggiata \"Before Mitigation\"\n",
    "before_mitigation = error_data.get(\"N=1K_run6\", {}).get(\"Before Mitigation\", None)\n",
    "if before_mitigation is not None:\n",
    "    ax.axhline(y=before_mitigation, color=\"purple\", linestyle=\"--\", linewidth=2, label=\"Before Mitigation\")\n",
    "\n",
    "# Aggiungere linee verticali per ogni valore di p\n",
    "for p in p_values:\n",
    "    ax.axvline(x=p, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Loop sui vari N (da 1K a 6K)\n",
    "legend_handles = []\n",
    "for i, n in enumerate(range(1, 7)):\n",
    "    N_key = f\"N={n}K_run6\"\n",
    "    if N_key not in error_data:\n",
    "        continue\n",
    "    \n",
    "    data = error_data[N_key]\n",
    "    \n",
    "    # Estrarre i valori di falsi positivi per ogni p\n",
    "    error = [data.get(f\"After SMOTE N = {n*1000} p_class 0 = {round(p, 2)}\", None) for p in p_values]\n",
    "    \n",
    "    # Filtriamo solo i valori validi\n",
    "    p_values_filtered = [p for j, p in enumerate(p_values) if error[j] is not None]\n",
    "    error_filtered = [fp for fp in error if fp is not None]\n",
    "    \n",
    "    # Plottiamo la linea corrispondente\n",
    "    line, = ax.plot(\n",
    "        p_values_filtered, error_filtered, \n",
    "        marker=\"o\", linestyle=\"-\", color=colors[i], label=labels[i]\n",
    "    )\n",
    "    legend_handles.append(line)\n",
    "\n",
    "# Impostazioni asse\n",
    "ax.set_title(f\"Minsup = {min_sup}, pruning = {th_redundancy}, K% = {percentage}, subgroups: {K}/{L}\")\n",
    "ax.set_xlabel(\"p_class 0\")\n",
    "ax.set_ylabel(\"Errors\")\n",
    "ax.grid()\n",
    "\n",
    "# Aggiungere la leggenda\n",
    "ax.legend(handles=legend_handles, loc=\"upper right\", fontsize=10, frameon=True, title=\"Legend\")\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
