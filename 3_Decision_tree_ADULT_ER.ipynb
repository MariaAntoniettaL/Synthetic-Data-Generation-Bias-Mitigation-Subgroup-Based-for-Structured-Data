{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ANALISI CONDOTTA CON LA FEATURE error rate (PASSATA A BOOLEAN OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_for_adult import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "\n",
    "      \n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv(\"adult.data\", header = None, names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning = 0.01\n",
    "epsilon = pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = 0.2\n",
    "percentage = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosità precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GDecisioN tree predictions\n",
    "X_train = df_train_enc.drop(columns = 'income', axis = 1)\n",
    "y_train = df_train_enc['income']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'income', axis = 1)\n",
    "y_test = df_test_enc['income']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'income', axis = 1)\n",
    "y_val = df_val_enc['income']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'income', axis = 1)\n",
    "y_holdout = df_holdout_enc['income']\n",
    "\n",
    "classifier_train = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.803     0.593                0.130   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.407              641              638   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       6508  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione è giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>2</td>\n",
       "      <td>0.077</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0</td>\n",
       "      <td>0.284</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass  fnlwgt  education  marital-status  occupation  relationship  \\\n",
       "18761          2   0.077          3               0           4             1   \n",
       "27582          3   0.048          3               1           4             0   \n",
       "30911          2   0.174          3               3           4             4   \n",
       "11128          0   0.012          2               1           2             0   \n",
       "683            0   0.284          3               3           2             4   \n",
       "\n",
       "       race  sex  capital-gain  capital-loss  native-country  age_group  \\\n",
       "18761     4    0         0.000         0.000               5          2   \n",
       "27582     4    1         0.000         0.000               5          5   \n",
       "30911     2    0         0.039         0.000               5          1   \n",
       "11128     2    1         0.000         0.507               5          3   \n",
       "683       2    1         0.000         0.000               5          0   \n",
       "\n",
       "       edu_num_group  hours_per_week_group  y_val_true  y_pred  \n",
       "18761              1                     1           0       0  \n",
       "27582              1                     2           1       0  \n",
       "30911              1                     1           0       0  \n",
       "11128              4                     1           1       1  \n",
       "683                1                     1           0       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set\n",
    "y_pred_val_dt = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val_dt\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.077</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>Self-emp</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>65-100</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.174</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.012</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>45-54</td>\n",
       "      <td>14 Master's Degree</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.284</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        workclass  fnlwgt        education marital-status    occupation  \\\n",
       "18761     Private   0.077    Non Graduated       Divorced  Self-emp-occ   \n",
       "27582    Self-emp   0.048    Non Graduated        Married  Self-emp-occ   \n",
       "30911     Private   0.174    Non Graduated      Separated  Self-emp-occ   \n",
       "11128  Government   0.012  Master's Degree        Married   Private-occ   \n",
       "683    Government   0.284    Non Graduated      Separated   Private-occ   \n",
       "\n",
       "         relationship    race      sex  capital-gain  capital-loss  \\\n",
       "18761   Not-in-family   White   Female         0.000         0.000   \n",
       "27582         Husband   White     Male         0.000         0.000   \n",
       "30911       Unmarried   Black   Female         0.039         0.000   \n",
       "11128         Husband   Black     Male         0.000         0.507   \n",
       "683         Unmarried   Black     Male         0.000         0.000   \n",
       "\n",
       "      native-country  income age_group       edu_num_group  \\\n",
       "18761  United-States       0     35-44          10 College   \n",
       "27582  United-States       1    65-100          10 College   \n",
       "30911  United-States       0     25-34          10 College   \n",
       "11128  United-States       1     45-54  14 Master's Degree   \n",
       "683    United-States       0     17-24          10 College   \n",
       "\n",
       "      hours_per_week_group  y_pred  error  \n",
       "18761             Overtime       0      0  \n",
       "27582            Part-time       0      1  \n",
       "30911             Overtime       0      0  \n",
       "11128             Overtime       1      0  \n",
       "683               Overtime       0      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione è giusta 0 se la predizione è sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['error'] = (df_val_class['y_val_true'] != df_val_class['y_pred']).astype(int)\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>error</th>\n",
       "      <th>error_div</th>\n",
       "      <th>error_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(sex= Male, capital-gain=0.0, hours_per_week_group=Overtime, race= White, capital-loss=0.0, relationship= Husband, marital-status=Married, native-country=United-States)</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.209</td>\n",
       "      <td>15.616</td>\n",
       "      <td>8</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(sex= Male, capital-gain=0.0, hours_per_week_group=Overtime, race= White, capital-loss=0.0, relationship= Husband, native-country=United-States)</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.209</td>\n",
       "      <td>15.616</td>\n",
       "      <td>7</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(capital-gain=0.0, hours_per_week_group=Overtime, race= White, capital-loss=0.0, relationship= Husband, marital-status=Married, native-country=United-States)</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.209</td>\n",
       "      <td>15.616</td>\n",
       "      <td>7</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(capital-gain=0.0, hours_per_week_group=Overtime, race= White, capital-loss=0.0, relationship= Husband, native-country=United-States)</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.209</td>\n",
       "      <td>15.616</td>\n",
       "      <td>6</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262</td>\n",
       "      <td>(capital-gain=0.0, hours_per_week_group=Overtime, race= White, capital-loss=0.0, marital-status=Married, native-country=United-States)</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.208</td>\n",
       "      <td>16.167</td>\n",
       "      <td>6</td>\n",
       "      <td>1707.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.239   \n",
       "1    0.239   \n",
       "2    0.239   \n",
       "3    0.239   \n",
       "4    0.262   \n",
       "\n",
       "                                                                                                                                                                    itemset  \\\n",
       "0  (sex= Male, capital-gain=0.0, hours_per_week_group=Overtime, race= White, capital-loss=0.0, relationship= Husband, marital-status=Married, native-country=United-States)   \n",
       "1                          (sex= Male, capital-gain=0.0, hours_per_week_group=Overtime, race= White, capital-loss=0.0, relationship= Husband, native-country=United-States)   \n",
       "2             (capital-gain=0.0, hours_per_week_group=Overtime, race= White, capital-loss=0.0, relationship= Husband, marital-status=Married, native-country=United-States)   \n",
       "3                                     (capital-gain=0.0, hours_per_week_group=Overtime, race= White, capital-loss=0.0, relationship= Husband, native-country=United-States)   \n",
       "4                                    (capital-gain=0.0, hours_per_week_group=Overtime, race= White, capital-loss=0.0, marital-status=Married, native-country=United-States)   \n",
       "\n",
       "   error  error_div  error_t  length  support_count  \n",
       "0  0.406      0.209   15.616       8       1554.000  \n",
       "1  0.406      0.209   15.616       7       1554.000  \n",
       "2  0.406      0.209   15.616       7       1554.000  \n",
       "3  0.406      0.209   15.616       6       1554.000  \n",
       "4  0.405      0.208   16.167       6       1707.000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_diver = DivergenceExplorer(df_val)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"error_div\", \"error_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "      <th>error</th>\n",
       "      <th>error_div</th>\n",
       "      <th>error_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.286</td>\n",
       "      <td>(capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0, marital-status=Married, native-country=United-States)</td>\n",
       "      <td>5</td>\n",
       "      <td>1859.000</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.204</td>\n",
       "      <td>16.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.288</td>\n",
       "      <td>(capital-gain=0.0, relationship= Husband, hours_per_week_group=Overtime, capital-loss=0.0)</td>\n",
       "      <td>4</td>\n",
       "      <td>1875.000</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.198</td>\n",
       "      <td>16.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.326</td>\n",
       "      <td>(capital-gain=0.0, hours_per_week_group=Overtime, marital-status=Married, capital-loss=0.0)</td>\n",
       "      <td>4</td>\n",
       "      <td>2119.000</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.193</td>\n",
       "      <td>16.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.336</td>\n",
       "      <td>(capital-gain=0.0, native-country=United-States, marital-status=Married, capital-loss=0.0)</td>\n",
       "      <td>4</td>\n",
       "      <td>2188.000</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.190</td>\n",
       "      <td>16.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.309</td>\n",
       "      <td>(capital-gain=0.0, native-country=United-States, hours_per_week_group=Overtime, marital-status=Married)</td>\n",
       "      <td>4</td>\n",
       "      <td>2010.000</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.187</td>\n",
       "      <td>15.670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support  \\\n",
       "10    0.286   \n",
       "17    0.288   \n",
       "28    0.326   \n",
       "40    0.336   \n",
       "45    0.309   \n",
       "\n",
       "                                                                                                                      itemset  \\\n",
       "10  (capital-gain=0.0, hours_per_week_group=Overtime, capital-loss=0.0, marital-status=Married, native-country=United-States)   \n",
       "17                                 (capital-gain=0.0, relationship= Husband, hours_per_week_group=Overtime, capital-loss=0.0)   \n",
       "28                                (capital-gain=0.0, hours_per_week_group=Overtime, marital-status=Married, capital-loss=0.0)   \n",
       "40                                 (capital-gain=0.0, native-country=United-States, marital-status=Married, capital-loss=0.0)   \n",
       "45                    (capital-gain=0.0, native-country=United-States, hours_per_week_group=Overtime, marital-status=Married)   \n",
       "\n",
       "    length  support_count  error  error_div  error_t  \n",
       "10       5       1859.000  0.401      0.204   16.496  \n",
       "17       4       1875.000  0.395      0.198   16.098  \n",
       "28       4       2119.000  0.390      0.193   16.507  \n",
       "40       4       2188.000  0.387      0.190   16.472  \n",
       "45       4       2010.000  0.384      0.187   15.670  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = error_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "df_pruned_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 83\n",
      "total problematic 50\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_error)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_error[(df_pruned_error['error_div'] > 0) & (df_pruned_error['error_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (893, 7)\n",
      "Dim pruned th_redundancy  (83, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_error.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset_and_or li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2645\n"
     ]
    }
   ],
   "source": [
    "print(len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "TRAIN SET MITIGATED ROWS:  15659\n",
      "VALIDATION SET ROWS:  6508\n",
      "FILTERED DF holdout ROWS:  2645\n",
      "TEST SET FILTERED ROWS:  6507\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'income', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['income']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "#cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2645\n",
      "verifica : 2645\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['income']\n",
    "\n",
    "classifier_train_mitigated_random = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.394</td>\n",
       "      <td>615</td>\n",
       "      <td>618</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.382</td>\n",
       "      <td>645</td>\n",
       "      <td>599</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.803     0.593                0.130   \n",
       "After Mitigation(K=5, fp)     0.811     0.606                0.124   \n",
       "After RANDOM mitigation       0.809     0.609                0.131   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.407              641   \n",
       "After Mitigation(K=5, fp)                0.394              615   \n",
       "After RANDOM mitigation                  0.382              645   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      638       13014       6508  \n",
       "After Mitigation(K=5, fp)              618       15659       6508  \n",
       "After RANDOM mitigation                599       15659       6508  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance su sottogruppi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.647</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.453</td>\n",
       "      <td>466</td>\n",
       "      <td>484</td>\n",
       "      <td>13014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.662</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.435</td>\n",
       "      <td>445</td>\n",
       "      <td>465</td>\n",
       "      <td>15659</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.654</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.428</td>\n",
       "      <td>475</td>\n",
       "      <td>457</td>\n",
       "      <td>15659</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                         Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                    0.647     0.552   \n",
       "After Mitigation(K=5, on subgroups, fp)            0.662     0.570   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)     0.654     0.568   \n",
       "\n",
       "Metrics                                         False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                               0.287   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.274   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.292   \n",
       "\n",
       "Metrics                                         False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                               0.453   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.435   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.428   \n",
       "\n",
       "Metrics                                         False Positives  \\\n",
       "Before Mitigation, on subgroups                             466   \n",
       "After Mitigation(K=5, on subgroups, fp)                     445   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              475   \n",
       "\n",
       "Metrics                                         False Negatives  Train Size  \\\n",
       "Before Mitigation, on subgroups                             484       13014   \n",
       "After Mitigation(K=5, on subgroups, fp)                     465       15659   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              457       15659   \n",
       "\n",
       "Metrics                                         Test Size  \n",
       "Before Mitigation, on subgroups                      2694  \n",
       "After Mitigation(K=5, on subgroups, fp)              2694  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)       2694  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered_fp = K_subgroups_dataset_and_or(df_pruned_error, df_test, K)\n",
    "inutile, df_test_filtered_enc_fp, inutile2, inutile3 = encoding_funct(df_train, df_test_filtered_fp, df_holdout, df_val)\n",
    "\n",
    "X_test_filtered_fp = df_test_filtered_enc_fp.drop(columns='income', axis = 1)\n",
    "y_true_test_filtered_fp = df_test_filtered_enc_fp['income']\n",
    "\n",
    "y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after = classifier_train_mitigated.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_random = classifier_train_mitigated_random.predict(X_test_filtered_fp)\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after )\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_random)\n",
    "\n",
    "\n",
    "metrics_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after, len(y_train_mitigated), len(y_pred_test_filtered_fp_after)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(y_train_mitigated_random), len(y_pred_test_filtered_fp_after_random)]\n",
    "})\n",
    "metrics_after_fp_sottogruppi = metrics_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi[metric] = metrics_after_fp_sottogruppi[metric].astype(int)\n",
    "\n",
    "metrics_after_fp\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp\")\n",
    "metrics_after_fp_sottogruppi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE\n",
    "\n",
    "\n",
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.130</td>\n",
       "      <td>2645.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.077</td>\n",
       "      <td>2645.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.803     0.593             0.063   \n",
       "After Mitigation(K=5 fp)            0.811     0.606             0.062   \n",
       "After RANDOM Mitigation(K=5 fp)     0.809     0.609             0.032   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.179               0.169   \n",
       "After Mitigation(K=5 fp)           0.180               0.168   \n",
       "After RANDOM Mitigation(K=5 fp)    0.171               0.150   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.163               0.136   \n",
       "After Mitigation(K=5 fp)                      0.159               0.130   \n",
       "After RANDOM Mitigation(K=5 fp)               0.121               0.077   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)              2645.000  \n",
       "After RANDOM Mitigation(K=5 fp)       2645.000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_no_mitigation  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_no_mitigation\n",
    "\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_baseline1  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_baseline1\n",
    "\n",
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values(\"error_div\", ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_random_per_confrontare_con_baseline1  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_random_per_confrontare_con_baseline1\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_error_div_list_no_mitigation = np.nanmean(error_div_list_no_mitigation)\n",
    "media_error_div_list_nomitigation_primi10 = np.nanmean(error_div_list_no_mitigation[:10])\n",
    "media_error_div_list_nomitigation_primi20 = np.nanmean(error_div_list_no_mitigation[:20])\n",
    "media_error_div_list_nomitigation_primi40 = np.nanmean(error_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_error_div_no_mitigation = max(abs(x) for x in error_div_list_no_mitigation)\n",
    "\n",
    "media_error_div_list_baseline1 = np.nanmean(error_div_list_baseline1)\n",
    "media_error_div_list_baseline1_primi10 = np.nanmean(error_div_list_baseline1[:10])\n",
    "media_error_div_list_baseline1_primi20 = np.nanmean(error_div_list_baseline1[:20])\n",
    "media_error_div_list_baseline1_primi40 = np.nanmean(error_div_list_baseline1[:40])\n",
    "error_div_massimo_valore_assoluto_error_div_baseline1 = max(abs(x) for x in error_div_list_baseline1)\n",
    "\n",
    "media_error_div_list_random_per_confrontare_con_baseline1 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1)\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_error_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in error_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_correctness_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_error_div_list_no_mitigation, massimo_valore_assoluto_error_div_no_mitigation,\n",
    "        media_error_div_list_nomitigation_primi10, media_error_div_list_nomitigation_primi20, media_error_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_error_div_list_baseline1, error_div_massimo_valore_assoluto_error_div_baseline1,\n",
    "        media_error_div_list_baseline1_primi10, media_error_div_list_baseline1_primi20, media_error_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_error_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_error_div_random_per_confrontare_con_baseline1, media_error_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_error_div_list_random_per_confrontare_con_baseline1_primi20, media_error_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_correctness_sottogruppi = divergence_after_correctness_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_correctness_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SIMULANDO DATI ATTRAVERSO SMOTE\n",
    "\n",
    "SEGUE CODICE USANDO SMOTE \n",
    "DIVIDO IN TRAIN, TEST E VALIDATION -- ora uso quelli gia esistenti\n",
    "DIV EXPLORER SUL VALIDATION  -- già fatto \n",
    "GENERO NUOVI DATI CON SMOTE a partire dai dati di divexplorer sul validation\n",
    "INSERISCO QUESTI NUOVI DATI NEL TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 2825\n",
      "numero di dati simulati con smotenc 3338\n",
      "income\n",
      "1    1669\n",
      "0    1669\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['error', 'y_pred', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]\n",
    "\n",
    "smote_nc = SMOTENC( categorical_features=categorical_features, random_state=seed)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "\n",
    "print(\"numero di dati simulati con smotenc\",len(y_resampled))\n",
    "\n",
    "class_counts = y_resampled.value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16352\n"
     ]
    }
   ],
   "source": [
    "X_train_mitigated_SMOTE = pd.concat([X_train, X_resampled], ignore_index=True)\n",
    "y_train_mitigated_SMOTE = pd.concat([y_train, y_resampled], ignore_index=True)\n",
    "print(len(X_train_mitigated_SMOTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_train_mitigated_SMOTE = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_SMOTE.fit(X_train_mitigated_SMOTE, y_train_mitigated_SMOTE)\n",
    "y_mitigated_SMOTE_pred = classifier_train_mitigated_SMOTE.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#vediamo che succede se prendo lo stesso numero di righe ma random da holdout\\nprint(len(X_resampled))\\nn_random_smote = len(X_resampled)\\n\\ndf_holdout_smote_sampled = df_holdout_enc.sample(n=n_random_smote, random_state=seed)\\nprint(\"verifica :\", len(df_holdout_smote_sampled)) #verifica\\n\\ndf_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\\ndf_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\\n\\nX_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\\ny_train_mitigated_random_smote = df_train_mitigated_random_smote[\\'income\\']\\n\\nclassifier_train_mitigated_random_smote = DecisionTreeClassifier(random_state=seed)\\n\\nclassifier_train_mitigated_random_smote.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\\ny_mitigated_pred_random_smote = classifier_train_mitigated_random_smote.predict(X_test)\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#vediamo che succede se prendo lo stesso numero di righe ma random da holdout\n",
    "print(len(X_resampled))\n",
    "n_random_smote = len(X_resampled)\n",
    "\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=n_random_smote, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_smote_sampled)) #verifica\n",
    "\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random_smote.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote = classifier_train_mitigated_random_smote.predict(X_test)\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_SMOTE_pred )\\naccuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote )\\n\\n\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\\n    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\\n    'After SMOTE fp mitigation' : [accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_mitigated_SMOTE_pred)],\\n    'After RANDOM mitigation' : [accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random, len(y_train_mitigated_random_smote), len(y_mitigated_pred_random_smote)]\\n    \\n})\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\\nmetrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n    \\nmetrics_after_fp_SMOTE\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_SMOTE_pred )\n",
    "accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote )\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After SMOTE fp mitigation' : [accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_mitigated_SMOTE_pred)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random, len(y_train_mitigated_random_smote), len(y_mitigated_pred_random_smote)]\n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "    \n",
    "metrics_after_fp_SMOTE'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A QUESTO PUNTO POSSIAMO VEDERE LE PERFORMANCE SUI SOTTOGRUPPI PRIMA E DOPO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \\ny_pred_test_filtered_fp_after_SMOTE = classifier_train_mitigated_SMOTE.predict(X_test_filtered_fp)\\ny_pred_RANDOM_subgroups = classifier_train_mitigated_random_smote.predict(X_test_filtered_fp)\\n\\n\\n#accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\\naccuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE )\\naccuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_RANDOM_subgroups )\\n\\nmetrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\\n    \\'Metrics\\' : [\\'Accuracy\\', \\'F1 Score\\', \\'False Positive Rate\\', \\'False Negative Rate\\', \\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\'],\\n    \\'Before Mitigation, on subgroups\\' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\\n    \\'After RANDOM mitigation, on subgroups\\' : [accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE, len(y_train), len(y_pred_RANDOM_subgroups)],\\n    \\'After Mitigation(K=5, on subgroups, fp and SMOTE)\\': [accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_pred_test_filtered_fp_after_SMOTE)],\\n})\\nmetrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index(\\'Metrics\\').T\\n\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\']\\n\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\\n\\nmetrics_after_fp_SMOTE\\n\\n\\nprint(\"Subgroups Decision Tree performance when boolean outcomes = correctness e SMOTE \")\\nmetrics_after_fp_sottogruppi_SMOTE'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "y_pred_test_filtered_fp_after_SMOTE = classifier_train_mitigated_SMOTE.predict(X_test_filtered_fp)\n",
    "y_pred_RANDOM_subgroups = classifier_train_mitigated_random_smote.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "#accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE )\n",
    "accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_RANDOM_subgroups )\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM mitigation, on subgroups' : [accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE, len(y_train), len(y_pred_RANDOM_subgroups)],\n",
    "    'After Mitigation(K=5, on subgroups, fp and SMOTE)': [accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_pred_test_filtered_fp_after_SMOTE)],\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = correctness e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p è la probabilità che il campione simulato sia di classe 0 qui (perchè voglio diminuire il numero di falsi positivi)\n",
    "- FISSO p VARIA N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 2825\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = [ 'y_pred', 'error', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1156, 1669)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered['income'].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0=0\n",
    "p1 = 0.1\n",
    "p2 = 0.2\n",
    "p3 = 0.3 \n",
    "p4 = 0.4\n",
    "p5 = 0.5\n",
    "p6 = 0.6\n",
    "p7 = 0.7\n",
    "p8 = 0.8\n",
    "p9 = 0.9\n",
    "p10 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df_holdout_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.077</td>\n",
       "      <td>2645.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.136</td>\n",
       "      <td>2645.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.103</td>\n",
       "      <td>2645.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.087</td>\n",
       "      <td>2645.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.125</td>\n",
       "      <td>2645.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.809     0.609             0.032   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.800     0.608             0.046   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.805     0.598             0.046   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.803     0.580             0.039   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.810     0.585             0.055   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.179               0.169   \n",
       "After RANDOM Mitigation(K=5 fp)            0.171               0.150   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.198               0.184   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.180               0.166   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.178               0.155   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.188               0.168   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.163   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.121   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.174   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.151   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.134   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.151   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.136          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.077       2645.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.136       2645.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.103       2645.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.087       2645.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.125       2645.000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_2K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.382</td>\n",
       "      <td>645</td>\n",
       "      <td>599</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.345</td>\n",
       "      <td>795</td>\n",
       "      <td>541</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.1</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.348</td>\n",
       "      <td>744</td>\n",
       "      <td>545</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.2</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.357</td>\n",
       "      <td>742</td>\n",
       "      <td>560</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.3</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.374</td>\n",
       "      <td>672</td>\n",
       "      <td>586</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.4</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.381</td>\n",
       "      <td>691</td>\n",
       "      <td>597</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.399</td>\n",
       "      <td>645</td>\n",
       "      <td>625</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.399</td>\n",
       "      <td>637</td>\n",
       "      <td>625</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.406</td>\n",
       "      <td>599</td>\n",
       "      <td>637</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.436</td>\n",
       "      <td>599</td>\n",
       "      <td>683</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.432</td>\n",
       "      <td>546</td>\n",
       "      <td>677</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.444</td>\n",
       "      <td>541</td>\n",
       "      <td>696</td>\n",
       "      <td>15659</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 5000         0.809     0.609                0.131   \n",
       "After SMOTE N = 5000 p_class 0 = 0       0.795     0.606                0.161   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1     0.802     0.613                0.151   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2     0.800     0.608                0.150   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3     0.807     0.610                0.136   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4     0.802     0.601                0.140   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.805     0.598                0.131   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.806     0.599                0.129   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.810     0.601                0.121   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.803     0.580                0.121   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.812     0.593                0.111   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.810     0.585                0.110   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 5000                    0.382              645   \n",
       "After SMOTE N = 5000 p_class 0 = 0                  0.345              795   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1                0.348              744   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2                0.357              742   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3                0.374              672   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4                0.381              691   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.399              645   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.399              637   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.406              599   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.436              599   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.432              546   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.444              541   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  599       15659       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0                541       15659       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.1              545       15659       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.2              560       15659       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.3              586       15659       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.4              597       15659       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              625       15659       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              625       15659       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              637       15659       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              683       15659       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              677       15659       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                696       15659       6508  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.099</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.130</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.110</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.076</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.112</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.809     0.609             0.044   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.799     0.599             0.052   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.805     0.598             0.052   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.809     0.594             0.035   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.810     0.586             0.046   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.179               0.169   \n",
       "After RANDOM Mitigation(K=5 fp)            0.174               0.160   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.194               0.181   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.180               0.166   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.178               0.159   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.172               0.154   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.163   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.149   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.172   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.154   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.127   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.139   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.136          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.099       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.130       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.110       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.076       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.112       2000.000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 2000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_2K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.390</td>\n",
       "      <td>664</td>\n",
       "      <td>611</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.357</td>\n",
       "      <td>766</td>\n",
       "      <td>560</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.1</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.357</td>\n",
       "      <td>740</td>\n",
       "      <td>560</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.2</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.377</td>\n",
       "      <td>717</td>\n",
       "      <td>591</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.3</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.369</td>\n",
       "      <td>712</td>\n",
       "      <td>578</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.4</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.382</td>\n",
       "      <td>685</td>\n",
       "      <td>599</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.397</td>\n",
       "      <td>646</td>\n",
       "      <td>623</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.399</td>\n",
       "      <td>632</td>\n",
       "      <td>625</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.407</td>\n",
       "      <td>597</td>\n",
       "      <td>638</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.420</td>\n",
       "      <td>585</td>\n",
       "      <td>658</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.438</td>\n",
       "      <td>543</td>\n",
       "      <td>687</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.443</td>\n",
       "      <td>539</td>\n",
       "      <td>695</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 5000         0.804     0.600                0.134   \n",
       "After SMOTE N = 5000 p_class 0 = 0       0.796     0.603                0.155   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1     0.800     0.608                0.150   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2     0.799     0.599                0.145   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3     0.802     0.606                0.144   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4     0.803     0.601                0.139   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.805     0.598                0.131   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.807     0.600                0.128   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.810     0.601                0.121   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.809     0.594                0.118   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.811     0.589                0.110   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.810     0.586                0.109   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 5000                    0.390              664   \n",
       "After SMOTE N = 5000 p_class 0 = 0                  0.357              766   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1                0.357              740   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2                0.377              717   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3                0.369              712   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4                0.382              685   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.397              646   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.399              632   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.407              597   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.420              585   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.438              543   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.443              539   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  611       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0                560       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.1              560       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.2              591       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.3              578       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.4              599       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              623       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              625       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              638       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              658       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              687       15014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                695       15014       6508  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.088</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.118</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.059</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.140</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.137</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.809     0.609             0.037   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.800     0.607             0.027   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.806     0.606             0.027   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.806     0.582             0.062   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.813     0.588             0.064   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.179               0.169   \n",
       "After RANDOM Mitigation(K=5 fp)            0.167               0.153   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.192               0.177   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.174               0.154   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.184               0.173   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.189               0.175   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.163   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.134   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.165   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.112   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.162   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.161   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.136          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.088       3000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.118       3000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.059       3000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.140       3000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.137       3000.000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 3000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_3K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.395</td>\n",
       "      <td>622</td>\n",
       "      <td>620</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.334</td>\n",
       "      <td>822</td>\n",
       "      <td>524</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.1</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.338</td>\n",
       "      <td>764</td>\n",
       "      <td>530</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.2</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.357</td>\n",
       "      <td>745</td>\n",
       "      <td>559</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.3</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.371</td>\n",
       "      <td>698</td>\n",
       "      <td>581</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.4</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.387</td>\n",
       "      <td>671</td>\n",
       "      <td>607</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.382</td>\n",
       "      <td>663</td>\n",
       "      <td>599</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.399</td>\n",
       "      <td>634</td>\n",
       "      <td>626</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.428</td>\n",
       "      <td>599</td>\n",
       "      <td>671</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.441</td>\n",
       "      <td>568</td>\n",
       "      <td>692</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.443</td>\n",
       "      <td>562</td>\n",
       "      <td>694</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.445</td>\n",
       "      <td>522</td>\n",
       "      <td>697</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 5000         0.809     0.604                0.126   \n",
       "After SMOTE N = 5000 p_class 0 = 0       0.793     0.608                0.166   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1     0.801     0.616                0.155   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2     0.800     0.607                0.151   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3     0.803     0.607                0.141   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4     0.804     0.601                0.136   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.806     0.606                0.134   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.806     0.599                0.128   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.805     0.586                0.121   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.806     0.582                0.115   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.807     0.582                0.114   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.813     0.588                0.106   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 5000                    0.395              622   \n",
       "After SMOTE N = 5000 p_class 0 = 0                  0.334              822   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1                0.338              764   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2                0.357              745   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3                0.371              698   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4                0.387              671   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.382              663   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.399              634   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.428              599   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.441              568   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.443              562   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.445              522   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  620       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0                524       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.1              530       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.2              559       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.3              581       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.4              607       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              599       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              626       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              671       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              692       16014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              694       16014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                697       16014       6508  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.131</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.114</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.123</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.123</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.084</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.809     0.609             0.056   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.796     0.600             0.056   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.796     0.579             0.056   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.803     0.576             0.056   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.813     0.588             0.033   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.179               0.169   \n",
       "After RANDOM Mitigation(K=5 fp)            0.182               0.165   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.186               0.171   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.196               0.177   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.195               0.177   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.170               0.145   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.163   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.155   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.162   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.167   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.161   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.124   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.136          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.131       4000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.114       4000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.123       4000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.123       4000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.084       4000.000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 4000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_4K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.388</td>\n",
       "      <td>634</td>\n",
       "      <td>609</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.328</td>\n",
       "      <td>821</td>\n",
       "      <td>514</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.1</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.334</td>\n",
       "      <td>772</td>\n",
       "      <td>523</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.2</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.365</td>\n",
       "      <td>756</td>\n",
       "      <td>573</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.3</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.360</td>\n",
       "      <td>702</td>\n",
       "      <td>564</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.4</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.371</td>\n",
       "      <td>708</td>\n",
       "      <td>582</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.417</td>\n",
       "      <td>676</td>\n",
       "      <td>654</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.408</td>\n",
       "      <td>643</td>\n",
       "      <td>640</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.424</td>\n",
       "      <td>630</td>\n",
       "      <td>665</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.444</td>\n",
       "      <td>588</td>\n",
       "      <td>696</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.443</td>\n",
       "      <td>550</td>\n",
       "      <td>695</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.446</td>\n",
       "      <td>516</td>\n",
       "      <td>700</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.803     0.593                0.130   \n",
       "After RANDOM mitigation N = 5000         0.809     0.607                0.128   \n",
       "After SMOTE N = 5000 p_class 0 = 0       0.795     0.612                0.166   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1     0.801     0.617                0.156   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2     0.796     0.600                0.153   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3     0.805     0.613                0.142   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4     0.802     0.605                0.143   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.796     0.579                0.137   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.803     0.591                0.130   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.801     0.582                0.128   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.803     0.576                0.119   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.809     0.584                0.111   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.813     0.588                0.104   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.407              641   \n",
       "After RANDOM mitigation N = 5000                    0.388              634   \n",
       "After SMOTE N = 5000 p_class 0 = 0                  0.328              821   \n",
       "After SMOTE N = 5000 p_class 0 = 0.1                0.334              772   \n",
       "After SMOTE N = 5000 p_class 0 = 0.2                0.365              756   \n",
       "After SMOTE N = 5000 p_class 0 = 0.3                0.360              702   \n",
       "After SMOTE N = 5000 p_class 0 = 0.4                0.371              708   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.417              676   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.408              643   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.424              630   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.444              588   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.443              550   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.446              516   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  609       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0                514       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.1              523       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.2              573       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.3              564       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.4              582       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              654       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              640       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              665       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              696       17014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              695       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                700       17014       6508  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 5000 p changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.139</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.149</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.065</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.110</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.123</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.809     0.609             0.063   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.798     0.603             0.025   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.798     0.584             0.025   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.806     0.586             0.054   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.808     0.576             0.052   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.179               0.169   \n",
       "After RANDOM Mitigation(K=5 fp)            0.193               0.173   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.192               0.179   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.173               0.154   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.193               0.176   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.190               0.169   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.163   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.164   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.170   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.110   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.159   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.151   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.136          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.139       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.149       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.065       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.110       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.123       5000.000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 5000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_5K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.647</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.453</td>\n",
       "      <td>466</td>\n",
       "      <td>484</td>\n",
       "      <td>13014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.646</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.454</td>\n",
       "      <td>470</td>\n",
       "      <td>485</td>\n",
       "      <td>18014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.628</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.359</td>\n",
       "      <td>619</td>\n",
       "      <td>384</td>\n",
       "      <td>18014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.638</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.386</td>\n",
       "      <td>562</td>\n",
       "      <td>413</td>\n",
       "      <td>18014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.646</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.400</td>\n",
       "      <td>525</td>\n",
       "      <td>428</td>\n",
       "      <td>18014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.633</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.434</td>\n",
       "      <td>526</td>\n",
       "      <td>464</td>\n",
       "      <td>18014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.643</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.460</td>\n",
       "      <td>470</td>\n",
       "      <td>492</td>\n",
       "      <td>18014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.653</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.446</td>\n",
       "      <td>458</td>\n",
       "      <td>477</td>\n",
       "      <td>18014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.647     0.552   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.646     0.550   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.628     0.577   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.638     0.574   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.646     0.574   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.633     0.550   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.643     0.545   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.653     0.559   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.287   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.289   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.381   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.346   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.323   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.324   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.289   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.282   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.453   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.454   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.359   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.386   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.400   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.434   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.460   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.446   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                     466   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      470   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              619   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              562   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              525   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              526   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              470   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                458   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     484   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      485   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              384   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              413   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              428   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              464   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              492   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                477   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       2694  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               18014       2694  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       18014       2694  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       18014       2694  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       18014       2694  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       18014       2694  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       18014       2694  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         18014       2694  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 6000 p changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.093</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.180</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.107</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.120</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.077</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.809     0.609             0.043   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.798     0.608             0.054   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.802     0.595             0.054   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.805     0.583             0.053   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.810     0.576             0.030   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.179               0.169   \n",
       "After RANDOM Mitigation(K=5 fp)            0.168               0.154   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.201               0.195   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.203               0.186   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.198               0.177   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.171               0.142   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.163   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.141   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.190   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.167   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.164   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.119   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.136          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.093       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.180       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.107       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.120       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.077       6000.000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 6000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_6K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.647</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.453</td>\n",
       "      <td>466</td>\n",
       "      <td>484</td>\n",
       "      <td>13014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.657</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.426</td>\n",
       "      <td>470</td>\n",
       "      <td>455</td>\n",
       "      <td>19014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.633</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.341</td>\n",
       "      <td>624</td>\n",
       "      <td>365</td>\n",
       "      <td>19014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.637</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.363</td>\n",
       "      <td>591</td>\n",
       "      <td>388</td>\n",
       "      <td>19014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.626</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.398</td>\n",
       "      <td>583</td>\n",
       "      <td>425</td>\n",
       "      <td>19014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.647</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.402</td>\n",
       "      <td>522</td>\n",
       "      <td>430</td>\n",
       "      <td>19014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.443</td>\n",
       "      <td>497</td>\n",
       "      <td>474</td>\n",
       "      <td>19014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.652</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.442</td>\n",
       "      <td>464</td>\n",
       "      <td>473</td>\n",
       "      <td>19014</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.647     0.552   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.657     0.570   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.633     0.587   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.637     0.582   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.626     0.561   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.647     0.573   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.640     0.551   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.652     0.560   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.287   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.289   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.384   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.364   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.359   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.321   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.306   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.286   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.453   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.426   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.341   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.363   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.398   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.402   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.443   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.442   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                     466   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      470   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              624   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              591   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              583   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              522   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              497   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                464   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     484   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      455   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              365   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              388   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              425   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              430   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              474   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                473   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       2694  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               19014       2694  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       19014       2694  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       19014       2694  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       19014       2694  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       19014       2694  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       19014       2694  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         19014       2694  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.106</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.151</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.087</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.106</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.099</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.809     0.609             0.048   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.796     0.603             0.035   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.803     0.594             0.035   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.804     0.581             0.047   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.808     0.566             0.045   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.179               0.169   \n",
       "After RANDOM Mitigation(K=5 fp)            0.174               0.161   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.193               0.181   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.190               0.165   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.195               0.168   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.182               0.161   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.163   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.149   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.172   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.135   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.148   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.139   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.136          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.106       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.151       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.087       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.106       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.099       7000.000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 7000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_6K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.116</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.142</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.090</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.111</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.082</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.809     0.609             0.052   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.795     0.602             0.038   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.797     0.581             0.038   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.801     0.570             0.053   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.803     0.562             0.031   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.179               0.169   \n",
       "After RANDOM Mitigation(K=5 fp)            0.187               0.169   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.194               0.182   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.191               0.172   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.193               0.173   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.166               0.137   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.163   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.158   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.173   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.145   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.156   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.117   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.136          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.116       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.142       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.090       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.111       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.082       8000.000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 8000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_6K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.111</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.2)</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.119</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.086</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.110</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.096</td>\n",
       "      <td>9000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.803     0.593             0.063   \n",
       "After RANDOM Mitigation(K=5 fp)             0.809     0.609             0.050   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)     0.801     0.616             0.035   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.806     0.606             0.035   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.804     0.578             0.052   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.806     0.560             0.037   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.179               0.169   \n",
       "After RANDOM Mitigation(K=5 fp)            0.175               0.161   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)    0.195               0.181   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.183               0.161   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.190               0.169   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.172               0.152   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.163   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.150   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.170   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.133   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.149   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.131   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.136          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.111       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.2)               0.119       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.086       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.110       9000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.096       9000.000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0\n",
    "N = 9000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*p0), 1: count_1 + int(N*p10)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p0 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p0 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p0 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p0.fit(X_train_mit_SMOTE_p0, y_train_mit_SMOTE_p0)\n",
    "y_pred_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test)\n",
    "\n",
    "#0.1\n",
    "sampling_strategy = {0: count_0 + int(N*p1), 1: count_1 + int(N*p9)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "\n",
    "#0.2\n",
    "sampling_strategy = {0: count_0 + int(N*p2), 1: count_1 + int(N*p8)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#0.3\n",
    "sampling_strategy = {0: count_0 + int(N*p3), 1: count_1 + int(N*p7)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "\n",
    "#0.4\n",
    "sampling_strategy = {0: count_0 + int(N*p4), 1: count_1 + int(N*p6)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#0.5\n",
    "sampling_strategy = {0: count_0 + int(N*p5), 1: count_1 + int(N*p5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.6\n",
    "sampling_strategy = {0: count_0 + int(N*p6), 1: count_1 + int(N*p4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.7\n",
    "sampling_strategy = {0: count_0 + int(N*p7), 1: count_1 + int(N*p3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p7 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p7 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p7 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p7.fit(X_train_mit_SMOTE_p7, y_train_mit_SMOTE_p7)\n",
    "y_pred_SMOTE_p7= classifier_train_mit_SMOTE_p7.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.8\n",
    "sampling_strategy = {0: count_0 + int(N*p8), 1: count_1 + int(N*p2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p8 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p8 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p8 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p8.fit(X_train_mit_SMOTE_p8, y_train_mit_SMOTE_p8)\n",
    "y_pred_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.9\n",
    "sampling_strategy = {0: count_0 + int(N*p9), 1: count_1 + int(N*p1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p9 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p9 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p9 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p9.fit(X_train_mit_SMOTE_p9, y_train_mit_SMOTE_p9)\n",
    "y_pred_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "sampling_strategy = {0: count_0 + int(N*p10), 1: count_1 + int(N*p0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p10 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p10 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p10 = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p10.fit(X_train_mit_SMOTE_p10, y_train_mit_SMOTE_p10)\n",
    "y_pred_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p0 )    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p7 )\n",
    "accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p8 )\n",
    "accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p9 )\n",
    "accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p10 )\n",
    "\n",
    "\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0' : [accuracy_fp_after_SMOTE_p0, f1_score_fp_after_SMOTE_p0, fpr_fp_after_SMOTE_p0, fnr_fp_after_SMOTE_p0, fp_fp_after_SMOTE_p0, fn_fp_after_SMOTE_p0, len(X_train_mit_SMOTE_p0), len(y_pred_SMOTE_p0)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.1' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.2' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.3' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.4' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p7, f1_score_fp_after_SMOTE_p7, fpr_fp_after_SMOTE_p7, fnr_fp_after_SMOTE_p7, fp_fp_after_SMOTE_p7, fn_fp_after_SMOTE_p7, len(X_train_mit_SMOTE_p7), len(y_pred_SMOTE_p7)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p8, f1_score_fp_after_SMOTE_p8, fpr_fp_after_SMOTE_p8, fnr_fp_after_SMOTE_p8, fp_fp_after_SMOTE_p8, fn_fp_after_SMOTE_p8, len(X_train_mit_SMOTE_p8), len(y_pred_SMOTE_p8)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p9, f1_score_fp_after_SMOTE_p9, fpr_fp_after_SMOTE_p9, fnr_fp_after_SMOTE_p9, fp_fp_after_SMOTE_p9, fn_fp_after_SMOTE_p9, len(X_train_mit_SMOTE_p9), len(y_pred_SMOTE_p9)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p10, f1_score_fp_after_SMOTE_p10, fpr_fp_after_SMOTE_p10, fnr_fp_after_SMOTE_p10, fp_fp_after_SMOTE_p10, fn_fp_after_SMOTE_p10, len(X_train_mit_SMOTE_p10), len(y_pred_SMOTE_p10)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "\n",
    "errors_after_6K = [fp + fn for fp, fn in zip(falsi_positivi_2K_fp_5sub, falsi_negativi_2K_fp_5sub)]\n",
    "errors_before = falsi_negativi_2K_fp_5sub_before + falsi_positivi_2K_fp_5sub_before \n",
    "\n",
    "accuracy02 = metrics_after_fp_SMOTE['Accuracy'].iloc[4]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[10]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[12]\n",
    "\n",
    "f1score02 = metrics_after_fp_SMOTE['F1 Score'].iloc[4]\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[10]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[12]\n",
    "#SOTTOGRUPPI\n",
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p0 = classifier_train_mit_SMOTE_p0.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p7 = classifier_train_mit_SMOTE_p7.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p8 = classifier_train_mit_SMOTE_p8.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p9 = classifier_train_mit_SMOTE_p9.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p10 = classifier_train_mit_SMOTE_p10.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "\n",
    "#non ci importa dei sttogruppi \n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che è quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.2\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p2\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p2_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che è SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p5\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p5_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che è SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p8\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p8_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che è SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p10\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p10_5K = df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by='error_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = df_pruned_error.sort_values('error_div', ascending=False)\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_error['error_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = np.nanmean(fp_div_list_no_mitigation)\n",
    "media_fp_div_list_nomitigation_primi10 = np.nanmean(fp_div_list_no_mitigation[:10])\n",
    "media_fp_div_list_nomitigation_primi20 = np.nanmean(fp_div_list_no_mitigation[:20])\n",
    "media_fp_div_list_nomitigation_primi40 = np.nanmean(fp_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p2_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p2_5K_primi10 = np.nanmean(fp_div_list_baseline2_p2_5K[:10])\n",
    "media_fp_div_list_baseline2_p2_5K_primi20 = np.nanmean(fp_div_list_baseline2_p2_5K[:20])\n",
    "media_fp_div_list_baseline2_p2_5K_primi40 = np.nanmean(fp_div_list_baseline2_p2_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K = max(abs(x) for x in fp_div_list_baseline2_p2_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p5_5K = np.nanmean(fp_div_list_baseline2_p5_5K)\n",
    "media_fp_div_list_baseline2_p5_5K_primi10 = np.nanmean(fp_div_list_baseline2_p5_5K[:10])\n",
    "media_fp_div_list_baseline2_p5_5K_primi20 = np.nanmean(fp_div_list_baseline2_p5_5K[:20])\n",
    "media_fp_div_list_baseline2_p5_5K_primi40 = np.nanmean(fp_div_list_baseline2_p5_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K = max(abs(x) for x in fp_div_list_baseline2_p5_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p8_5K = np.nanmean(fp_div_list_baseline2_p8_5K)\n",
    "media_fp_div_list_baseline2_p8_5K_primi10 = abs(sum(fp_div_list_baseline2_p8_5K[:10]) / len(fp_div_list_baseline2_p8_5K[:10]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi20 = abs(sum(fp_div_list_baseline2_p8_5K[:20]) / len(fp_div_list_baseline2_p8_5K[:20]))\n",
    "media_fp_div_list_baseline2_p8_5K_primi40 = abs(sum(fp_div_list_baseline2_p8_5K[:40]) / len(fp_div_list_baseline2_p8_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K = max(abs(x) for x in fp_div_list_baseline2_p8_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p10_5K = np.nanmean(fp_div_list_baseline2_p10_5K)\n",
    "media_fp_div_list_baseline2_p10_5K_primi10 = np.nanmean(fp_div_list_baseline2_p10_5K[:10])\n",
    "media_fp_div_list_baseline2_p10_5K_primi20 = np.nanmean(fp_div_list_baseline2_p10_5K[:20])\n",
    "media_fp_div_list_baseline2_p10_5K_primi40 = np.nanmean(fp_div_list_baseline2_p10_5K[:40])\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K = max(abs(x) for x in fp_div_list_baseline2_p10_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1)\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(fp_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=0.2)': [\n",
    "        accuracy02, f1score02, media_fp_div_list_baseline2_p2_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p2_5K,\n",
    "        media_fp_div_list_baseline2_p2_5K_primi10, media_fp_div_list_baseline2_p2_5K_primi20, media_fp_div_list_baseline2_p2_5K_primi40, N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p5_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p5_5K,\n",
    "        media_fp_div_list_baseline2_p5_5K_primi10, media_fp_div_list_baseline2_p5_5K_primi20, media_fp_div_list_baseline2_p5_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p8_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p8_5K,\n",
    "        media_fp_div_list_baseline2_p8_5K_primi10, media_fp_div_list_baseline2_p8_5K_primi20, media_fp_div_list_baseline2_p8_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p10_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p10_5K,\n",
    "        media_fp_div_list_baseline2_p10_5K_primi10, media_fp_div_list_baseline2_p10_5K_primi20, media_fp_div_list_baseline2_p10_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creazione del grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "p =[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "# Linea per i falsi positivi\n",
    "\n",
    "plt.plot(p, errors_after_2K, marker='o', label='Error 2K ', color='black')\n",
    "plt.plot(p, errors_after_3K, marker='o', label='Error 3K ', color='red')\n",
    "plt.plot(p, errors_after_4K, marker='o', label='Error 4K ', color='green')\n",
    "plt.plot(p, errors_after_5K, marker='o', label='Error 5K ', color='blue')\n",
    "plt.plot(p, errors_after_6K,  marker='o', label='Error 6K ', color='orange')\n",
    "\n",
    "\n",
    "plt.axhline(y=errors_before, color='purple', linestyle='--', label='Initial Errors')\n",
    "\n",
    "# Etichette e titolo\n",
    "plt.xlabel('probability for the synthetic point to belong to the class 0')\n",
    "plt.ylabel('Count Errors')\n",
    "plt.title(f'Errors, err, #subgroups = {K}, support = {min_sup} on {filtered_instances}, redundancy = 0.01')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.yticks(range(1175, 1350, 25))\n",
    "plt.xticks(np.arange(0, 1.1, 0.1)) \n",
    "# Mostra il grafico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1156, 1669)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
