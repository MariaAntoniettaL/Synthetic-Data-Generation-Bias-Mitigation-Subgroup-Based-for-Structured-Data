{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE\n",
    "Nel file preprocessing_for_adult.py sono contenute le funzioni per il preprocessing da applicare ad adult.data: la prima (preprocessing_funct_not_enc) discretizza, normalizza ecc mentre la seconda (encoding_funct) esegue l'encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_for_adult import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_and, K_subgroups_dataset_and_or, metrics_to_compare, preprocessing_funct_not_enc_SMOTE, encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "from divexplorer.outcomes import get_false_positive_rate_outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = 0.2\n",
    "percentage = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv(\"adult.data\", header = None, names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosit√† precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_no_income = df_train_enc.drop(columns = 'income')\n",
    "plt.figure(figsize=(4, 3))\n",
    "g = sns.heatmap(df_train_no_income.corr(),\n",
    "                annot = False,\n",
    "                cmap = \"coolwarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "X_train = df_train_enc.drop(columns = 'income', axis = 1)\n",
    "y_train = df_train_enc['income']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'income', axis = 1)\n",
    "y_test = df_test_enc['income']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'income', axis = 1)\n",
    "y_val = df_val_enc['income']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'income', axis = 1)\n",
    "y_holdout = df_holdout_enc['income']\n",
    "\n",
    "classifier_train = LogisticRegression(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.643</td>\n",
       "      <td>234</td>\n",
       "      <td>1008</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.809     0.474                0.047   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.643              234             1008   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       6508  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione √® giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>2</td>\n",
       "      <td>0.077</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0</td>\n",
       "      <td>0.284</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass  fnlwgt  education  marital-status  occupation  relationship  \\\n",
       "18761          2   0.077          3               0           4             1   \n",
       "27582          3   0.048          3               1           4             0   \n",
       "30911          2   0.174          3               3           4             4   \n",
       "11128          0   0.012          2               1           2             0   \n",
       "683            0   0.284          3               3           2             4   \n",
       "\n",
       "       race  sex  capital-gain  capital-loss  native-country  age_group  \\\n",
       "18761     4    0         0.000         0.000               5          2   \n",
       "27582     4    1         0.000         0.000               5          5   \n",
       "30911     2    0         0.039         0.000               5          1   \n",
       "11128     2    1         0.000         0.507               5          3   \n",
       "683       2    1         0.000         0.000               5          0   \n",
       "\n",
       "       edu_num_group  hours_per_week_group  y_val_true  y_pred  \n",
       "18761              1                     1           0       0  \n",
       "27582              1                     2           1       0  \n",
       "30911              1                     1           0       0  \n",
       "11128              4                     1           1       1  \n",
       "683                1                     1           0       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set, queste mi servono solo per il div explorer che ha bisogno di ground truth e predizioni\n",
    "y_pred_val = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>fp</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.077</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>Self-emp</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>65-100</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.174</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.012</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>45-54</td>\n",
       "      <td>14 Master's Degree</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.284</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        workclass  fnlwgt        education marital-status    occupation  \\\n",
       "18761     Private   0.077    Non Graduated       Divorced  Self-emp-occ   \n",
       "27582    Self-emp   0.048    Non Graduated        Married  Self-emp-occ   \n",
       "30911     Private   0.174    Non Graduated      Separated  Self-emp-occ   \n",
       "11128  Government   0.012  Master's Degree        Married   Private-occ   \n",
       "683    Government   0.284    Non Graduated      Separated   Private-occ   \n",
       "\n",
       "         relationship    race      sex  capital-gain  capital-loss  \\\n",
       "18761   Not-in-family   White   Female         0.000         0.000   \n",
       "27582         Husband   White     Male         0.000         0.000   \n",
       "30911       Unmarried   Black   Female         0.039         0.000   \n",
       "11128         Husband   Black     Male         0.000         0.507   \n",
       "683         Unmarried   Black     Male         0.000         0.000   \n",
       "\n",
       "      native-country  income age_group       edu_num_group  \\\n",
       "18761  United-States       0     35-44          10 College   \n",
       "27582  United-States       1    65-100          10 College   \n",
       "30911  United-States       0     25-34          10 College   \n",
       "11128  United-States       1     45-54  14 Master's Degree   \n",
       "683    United-States       0     17-24          10 College   \n",
       "\n",
       "      hours_per_week_group    fp  y_pred  accuracy  \n",
       "18761             Overtime 0.000       0         1  \n",
       "27582            Part-time   NaN       0         0  \n",
       "30911             Overtime 0.000       0         1  \n",
       "11128             Overtime   NaN       1         1  \n",
       "683               Overtime 0.000       0         1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]\n",
    "\n",
    "df_val_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_val['fp'] = df_val_class['fp']\n",
    "\n",
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione √® giusta 0 se la predizione √® sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['accuracy'] = (df_val_class['y_val_true']==df_val_class['y_pred']).astype(int)\n",
    "df_val.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI CONDOTTA CON LA FEATURE FP (PASSATA A BOOLEAN OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fp</th>\n",
       "      <th>fp_div</th>\n",
       "      <th>fp_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202</td>\n",
       "      <td>(race= White, education=Bachelor's Degree)</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.143</td>\n",
       "      <td>10.239</td>\n",
       "      <td>2</td>\n",
       "      <td>1317.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.211</td>\n",
       "      <td>(native-country=United-States, education=Bachelor's Degree)</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.137</td>\n",
       "      <td>10.200</td>\n",
       "      <td>2</td>\n",
       "      <td>1374.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.233</td>\n",
       "      <td>(education=Bachelor's Degree)</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.129</td>\n",
       "      <td>10.237</td>\n",
       "      <td>1</td>\n",
       "      <td>1517.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.207</td>\n",
       "      <td>(capital-gain=0.0, education=Bachelor's Degree)</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.121</td>\n",
       "      <td>9.498</td>\n",
       "      <td>2</td>\n",
       "      <td>1346.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219</td>\n",
       "      <td>(capital-loss=0.0, education=Bachelor's Degree)</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.115</td>\n",
       "      <td>9.240</td>\n",
       "      <td>2</td>\n",
       "      <td>1427.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support                                                      itemset    fp  \\\n",
       "0    0.202                   (race= White, education=Bachelor's Degree) 0.193   \n",
       "1    0.211  (native-country=United-States, education=Bachelor's Degree) 0.188   \n",
       "2    0.233                                (education=Bachelor's Degree) 0.180   \n",
       "3    0.207              (capital-gain=0.0, education=Bachelor's Degree) 0.171   \n",
       "4    0.219              (capital-loss=0.0, education=Bachelor's Degree) 0.166   \n",
       "\n",
       "   fp_div   fp_t  length  support_count  \n",
       "0   0.143 10.239       2       1317.000  \n",
       "1   0.137 10.200       2       1374.000  \n",
       "2   0.129 10.237       1       1517.000  \n",
       "3   0.121  9.498       2       1346.000  \n",
       "4   0.115  9.240       2       1427.000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_diver = DivergenceExplorer(df_val)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"fp_div\", \"fp_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "      <th>fp</th>\n",
       "      <th>fp_div</th>\n",
       "      <th>fp_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202</td>\n",
       "      <td>(race= White, education=Bachelor's Degree)</td>\n",
       "      <td>2</td>\n",
       "      <td>1317.000</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.143</td>\n",
       "      <td>10.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.233</td>\n",
       "      <td>(education=Bachelor's Degree)</td>\n",
       "      <td>1</td>\n",
       "      <td>1517.000</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.129</td>\n",
       "      <td>10.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219</td>\n",
       "      <td>(capital-loss=0.0, education=Bachelor's Degree)</td>\n",
       "      <td>2</td>\n",
       "      <td>1427.000</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.115</td>\n",
       "      <td>9.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.403</td>\n",
       "      <td>(relationship= Husband)</td>\n",
       "      <td>1</td>\n",
       "      <td>2621.000</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.072</td>\n",
       "      <td>7.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.414</td>\n",
       "      <td>(marital-status=Married, sex= Male)</td>\n",
       "      <td>2</td>\n",
       "      <td>2692.000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.068</td>\n",
       "      <td>7.624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support                                          itemset  length  \\\n",
       "0     0.202       (race= White, education=Bachelor's Degree)       2   \n",
       "2     0.233                    (education=Bachelor's Degree)       1   \n",
       "4     0.219  (capital-loss=0.0, education=Bachelor's Degree)       2   \n",
       "35    0.403                          (relationship= Husband)       1   \n",
       "64    0.414              (marital-status=Married, sex= Male)       2   \n",
       "\n",
       "    support_count    fp  fp_div   fp_t  \n",
       "0        1317.000 0.193   0.143 10.239  \n",
       "2        1517.000 0.180   0.129 10.237  \n",
       "4        1427.000 0.166   0.115  9.240  \n",
       "35       2621.000 0.122   0.072  7.847  \n",
       "64       2692.000 0.118   0.068  7.624  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 31\n",
      "total problematic 18\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_fp)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_fp[(df_pruned_fp['fp_div'] > 0) & (df_pruned_fp['fp_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (893, 7)\n",
      "Dim pruned th_redundancy  (31, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_fp.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset_and_or li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "df_holdout_filtered_solo0 = df_holdout_filtered[df_holdout_filtered['income']==0]\n",
    "\n",
    "\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered_solo0, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "df_holdout_filtered = df_holdout_filtered_solo0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020\n"
     ]
    }
   ],
   "source": [
    "print(len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \\ndf_train_enc_mit, df_test_enc_filtered_fp, df_filtered_enc, df_val_enc_mit = encoding_funct(df_train=df_train_mitigated, df_test=df_test_filtered_fp, df_holdout=df_holdout_filtered, df_val=df_val)\\n#controllo divisione dataset\\ndf_train_enc_mit_fp = df_train_enc_mit  \\nprint(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\\nprint(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\\nprint(f\"VALIDATION SET ROWS: \", df_val_enc_mit.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\\nprint(f\"FILTERED DF holdout ROWS: \", df_filtered_enc.shape[0])\\nprint(f\"TEST SET FILTERED ROWS: \", df_test_enc_filtered_fp.shape[0])'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, df_test_enc_filtered_fp, df_filtered_enc, df_val_enc_mit = encoding_funct(df_train=df_train_mitigated, df_test=df_test_filtered_fp, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc_mit.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", df_filtered_enc.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", df_test_enc_filtered_fp.shape[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "TRAIN SET MITIGATED ROWS:  14034\n",
      "VALIDATION SET ROWS:  6508\n",
      "FILTERED DF holdout ROWS:  1020\n",
      "TEST SET FILTERED ROWS:  6507\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'income', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['income']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = LogisticRegression(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "#cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020\n",
      "verifica : 1020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['income']\n",
    "\n",
    "classifier_train_mitigated_random = LogisticRegression(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.643</td>\n",
       "      <td>234</td>\n",
       "      <td>1008</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.719</td>\n",
       "      <td>146</td>\n",
       "      <td>1127</td>\n",
       "      <td>14034</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.642</td>\n",
       "      <td>241</td>\n",
       "      <td>1006</td>\n",
       "      <td>14034</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.809     0.474                0.047   \n",
       "After Mitigation(K=5, fp)     0.804     0.409                0.030   \n",
       "After RANDOM mitigation       0.808     0.474                0.049   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.643              234   \n",
       "After Mitigation(K=5, fp)                0.719              146   \n",
       "After RANDOM mitigation                  0.642              241   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                     1008       13014       6508  \n",
       "After Mitigation(K=5, fp)             1127       14034       6508  \n",
       "After RANDOM mitigation               1006       14034       6508  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance su sottogruppi \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.724</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.438</td>\n",
       "      <td>164</td>\n",
       "      <td>252</td>\n",
       "      <td>13014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.707</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.618</td>\n",
       "      <td>85</td>\n",
       "      <td>356</td>\n",
       "      <td>14034</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.722</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.434</td>\n",
       "      <td>169</td>\n",
       "      <td>250</td>\n",
       "      <td>14034</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                         Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                    0.724     0.609   \n",
       "After Mitigation(K=5, on subgroups, fp)            0.707     0.499   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)     0.722     0.609   \n",
       "\n",
       "Metrics                                         False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                               0.176   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.091   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.182   \n",
       "\n",
       "Metrics                                         False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                               0.438   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.618   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.434   \n",
       "\n",
       "Metrics                                         False Positives  \\\n",
       "Before Mitigation, on subgroups                             164   \n",
       "After Mitigation(K=5, on subgroups, fp)                      85   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              169   \n",
       "\n",
       "Metrics                                         False Negatives  Train Size  \\\n",
       "Before Mitigation, on subgroups                             252       13014   \n",
       "After Mitigation(K=5, on subgroups, fp)                     356       14034   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              250       14034   \n",
       "\n",
       "Metrics                                         Test Size  \n",
       "Before Mitigation, on subgroups                      1507  \n",
       "After Mitigation(K=5, on subgroups, fp)              1507  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)       1507  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered_fp = K_subgroups_dataset_and_or(df_pruned_fp, df_test, K)\n",
    "inutile, df_test_filtered_enc_fp, inutile2, inutile3 = encoding_funct(df_train, df_test_filtered_fp, df_holdout, df_val)\n",
    "\n",
    "X_test_filtered_fp = df_test_filtered_enc_fp.drop(columns='income', axis = 1)\n",
    "y_true_test_filtered_fp = df_test_filtered_enc_fp['income']\n",
    "\n",
    "y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after = classifier_train_mitigated.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_random = classifier_train_mitigated_random.predict(X_test_filtered_fp)\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after )\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_random)\n",
    "\n",
    "\n",
    "metrics_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after, len(y_train_mitigated), len(y_pred_test_filtered_fp_after)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(y_train_mitigated_random), len(y_pred_test_filtered_fp_after_random)]\n",
    "})\n",
    "metrics_after_fp_sottogruppi = metrics_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi[metric] = metrics_after_fp_sottogruppi[metric].astype(int)\n",
    "\n",
    "metrics_after_fp\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp\")\n",
    "metrics_after_fp_sottogruppi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline1  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_random_per_confrontare_con_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1020.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.019</td>\n",
       "      <td>1020.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.809     0.474             0.018   \n",
       "After Mitigation(K=5 fp)            0.804     0.409             0.007   \n",
       "After RANDOM Mitigation(K=5 fp)     0.808     0.474             0.016   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.144               0.077   \n",
       "After Mitigation(K=5 fp)           0.062               0.033   \n",
       "After RANDOM Mitigation(K=5 fp)    0.149               0.077   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.052               0.021   \n",
       "After Mitigation(K=5 fp)                      0.021               0.007   \n",
       "After RANDOM Mitigation(K=5 fp)               0.051               0.019   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)              1020.000  \n",
       "After RANDOM Mitigation(K=5 fp)       1020.000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline1 = abs(sum(fp_div_list_baseline1) / len(fp_div_list_baseline1))\n",
    "media_fp_div_list_baseline1_primi10 = abs(sum(fp_div_list_baseline1[:10]) / len(fp_div_list_baseline1[:10]))\n",
    "media_fp_div_list_baseline1_primi20 = abs(sum(fp_div_list_baseline1[:20]) / len(fp_div_list_baseline1[:20]))\n",
    "media_fp_div_list_baseline1_primi40 = abs(sum(fp_div_list_baseline1[:40]) / len(fp_div_list_baseline1[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_baseline1 = max(abs(x) for x in fp_div_list_baseline1)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_fp_div_list_baseline1, fp_div_massimo_valore_assoluto_fp_div_baseline1,\n",
    "        media_fp_div_list_baseline1_primi10, media_fp_div_list_baseline1_primi20, media_fp_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SIMULANDO DATI ATTRAVERSO SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGUE CODICE USANDO SMOTE \n",
    "DIVIDO IN TRAIN, TEST E VALIDATION -- ora uso quelli gia esistenti\n",
    "DIV EXPLORER SUL VALIDATION  -- gi√† fatto \n",
    "GENERO NUOVI DATI CON SMOTE a partire dai dati di divexplorer sul validation\n",
    "INSERISCO QUESTI NUOVI DATI NEL TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 1515\n",
      "numero di dati simulati con smotenc 1956\n",
      "income\n",
      "0    978\n",
      "1    978\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['fp', 'y_pred', 'accuracy', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]\n",
    "\n",
    "smote_nc = SMOTENC( categorical_features=categorical_features, random_state=seed)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "\n",
    "print(\"numero di dati simulati con smotenc\",len(y_resampled))\n",
    "\n",
    "class_counts = y_resampled.value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggiungo una sampling strategy in modo da avere piu etichette = 0 visto che i sottogruppi porblematici hanno piu spesso etichette = 1 (per costruzione-per come ho impostato la ricerca dei sottogruppi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sampling_strategy = {0: 2500, 1: 1400}\\n\\nsmote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\\nX_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\n\\nprint(len(y_resampled))\\n\\nclass_counts = y_resampled.value_counts()\\nprint(class_counts)\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''sampling_strategy = {0: 2500, 1: 1400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "\n",
    "print(len(y_resampled))\n",
    "\n",
    "class_counts = y_resampled.value_counts()\n",
    "print(class_counts)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14970\n"
     ]
    }
   ],
   "source": [
    "X_train_mitigated_SMOTE = pd.concat([X_train, X_resampled], ignore_index=True)\n",
    "y_train_mitigated_SMOTE = pd.concat([y_train, y_resampled], ignore_index=True)\n",
    "print(len(X_train_mitigated_SMOTE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.head()  come verifica che tutto sia numerico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "classifier_train_mitigated_SMOTE = LogisticRegression(random_state=seed)\n",
    "classifier_train_mitigated_SMOTE.fit(X_train_mitigated_SMOTE, y_train_mitigated_SMOTE)\n",
    "y_mitigated_SMOTE_pred = classifier_train_mitigated_SMOTE.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#vediamo che succede se prendo lo stesso numero di righe ma random da holdout\\nprint(len(X_resampled))\\nn_random_smote = len(X_resampled)\\n\\ndf_holdout_smote_sampled = df_holdout_enc.sample(n=n_random_smote, random_state=seed)\\nprint(\"verifica :\", len(df_holdout_smote_sampled)) #verifica\\n\\ndf_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\\ndf_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\\n\\nX_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\\ny_train_mitigated_random_smote = df_train_mitigated_random_smote[\\'income\\']\\n\\nclassifier_train_mitigated_random_smote = LogisticRegression(random_state=seed)\\n\\nclassifier_train_mitigated_random_smote.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\\ny_mitigated_pred_random_smote = classifier_train_mitigated_random_smote.predict(X_test)'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#vediamo che succede se prendo lo stesso numero di righe ma random da holdout\n",
    "print(len(X_resampled))\n",
    "n_random_smote = len(X_resampled)\n",
    "\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=n_random_smote, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_smote_sampled)) #verifica\n",
    "\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote = LogisticRegression(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random_smote.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote = classifier_train_mitigated_random_smote.predict(X_test)'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_SMOTE_pred )\\naccuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote )\\n\\n\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\\n    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\\n    'After SMOTE fp mitigation' : [accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_mitigated_SMOTE_pred)],\\n    'After RANDOM mitigation' : [accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random, len(y_train_mitigated_random_smote), len(y_mitigated_pred_random_smote)]\\n    \\n})\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\\nmetrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n    \\nmetrics_after_fp_SMOTE\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_SMOTE_pred )\n",
    "accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote )\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After SMOTE fp mitigation' : [accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_mitigated_SMOTE_pred)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random, len(y_train_mitigated_random_smote), len(y_mitigated_pred_random_smote)]\n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "    \n",
    "metrics_after_fp_SMOTE'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A QUESTO PUNTO POSSIAMO VEDERE LE PERFORMANCE SUI SOTTOGRUPPI PRIMA E DOPO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \\ny_pred_test_filtered_fp_after_SMOTE = classifier_train_mitigated_SMOTE.predict(X_test_filtered_fp)\\ny_pred_RANDOM_subgroups = classifier_train_mitigated_random_smote.predict(X_test_filtered_fp)\\n\\n\\n#accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\\naccuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE )\\naccuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_RANDOM_subgroups )\\n\\nmetrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\\n    \\'Metrics\\' : [\\'Accuracy\\', \\'F1 Score\\', \\'False Positive Rate\\', \\'False Negative Rate\\', \\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\'],\\n    \\'Before Mitigation, on subgroups\\' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\\n    \\'After RANDOM mitigation, on subgroups\\' : [accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE, len(y_train), len(y_pred_RANDOM_subgroups)],\\n    \\'After Mitigation(K=5, on subgroups, fp and SMOTE)\\': [accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_pred_test_filtered_fp_after_SMOTE)],\\n})\\nmetrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index(\\'Metrics\\').T\\n\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\']\\n\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\\n\\nmetrics_after_fp_SMOTE\\n\\n\\nprint(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\\nmetrics_after_fp_sottogruppi_SMOTE'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "y_pred_test_filtered_fp_after_SMOTE = classifier_train_mitigated_SMOTE.predict(X_test_filtered_fp)\n",
    "y_pred_RANDOM_subgroups = classifier_train_mitigated_random_smote.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "#accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE )\n",
    "accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_RANDOM_subgroups )\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM mitigation, on subgroups' : [accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE, len(y_train), len(y_pred_RANDOM_subgroups)],\n",
    "    'After Mitigation(K=5, on subgroups, fp and SMOTE)': [accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_pred_test_filtered_fp_after_SMOTE)],\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p √® la probabilit√† che il campione simulato sia di classe 0 qui (perch√® voglio diminuire il numero di falsi positivi)\n",
    "- FISSO p VARIA N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 1515\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['fp', 'y_pred', 'accuracy', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 978)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered['income'].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.643</td>\n",
       "      <td>234</td>\n",
       "      <td>1008</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.642</td>\n",
       "      <td>241</td>\n",
       "      <td>1006</td>\n",
       "      <td>14034</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.624</td>\n",
       "      <td>281</td>\n",
       "      <td>979</td>\n",
       "      <td>14034</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.643</td>\n",
       "      <td>239</td>\n",
       "      <td>1008</td>\n",
       "      <td>14034</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.649</td>\n",
       "      <td>224</td>\n",
       "      <td>1018</td>\n",
       "      <td>14034</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.672</td>\n",
       "      <td>193</td>\n",
       "      <td>1053</td>\n",
       "      <td>14034</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.698</td>\n",
       "      <td>170</td>\n",
       "      <td>1094</td>\n",
       "      <td>14034</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.713</td>\n",
       "      <td>153</td>\n",
       "      <td>1118</td>\n",
       "      <td>14034</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.809     0.474                0.047   \n",
       "After RANDOM mitigation N = 5000         0.808     0.474                0.049   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.806     0.483                0.057   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.808     0.473                0.048   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.809     0.470                0.045   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.809     0.453                0.039   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.806     0.429                0.034   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.805     0.415                0.031   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.643              234   \n",
       "After RANDOM mitigation N = 5000                    0.642              241   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.624              281   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.643              239   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.649              224   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.672              193   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.698              170   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.713              153   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                1008       13014       6508  \n",
       "After RANDOM mitigation N = 5000                 1006       14034       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              979       14034       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6             1008       14034       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7             1018       14034       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8             1053       14034       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9             1094       14034       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1               1118       14034       6508  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*0.5), 1: count_1 + int(N*0.5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + int(N*0.6), 1: count_1 + int(N*0.4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + int(N*0.7), 1: count_1 + int(N*0.3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 +int(N*0.8), 1: count_1 + int(N*0.2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + int(N*0.9), 1: count_1 + int(N*0.1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + int(N*1), 1: count_1 + int(N*0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = LogisticRegression(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.019</td>\n",
       "      <td>1020.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.039</td>\n",
       "      <td>1020.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1020.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1020.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.809     0.474             0.018   \n",
       "After RANDOM Mitigation(K=5 fp)             0.808     0.474             0.016   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.808     0.473             0.026   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.809     0.453             0.011   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.805     0.415             0.006   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.144               0.077   \n",
       "After RANDOM Mitigation(K=5 fp)            0.149               0.077   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.188               0.115   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.103               0.054   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.064               0.032   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.052   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.051   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.078   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.035   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.020   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.021          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.019       1020.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.039       1020.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.011       1020.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.006       1020.000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000 p changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.643</td>\n",
       "      <td>234</td>\n",
       "      <td>1008</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.641</td>\n",
       "      <td>246</td>\n",
       "      <td>1005</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.603</td>\n",
       "      <td>313</td>\n",
       "      <td>946</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.644</td>\n",
       "      <td>252</td>\n",
       "      <td>1010</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.659</td>\n",
       "      <td>208</td>\n",
       "      <td>1034</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.703</td>\n",
       "      <td>170</td>\n",
       "      <td>1103</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.721</td>\n",
       "      <td>137</td>\n",
       "      <td>1130</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.757</td>\n",
       "      <td>117</td>\n",
       "      <td>1187</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.809     0.474                0.047   \n",
       "After RANDOM mitigation N = 5000         0.808     0.474                0.050   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.807     0.497                0.063   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.806     0.469                0.051   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.809     0.462                0.042   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.804     0.422                0.034   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.805     0.409                0.028   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.800     0.369                0.024   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.643              234   \n",
       "After RANDOM mitigation N = 5000                    0.641              246   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.603              313   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.644              252   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.659              208   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.703              170   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.721              137   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.757              117   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                1008       13014       6508  \n",
       "After RANDOM mitigation N = 5000                 1005       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              946       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6             1010       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7             1034       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8             1103       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9             1130       15014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1               1187       15014       6508  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 2000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 1000, 1: count_1 + 1000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 1200, 1: count_1 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 1400, 1: count_1 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 1600, 1: count_1 + 400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 1800, 1: count_1 + 200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + 2000, 1: count_1}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = LogisticRegression(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.028</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.007</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.809     0.474             0.018   \n",
       "After RANDOM Mitigation(K=5 fp)             0.808     0.474             0.017   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.806     0.469             0.034   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.804     0.422             0.007   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.800     0.369             0.005   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.144               0.077   \n",
       "After RANDOM Mitigation(K=5 fp)            0.152               0.079   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.213               0.132   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.070               0.038   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.036               0.020   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.052   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.055   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.091   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.024   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.009   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.021          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.028       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.043       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.007       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.005       2000.000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 3000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.023</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=0.5)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.063</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=0.8)</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=1)</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.809     0.474             0.018   \n",
       "After RANDOM Mitigation(K=5 fp)             0.808     0.474             0.018   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)     0.807     0.474             0.037   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)     0.804     0.415             0.005   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)       0.797     0.349             0.003   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.144               0.077   \n",
       "After RANDOM Mitigation(K=5 fp)            0.153               0.080   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)    0.226               0.140   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)    0.062               0.032   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)      0.033               0.013   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.052   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.055   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)               0.101   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)               0.019   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)                 0.003   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.021          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.023       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)               0.063       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)               0.005       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)                 0.003       3000.000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#p1 = 0.5\n",
    "N = 3000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 1500, 1: count_1 + 1500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 1800, 1: count_1 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 2100, 1: count_1 + 900}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 2400, 1: count_1 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 2700, 1: count_1 + 300}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + 3000, 1: count_1}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = LogisticRegression(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 3000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 3000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 3000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 3000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 3000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 3000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_3K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_3K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_3K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_3K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 3K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 3K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 3K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.029</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=0.5)</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.051</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=0.8)</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.006</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=1)</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.809     0.474             0.018   \n",
       "After RANDOM Mitigation(K=5 fp)             0.808     0.474             0.020   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)     0.806     0.474             0.030   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)     0.804     0.406             0.006   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)       0.796     0.335             0.003   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.144               0.077   \n",
       "After RANDOM Mitigation(K=5 fp)            0.158               0.083   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)    0.237               0.129   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)    0.055               0.030   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)      0.030               0.011   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.052   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.058   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)               0.092   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)               0.018   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)                 0.003   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.021          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.029       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)               0.051       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)               0.006       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)                 0.003       4000.000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#p1 = 0.5\n",
    "N = 4000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 2000, 1: count_1 + 2000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 2400, 1: count_1 + 1600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 2800, 1: count_1 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 3200, 1: count_1 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 3600, 1: count_1 + 400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + 4000, 1: count_1}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = LogisticRegression(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 4000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 4000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 4000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 4000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 4000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_4K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_4K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_4K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_4K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 4K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 4K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 4K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 5000 p changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.643</td>\n",
       "      <td>234</td>\n",
       "      <td>1008</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.633</td>\n",
       "      <td>258</td>\n",
       "      <td>992</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.571</td>\n",
       "      <td>358</td>\n",
       "      <td>895</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.640</td>\n",
       "      <td>265</td>\n",
       "      <td>1004</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.684</td>\n",
       "      <td>191</td>\n",
       "      <td>1072</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.721</td>\n",
       "      <td>143</td>\n",
       "      <td>1131</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.759</td>\n",
       "      <td>114</td>\n",
       "      <td>1190</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.807</td>\n",
       "      <td>86</td>\n",
       "      <td>1265</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.809     0.474                0.047   \n",
       "After RANDOM mitigation N = 5000         0.808     0.480                0.052   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.807     0.518                0.072   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.805     0.471                0.054   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.806     0.440                0.039   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.804     0.407                0.029   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.800     0.367                0.023   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.792     0.310                0.017   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.643              234   \n",
       "After RANDOM mitigation N = 5000                    0.633              258   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.571              358   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.640              265   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.684              191   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.721              143   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.759              114   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.807               86   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                1008       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  992       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              895       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6             1004       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7             1072       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8             1131       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9             1190       18014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1               1265       18014       6508  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 5000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 2500, 1: count_1 + 2500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 3000, 1: count_1 + 2000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 3500, 1: count_1 + 1500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 4000, 1: count_1 + 1000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 4500, 1: count_1 + 500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + 5000, 1: count_1}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = LogisticRegression(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_5K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "su sottogruppi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.724</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.438</td>\n",
       "      <td>164</td>\n",
       "      <td>252</td>\n",
       "      <td>13014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.715</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.434</td>\n",
       "      <td>180</td>\n",
       "      <td>250</td>\n",
       "      <td>18014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.714</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.281</td>\n",
       "      <td>269</td>\n",
       "      <td>162</td>\n",
       "      <td>18014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.714</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.438</td>\n",
       "      <td>179</td>\n",
       "      <td>252</td>\n",
       "      <td>18014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.716</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.550</td>\n",
       "      <td>111</td>\n",
       "      <td>317</td>\n",
       "      <td>18014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.707</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.646</td>\n",
       "      <td>70</td>\n",
       "      <td>372</td>\n",
       "      <td>18014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.692</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.743</td>\n",
       "      <td>36</td>\n",
       "      <td>428</td>\n",
       "      <td>18014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.672</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.837</td>\n",
       "      <td>13</td>\n",
       "      <td>482</td>\n",
       "      <td>18014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.724     0.609   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.715     0.603   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.714     0.658   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.714     0.601   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.716     0.548   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.707     0.480   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.692     0.389   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.672     0.275   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.176   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.193   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.289   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.192   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.119   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.075   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.039   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.014   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.438   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.434   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.281   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.438   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.550   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.646   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.743   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.837   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                     164   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      180   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              269   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              179   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              111   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)               70   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)               36   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                 13   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     252   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      250   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              162   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              252   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              317   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              372   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              428   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                482   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       1507  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               18014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       18014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       18014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       18014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       18014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       18014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         18014       1507  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisi divergenza per  p=0.5, p=0.8, p=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.027</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.070</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.006</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.809     0.474             0.018   \n",
       "After RANDOM Mitigation(K=5 fp)             0.808     0.474             0.019   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.805     0.471             0.039   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.804     0.407             0.006   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.792     0.310             0.005   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.144               0.077   \n",
       "After RANDOM Mitigation(K=5 fp)            0.161               0.083   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.244               0.149   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.046               0.026   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.031               0.013   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.052   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.057   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.107   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.015   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.005   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.021          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.027       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.070       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.006       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.005       5000.000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 6000, p changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.643</td>\n",
       "      <td>234</td>\n",
       "      <td>1008</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.631</td>\n",
       "      <td>259</td>\n",
       "      <td>990</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.5</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.566</td>\n",
       "      <td>372</td>\n",
       "      <td>887</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.6</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.629</td>\n",
       "      <td>270</td>\n",
       "      <td>986</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.7</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.680</td>\n",
       "      <td>191</td>\n",
       "      <td>1067</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.8</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.729</td>\n",
       "      <td>135</td>\n",
       "      <td>1143</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.9</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.772</td>\n",
       "      <td>100</td>\n",
       "      <td>1210</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 1</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.811</td>\n",
       "      <td>85</td>\n",
       "      <td>1272</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.809     0.474                0.047   \n",
       "After RANDOM mitigation N = 6000         0.808     0.481                0.052   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5     0.807     0.520                0.075   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6     0.807     0.481                0.055   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7     0.807     0.443                0.039   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8     0.804     0.399                0.027   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9     0.799     0.353                0.020   \n",
       "After SMOTE N = 6000 p_class 0 = 1       0.791     0.304                0.017   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.643              234   \n",
       "After RANDOM mitigation N = 6000                    0.631              259   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5                0.566              372   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6                0.629              270   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7                0.680              191   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8                0.729              135   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9                0.772              100   \n",
       "After SMOTE N = 6000 p_class 0 = 1                  0.811               85   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                1008       13014       6508  \n",
       "After RANDOM mitigation N = 6000                  990       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.5              887       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.6              986       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.7             1067       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.8             1143       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.9             1210       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 1               1272       19014       6508  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 6000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 3000, 1: count_1 + 3000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 3600, 1: count_1 + 2400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 4100, 1: count_1 + 1800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 4800, 1: count_1 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 5400, 1: count_1 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0+ 6000, 1: count_1}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = LogisticRegression(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 6000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 6000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_6K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_6K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_6K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_6K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOTTOGRUPPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.724</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.438</td>\n",
       "      <td>164</td>\n",
       "      <td>252</td>\n",
       "      <td>13014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.424</td>\n",
       "      <td>181</td>\n",
       "      <td>244</td>\n",
       "      <td>19014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.274</td>\n",
       "      <td>279</td>\n",
       "      <td>158</td>\n",
       "      <td>19014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.716</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.425</td>\n",
       "      <td>183</td>\n",
       "      <td>245</td>\n",
       "      <td>19014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.717</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.543</td>\n",
       "      <td>113</td>\n",
       "      <td>313</td>\n",
       "      <td>19014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.707</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.658</td>\n",
       "      <td>63</td>\n",
       "      <td>379</td>\n",
       "      <td>19014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.693</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.755</td>\n",
       "      <td>28</td>\n",
       "      <td>435</td>\n",
       "      <td>19014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.851</td>\n",
       "      <td>12</td>\n",
       "      <td>490</td>\n",
       "      <td>19014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.724     0.609   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.718     0.610   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.710     0.657   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.716     0.607   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.717     0.553   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.707     0.471   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.693     0.379   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.667     0.255   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.176   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.194   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.300   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.197   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.121   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.068   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.030   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.013   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.438   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.424   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.274   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.425   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.543   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.658   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.755   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.851   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                     164   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      181   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              279   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              183   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              113   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)               63   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)               28   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                 12   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     252   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      244   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              158   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              245   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              313   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              379   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              435   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                490   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       1507  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               19014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       19014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       19014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       19014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       19014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       19014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         19014       1507  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_6K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_6K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_6K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_6K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.020</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.070</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.809     0.474             0.018   \n",
       "After RANDOM Mitigation(K=5 fp)             0.808     0.474             0.019   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.807     0.481             0.040   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.804     0.399             0.005   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.791     0.304             0.004   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.144               0.077   \n",
       "After RANDOM Mitigation(K=5 fp)            0.162               0.080   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.251               0.153   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.040               0.024   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.030               0.010   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.052   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.055   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.109   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.015   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.004   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.021          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.020       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.070       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.005       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.004       6000.000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 7000, p changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.020</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.070</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.809     0.474             0.018   \n",
       "After RANDOM Mitigation(K=5 fp)             0.808     0.474             0.019   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.807     0.481             0.040   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.804     0.399             0.005   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.791     0.304             0.004   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.144               0.077   \n",
       "After RANDOM Mitigation(K=5 fp)            0.162               0.080   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.251               0.153   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.040               0.024   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.030               0.010   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.052   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.055   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.109   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.015   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.004   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.021          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.020       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.070       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.005       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.004       6000.000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.643</td>\n",
       "      <td>234</td>\n",
       "      <td>1008</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.633</td>\n",
       "      <td>252</td>\n",
       "      <td>992</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 7000 p_class 0 = 0.5</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.566</td>\n",
       "      <td>382</td>\n",
       "      <td>888</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 7000 p_class 0 = 0.6</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.628</td>\n",
       "      <td>273</td>\n",
       "      <td>984</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 7000 p_class 0 = 0.7</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.689</td>\n",
       "      <td>186</td>\n",
       "      <td>1081</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 7000 p_class 0 = 0.8</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.732</td>\n",
       "      <td>135</td>\n",
       "      <td>1148</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 7000 p_class 0 = 0.9</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.769</td>\n",
       "      <td>103</td>\n",
       "      <td>1206</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 7000 p_class 0 = 1</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.813</td>\n",
       "      <td>90</td>\n",
       "      <td>1275</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.809     0.474                0.047   \n",
       "After RANDOM mitigation N = 5000         0.809     0.481                0.051   \n",
       "After SMOTE N = 7000 p_class 0 = 0.5     0.805     0.517                0.077   \n",
       "After SMOTE N = 7000 p_class 0 = 0.6     0.807     0.482                0.055   \n",
       "After SMOTE N = 7000 p_class 0 = 0.7     0.805     0.435                0.038   \n",
       "After SMOTE N = 7000 p_class 0 = 0.8     0.803     0.396                0.027   \n",
       "After SMOTE N = 7000 p_class 0 = 0.9     0.799     0.356                0.021   \n",
       "After SMOTE N = 7000 p_class 0 = 1       0.790     0.300                0.018   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.643              234   \n",
       "After RANDOM mitigation N = 5000                    0.633              252   \n",
       "After SMOTE N = 7000 p_class 0 = 0.5                0.566              382   \n",
       "After SMOTE N = 7000 p_class 0 = 0.6                0.628              273   \n",
       "After SMOTE N = 7000 p_class 0 = 0.7                0.689              186   \n",
       "After SMOTE N = 7000 p_class 0 = 0.8                0.732              135   \n",
       "After SMOTE N = 7000 p_class 0 = 0.9                0.769              103   \n",
       "After SMOTE N = 7000 p_class 0 = 1                  0.813               90   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                1008       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  992       20014       6508  \n",
       "After SMOTE N = 7000 p_class 0 = 0.5              888       20014       6508  \n",
       "After SMOTE N = 7000 p_class 0 = 0.6              984       20014       6508  \n",
       "After SMOTE N = 7000 p_class 0 = 0.7             1081       20014       6508  \n",
       "After SMOTE N = 7000 p_class 0 = 0.8             1148       20014       6508  \n",
       "After SMOTE N = 7000 p_class 0 = 0.9             1206       20014       6508  \n",
       "After SMOTE N = 7000 p_class 0 = 1               1275       20014       6508  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 7000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 3500, 1: count_1 + 3500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 4200, 1: count_1 + 2800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 4900, 1: count_1 + 2100}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 5600, 1: count_1 + 1400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 6300, 1: count_1 + 700}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + 7000, 1: count_1}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = LogisticRegression(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 7000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 7000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 7000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 7000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 7000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 7000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_7K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_7K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_7K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_7K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOTTOGRUPPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.724</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.438</td>\n",
       "      <td>164</td>\n",
       "      <td>252</td>\n",
       "      <td>13014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.432</td>\n",
       "      <td>176</td>\n",
       "      <td>249</td>\n",
       "      <td>20014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.707</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.274</td>\n",
       "      <td>283</td>\n",
       "      <td>158</td>\n",
       "      <td>20014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.717</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.427</td>\n",
       "      <td>181</td>\n",
       "      <td>246</td>\n",
       "      <td>20014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.717</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.566</td>\n",
       "      <td>101</td>\n",
       "      <td>326</td>\n",
       "      <td>20014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.674</td>\n",
       "      <td>59</td>\n",
       "      <td>388</td>\n",
       "      <td>20014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.694</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.759</td>\n",
       "      <td>24</td>\n",
       "      <td>437</td>\n",
       "      <td>20014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.868</td>\n",
       "      <td>12</td>\n",
       "      <td>500</td>\n",
       "      <td>20014</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.724     0.609   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.718     0.606   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.707     0.655   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.717     0.607   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.717     0.539   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.703     0.457   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.694     0.376   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.660     0.229   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.176   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.189   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.304   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.194   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.108   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.063   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.026   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.013   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.438   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.432   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.274   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.427   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.566   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.674   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.759   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.868   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                     164   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      176   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              283   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              181   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              101   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)               59   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)               24   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                 12   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     252   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      249   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              158   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              246   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              326   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              388   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              437   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                500   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       1507  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               20014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       20014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       20014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       20014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       20014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       20014       1507  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         20014       1507  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_7K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_7K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_7K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_7K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.031</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.071</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.004</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.809     0.474             0.018   \n",
       "After RANDOM Mitigation(K=5 fp)             0.808     0.474             0.019   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.807     0.482             0.038   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.803     0.396             0.004   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.790     0.300             0.004   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.144               0.077   \n",
       "After RANDOM Mitigation(K=5 fp)            0.158               0.081   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.254               0.154   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.036               0.021   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.031               0.013   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.052   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.057   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.109   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.011   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.004   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.021          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.031       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.071       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.004       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.004       7000.000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mariaantoniettalongo/Desktop/TESI/.tesi/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.643</td>\n",
       "      <td>234</td>\n",
       "      <td>1008</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.635</td>\n",
       "      <td>256</td>\n",
       "      <td>995</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.5</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.564</td>\n",
       "      <td>387</td>\n",
       "      <td>884</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.6</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.628</td>\n",
       "      <td>274</td>\n",
       "      <td>985</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.7</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.695</td>\n",
       "      <td>182</td>\n",
       "      <td>1089</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.8</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.733</td>\n",
       "      <td>140</td>\n",
       "      <td>1149</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.9</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.770</td>\n",
       "      <td>100</td>\n",
       "      <td>1207</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 1</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.832</td>\n",
       "      <td>85</td>\n",
       "      <td>1304</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.809     0.474                0.047   \n",
       "After RANDOM mitigation N = 5000         0.808     0.478                0.052   \n",
       "After SMOTE N = 8000 p_class 0 = 0.5     0.805     0.518                0.078   \n",
       "After SMOTE N = 8000 p_class 0 = 0.6     0.807     0.481                0.055   \n",
       "After SMOTE N = 8000 p_class 0 = 0.7     0.805     0.430                0.037   \n",
       "After SMOTE N = 8000 p_class 0 = 0.8     0.802     0.394                0.028   \n",
       "After SMOTE N = 8000 p_class 0 = 0.9     0.799     0.356                0.020   \n",
       "After SMOTE N = 8000 p_class 0 = 1       0.787     0.275                0.017   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.643              234   \n",
       "After RANDOM mitigation N = 5000                    0.635              256   \n",
       "After SMOTE N = 8000 p_class 0 = 0.5                0.564              387   \n",
       "After SMOTE N = 8000 p_class 0 = 0.6                0.628              274   \n",
       "After SMOTE N = 8000 p_class 0 = 0.7                0.695              182   \n",
       "After SMOTE N = 8000 p_class 0 = 0.8                0.733              140   \n",
       "After SMOTE N = 8000 p_class 0 = 0.9                0.770              100   \n",
       "After SMOTE N = 8000 p_class 0 = 1                  0.832               85   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                1008       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  995       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.5              884       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.6              985       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.7             1089       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.8             1149       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.9             1207       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 1               1304       21014       6508  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 8000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 4000, 1: count_1 + 4000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 4800, 1: count_1 + 3200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 5600, 1: count_1 + 2400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 6400, 1: count_1 + 1600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 7200, 1: count_1 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + 8000, 1: count_1 }\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = LogisticRegression(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = LogisticRegression(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 8000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_8K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_8K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.033</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.064</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.005</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.809     0.474             0.018   \n",
       "After RANDOM Mitigation(K=5 fp)             0.808     0.474             0.017   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.807     0.481             0.038   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.802     0.394             0.005   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.787     0.275             0.005   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.144               0.077   \n",
       "After RANDOM Mitigation(K=5 fp)            0.156               0.080   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.264               0.156   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.035               0.022   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.031               0.013   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.052   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.057   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.106   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.014   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.005   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.021          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.033       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.064       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.005       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.005       8000.000  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT: andamento di falsi positivi e di falsi negativi al variare di N e p di appartenere alla classe 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creazione del grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "p =[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "# Linea per i falsi positivi\n",
    "\n",
    "\n",
    "plt.plot(p, falsi_positivi_2K_fp_5sub, marker='o', label='False Positives 2K', color='black')\n",
    "plt.plot(p, falsi_positivi_3K_fp_5sub, marker='o', label='False Positives 3K', color='red')\n",
    "plt.plot(p, falsi_positivi_4K_fp_5sub, marker='o', label='False Positives 4K', color='green')\n",
    "plt.plot(p, falsi_positivi_5K_fp_5sub, marker='o', label='False Positives 5K', color='blue')\n",
    "plt.plot(p, falsi_positivi_6K_fp_5sub, marker='o', label='False Positives 6K', color='orange')\n",
    "#plt.plot(p, falsi_positivi_7K_fp_5sub, marker='o', label='False Positives 7K', color='red')\n",
    "\n",
    "\n",
    "plt.axhline(y=falsi_positivi_5K_fp_5sub_before, color='purple', linestyle='--', label='Initial False Positives')\n",
    "\n",
    "# Etichette e titolo\n",
    "plt.xlabel('probability for the synthetic point to belong to the class 0')\n",
    "plt.ylabel('Count false positives')\n",
    "plt.title(f'False Positives, fp, # prob subgroups added = {K} on {filtered_instances}, support = {min_sup}, pruning = 0.01')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "plt.yticks(range(500, 701, 25))\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creazione del grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "p =[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "# Linea per i falsi positivi\n",
    "\n",
    "plt.plot(p, falsi_positivi_5K_fp_5sub_sub, marker='o', label='False Positives 5K ', color='blue')\n",
    "plt.plot(p, falsi_positivi_6K_fp_5sub_sub, marker='o', label='False Positives 6K ', color='orange')\n",
    "plt.plot(p, falsi_positivi_7K_fp_5sub_sub, marker='o', label='False Positives 7K ', color='red')\n",
    "\n",
    "\n",
    "plt.axhline(y=falsi_positivi_5K_fp_5sub_sub_before, color='purple', linestyle='--', label='Initial False Positives')\n",
    "\n",
    "# Etichette e titolo\n",
    "plt.xlabel('probability for the synthetic point to belong to the class 0')\n",
    "plt.ylabel('Count false positives')\n",
    "plt.title('False Positives, fp, #subgroups = 5, support = 0.2, redundancy = 0.01, subgroups ')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "plt.yticks(range(500, 701, 50))\n",
    "# Mostra il grafico\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
