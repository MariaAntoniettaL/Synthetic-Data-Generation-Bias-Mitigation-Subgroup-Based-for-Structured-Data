{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE\n",
    "Nel file preprocessing_for_adult.py sono contenute le funzioni per il preprocessing da applicare ad adult.data: la prima (preprocessing_funct_not_enc) discretizza, normalizza ecc mentre la seconda (encoding_funct) esegue l'encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_for_adult import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_and, K_subgroups_dataset_and_or, metrics_to_compare, preprocessing_funct_not_enc_SMOTE, encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import torch\n",
    "\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "from divexplorer.outcomes import get_false_positive_rate_outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = 0.2\n",
    "percentage = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv(\"adult.data\", header = None, names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosit√† precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_no_income = df_train_enc.drop(columns = 'income')\n",
    "plt.figure(figsize=(4, 3))\n",
    "g = sns.heatmap(df_train_no_income.corr(),\n",
    "                annot = False,\n",
    "                cmap = \"coolwarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "X_train = df_train_enc.drop(columns = 'income', axis = 1)\n",
    "y_train = df_train_enc['income']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'income', axis = 1)\n",
    "y_test = df_test_enc['income']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'income', axis = 1)\n",
    "y_val = df_val_enc['income']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'income', axis = 1)\n",
    "y_holdout = df_holdout_enc['income']\n",
    "\n",
    "classifier_train = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.865     0.681                0.050   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.402              247              630   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       6508  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione √® giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>2</td>\n",
       "      <td>0.077</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0</td>\n",
       "      <td>0.284</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass  fnlwgt  education  marital-status  occupation  relationship  \\\n",
       "18761          2   0.077          3               0           4             1   \n",
       "27582          3   0.048          3               1           4             0   \n",
       "30911          2   0.174          3               3           4             4   \n",
       "11128          0   0.012          2               1           2             0   \n",
       "683            0   0.284          3               3           2             4   \n",
       "\n",
       "       race  sex  capital-gain  capital-loss  native-country  age_group  \\\n",
       "18761     4    0         0.000         0.000               5          2   \n",
       "27582     4    1         0.000         0.000               5          5   \n",
       "30911     2    0         0.039         0.000               5          1   \n",
       "11128     2    1         0.000         0.507               5          3   \n",
       "683       2    1         0.000         0.000               5          0   \n",
       "\n",
       "       edu_num_group  hours_per_week_group  y_val_true  y_pred  \n",
       "18761              1                     1           0       0  \n",
       "27582              1                     2           1       0  \n",
       "30911              1                     1           0       0  \n",
       "11128              4                     1           1       1  \n",
       "683                1                     1           0       0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set, queste mi servono solo per il div explorer che ha bisogno di ground truth e predizioni\n",
    "y_pred_val = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>fp</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.077</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>Self-emp</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>65-100</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.174</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.012</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>45-54</td>\n",
       "      <td>14 Master's Degree</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.284</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        workclass  fnlwgt        education marital-status    occupation  \\\n",
       "18761     Private   0.077    Non Graduated       Divorced  Self-emp-occ   \n",
       "27582    Self-emp   0.048    Non Graduated        Married  Self-emp-occ   \n",
       "30911     Private   0.174    Non Graduated      Separated  Self-emp-occ   \n",
       "11128  Government   0.012  Master's Degree        Married   Private-occ   \n",
       "683    Government   0.284    Non Graduated      Separated   Private-occ   \n",
       "\n",
       "         relationship    race      sex  capital-gain  capital-loss  \\\n",
       "18761   Not-in-family   White   Female         0.000         0.000   \n",
       "27582         Husband   White     Male         0.000         0.000   \n",
       "30911       Unmarried   Black   Female         0.039         0.000   \n",
       "11128         Husband   Black     Male         0.000         0.507   \n",
       "683         Unmarried   Black     Male         0.000         0.000   \n",
       "\n",
       "      native-country  income age_group       edu_num_group  \\\n",
       "18761  United-States       0     35-44          10 College   \n",
       "27582  United-States       1    65-100          10 College   \n",
       "30911  United-States       0     25-34          10 College   \n",
       "11128  United-States       1     45-54  14 Master's Degree   \n",
       "683    United-States       0     17-24          10 College   \n",
       "\n",
       "      hours_per_week_group    fp  y_pred  accuracy  \n",
       "18761             Overtime 0.000       0         1  \n",
       "27582            Part-time   NaN       0         0  \n",
       "30911             Overtime 0.000       0         1  \n",
       "11128             Overtime   NaN       1         1  \n",
       "683               Overtime 0.000       0         1  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]\n",
    "\n",
    "df_val_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_val['fp'] = df_val_class['fp']\n",
    "\n",
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione √® giusta 0 se la predizione √® sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['accuracy'] = (df_val_class['y_val_true']==df_val_class['y_pred']).astype(int)\n",
    "df_val.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI CONDOTTA CON LA FEATURE FP (PASSATA A BOOLEAN OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fp</th>\n",
       "      <th>fp_div</th>\n",
       "      <th>fp_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(capital-loss=0.0, marital-status=Married, native-country=United-States, capital-gain=0.0, sex= Male, race= White, relationship= Husband, hours_per_week_group=Overtime)</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.149</td>\n",
       "      <td>10.809</td>\n",
       "      <td>8</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(capital-loss=0.0, native-country=United-States, capital-gain=0.0, sex= Male, race= White, relationship= Husband, hours_per_week_group=Overtime)</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.149</td>\n",
       "      <td>10.809</td>\n",
       "      <td>7</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(capital-loss=0.0, marital-status=Married, native-country=United-States, capital-gain=0.0, race= White, relationship= Husband, hours_per_week_group=Overtime)</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.149</td>\n",
       "      <td>10.809</td>\n",
       "      <td>7</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(capital-loss=0.0, native-country=United-States, capital-gain=0.0, race= White, relationship= Husband, hours_per_week_group=Overtime)</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.149</td>\n",
       "      <td>10.809</td>\n",
       "      <td>6</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.259</td>\n",
       "      <td>(native-country=United-States, capital-gain=0.0, sex= Male, race= White, relationship= Husband, hours_per_week_group=Overtime)</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.147</td>\n",
       "      <td>10.970</td>\n",
       "      <td>6</td>\n",
       "      <td>1686.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.239   \n",
       "1    0.239   \n",
       "2    0.239   \n",
       "3    0.239   \n",
       "4    0.259   \n",
       "\n",
       "                                                                                                                                                                    itemset  \\\n",
       "0  (capital-loss=0.0, marital-status=Married, native-country=United-States, capital-gain=0.0, sex= Male, race= White, relationship= Husband, hours_per_week_group=Overtime)   \n",
       "1                          (capital-loss=0.0, native-country=United-States, capital-gain=0.0, sex= Male, race= White, relationship= Husband, hours_per_week_group=Overtime)   \n",
       "2             (capital-loss=0.0, marital-status=Married, native-country=United-States, capital-gain=0.0, race= White, relationship= Husband, hours_per_week_group=Overtime)   \n",
       "3                                     (capital-loss=0.0, native-country=United-States, capital-gain=0.0, race= White, relationship= Husband, hours_per_week_group=Overtime)   \n",
       "4                                            (native-country=United-States, capital-gain=0.0, sex= Male, race= White, relationship= Husband, hours_per_week_group=Overtime)   \n",
       "\n",
       "     fp  fp_div   fp_t  length  support_count  \n",
       "0 0.200   0.149 10.809       8       1554.000  \n",
       "1 0.200   0.149 10.809       7       1554.000  \n",
       "2 0.200   0.149 10.809       7       1554.000  \n",
       "3 0.200   0.149 10.809       6       1554.000  \n",
       "4 0.198   0.147 10.970       6       1686.000  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_diver = DivergenceExplorer(df_val)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"fp_div\", \"fp_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "      <th>fp</th>\n",
       "      <th>fp_div</th>\n",
       "      <th>fp_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.356</td>\n",
       "      <td>(relationship= Husband, hours_per_week_group=Overtime)</td>\n",
       "      <td>2</td>\n",
       "      <td>2318.000</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.131</td>\n",
       "      <td>11.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.202</td>\n",
       "      <td>(race= White, education=Bachelor's Degree)</td>\n",
       "      <td>2</td>\n",
       "      <td>1317.000</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.125</td>\n",
       "      <td>9.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.401</td>\n",
       "      <td>(hours_per_week_group=Overtime, marital-status=Married)</td>\n",
       "      <td>2</td>\n",
       "      <td>2612.000</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.116</td>\n",
       "      <td>11.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.233</td>\n",
       "      <td>(education=Bachelor's Degree)</td>\n",
       "      <td>1</td>\n",
       "      <td>1517.000</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.113</td>\n",
       "      <td>9.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.403</td>\n",
       "      <td>(relationship= Husband)</td>\n",
       "      <td>1</td>\n",
       "      <td>2621.000</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.110</td>\n",
       "      <td>10.780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     support                                                  itemset  length  \\\n",
       "58     0.356   (relationship= Husband, hours_per_week_group=Overtime)       2   \n",
       "83     0.202               (race= White, education=Bachelor's Degree)       2   \n",
       "122    0.401  (hours_per_week_group=Overtime, marital-status=Married)       2   \n",
       "132    0.233                            (education=Bachelor's Degree)       1   \n",
       "164    0.403                                  (relationship= Husband)       1   \n",
       "\n",
       "     support_count    fp  fp_div   fp_t  \n",
       "58        2318.000 0.182   0.131 11.458  \n",
       "83        1317.000 0.177   0.125  9.303  \n",
       "122       2612.000 0.168   0.116 11.156  \n",
       "132       1517.000 0.164   0.113  9.278  \n",
       "164       2621.000 0.161   0.110 10.780  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 37\n",
      "total problematic 23\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_fp)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_fp[(df_pruned_fp['fp_div'] > 0) & (df_pruned_fp['fp_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (893, 7)\n",
      "Dim pruned th_redundancy  (37, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_fp.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset_and_or li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "df_holdout_filtered_solo0 = df_holdout_filtered[df_holdout_filtered['income']==0]\n",
    "\n",
    "\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered_solo0, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "df_holdout_filtered = df_holdout_filtered_solo0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2182\n"
     ]
    }
   ],
   "source": [
    "print(len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \\ndf_train_enc_mit, df_test_enc_filtered_fp, df_filtered_enc, df_val_enc_mit = encoding_funct(df_train=df_train_mitigated, df_test=df_test_filtered_fp, df_holdout=df_holdout_filtered, df_val=df_val)\\n#controllo divisione dataset\\ndf_train_enc_mit_fp = df_train_enc_mit  \\nprint(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\\nprint(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\\nprint(f\"VALIDATION SET ROWS: \", df_val_enc_mit.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\\nprint(f\"FILTERED DF holdout ROWS: \", df_filtered_enc.shape[0])\\nprint(f\"TEST SET FILTERED ROWS: \", df_test_enc_filtered_fp.shape[0])'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, df_test_enc_filtered_fp, df_filtered_enc, df_val_enc_mit = encoding_funct(df_train=df_train_mitigated, df_test=df_test_filtered_fp, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc_mit.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", df_filtered_enc.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", df_test_enc_filtered_fp.shape[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "TRAIN SET MITIGATED ROWS:  15196\n",
      "VALIDATION SET ROWS:  6508\n",
      "FILTERED DF holdout ROWS:  2182\n",
      "TEST SET FILTERED ROWS:  6507\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'income', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['income']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "#cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2182\n",
      "verifica : 2182\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['income']\n",
    "\n",
    "classifier_train_mitigated_random = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.498</td>\n",
       "      <td>142</td>\n",
       "      <td>781</td>\n",
       "      <td>15196</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.397</td>\n",
       "      <td>235</td>\n",
       "      <td>623</td>\n",
       "      <td>15196</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.865     0.681                0.050   \n",
       "After Mitigation(K=5, fp)     0.858     0.630                0.029   \n",
       "After RANDOM mitigation       0.868     0.688                0.048   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.402              247   \n",
       "After Mitigation(K=5, fp)                0.498              142   \n",
       "After RANDOM mitigation                  0.397              235   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      630       13014       6508  \n",
       "After Mitigation(K=5, fp)              781       15196       6508  \n",
       "After RANDOM mitigation                623       15196       6508  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance su sottogruppi \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.369</td>\n",
       "      <td>230</td>\n",
       "      <td>501</td>\n",
       "      <td>13014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.477</td>\n",
       "      <td>130</td>\n",
       "      <td>647</td>\n",
       "      <td>15196</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.365</td>\n",
       "      <td>222</td>\n",
       "      <td>495</td>\n",
       "      <td>15196</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                         Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                    0.787     0.701   \n",
       "After Mitigation(K=5, on subgroups, fp)            0.774     0.646   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)     0.791     0.706   \n",
       "\n",
       "Metrics                                         False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                               0.111   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.062   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.107   \n",
       "\n",
       "Metrics                                         False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                               0.369   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.477   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.365   \n",
       "\n",
       "Metrics                                         False Positives  \\\n",
       "Before Mitigation, on subgroups                             230   \n",
       "After Mitigation(K=5, on subgroups, fp)                     130   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              222   \n",
       "\n",
       "Metrics                                         False Negatives  Train Size  \\\n",
       "Before Mitigation, on subgroups                             501       13014   \n",
       "After Mitigation(K=5, on subgroups, fp)                     647       15196   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              495       15196   \n",
       "\n",
       "Metrics                                         Test Size  \n",
       "Before Mitigation, on subgroups                      3436  \n",
       "After Mitigation(K=5, on subgroups, fp)              3436  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)       3436  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered_fp = K_subgroups_dataset_and_or(df_pruned_fp, df_test, K)\n",
    "inutile, df_test_filtered_enc_fp, inutile2, inutile3 = encoding_funct(df_train, df_test_filtered_fp, df_holdout, df_val)\n",
    "\n",
    "X_test_filtered_fp = df_test_filtered_enc_fp.drop(columns='income', axis = 1)\n",
    "y_true_test_filtered_fp = df_test_filtered_enc_fp['income']\n",
    "\n",
    "y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after = classifier_train_mitigated.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_random = classifier_train_mitigated_random.predict(X_test_filtered_fp)\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after )\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_random)\n",
    "\n",
    "\n",
    "metrics_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after, len(y_train_mitigated), len(y_pred_test_filtered_fp_after)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(y_train_mitigated_random), len(y_pred_test_filtered_fp_after_random)]\n",
    "})\n",
    "metrics_after_fp_sottogruppi = metrics_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi[metric] = metrics_after_fp_sottogruppi[metric].astype(int)\n",
    "\n",
    "metrics_after_fp\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp\")\n",
    "metrics_after_fp_sottogruppi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline1  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_random_per_confrontare_con_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>2182.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.021</td>\n",
       "      <td>2182.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.865     0.681             0.022   \n",
       "After Mitigation(K=5 fp)            0.858     0.630             0.008   \n",
       "After RANDOM Mitigation(K=5 fp)     0.868     0.688             0.021   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.117               0.092   \n",
       "After Mitigation(K=5 fp)           0.059               0.036   \n",
       "After RANDOM Mitigation(K=5 fp)    0.112               0.082   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.055               0.022   \n",
       "After Mitigation(K=5 fp)                      0.008               0.008   \n",
       "After RANDOM Mitigation(K=5 fp)               0.046               0.021   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)              2182.000  \n",
       "After RANDOM Mitigation(K=5 fp)       2182.000  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline1 = abs(sum(fp_div_list_baseline1) / len(fp_div_list_baseline1))\n",
    "media_fp_div_list_baseline1_primi10 = abs(sum(fp_div_list_baseline1[:10]) / len(fp_div_list_baseline1[:10]))\n",
    "media_fp_div_list_baseline1_primi20 = abs(sum(fp_div_list_baseline1[:20]) / len(fp_div_list_baseline1[:20]))\n",
    "media_fp_div_list_baseline1_primi40 = abs(sum(fp_div_list_baseline1[:40]) / len(fp_div_list_baseline1[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_baseline1 = max(abs(x) for x in fp_div_list_baseline1)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_fp_div_list_baseline1, fp_div_massimo_valore_assoluto_fp_div_baseline1,\n",
    "        media_fp_div_list_baseline1_primi10, media_fp_div_list_baseline1_primi20, media_fp_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SIMULANDO DATI ATTRAVERSO SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGUE CODICE USANDO SMOTE \n",
    "DIVIDO IN TRAIN, TEST E VALIDATION -- ora uso quelli gia esistenti\n",
    "DIV EXPLORER SUL VALIDATION  -- gi√† fatto \n",
    "GENERO NUOVI DATI CON SMOTE a partire dai dati di divexplorer sul validation\n",
    "INSERISCO QUESTI NUOVI DATI NEL TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 3704\n",
      "numero di dati simulati con smotenc 4610\n",
      "income\n",
      "1    2305\n",
      "0    2305\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['fp', 'y_pred', 'accuracy', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]\n",
    "\n",
    "smote_nc = SMOTENC( categorical_features=categorical_features, random_state=seed)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "\n",
    "print(\"numero di dati simulati con smotenc\",len(y_resampled))\n",
    "\n",
    "class_counts = y_resampled.value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggiungo una sampling strategy in modo da avere piu etichette = 0 visto che i sottogruppi porblematici hanno piu spesso etichette = 1 (per costruzione-per come ho impostato la ricerca dei sottogruppi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sampling_strategy = {0: 2500, 1: 1400}\\n\\nsmote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\\nX_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\n\\nprint(len(y_resampled))\\n\\nclass_counts = y_resampled.value_counts()\\nprint(class_counts)\\n'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''sampling_strategy = {0: 2500, 1: 1400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "\n",
    "print(len(y_resampled))\n",
    "\n",
    "class_counts = y_resampled.value_counts()\n",
    "print(class_counts)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17624\n"
     ]
    }
   ],
   "source": [
    "X_train_mitigated_SMOTE = pd.concat([X_train, X_resampled], ignore_index=True)\n",
    "y_train_mitigated_SMOTE = pd.concat([y_train, y_resampled], ignore_index=True)\n",
    "print(len(X_train_mitigated_SMOTE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.head()  come verifica che tutto sia numerico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_train_mitigated_SMOTE = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_SMOTE.fit(X_train_mitigated_SMOTE, y_train_mitigated_SMOTE)\n",
    "y_mitigated_SMOTE_pred = classifier_train_mitigated_SMOTE.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#vediamo che succede se prendo lo stesso numero di righe ma random da holdout\\nprint(len(X_resampled))\\nn_random_smote = len(X_resampled)\\n\\ndf_holdout_smote_sampled = df_holdout_enc.sample(n=n_random_smote, random_state=seed)\\nprint(\"verifica :\", len(df_holdout_smote_sampled)) #verifica\\n\\ndf_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\\ndf_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\\n\\nX_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\\ny_train_mitigated_random_smote = df_train_mitigated_random_smote[\\'income\\']\\n\\nclassifier_train_mitigated_random_smote = GradientBoostingClassifier(random_state=seed)\\n\\nclassifier_train_mitigated_random_smote.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\\ny_mitigated_pred_random_smote = classifier_train_mitigated_random_smote.predict(X_test)'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#vediamo che succede se prendo lo stesso numero di righe ma random da holdout\n",
    "print(len(X_resampled))\n",
    "n_random_smote = len(X_resampled)\n",
    "\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=n_random_smote, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_smote_sampled)) #verifica\n",
    "\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random_smote.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote = classifier_train_mitigated_random_smote.predict(X_test)'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_SMOTE_pred )\\naccuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote )\\n\\n\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\\n    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\\n    'After SMOTE fp mitigation' : [accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_mitigated_SMOTE_pred)],\\n    'After RANDOM mitigation' : [accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random, len(y_train_mitigated_random_smote), len(y_mitigated_pred_random_smote)]\\n    \\n})\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\\nmetrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n    \\nmetrics_after_fp_SMOTE\""
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_SMOTE_pred )\n",
    "accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote )\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After SMOTE fp mitigation' : [accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_mitigated_SMOTE_pred)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random, len(y_train_mitigated_random_smote), len(y_mitigated_pred_random_smote)]\n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "    \n",
    "metrics_after_fp_SMOTE'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A QUESTO PUNTO POSSIAMO VEDERE LE PERFORMANCE SUI SOTTOGRUPPI PRIMA E DOPO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \\ny_pred_test_filtered_fp_after_SMOTE = classifier_train_mitigated_SMOTE.predict(X_test_filtered_fp)\\ny_pred_RANDOM_subgroups = classifier_train_mitigated_random_smote.predict(X_test_filtered_fp)\\n\\n\\n#accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\\naccuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE )\\naccuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_RANDOM_subgroups )\\n\\nmetrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\\n    \\'Metrics\\' : [\\'Accuracy\\', \\'F1 Score\\', \\'False Positive Rate\\', \\'False Negative Rate\\', \\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\'],\\n    \\'Before Mitigation, on subgroups\\' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\\n    \\'After RANDOM mitigation, on subgroups\\' : [accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE, len(y_train), len(y_pred_RANDOM_subgroups)],\\n    \\'After Mitigation(K=5, on subgroups, fp and SMOTE)\\': [accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_pred_test_filtered_fp_after_SMOTE)],\\n})\\nmetrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index(\\'Metrics\\').T\\n\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\']\\n\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\\n\\nmetrics_after_fp_SMOTE\\n\\n\\nprint(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\\nmetrics_after_fp_sottogruppi_SMOTE'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "y_pred_test_filtered_fp_after_SMOTE = classifier_train_mitigated_SMOTE.predict(X_test_filtered_fp)\n",
    "y_pred_RANDOM_subgroups = classifier_train_mitigated_random_smote.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "#accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE )\n",
    "accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_RANDOM_subgroups )\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM mitigation, on subgroups' : [accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE, len(y_train), len(y_pred_RANDOM_subgroups)],\n",
    "    'After Mitigation(K=5, on subgroups, fp and SMOTE)': [accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_pred_test_filtered_fp_after_SMOTE)],\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p √® la probabilit√† che il campione simulato sia di classe 0 qui (perch√® voglio diminuire il numero di falsi positivi)\n",
    "- FISSO p VARIA N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 3761\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "#X_to_SMOTE =  df_val_filtered.drop(columns = ['fp', 'y_pred', 'accuracy', 'income'], axis = 1)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1414, 2347)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered['income'].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.397</td>\n",
       "      <td>235</td>\n",
       "      <td>623</td>\n",
       "      <td>15196</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.372</td>\n",
       "      <td>302</td>\n",
       "      <td>584</td>\n",
       "      <td>15196</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.397</td>\n",
       "      <td>254</td>\n",
       "      <td>623</td>\n",
       "      <td>15196</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.402</td>\n",
       "      <td>239</td>\n",
       "      <td>631</td>\n",
       "      <td>15196</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.443</td>\n",
       "      <td>197</td>\n",
       "      <td>694</td>\n",
       "      <td>15196</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.469</td>\n",
       "      <td>168</td>\n",
       "      <td>735</td>\n",
       "      <td>15196</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.485</td>\n",
       "      <td>150</td>\n",
       "      <td>761</td>\n",
       "      <td>15196</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.868     0.688                0.048   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.864     0.690                0.061   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.865     0.683                0.051   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.866     0.683                0.048   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.863     0.662                0.040   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.861     0.649                0.034   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.860     0.639                0.030   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.397              235   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.372              302   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.397              254   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.402              239   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.443              197   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.469              168   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.485              150   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  623       15196       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              584       15196       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              623       15196       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              631       15196       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              694       15196       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              735       15196       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                761       15196       6508  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + int(N*0.5), 1: count_1 + int(N*0.5)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + int(N*0.6), 1: count_1 + int(N*0.4)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + int(N*0.7), 1: count_1 + int(N*0.3)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 +int(N*0.8), 1: count_1 + int(N*0.2)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + int(N*0.9), 1: count_1 + int(N*0.1)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + int(N*1), 1: count_1 + int(N*0)}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.021</td>\n",
       "      <td>2182.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2182.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.009</td>\n",
       "      <td>2182.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>2182.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.022   \n",
       "After RANDOM Mitigation(K=5 fp)             0.868     0.688             0.021   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.865     0.683             0.040   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.863     0.662             0.009   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.860     0.639             0.008   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.117               0.092   \n",
       "After RANDOM Mitigation(K=5 fp)            0.112               0.082   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.142               0.123   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.079               0.046   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.063               0.037   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.055   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.046   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.096   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.012   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.008   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.022          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.021       2182.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.040       2182.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.009       2182.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.008       2182.000  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000 p changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.402</td>\n",
       "      <td>237</td>\n",
       "      <td>631</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.369</td>\n",
       "      <td>302</td>\n",
       "      <td>579</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.394</td>\n",
       "      <td>248</td>\n",
       "      <td>618</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.399</td>\n",
       "      <td>238</td>\n",
       "      <td>625</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.458</td>\n",
       "      <td>189</td>\n",
       "      <td>718</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.466</td>\n",
       "      <td>167</td>\n",
       "      <td>731</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.479</td>\n",
       "      <td>153</td>\n",
       "      <td>751</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.867     0.683                0.048   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.865     0.692                0.061   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.867     0.687                0.050   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.867     0.686                0.048   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.861     0.652                0.038   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.862     0.651                0.034   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.861     0.644                0.031   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.402              237   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.369              302   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.394              248   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.399              238   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.458              189   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.466              167   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.479              153   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  631       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              579       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              618       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              625       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              718       15014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              731       15014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                751       15014       6508  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 2000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 1000, 1: count_1 + 1000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 1200, 1: count_1 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 1400, 1: count_1 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 1600, 1: count_1 + 400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 1800, 1: count_1 + 200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + 2000, 1: count_1}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_2K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_2K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_2K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.022</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.044</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>2000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.022   \n",
       "After RANDOM Mitigation(K=5 fp)             0.868     0.688             0.022   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.867     0.687             0.044   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.861     0.652             0.007   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.861     0.644             0.008   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.117               0.092   \n",
       "After RANDOM Mitigation(K=5 fp)            0.113               0.087   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.145               0.124   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.080               0.042   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.066               0.038   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.055   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.053   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.098   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.009   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.008   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.022          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.022       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.044       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.007       2000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.008       2000.000  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 3000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=0.5)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.042</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=0.8)</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 3K, p=1)</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>3000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.022   \n",
       "After RANDOM Mitigation(K=5 fp)             0.868     0.688             0.025   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)     0.866     0.687             0.042   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)     0.861     0.649             0.007   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)       0.857     0.627             0.008   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.117               0.092   \n",
       "After RANDOM Mitigation(K=5 fp)            0.116               0.090   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)    0.142               0.120   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)    0.076               0.041   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)      0.058               0.035   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.055   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.054   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)               0.094   \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)               0.009   \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)                 0.008   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.022          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.025       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.5)               0.042       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=0.8)               0.007       3000.000  \n",
       "After Mitigation(K=5 fp, N = 3K, p=1)                 0.008       3000.000  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#p1 = 0.5\n",
    "N = 3000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 1500, 1: count_1 + 1500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 1800, 1: count_1 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 2100, 1: count_1 + 900}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 2400, 1: count_1 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 2700, 1: count_1 + 300}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + 3000, 1: count_1}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 3000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 3000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 3000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 3000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 3000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 3000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_3K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_3K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_3K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_3K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 3K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 3K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 3K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.018</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=0.5)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.078</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=0.8)</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.007</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 4K, p=1)</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.022   \n",
       "After RANDOM Mitigation(K=5 fp)             0.868     0.688             0.018   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)     0.866     0.686             0.058   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)     0.858     0.640             0.007   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)       0.851     0.592             0.003   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.117               0.092   \n",
       "After RANDOM Mitigation(K=5 fp)            0.112               0.079   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)    0.161               0.140   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)    0.080               0.041   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)      0.040               0.019   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.055   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.041   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)               0.128   \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)               0.010   \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)                 0.003   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.022          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.018       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.5)               0.078       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=0.8)               0.007       4000.000  \n",
       "After Mitigation(K=5 fp, N = 4K, p=1)                 0.003       4000.000  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#p1 = 0.5\n",
    "N = 4000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 2000, 1: count_1 + 2000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 2400, 1: count_1 + 1600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 2800, 1: count_1 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 3200, 1: count_1 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 3600, 1: count_1 + 400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + 4000, 1: count_1}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 4000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 4000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 4000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 4000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 4000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "falsi_positivi_4K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_4K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_4K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_4K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n",
    "\n",
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 4K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 4K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 4K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.406</td>\n",
       "      <td>242</td>\n",
       "      <td>637</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.5</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.365</td>\n",
       "      <td>321</td>\n",
       "      <td>572</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.6</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.392</td>\n",
       "      <td>259</td>\n",
       "      <td>615</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.7</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.425</td>\n",
       "      <td>223</td>\n",
       "      <td>666</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.8</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.477</td>\n",
       "      <td>175</td>\n",
       "      <td>748</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.9</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.496</td>\n",
       "      <td>150</td>\n",
       "      <td>778</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.550</td>\n",
       "      <td>109</td>\n",
       "      <td>863</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.865     0.679                0.049   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5     0.863     0.690                0.065   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6     0.866     0.686                0.052   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7     0.863     0.670                0.045   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8     0.858     0.640                0.035   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9     0.857     0.630                0.030   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.851     0.592                0.022   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.406              242   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5                0.365              321   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6                0.392              259   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7                0.425              223   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8                0.477              175   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9                0.496              150   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.550              109   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  637       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.5              572       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.6              615       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.7              666       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.8              748       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.9              778       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                863       17014       6508  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 5000 p changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.410</td>\n",
       "      <td>231</td>\n",
       "      <td>643</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.353</td>\n",
       "      <td>339</td>\n",
       "      <td>554</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.396</td>\n",
       "      <td>255</td>\n",
       "      <td>621</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.448</td>\n",
       "      <td>195</td>\n",
       "      <td>702</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.478</td>\n",
       "      <td>162</td>\n",
       "      <td>749</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.504</td>\n",
       "      <td>146</td>\n",
       "      <td>790</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.564</td>\n",
       "      <td>92</td>\n",
       "      <td>884</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.866     0.679                0.047   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5     0.863     0.694                0.069   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6     0.865     0.684                0.052   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7     0.862     0.659                0.039   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8     0.860     0.643                0.033   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9     0.856     0.624                0.030   \n",
       "After SMOTE N = 4000 p_class 0 = 1       0.850     0.584                0.019   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.410              231   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                0.353              339   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                0.396              255   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                0.448              195   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                0.478              162   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                0.504              146   \n",
       "After SMOTE N = 4000 p_class 0 = 1                  0.564               92   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  643       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5              554       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6              621       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7              702       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8              749       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9              790       18014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1                884       18014       6508  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p1 = 0.5\n",
    "N = 5000\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 2500, 1: count_1 + 2500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 3000, 1: count_1 + 2000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 3500, 1: count_1 + 1500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 4000, 1: count_1 + 1000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 4500, 1: count_1 + 500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + 5000, 1: count_1}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 5000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 4000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "falsi_positivi_5K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "su sottogruppi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.369</td>\n",
       "      <td>230</td>\n",
       "      <td>501</td>\n",
       "      <td>13014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.381</td>\n",
       "      <td>214</td>\n",
       "      <td>516</td>\n",
       "      <td>18014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.314</td>\n",
       "      <td>320</td>\n",
       "      <td>426</td>\n",
       "      <td>18014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.363</td>\n",
       "      <td>236</td>\n",
       "      <td>492</td>\n",
       "      <td>18014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.420</td>\n",
       "      <td>176</td>\n",
       "      <td>570</td>\n",
       "      <td>18014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.452</td>\n",
       "      <td>150</td>\n",
       "      <td>613</td>\n",
       "      <td>18014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.771</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.483</td>\n",
       "      <td>131</td>\n",
       "      <td>655</td>\n",
       "      <td>18014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.758</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.554</td>\n",
       "      <td>82</td>\n",
       "      <td>751</td>\n",
       "      <td>18014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.787     0.701   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.788     0.697   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.783     0.714   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.788     0.704   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.783     0.678   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.778     0.661   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.771     0.641   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.758     0.592   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.111   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.103   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.154   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.113   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.085   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.072   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.063   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.039   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.369   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.381   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.314   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.363   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.420   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.452   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.483   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.554   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                     230   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      214   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              320   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              236   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              176   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              150   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              131   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                 82   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     501   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      516   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              426   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              492   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              570   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              613   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              655   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                751   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       3436  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               18014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       18014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       18014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       18014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       18014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       18014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         18014       3436  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_5K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_5K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisi divergenza per  p=0.5, p=0.8, p=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.014</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.096</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.022   \n",
       "After RANDOM Mitigation(K=5 fp)             0.868     0.688             0.014   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.865     0.684             0.062   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.860     0.643             0.007   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.850     0.584             0.000   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.117               0.092   \n",
       "After RANDOM Mitigation(K=5 fp)            0.096               0.065   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.181               0.155   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.068               0.038   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.036               0.009   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.055   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.031   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.141   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.007   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.000   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.022          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.014       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.096       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.007       5000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.000       5000.000  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 6000, p changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.390</td>\n",
       "      <td>252</td>\n",
       "      <td>612</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.5</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.358</td>\n",
       "      <td>328</td>\n",
       "      <td>562</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.6</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.397</td>\n",
       "      <td>265</td>\n",
       "      <td>622</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.7</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.450</td>\n",
       "      <td>199</td>\n",
       "      <td>706</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.8</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.481</td>\n",
       "      <td>167</td>\n",
       "      <td>754</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.9</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.508</td>\n",
       "      <td>134</td>\n",
       "      <td>797</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 1</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.570</td>\n",
       "      <td>83</td>\n",
       "      <td>893</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 6000         0.867     0.689                0.051   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5     0.863     0.693                0.066   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6     0.864     0.681                0.054   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7     0.861     0.656                0.040   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8     0.858     0.639                0.034   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9     0.857     0.624                0.027   \n",
       "After SMOTE N = 6000 p_class 0 = 1       0.850     0.580                0.017   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 6000                    0.390              252   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5                0.358              328   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6                0.397              265   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7                0.450              199   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8                0.481              167   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9                0.508              134   \n",
       "After SMOTE N = 6000 p_class 0 = 1                  0.570               83   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 6000                  612       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.5              562       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.6              622       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.7              706       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.8              754       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.9              797       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 1                893       19014       6508  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 6000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 3000, 1: count_1 + 3000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 3600, 1: count_1 + 2400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 4100, 1: count_1 + 1800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 4800, 1: count_1 + 1200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 5400, 1: count_1 + 600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0+ 6000, 1: count_1}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 6000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 6000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 6000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_6K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_6K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_6K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_6K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOTTOGRUPPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.369</td>\n",
       "      <td>230</td>\n",
       "      <td>501</td>\n",
       "      <td>13014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.358</td>\n",
       "      <td>236</td>\n",
       "      <td>486</td>\n",
       "      <td>19014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.784</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.320</td>\n",
       "      <td>308</td>\n",
       "      <td>434</td>\n",
       "      <td>19014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.785</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.362</td>\n",
       "      <td>249</td>\n",
       "      <td>491</td>\n",
       "      <td>19014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.423</td>\n",
       "      <td>181</td>\n",
       "      <td>573</td>\n",
       "      <td>19014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.775</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.458</td>\n",
       "      <td>151</td>\n",
       "      <td>621</td>\n",
       "      <td>19014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.771</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.490</td>\n",
       "      <td>122</td>\n",
       "      <td>665</td>\n",
       "      <td>19014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.758</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.560</td>\n",
       "      <td>74</td>\n",
       "      <td>759</td>\n",
       "      <td>19014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.787     0.701   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.790     0.707   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.784     0.713   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.785     0.700   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.781     0.675   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.775     0.656   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.771     0.637   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.758     0.589   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.111   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.113   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.148   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.120   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.087   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.073   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.059   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.036   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.369   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.358   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.320   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.362   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.423   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.458   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.490   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.560   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                     230   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      236   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              308   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              249   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              181   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              151   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              122   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                 74   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     501   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      486   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              434   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              491   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              573   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              621   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              665   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                759   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       3436  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               19014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       19014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       19014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       19014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       19014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       19014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         19014       3436  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_6K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_6K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_6K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_6K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.025</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.085</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.022   \n",
       "After RANDOM Mitigation(K=5 fp)             0.868     0.688             0.025   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.864     0.681             0.061   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.858     0.639             0.006   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.850     0.580             0.000   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.117               0.092   \n",
       "After RANDOM Mitigation(K=5 fp)            0.120               0.095   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.166               0.145   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.071               0.037   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.034               0.009   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.055   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.062   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.132   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.006   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.000   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.022          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.025       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.085       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.006       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.000       6000.000  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 7000, p changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.025</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.085</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.022   \n",
       "After RANDOM Mitigation(K=5 fp)             0.868     0.688             0.025   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.864     0.681             0.061   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.858     0.639             0.006   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.850     0.580             0.000   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.117               0.092   \n",
       "After RANDOM Mitigation(K=5 fp)            0.120               0.095   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.166               0.145   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.071               0.037   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.034               0.009   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.055   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.062   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.132   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.006   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.000   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.022          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.025       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.085       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.006       6000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.000       6000.000  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.399</td>\n",
       "      <td>243</td>\n",
       "      <td>626</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 7000 p_class 0 = 0.5</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.355</td>\n",
       "      <td>337</td>\n",
       "      <td>557</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 7000 p_class 0 = 0.6</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.391</td>\n",
       "      <td>262</td>\n",
       "      <td>613</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 7000 p_class 0 = 0.7</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.454</td>\n",
       "      <td>196</td>\n",
       "      <td>712</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 7000 p_class 0 = 0.8</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.496</td>\n",
       "      <td>156</td>\n",
       "      <td>778</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 7000 p_class 0 = 0.9</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.524</td>\n",
       "      <td>126</td>\n",
       "      <td>821</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 7000 p_class 0 = 1</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.597</td>\n",
       "      <td>64</td>\n",
       "      <td>936</td>\n",
       "      <td>20014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.866     0.684                0.049   \n",
       "After SMOTE N = 7000 p_class 0 = 0.5     0.863     0.693                0.068   \n",
       "After SMOTE N = 7000 p_class 0 = 0.6     0.866     0.686                0.053   \n",
       "After SMOTE N = 7000 p_class 0 = 0.7     0.860     0.653                0.040   \n",
       "After SMOTE N = 7000 p_class 0 = 0.8     0.856     0.628                0.032   \n",
       "After SMOTE N = 7000 p_class 0 = 0.9     0.854     0.612                0.026   \n",
       "After SMOTE N = 7000 p_class 0 = 1       0.846     0.558                0.013   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.399              243   \n",
       "After SMOTE N = 7000 p_class 0 = 0.5                0.355              337   \n",
       "After SMOTE N = 7000 p_class 0 = 0.6                0.391              262   \n",
       "After SMOTE N = 7000 p_class 0 = 0.7                0.454              196   \n",
       "After SMOTE N = 7000 p_class 0 = 0.8                0.496              156   \n",
       "After SMOTE N = 7000 p_class 0 = 0.9                0.524              126   \n",
       "After SMOTE N = 7000 p_class 0 = 1                  0.597               64   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  626       20014       6508  \n",
       "After SMOTE N = 7000 p_class 0 = 0.5              557       20014       6508  \n",
       "After SMOTE N = 7000 p_class 0 = 0.6              613       20014       6508  \n",
       "After SMOTE N = 7000 p_class 0 = 0.7              712       20014       6508  \n",
       "After SMOTE N = 7000 p_class 0 = 0.8              778       20014       6508  \n",
       "After SMOTE N = 7000 p_class 0 = 0.9              821       20014       6508  \n",
       "After SMOTE N = 7000 p_class 0 = 1                936       20014       6508  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 7000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 3500, 1: count_1 + 3500}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 4200, 1: count_1 + 2800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 4900, 1: count_1 + 2100}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 5600, 1: count_1 + 1400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 6300, 1: count_1 + 700}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + 7000, 1: count_1}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 7000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 7000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 7000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 7000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 7000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 7000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_7K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_7K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_7K_fp_5sub_before = metrics_after_fp_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_7K_fp_5sub_before = metrics_after_fp_SMOTE['False Negatives'].iloc[0]\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOTTOGRUPPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.369</td>\n",
       "      <td>230</td>\n",
       "      <td>501</td>\n",
       "      <td>13014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.369</td>\n",
       "      <td>226</td>\n",
       "      <td>501</td>\n",
       "      <td>20014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.315</td>\n",
       "      <td>317</td>\n",
       "      <td>427</td>\n",
       "      <td>20014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.357</td>\n",
       "      <td>243</td>\n",
       "      <td>484</td>\n",
       "      <td>20014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)</th>\n",
       "      <td>0.780</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.426</td>\n",
       "      <td>180</td>\n",
       "      <td>577</td>\n",
       "      <td>20014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.475</td>\n",
       "      <td>140</td>\n",
       "      <td>644</td>\n",
       "      <td>20014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)</th>\n",
       "      <td>0.768</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.504</td>\n",
       "      <td>112</td>\n",
       "      <td>684</td>\n",
       "      <td>20014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)</th>\n",
       "      <td>0.752</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.589</td>\n",
       "      <td>54</td>\n",
       "      <td>799</td>\n",
       "      <td>20014</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                                 Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                            0.787     0.701   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)             0.788     0.702   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)     0.783     0.714   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)     0.788     0.706   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)     0.780     0.673   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)     0.772     0.645   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)     0.768     0.628   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)       0.752     0.566   \n",
       "\n",
       "Metrics                                                 False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.111   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.109   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.152   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.117   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.087   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.067   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.054   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.026   \n",
       "\n",
       "Metrics                                                 False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                                       0.369   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                        0.369   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)                0.315   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)                0.357   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)                0.426   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)                0.475   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)                0.504   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                  0.589   \n",
       "\n",
       "Metrics                                                 False Positives  \\\n",
       "Before Mitigation, on subgroups                                     230   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      226   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              317   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              243   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              180   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              140   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              112   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                 54   \n",
       "\n",
       "Metrics                                                 False Negatives  \\\n",
       "Before Mitigation, on subgroups                                     501   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                      501   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)              427   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)              484   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)              577   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)              644   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)              684   \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)                799   \n",
       "\n",
       "Metrics                                                 Train Size  Test Size  \n",
       "Before Mitigation, on subgroups                              13014       3436  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)               20014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)       20014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)       20014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)       20014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)       20014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)       20014       3436  \n",
       "After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)         20014       3436  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "#previsione su sottogruppi al variare di p fissato n = 5K\n",
    "y_pred_test_filtered_fp_after_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p1)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p2)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p3)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p4)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p5)\n",
    "accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6 = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE_p6)\n",
    "\n",
    "#random\n",
    "y_pred_test_filtered_random_mit = classifier_train_mitigated_random_smote_p.predict(X_test_filtered_fp)\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_random_mit)\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(X_train_mitigated_random_smote), len(y_pred_test_filtered_random_mit)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.5)': [accuracy_fp_sottogruppi_after_SMOTE_p1, f1_score_fp_sottogruppi_after_SMOTE_p1, fpr_fp_sottogruppi_after_SMOTE_p1, fnr_fp_sottogruppi_after_SMOTE_p1, fp_fp_sottogruppi_after_SMOTE_p1, fn_fp_sottogruppi_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_test_filtered_fp_after_SMOTE_p1)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.6)': [accuracy_fp_sottogruppi_after_SMOTE_p2, f1_score_fp_sottogruppi_after_SMOTE_p2, fpr_fp_sottogruppi_after_SMOTE_p2, fnr_fp_sottogruppi_after_SMOTE_p2, fp_fp_sottogruppi_after_SMOTE_p2, fn_fp_sottogruppi_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_test_filtered_fp_after_SMOTE_p2)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.7)': [accuracy_fp_sottogruppi_after_SMOTE_p3, f1_score_fp_sottogruppi_after_SMOTE_p3, fpr_fp_sottogruppi_after_SMOTE_p3, fnr_fp_sottogruppi_after_SMOTE_p3, fp_fp_sottogruppi_after_SMOTE_p3, fn_fp_sottogruppi_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_test_filtered_fp_after_SMOTE_p3)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.8)': [accuracy_fp_sottogruppi_after_SMOTE_p4, f1_score_fp_sottogruppi_after_SMOTE_p4, fpr_fp_sottogruppi_after_SMOTE_p4, fnr_fp_sottogruppi_after_SMOTE_p4, fp_fp_sottogruppi_after_SMOTE_p4, fn_fp_sottogruppi_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_test_filtered_fp_after_SMOTE_p4)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 0.9)': [accuracy_fp_sottogruppi_after_SMOTE_p5, f1_score_fp_sottogruppi_after_SMOTE_p5, fpr_fp_sottogruppi_after_SMOTE_p5, fnr_fp_sottogruppi_after_SMOTE_p5, fp_fp_sottogruppi_after_SMOTE_p5, fn_fp_sottogruppi_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_test_filtered_fp_after_SMOTE_p5)],\n",
    "    'After Mitigation(K=5, on subgroups, fp, SMOTE, 0: 1)': [accuracy_fp_sottogruppi_after_SMOTE_p6, f1_score_fp_sottogruppi_after_SMOTE_p6, fpr_fp_sottogruppi_after_SMOTE_p6, fnr_fp_sottogruppi_after_SMOTE_p6, fp_fp_sottogruppi_after_SMOTE_p6, fn_fp_sottogruppi_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_test_filtered_fp_after_SMOTE_p6)]\n",
    "\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_7K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_7K_fp_5sub_sub = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "falsi_positivi_7K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Positives'].iloc[0]\n",
    "falsi_negativi_7K_fp_5sub_sub_before = metrics_after_fp_sottogruppi_SMOTE['False Negatives'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.019</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.098</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.022   \n",
       "After RANDOM Mitigation(K=5 fp)             0.868     0.688             0.019   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.866     0.686             0.061   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.856     0.628             0.006   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.846     0.558             0.001   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.117               0.092   \n",
       "After RANDOM Mitigation(K=5 fp)            0.110               0.077   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.171               0.154   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.063               0.036   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.025               0.001   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.055   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.040   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.141   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.006   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.001   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.022          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.019       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.098       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.006       7000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.001       7000.000  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.402</td>\n",
       "      <td>247</td>\n",
       "      <td>630</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.389</td>\n",
       "      <td>257</td>\n",
       "      <td>610</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.5</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.357</td>\n",
       "      <td>334</td>\n",
       "      <td>560</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.6</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.406</td>\n",
       "      <td>261</td>\n",
       "      <td>636</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.7</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.462</td>\n",
       "      <td>185</td>\n",
       "      <td>725</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.8</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.495</td>\n",
       "      <td>161</td>\n",
       "      <td>776</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 0.9</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.521</td>\n",
       "      <td>121</td>\n",
       "      <td>817</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 8000 p_class 0 = 1</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.614</td>\n",
       "      <td>64</td>\n",
       "      <td>963</td>\n",
       "      <td>21014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.865     0.681                0.050   \n",
       "After RANDOM mitigation N = 5000         0.867     0.688                0.052   \n",
       "After SMOTE N = 8000 p_class 0 = 0.5     0.863     0.693                0.068   \n",
       "After SMOTE N = 8000 p_class 0 = 0.6     0.862     0.675                0.053   \n",
       "After SMOTE N = 8000 p_class 0 = 0.7     0.860     0.649                0.037   \n",
       "After SMOTE N = 8000 p_class 0 = 0.8     0.856     0.628                0.033   \n",
       "After SMOTE N = 8000 p_class 0 = 0.9     0.856     0.616                0.024   \n",
       "After SMOTE N = 8000 p_class 0 = 1       0.842     0.541                0.013   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.402              247   \n",
       "After RANDOM mitigation N = 5000                    0.389              257   \n",
       "After SMOTE N = 8000 p_class 0 = 0.5                0.357              334   \n",
       "After SMOTE N = 8000 p_class 0 = 0.6                0.406              261   \n",
       "After SMOTE N = 8000 p_class 0 = 0.7                0.462              185   \n",
       "After SMOTE N = 8000 p_class 0 = 0.8                0.495              161   \n",
       "After SMOTE N = 8000 p_class 0 = 0.9                0.521              121   \n",
       "After SMOTE N = 8000 p_class 0 = 1                  0.614               64   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 630       13014       6508  \n",
       "After RANDOM mitigation N = 5000                  610       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.5              560       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.6              636       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.7              725       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.8              776       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 0.9              817       21014       6508  \n",
       "After SMOTE N = 8000 p_class 0 = 1                963       21014       6508  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 8000\n",
    "#p1 = 0.5\n",
    "original_size = len(X_to_SMOTE)\n",
    "sampling_strategy = {0: count_0 + 4000, 1: count_1 + 4000}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p1 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p1 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p1 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p1.fit(X_train_mit_SMOTE_p1, y_train_mit_SMOTE_p1)\n",
    "y_pred_SMOTE_p1 = classifier_train_mit_SMOTE_p1.predict(X_test)\n",
    "\n",
    "#p2 = 0.6 \n",
    "sampling_strategy = {0: count_0 + 4800, 1: count_1 + 3200}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p2 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p2 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p2 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p2.fit(X_train_mit_SMOTE_p2, y_train_mit_SMOTE_p2)\n",
    "y_pred_SMOTE_p2 = classifier_train_mit_SMOTE_p2.predict(X_test)\n",
    "\n",
    "#p3 = 0.7\n",
    "sampling_strategy = {0: count_0 + 5600, 1: count_1 + 2400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p3 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p3 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p3 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p3.fit(X_train_mit_SMOTE_p3, y_train_mit_SMOTE_p3)\n",
    "y_pred_SMOTE_p3 = classifier_train_mit_SMOTE_p3.predict(X_test)\n",
    "\n",
    "#p4 = 0.8\n",
    "sampling_strategy = {0: count_0 + 6400, 1: count_1 + 1600}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p4 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p4 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p4 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p4.fit(X_train_mit_SMOTE_p4, y_train_mit_SMOTE_p4)\n",
    "y_pred_SMOTE_p4 = classifier_train_mit_SMOTE_p4.predict(X_test)\n",
    "\n",
    "\n",
    "#p5 = 0.9\n",
    "sampling_strategy = {0: count_0 + 7200, 1: count_1 + 800}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p5 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p5 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p5 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p5.fit(X_train_mit_SMOTE_p5, y_train_mit_SMOTE_p5)\n",
    "y_pred_SMOTE_p5 = classifier_train_mit_SMOTE_p5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#p6 = 1\n",
    "sampling_strategy = {0: count_0 + 8000, 1: count_1 }\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    " \n",
    "# solo i campioni generati \n",
    "X_generated = X_sampled_SMOTE[-N:]\n",
    "y_generated = y_sampled_SMOTE[-N:]\n",
    "\n",
    "X_train_mit_SMOTE_p6 = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "y_train_mit_SMOTE_p6 = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "\n",
    "\n",
    "#train and test\n",
    "classifier_train_mit_SMOTE_p6 = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mit_SMOTE_p6.fit(X_train_mit_SMOTE_p6, y_train_mit_SMOTE_p6)\n",
    "y_pred_SMOTE_p6 = classifier_train_mit_SMOTE_p6.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#qui i valori randomici \n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace = True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "    \n",
    "accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p1 )\n",
    "accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p2 )\n",
    "accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p3 )\n",
    "accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p4 )\n",
    "accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p5 )\n",
    "accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6 = metrics_to_compare(y_true = y_test, y_pred = y_pred_SMOTE_p6 )\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote_p)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = 5000' : [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.5' : [accuracy_fp_after_SMOTE_p1, f1_score_fp_after_SMOTE_p1, fpr_fp_after_SMOTE_p1, fnr_fp_after_SMOTE_p1, fp_fp_after_SMOTE_p1, fn_fp_after_SMOTE_p1, len(X_train_mit_SMOTE_p1), len(y_pred_SMOTE_p1)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.6' : [accuracy_fp_after_SMOTE_p2, f1_score_fp_after_SMOTE_p2, fpr_fp_after_SMOTE_p2, fnr_fp_after_SMOTE_p2, fp_fp_after_SMOTE_p2, fn_fp_after_SMOTE_p2, len(X_train_mit_SMOTE_p2), len(y_pred_SMOTE_p2)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.7' : [accuracy_fp_after_SMOTE_p3, f1_score_fp_after_SMOTE_p3, fpr_fp_after_SMOTE_p3, fnr_fp_after_SMOTE_p3, fp_fp_after_SMOTE_p3, fn_fp_after_SMOTE_p3, len(X_train_mit_SMOTE_p3), len(y_pred_SMOTE_p3)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.8' : [accuracy_fp_after_SMOTE_p4, f1_score_fp_after_SMOTE_p4, fpr_fp_after_SMOTE_p4, fnr_fp_after_SMOTE_p4, fp_fp_after_SMOTE_p4, fn_fp_after_SMOTE_p4, len(X_train_mit_SMOTE_p4), len(y_pred_SMOTE_p4)],\n",
    "    'After SMOTE N = 8000 p_class 0 = 0.9' : [accuracy_fp_after_SMOTE_p5, f1_score_fp_after_SMOTE_p5, fpr_fp_after_SMOTE_p5, fnr_fp_after_SMOTE_p5, fp_fp_after_SMOTE_p5, fn_fp_after_SMOTE_p5, len(X_train_mit_SMOTE_p5), len(y_pred_SMOTE_p5)] ,\n",
    "    'After SMOTE N = 8000 p_class 0 = 1  ' : [accuracy_fp_after_SMOTE_p6, f1_score_fp_after_SMOTE_p6, fpr_fp_after_SMOTE_p6, fnr_fp_after_SMOTE_p6, fp_fp_after_SMOTE_p6, fn_fp_after_SMOTE_p6, len(X_train_mit_SMOTE_p6), len(y_pred_SMOTE_p6)]\n",
    "    \n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvo risultati che mi servono per i plot\n",
    "falsi_positivi_8K_fp_5sub = metrics_after_fp_SMOTE['False Positives'].iloc[2:].tolist()\n",
    "falsi_negativi_8K_fp_5sub = metrics_after_fp_SMOTE['False Negatives'].iloc[2:].tolist()\n",
    "\n",
    "\n",
    "accuracy05 = metrics_after_fp_SMOTE['Accuracy'].iloc[3]\n",
    "accuracy08 = metrics_after_fp_SMOTE['Accuracy'].iloc[5]\n",
    "accuracy1 = metrics_after_fp_SMOTE['Accuracy'].iloc[7]\n",
    "\n",
    "f1score05 = metrics_after_fp_SMOTE['F1 Score'].iloc[3]\n",
    "f1score08 = metrics_after_fp_SMOTE['F1 Score'].iloc[5]\n",
    "f1score1 = metrics_after_fp_SMOTE['F1 Score'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.025</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.5)</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.067</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=0.8)</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp, N = 5K, p=1)</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                  Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                           0.865     0.681             0.022   \n",
       "After RANDOM Mitigation(K=5 fp)             0.868     0.688             0.025   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)     0.862     0.675             0.055   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)     0.856     0.628             0.006   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)       0.842     0.541             0.000   \n",
       "\n",
       "Metrics                                  max div  media div primi 10  \\\n",
       "Before Mitigation                          0.117               0.092   \n",
       "After RANDOM Mitigation(K=5 fp)            0.117               0.094   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)    0.158               0.137   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)    0.064               0.036   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)      0.025               0.000   \n",
       "\n",
       "Metrics                                  media div primi 20  \\\n",
       "Before Mitigation                                     0.055   \n",
       "After RANDOM Mitigation(K=5 fp)                       0.057   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.125   \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.006   \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.000   \n",
       "\n",
       "Metrics                                  media div primi 40  # new samples  \n",
       "Before Mitigation                                     0.022          0.000  \n",
       "After RANDOM Mitigation(K=5 fp)                       0.025       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.5)               0.067       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=0.8)               0.006       8000.000  \n",
       "After Mitigation(K=5 fp, N = 5K, p=1)                 0.000       8000.000  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi divergenza per  p=0.5, p=0.8, p=1  \n",
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_no_mitigation\n",
    "\n",
    "\n",
    "\n",
    "#prima per la baseline 2 che √® SMOTENC\n",
    "#p=0.5\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p1\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p1_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#p baseline 2 che √® SMOTENC p=0.8\n",
    "#p=0.8\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p4\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p4_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p1_5K\n",
    "\n",
    "\n",
    "#baseline 2 che √® SMOTENC p=1\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred_SMOTE_p6\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline2_p6_5K = df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_p6_5K\n",
    "\n",
    "\n",
    "#random\n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random_smote_p\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fn'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fn' a df_val non encoded\n",
    "df_test['fn'] = df_test_class['fn']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fn'])\n",
    "FP_fm = FP_fm.sort_values(by='fn_div', ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fn')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values('fn_div', ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1= df_pruned_fp['fn_div'].tolist()\n",
    "#fp_div_list_baseline2_random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline2_p1_5K = abs(sum(fp_div_list_baseline2_p1_5K) / len(fp_div_list_baseline2_p1_5K))\n",
    "media_fp_div_list_baseline2_p1_5K_primi10 = abs(sum(fp_div_list_baseline2_p1_5K[:10]) / len(fp_div_list_baseline2_p1_5K[:10]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi20 = abs(sum(fp_div_list_baseline2_p1_5K[:20]) / len(fp_div_list_baseline2_p1_5K[:20]))\n",
    "media_fp_div_list_baseline2_p1_5K_primi40 = abs(sum(fp_div_list_baseline2_p1_5K[:40]) / len(fp_div_list_baseline2_p1_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K = max(abs(x) for x in fp_div_list_baseline2_p1_5K)\n",
    "\n",
    "\n",
    "media_fp_div_list_baseline2_p4_5K = abs(sum(fp_div_list_baseline2_p4_5K) / len(fp_div_list_baseline2_p4_5K))\n",
    "media_fp_div_list_baseline2_p4_5K_primi10 = abs(sum(fp_div_list_baseline2_p4_5K[:10]) / len(fp_div_list_baseline2_p4_5K[:10]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi20 = abs(sum(fp_div_list_baseline2_p4_5K[:20]) / len(fp_div_list_baseline2_p4_5K[:20]))\n",
    "media_fp_div_list_baseline2_p4_5K_primi40 = abs(sum(fp_div_list_baseline2_p4_5K[:40]) / len(fp_div_list_baseline2_p4_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K = max(abs(x) for x in fp_div_list_baseline2_p4_5K)\n",
    "\n",
    "media_fp_div_list_baseline2_p6_5K = abs(sum(fp_div_list_baseline2_p6_5K) / len(fp_div_list_baseline2_p6_5K))\n",
    "media_fp_div_list_baseline2_p6_5K_primi10 = abs(sum(fp_div_list_baseline2_p6_5K[:10]) / len(fp_div_list_baseline2_p6_5K[:10]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi20 = abs(sum(fp_div_list_baseline2_p6_5K[:20]) / len(fp_div_list_baseline2_p6_5K[:20]))\n",
    "media_fp_div_list_baseline2_p6_5K_primi40 = abs(sum(fp_div_list_baseline2_p6_5K[:40]) / len(fp_div_list_baseline2_p6_5K[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K = max(abs(x) for x in fp_div_list_baseline2_p6_5K)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    \n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "        'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        N\n",
    "    ],\n",
    "     'After Mitigation(K=5 fp, N = 5K, p=0.5)': [\n",
    "        accuracy05, f1score05, media_fp_div_list_baseline2_p1_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p1_5K,\n",
    "        media_fp_div_list_baseline2_p1_5K_primi10, media_fp_div_list_baseline2_p1_5K_primi20, media_fp_div_list_baseline2_p1_5K_primi40, N\n",
    "    ],\n",
    "      'After Mitigation(K=5 fp, N = 5K, p=0.8)': [\n",
    "        accuracy08, f1score08, media_fp_div_list_baseline2_p4_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p4_5K,\n",
    "        media_fp_div_list_baseline2_p4_5K_primi10, media_fp_div_list_baseline2_p4_5K_primi20, media_fp_div_list_baseline2_p4_5K_primi40, N\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp, N = 5K, p=1)': [\n",
    "        accuracy1, f1score1, media_fp_div_list_baseline2_p6_5K , fp_div_massimo_valore_assoluto_fp_div_list_baseline2_p6_5K,\n",
    "        media_fp_div_list_baseline2_p6_5K_primi10, media_fp_div_list_baseline2_p6_5K_primi20, media_fp_div_list_baseline2_p6_5K_primi40, N\n",
    "    ]\n",
    "\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT: andamento di falsi positivi e di falsi negativi al variare di N e p di appartenere alla classe 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creazione del grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "p =[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "# Linea per i falsi positivi\n",
    "\n",
    "\n",
    "plt.plot(p, falsi_positivi_2K_fp_5sub, marker='o', label='False Positives 2K', color='black')\n",
    "plt.plot(p, falsi_positivi_3K_fp_5sub, marker='o', label='False Positives 3K', color='red')\n",
    "plt.plot(p, falsi_positivi_4K_fp_5sub, marker='o', label='False Positives 4K', color='green')\n",
    "plt.plot(p, falsi_positivi_5K_fp_5sub, marker='o', label='False Positives 5K', color='blue')\n",
    "plt.plot(p, falsi_positivi_6K_fp_5sub, marker='o', label='False Positives 6K', color='orange')\n",
    "#plt.plot(p, falsi_positivi_7K_fp_5sub, marker='o', label='False Positives 7K', color='red')\n",
    "\n",
    "\n",
    "plt.axhline(y=falsi_positivi_5K_fp_5sub_before, color='purple', linestyle='--', label='Initial False Positives')\n",
    "\n",
    "# Etichette e titolo\n",
    "plt.xlabel('probability for the synthetic point to belong to the class 0')\n",
    "plt.ylabel('Count false positives')\n",
    "plt.title(f'False Positives, fp, # prob subgroups added = {K} on {filtered_instances}, support = {min_sup}, pruning = 0.01')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "plt.yticks(range(500, 701, 25))\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creazione del grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "p =[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "# Linea per i falsi positivi\n",
    "\n",
    "plt.plot(p, falsi_positivi_5K_fp_5sub_sub, marker='o', label='False Positives 5K ', color='blue')\n",
    "plt.plot(p, falsi_positivi_6K_fp_5sub_sub, marker='o', label='False Positives 6K ', color='orange')\n",
    "plt.plot(p, falsi_positivi_7K_fp_5sub_sub, marker='o', label='False Positives 7K ', color='red')\n",
    "\n",
    "\n",
    "plt.axhline(y=falsi_positivi_5K_fp_5sub_sub_before, color='purple', linestyle='--', label='Initial False Positives')\n",
    "\n",
    "# Etichette e titolo\n",
    "plt.xlabel('probability for the synthetic point to belong to the class 0')\n",
    "plt.ylabel('Count false positives')\n",
    "plt.title('False Positives, fp, #subgroups = 5, support = 0.2, redundancy = 0.01, subgroups ')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "plt.yticks(range(500, 701, 50))\n",
    "# Mostra il grafico\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
