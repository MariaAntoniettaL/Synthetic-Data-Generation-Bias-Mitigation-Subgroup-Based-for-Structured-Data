{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE\n",
    "Nel file preprocessing_for_adult.py sono contenute le funzioni per il preprocessing da applicare ad adult.data: la prima (preprocessing_funct_not_enc) discretizza, normalizza ecc mentre la seconda (encoding_funct) esegue l'encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_for_adult import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_and, K_subgroups_dataset_and_or, metrics_to_compare, preprocessing_funct_not_enc_SMOTE, encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "from divexplorer.outcomes import get_false_positive_rate_outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = 0.2\n",
    "percentage = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv(\"adult.data\", header = None, names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "VALIDATION SET ROWS:  6507\n",
      "HOLDOUT SET ROWS:  6508\n",
      "TEST SET ROWS:  6508\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosit√† precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_no_income = df_train_enc.drop(columns = 'income')\n",
    "plt.figure(figsize=(4, 3))\n",
    "g = sns.heatmap(df_train_no_income.corr(),\n",
    "                annot = False,\n",
    "                cmap = \"coolwarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "X_train = df_train_enc.drop(columns = 'income', axis = 1)\n",
    "y_train = df_train_enc['income']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'income', axis = 1)\n",
    "y_test = df_test_enc['income']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'income', axis = 1)\n",
    "y_val = df_val_enc['income']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'income', axis = 1)\n",
    "y_holdout = df_holdout_enc['income']\n",
    "\n",
    "classifier_train = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.803     0.593                0.130   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.407              641              638   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       6508  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione √® giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>2</td>\n",
       "      <td>0.077</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0</td>\n",
       "      <td>0.284</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass  fnlwgt  education  marital-status  occupation  relationship  \\\n",
       "18761          2   0.077          3               0           4             1   \n",
       "27582          3   0.048          3               1           4             0   \n",
       "30911          2   0.174          3               3           4             4   \n",
       "11128          0   0.012          2               1           2             0   \n",
       "683            0   0.284          3               3           2             4   \n",
       "\n",
       "       race  sex  capital-gain  capital-loss  native-country  age_group  \\\n",
       "18761     4    0         0.000         0.000               5          2   \n",
       "27582     4    1         0.000         0.000               5          5   \n",
       "30911     2    0         0.039         0.000               5          1   \n",
       "11128     2    1         0.000         0.507               5          3   \n",
       "683       2    1         0.000         0.000               5          0   \n",
       "\n",
       "       edu_num_group  hours_per_week_group  y_val_true  y_pred  \n",
       "18761              1                     1           0       0  \n",
       "27582              1                     2           1       0  \n",
       "30911              1                     1           0       0  \n",
       "11128              4                     1           1       1  \n",
       "683                1                     1           0       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set, queste mi servono solo per il div explorer che ha bisogno di ground truth e predizioni\n",
    "y_pred_val = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>age_group</th>\n",
       "      <th>edu_num_group</th>\n",
       "      <th>hours_per_week_group</th>\n",
       "      <th>fp</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.077</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>Self-emp</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>65-100</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>Private</td>\n",
       "      <td>0.174</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Self-emp-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.012</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>45-54</td>\n",
       "      <td>14 Master's Degree</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.284</td>\n",
       "      <td>Non Graduated</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Private-occ</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>17-24</td>\n",
       "      <td>10 College</td>\n",
       "      <td>Overtime</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        workclass  fnlwgt        education marital-status    occupation  \\\n",
       "18761     Private   0.077    Non Graduated       Divorced  Self-emp-occ   \n",
       "27582    Self-emp   0.048    Non Graduated        Married  Self-emp-occ   \n",
       "30911     Private   0.174    Non Graduated      Separated  Self-emp-occ   \n",
       "11128  Government   0.012  Master's Degree        Married   Private-occ   \n",
       "683    Government   0.284    Non Graduated      Separated   Private-occ   \n",
       "\n",
       "         relationship    race      sex  capital-gain  capital-loss  \\\n",
       "18761   Not-in-family   White   Female         0.000         0.000   \n",
       "27582         Husband   White     Male         0.000         0.000   \n",
       "30911       Unmarried   Black   Female         0.039         0.000   \n",
       "11128         Husband   Black     Male         0.000         0.507   \n",
       "683         Unmarried   Black     Male         0.000         0.000   \n",
       "\n",
       "      native-country  income age_group       edu_num_group  \\\n",
       "18761  United-States       0     35-44          10 College   \n",
       "27582  United-States       1    65-100          10 College   \n",
       "30911  United-States       0     25-34          10 College   \n",
       "11128  United-States       1     45-54  14 Master's Degree   \n",
       "683    United-States       0     17-24          10 College   \n",
       "\n",
       "      hours_per_week_group    fp  y_pred  accuracy  \n",
       "18761             Overtime 0.000       0         1  \n",
       "27582            Part-time   NaN       0         0  \n",
       "30911             Overtime 0.000       0         1  \n",
       "11128             Overtime   NaN       1         1  \n",
       "683               Overtime 0.000       0         1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]\n",
    "\n",
    "df_val_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_val['fp'] = df_val_class['fp']\n",
    "\n",
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione √® giusta 0 se la predizione √® sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['accuracy'] = (df_val_class['y_val_true']==df_val_class['y_pred']).astype(int)\n",
    "df_val.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI CONDOTTA CON LA FEATURE FP (PASSATA A BOOLEAN OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>fp</th>\n",
       "      <th>fp_div</th>\n",
       "      <th>fp_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(capital-loss=0.0, relationship= Husband, marital-status=Married, hours_per_week_group=Overtime, sex= Male, race= White, capital-gain=0.0, native-country=United-States)</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.224</td>\n",
       "      <td>13.300</td>\n",
       "      <td>8</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(capital-loss=0.0, relationship= Husband, hours_per_week_group=Overtime, sex= Male, race= White, capital-gain=0.0, native-country=United-States)</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.224</td>\n",
       "      <td>13.300</td>\n",
       "      <td>7</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(capital-loss=0.0, relationship= Husband, marital-status=Married, hours_per_week_group=Overtime, race= White, capital-gain=0.0, native-country=United-States)</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.224</td>\n",
       "      <td>13.300</td>\n",
       "      <td>7</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.239</td>\n",
       "      <td>(capital-loss=0.0, relationship= Husband, hours_per_week_group=Overtime, race= White, capital-gain=0.0, native-country=United-States)</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.224</td>\n",
       "      <td>13.300</td>\n",
       "      <td>6</td>\n",
       "      <td>1554.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.259</td>\n",
       "      <td>(relationship= Husband, hours_per_week_group=Overtime, sex= Male, race= White, capital-gain=0.0, native-country=United-States)</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.223</td>\n",
       "      <td>13.527</td>\n",
       "      <td>6</td>\n",
       "      <td>1686.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  \\\n",
       "0    0.239   \n",
       "1    0.239   \n",
       "2    0.239   \n",
       "3    0.239   \n",
       "4    0.259   \n",
       "\n",
       "                                                                                                                                                                    itemset  \\\n",
       "0  (capital-loss=0.0, relationship= Husband, marital-status=Married, hours_per_week_group=Overtime, sex= Male, race= White, capital-gain=0.0, native-country=United-States)   \n",
       "1                          (capital-loss=0.0, relationship= Husband, hours_per_week_group=Overtime, sex= Male, race= White, capital-gain=0.0, native-country=United-States)   \n",
       "2             (capital-loss=0.0, relationship= Husband, marital-status=Married, hours_per_week_group=Overtime, race= White, capital-gain=0.0, native-country=United-States)   \n",
       "3                                     (capital-loss=0.0, relationship= Husband, hours_per_week_group=Overtime, race= White, capital-gain=0.0, native-country=United-States)   \n",
       "4                                            (relationship= Husband, hours_per_week_group=Overtime, sex= Male, race= White, capital-gain=0.0, native-country=United-States)   \n",
       "\n",
       "     fp  fp_div   fp_t  length  support_count  \n",
       "0 0.362   0.224 13.300       8       1554.000  \n",
       "1 0.362   0.224 13.300       7       1554.000  \n",
       "2 0.362   0.224 13.300       7       1554.000  \n",
       "3 0.362   0.224 13.300       6       1554.000  \n",
       "4 0.361   0.223 13.527       6       1686.000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_diver = DivergenceExplorer(df_val)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"fp_div\", \"fp_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "      <th>fp</th>\n",
       "      <th>fp_div</th>\n",
       "      <th>fp_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.297</td>\n",
       "      <td>(hours_per_week_group=Overtime, relationship= Husband, native-country=United-States, race= White)</td>\n",
       "      <td>4</td>\n",
       "      <td>1931.000</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.214</td>\n",
       "      <td>13.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.326</td>\n",
       "      <td>(hours_per_week_group=Overtime, native-country=United-States, marital-status=Married, race= White)</td>\n",
       "      <td>4</td>\n",
       "      <td>2124.000</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.211</td>\n",
       "      <td>13.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.353</td>\n",
       "      <td>(hours_per_week_group=Overtime, native-country=United-States, marital-status=Married)</td>\n",
       "      <td>3</td>\n",
       "      <td>2299.000</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.201</td>\n",
       "      <td>13.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.356</td>\n",
       "      <td>(hours_per_week_group=Overtime, relationship= Husband)</td>\n",
       "      <td>2</td>\n",
       "      <td>2318.000</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.196</td>\n",
       "      <td>13.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.401</td>\n",
       "      <td>(hours_per_week_group=Overtime, marital-status=Married)</td>\n",
       "      <td>2</td>\n",
       "      <td>2612.000</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.186</td>\n",
       "      <td>13.881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     support  \\\n",
       "16     0.297   \n",
       "28     0.326   \n",
       "69     0.353   \n",
       "84     0.356   \n",
       "138    0.401   \n",
       "\n",
       "                                                                                                itemset  \\\n",
       "16    (hours_per_week_group=Overtime, relationship= Husband, native-country=United-States, race= White)   \n",
       "28   (hours_per_week_group=Overtime, native-country=United-States, marital-status=Married, race= White)   \n",
       "69                (hours_per_week_group=Overtime, native-country=United-States, marital-status=Married)   \n",
       "84                                               (hours_per_week_group=Overtime, relationship= Husband)   \n",
       "138                                             (hours_per_week_group=Overtime, marital-status=Married)   \n",
       "\n",
       "     length  support_count    fp  fp_div   fp_t  \n",
       "16        4       1931.000 0.353   0.214 13.450  \n",
       "28        4       2124.000 0.349   0.211 13.859  \n",
       "69        3       2299.000 0.339   0.201 13.841  \n",
       "84        2       2318.000 0.335   0.196 13.694  \n",
       "138       2       2612.000 0.325   0.186 13.881  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 58\n",
      "total problematic 34\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_fp)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_fp[(df_pruned_fp['fp_div'] > 0) & (df_pruned_fp['fp_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (893, 7)\n",
      "Dim pruned th_redundancy  (58, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_fp.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset_and_or li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "df_holdout_filtered_solo0 = df_holdout_filtered[df_holdout_filtered['income']==0]\n",
    "\n",
    "\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered_solo0, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "df_holdout_filtered = df_holdout_filtered_solo0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1252\n"
     ]
    }
   ],
   "source": [
    "print(len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \\ndf_train_enc_mit, df_test_enc_filtered_fp, df_filtered_enc, df_val_enc_mit = encoding_funct(df_train=df_train_mitigated, df_test=df_test_filtered_fp, df_holdout=df_holdout_filtered, df_val=df_val)\\n#controllo divisione dataset\\ndf_train_enc_mit_fp = df_train_enc_mit  \\nprint(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\\nprint(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\\nprint(f\"VALIDATION SET ROWS: \", df_val_enc_mit.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\\nprint(f\"FILTERED DF holdout ROWS: \", df_filtered_enc.shape[0])\\nprint(f\"TEST SET FILTERED ROWS: \", df_test_enc_filtered_fp.shape[0])'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, df_test_enc_filtered_fp, df_filtered_enc, df_val_enc_mit = encoding_funct(df_train=df_train_mitigated, df_test=df_test_filtered_fp, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc_mit.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", df_filtered_enc.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", df_test_enc_filtered_fp.shape[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  13014\n",
      "TRAIN SET MITIGATED ROWS:  14266\n",
      "VALIDATION SET ROWS:  6508\n",
      "FILTERED DF holdout ROWS:  1252\n",
      "TEST SET FILTERED ROWS:  6507\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'income', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['income']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "#cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1252\n",
      "verifica : 1252\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['income']\n",
    "\n",
    "classifier_train_mitigated_random = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.436</td>\n",
       "      <td>533</td>\n",
       "      <td>684</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.390</td>\n",
       "      <td>634</td>\n",
       "      <td>612</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.803     0.593                0.130   \n",
       "After Mitigation(K=5, fp)     0.813     0.592                0.108   \n",
       "After RANDOM mitigation       0.809     0.605                0.128   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.407              641   \n",
       "After Mitigation(K=5, fp)                0.436              533   \n",
       "After RANDOM mitigation                  0.390              634   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      638       13014       6508  \n",
       "After Mitigation(K=5, fp)              684       14266       6508  \n",
       "After RANDOM mitigation                612       14266       6508  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance su sottogruppi \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups Decision Tree performance when boolean outcomes = fp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation, on subgroups</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.365</td>\n",
       "      <td>388</td>\n",
       "      <td>421</td>\n",
       "      <td>13014</td>\n",
       "      <td>2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.680</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.412</td>\n",
       "      <td>285</td>\n",
       "      <td>475</td>\n",
       "      <td>14266</td>\n",
       "      <td>2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5, on subgroups, fp)</th>\n",
       "      <td>0.670</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.357</td>\n",
       "      <td>373</td>\n",
       "      <td>412</td>\n",
       "      <td>14266</td>\n",
       "      <td>2376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                         Accuracy  F1 Score  \\\n",
       "Before Mitigation, on subgroups                    0.660     0.644   \n",
       "After Mitigation(K=5, on subgroups, fp)            0.680     0.641   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)     0.670     0.654   \n",
       "\n",
       "Metrics                                         False Positive Rate  \\\n",
       "Before Mitigation, on subgroups                               0.317   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.233   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.305   \n",
       "\n",
       "Metrics                                         False Negative Rate  \\\n",
       "Before Mitigation, on subgroups                               0.365   \n",
       "After Mitigation(K=5, on subgroups, fp)                       0.412   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)                0.357   \n",
       "\n",
       "Metrics                                         False Positives  \\\n",
       "Before Mitigation, on subgroups                             388   \n",
       "After Mitigation(K=5, on subgroups, fp)                     285   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              373   \n",
       "\n",
       "Metrics                                         False Negatives  Train Size  \\\n",
       "Before Mitigation, on subgroups                             421       13014   \n",
       "After Mitigation(K=5, on subgroups, fp)                     475       14266   \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)              412       14266   \n",
       "\n",
       "Metrics                                         Test Size  \n",
       "Before Mitigation, on subgroups                      2376  \n",
       "After Mitigation(K=5, on subgroups, fp)              2376  \n",
       "After RANDOM Mitigation(K=5, on subgroups, fp)       2376  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered_fp = K_subgroups_dataset_and_or(df_pruned_fp, df_test, K)\n",
    "inutile, df_test_filtered_enc_fp, inutile2, inutile3 = encoding_funct(df_train, df_test_filtered_fp, df_holdout, df_val)\n",
    "\n",
    "X_test_filtered_fp = df_test_filtered_enc_fp.drop(columns='income', axis = 1)\n",
    "y_true_test_filtered_fp = df_test_filtered_enc_fp['income']\n",
    "\n",
    "y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after = classifier_train_mitigated.predict(X_test_filtered_fp)\n",
    "y_pred_test_filtered_fp_after_random = classifier_train_mitigated_random.predict(X_test_filtered_fp)\n",
    "\n",
    "accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after )\n",
    "accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_random)\n",
    "\n",
    "\n",
    "metrics_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after, f1_score_fp_sottogruppi_after, fpr_fp_sottogruppi_after, fnr_fp_sottogruppi_after, fp_fp_sottogruppi_after, fn_fp_sottogruppi_after, len(y_train_mitigated), len(y_pred_test_filtered_fp_after)],\n",
    "    'After RANDOM Mitigation(K=5, on subgroups, fp)': [accuracy_fp_sottogruppi_after_random, f1_score_fp_sottogruppi_after_random, fpr_fp_sottogruppi_after_random, fnr_fp_sottogruppi_after_random, fp_fp_sottogruppi_after_random, fn_fp_sottogruppi_after_random, len(y_train_mitigated_random), len(y_pred_test_filtered_fp_after_random)]\n",
    "})\n",
    "metrics_after_fp_sottogruppi = metrics_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi[metric] = metrics_after_fp_sottogruppi[metric].astype(int)\n",
    "\n",
    "metrics_after_fp\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp\")\n",
    "metrics_after_fp_sottogruppi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_no_mitigation  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_no_mitigation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_baseline1  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['fp'] =  get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "#aggiungo la feature 'fp' a df_val non encoded\n",
    "df_test['fp'] = df_test_class['fp']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', 'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "df_pruned_fp.head()\n",
    "\n",
    "\n",
    "\n",
    "fp_div_list_random_per_confrontare_con_baseline1  = df_pruned_fp[\"fp_div\"].tolist()\n",
    "#fp_div_list_random_per_confrontare_con_baseline1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.009</td>\n",
       "      <td>1252.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.072</td>\n",
       "      <td>1252.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.803     0.593             0.054   \n",
       "After Mitigation(K=5 fp)            0.813     0.592             0.009   \n",
       "After RANDOM Mitigation(K=5 fp)     0.809     0.605             0.038   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.190               0.172   \n",
       "After Mitigation(K=5 fp)           0.123               0.079   \n",
       "After RANDOM Mitigation(K=5 fp)    0.177               0.154   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.153               0.097   \n",
       "After Mitigation(K=5 fp)                      0.049               0.009   \n",
       "After RANDOM Mitigation(K=5 fp)               0.129               0.072   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)              1252.000  \n",
       "After RANDOM Mitigation(K=5 fp)       1252.000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_fp_div_list_no_mitigation = abs(sum(fp_div_list_no_mitigation) / len(fp_div_list_no_mitigation))\n",
    "media_fp_div_list_nomitigation_primi10 = abs(sum(fp_div_list_no_mitigation[:10]) / len(fp_div_list_no_mitigation[:10]))\n",
    "media_fp_div_list_nomitigation_primi20 = abs(sum(fp_div_list_no_mitigation[:20]) / len(fp_div_list_no_mitigation[:20]))\n",
    "media_fp_div_list_nomitigation_primi40 = abs(sum(fp_div_list_no_mitigation[:40]) / len(fp_div_list_no_mitigation[:40]))\n",
    "massimo_valore_assoluto_fp_div_no_mitigation = max(abs(x) for x in fp_div_list_no_mitigation)\n",
    "\n",
    "media_fp_div_list_baseline1 = abs(sum(fp_div_list_baseline1) / len(fp_div_list_baseline1))\n",
    "media_fp_div_list_baseline1_primi10 = abs(sum(fp_div_list_baseline1[:10]) / len(fp_div_list_baseline1[:10]))\n",
    "media_fp_div_list_baseline1_primi20 = abs(sum(fp_div_list_baseline1[:20]) / len(fp_div_list_baseline1[:20]))\n",
    "media_fp_div_list_baseline1_primi40 = abs(sum(fp_div_list_baseline1[:40]) / len(fp_div_list_baseline1[:40]))\n",
    "fp_div_massimo_valore_assoluto_fp_div_baseline1 = max(abs(x) for x in fp_div_list_baseline1)\n",
    "\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1) / len(fp_div_list_random_per_confrontare_con_baseline1))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi10 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:10]) / len(fp_div_list_random_per_confrontare_con_baseline1[:10]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi20 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:20]) / len(fp_div_list_random_per_confrontare_con_baseline1[:20]))\n",
    "media_fp_div_list_random_per_confrontare_con_baseline1_primi40 = abs(sum(fp_div_list_random_per_confrontare_con_baseline1[:40]) / len(fp_div_list_random_per_confrontare_con_baseline1[:40]))\n",
    "massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in fp_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_fp_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_fp_div_list_no_mitigation, massimo_valore_assoluto_fp_div_no_mitigation,\n",
    "        media_fp_div_list_nomitigation_primi10, media_fp_div_list_nomitigation_primi20, media_fp_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_fp_div_list_baseline1, fp_div_massimo_valore_assoluto_fp_div_baseline1,\n",
    "        media_fp_div_list_baseline1_primi10, media_fp_div_list_baseline1_primi20, media_fp_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_fp_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_fp_div_random_per_confrontare_con_baseline1, media_fp_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_fp_div_list_random_per_confrontare_con_baseline1_primi20, media_fp_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_fp_sottogruppi = divergence_after_fp_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_fp_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SIMULANDO DATI ATTRAVERSO SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGUE CODICE USANDO SMOTE \n",
    "DIVIDO IN TRAIN, TEST E VALIDATION -- ora uso quelli gia esistenti\n",
    "DIV EXPLORER SUL VALIDATION  -- gi√† fatto \n",
    "GENERO NUOVI DATI CON SMOTE a partire dai dati di divexplorer sul validation\n",
    "INSERISCO QUESTI NUOVI DATI NEL TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 2610\n",
      "numero di dati simulati con smotenc 2802\n",
      "income\n",
      "1    1401\n",
      "0    1401\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['fp', 'y_pred', 'accuracy', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]\n",
    "\n",
    "smote_nc = SMOTENC( categorical_features=categorical_features, random_state=seed)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "\n",
    "print(\"numero di dati simulati con smotenc\",len(y_resampled))\n",
    "\n",
    "class_counts = y_resampled.value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggiungo una sampling strategy in modo da avere piu etichette = 0 visto che i sottogruppi porblematici hanno piu spesso etichette = 1 (per costruzione-per come ho impostato la ricerca dei sottogruppi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sampling_strategy = {0: 2500, 1: 1400}\\n\\nsmote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\\nX_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\n\\nprint(len(y_resampled))\\n\\nclass_counts = y_resampled.value_counts()\\nprint(class_counts)\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''sampling_strategy = {0: 2500, 1: 1400}\n",
    "\n",
    "smote_nc = SMOTENC(sampling_strategy = sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "\n",
    "print(len(y_resampled))\n",
    "\n",
    "class_counts = y_resampled.value_counts()\n",
    "print(class_counts)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15816\n"
     ]
    }
   ],
   "source": [
    "X_train_mitigated_SMOTE = pd.concat([X_train, X_resampled], ignore_index=True)\n",
    "y_train_mitigated_SMOTE = pd.concat([y_train, y_resampled], ignore_index=True)\n",
    "print(len(X_train_mitigated_SMOTE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.head()  come verifica che tutto sia numerico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_train_mitigated_SMOTE = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_SMOTE.fit(X_train_mitigated_SMOTE, y_train_mitigated_SMOTE)\n",
    "y_mitigated_SMOTE_pred = classifier_train_mitigated_SMOTE.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#vediamo che succede se prendo lo stesso numero di righe ma random da holdout\\nprint(len(X_resampled))\\nn_random_smote = len(X_resampled)\\n\\ndf_holdout_smote_sampled = df_holdout_enc.sample(n=n_random_smote, random_state=seed)\\nprint(\"verifica :\", len(df_holdout_smote_sampled)) #verifica\\n\\ndf_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\\ndf_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\\n\\nX_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\\ny_train_mitigated_random_smote = df_train_mitigated_random_smote[\\'income\\']\\n\\nclassifier_train_mitigated_random_smote = DecisionTreeClassifier(random_state=seed)\\n\\nclassifier_train_mitigated_random_smote.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\\ny_mitigated_pred_random_smote = classifier_train_mitigated_random_smote.predict(X_test)'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#vediamo che succede se prendo lo stesso numero di righe ma random da holdout\n",
    "print(len(X_resampled))\n",
    "n_random_smote = len(X_resampled)\n",
    "\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=n_random_smote, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_smote_sampled)) #verifica\n",
    "\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis = 1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random_smote.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote = classifier_train_mitigated_random_smote.predict(X_test)'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_SMOTE_pred )\\naccuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote )\\n\\n\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\\n    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\\n    'After SMOTE fp mitigation' : [accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_mitigated_SMOTE_pred)],\\n    'After RANDOM mitigation' : [accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random, len(y_train_mitigated_random_smote), len(y_mitigated_pred_random_smote)]\\n    \\n})\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\\nmetrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n    \\nmetrics_after_fp_SMOTE\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_SMOTE_pred )\n",
    "accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random_smote )\n",
    "\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After SMOTE fp mitigation' : [accuracy_fp_after_SMOTE, f1_score_fp_after_SMOTE, fpr_fp_after_SMOTE, fnr_fp_after_SMOTE, fp_fp_after_SMOTE, fn_fp_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_mitigated_SMOTE_pred)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_SMOTE_random, f1_score_fp_after_SMOTE_random, fpr_fp_after_SMOTE_random, fnr_fp_after_SMOTE_random, fp_fp_after_SMOTE_random, fn_fp_after_SMOTE_random, len(y_train_mitigated_random_smote), len(y_mitigated_pred_random_smote)]\n",
    "    \n",
    "})\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "    \n",
    "metrics_after_fp_SMOTE'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A QUESTO PUNTO POSSIAMO VEDERE LE PERFORMANCE SUI SOTTOGRUPPI PRIMA E DOPO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \\ny_pred_test_filtered_fp_after_SMOTE = classifier_train_mitigated_SMOTE.predict(X_test_filtered_fp)\\ny_pred_RANDOM_subgroups = classifier_train_mitigated_random_smote.predict(X_test_filtered_fp)\\n\\n\\n#accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\\naccuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE )\\naccuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_RANDOM_subgroups )\\n\\nmetrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\\n    \\'Metrics\\' : [\\'Accuracy\\', \\'F1 Score\\', \\'False Positive Rate\\', \\'False Negative Rate\\', \\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\'],\\n    \\'Before Mitigation, on subgroups\\' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\\n    \\'After RANDOM mitigation, on subgroups\\' : [accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE, len(y_train), len(y_pred_RANDOM_subgroups)],\\n    \\'After Mitigation(K=5, on subgroups, fp and SMOTE)\\': [accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_pred_test_filtered_fp_after_SMOTE)],\\n})\\nmetrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index(\\'Metrics\\').T\\n\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\']\\n\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\\n\\nmetrics_after_fp_SMOTE\\n\\n\\nprint(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\\nmetrics_after_fp_sottogruppi_SMOTE'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# y_pred_test_filtered_fp_before = classifier_train.predict(X_test_filtered_fp) trovato prima \n",
    "y_pred_test_filtered_fp_after_SMOTE = classifier_train_mitigated_SMOTE.predict(X_test_filtered_fp)\n",
    "y_pred_RANDOM_subgroups = classifier_train_mitigated_random_smote.predict(X_test_filtered_fp)\n",
    "\n",
    "\n",
    "#accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_before )\n",
    "accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_test_filtered_fp_after_SMOTE )\n",
    "accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE = metrics_to_compare(y_true = y_true_test_filtered_fp, y_pred = y_pred_RANDOM_subgroups )\n",
    "\n",
    "metrics_after_fp_sottogruppi_SMOTE = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation, on subgroups' : [accuracy_fp_sottogruppi_before, f1_score_fp_sottogruppi_before, fpr_fp_sottogruppi_before, fnr_fp_sottogruppi_before, fp_fp_sottogruppi_before, fn_fp_sottogruppi_before, len(y_train), len(y_pred_test_filtered_fp_before)],\n",
    "    'After RANDOM mitigation, on subgroups' : [accuracy_fp_sottogruppi_random_SMOTE, f1_score_fp_sottogruppi_random_SMOTE, fpr_fp_sottogruppi_random_SMOTE, fnr_fp_sottogruppi_random_SMOTE, fp_fp_sottogruppi_random_SMOTE, fn_fp_sottogruppi_random_SMOTE, len(y_train), len(y_pred_RANDOM_subgroups)],\n",
    "    'After Mitigation(K=5, on subgroups, fp and SMOTE)': [accuracy_fp_sottogruppi_after_SMOTE, f1_score_fp_sottogruppi_after_SMOTE, fpr_fp_sottogruppi_after_SMOTE, fnr_fp_sottogruppi_after_SMOTE, fp_fp_sottogruppi_after_SMOTE, fn_fp_sottogruppi_after_SMOTE, len(y_train_mitigated_SMOTE), len(y_pred_test_filtered_fp_after_SMOTE)],\n",
    "})\n",
    "metrics_after_fp_sottogruppi_SMOTE = metrics_after_fp_sottogruppi_SMOTE.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_sottogruppi_SMOTE[metric] = metrics_after_fp_sottogruppi_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE\n",
    "\n",
    "\n",
    "print(\"Subgroups Decision Tree performance when boolean outcomes = fp e SMOTE \")\n",
    "metrics_after_fp_sottogruppi_SMOTE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p √® la probabilit√† che il campione simulato sia di classe 0 qui (perch√® voglio diminuire il numero di falsi positivi)\n",
    "- FISSO p VARIA N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato qunado K = 5 2610\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_fp, df_val, K)\n",
    "print(\"Righe del dataset filtrato qunado K = 5\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['fp', 'y_pred', 'accuracy', 'income'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered['income']\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1209, 1401)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered['income'].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = np.arange(0.5, 1.05, 0.05)\n",
    "p_values = np.round(p_values, 2).tolist()\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N come holdout filtered e targeted acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1252</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.390</td>\n",
       "      <td>634</td>\n",
       "      <td>612</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.5</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.393</td>\n",
       "      <td>661</td>\n",
       "      <td>616</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.55</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.408</td>\n",
       "      <td>650</td>\n",
       "      <td>640</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.6</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.401</td>\n",
       "      <td>639</td>\n",
       "      <td>628</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.65</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.399</td>\n",
       "      <td>621</td>\n",
       "      <td>626</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.7</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.411</td>\n",
       "      <td>647</td>\n",
       "      <td>644</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.75</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.415</td>\n",
       "      <td>624</td>\n",
       "      <td>651</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.8</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.415</td>\n",
       "      <td>608</td>\n",
       "      <td>650</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.85</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.416</td>\n",
       "      <td>598</td>\n",
       "      <td>652</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.9</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.439</td>\n",
       "      <td>575</td>\n",
       "      <td>688</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.95</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.442</td>\n",
       "      <td>603</td>\n",
       "      <td>693</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 1.0</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.418</td>\n",
       "      <td>569</td>\n",
       "      <td>656</td>\n",
       "      <td>14266</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 1252          0.809     0.605   \n",
       "After SMOTE N = 1252 p_class 0 = 0.5      0.804     0.599   \n",
       "After SMOTE N = 1252 p_class 0 = 0.55     0.802     0.590   \n",
       "After SMOTE N = 1252 p_class 0 = 0.6      0.805     0.597   \n",
       "After SMOTE N = 1252 p_class 0 = 0.65     0.808     0.602   \n",
       "After SMOTE N = 1252 p_class 0 = 0.7      0.802     0.589   \n",
       "After SMOTE N = 1252 p_class 0 = 0.75     0.804     0.590   \n",
       "After SMOTE N = 1252 p_class 0 = 0.8      0.807     0.593   \n",
       "After SMOTE N = 1252 p_class 0 = 0.85     0.808     0.594   \n",
       "After SMOTE N = 1252 p_class 0 = 0.9      0.806     0.582   \n",
       "After SMOTE N = 1252 p_class 0 = 0.95     0.801     0.575   \n",
       "After SMOTE N = 1252 p_class 0 = 1.0      0.812     0.598   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 1252                     0.128   \n",
       "After SMOTE N = 1252 p_class 0 = 0.5                 0.134   \n",
       "After SMOTE N = 1252 p_class 0 = 0.55                0.132   \n",
       "After SMOTE N = 1252 p_class 0 = 0.6                 0.129   \n",
       "After SMOTE N = 1252 p_class 0 = 0.65                0.126   \n",
       "After SMOTE N = 1252 p_class 0 = 0.7                 0.131   \n",
       "After SMOTE N = 1252 p_class 0 = 0.75                0.126   \n",
       "After SMOTE N = 1252 p_class 0 = 0.8                 0.123   \n",
       "After SMOTE N = 1252 p_class 0 = 0.85                0.121   \n",
       "After SMOTE N = 1252 p_class 0 = 0.9                 0.116   \n",
       "After SMOTE N = 1252 p_class 0 = 0.95                0.122   \n",
       "After SMOTE N = 1252 p_class 0 = 1.0                 0.115   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 1252                     0.390              634   \n",
       "After SMOTE N = 1252 p_class 0 = 0.5                 0.393              661   \n",
       "After SMOTE N = 1252 p_class 0 = 0.55                0.408              650   \n",
       "After SMOTE N = 1252 p_class 0 = 0.6                 0.401              639   \n",
       "After SMOTE N = 1252 p_class 0 = 0.65                0.399              621   \n",
       "After SMOTE N = 1252 p_class 0 = 0.7                 0.411              647   \n",
       "After SMOTE N = 1252 p_class 0 = 0.75                0.415              624   \n",
       "After SMOTE N = 1252 p_class 0 = 0.8                 0.415              608   \n",
       "After SMOTE N = 1252 p_class 0 = 0.85                0.416              598   \n",
       "After SMOTE N = 1252 p_class 0 = 0.9                 0.439              575   \n",
       "After SMOTE N = 1252 p_class 0 = 0.95                0.442              603   \n",
       "After SMOTE N = 1252 p_class 0 = 1.0                 0.418              569   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 1252                   612       14266       6508  \n",
       "After SMOTE N = 1252 p_class 0 = 0.5               616       14266       6508  \n",
       "After SMOTE N = 1252 p_class 0 = 0.55              640       14266       6508  \n",
       "After SMOTE N = 1252 p_class 0 = 0.6               628       14266       6508  \n",
       "After SMOTE N = 1252 p_class 0 = 0.65              626       14266       6508  \n",
       "After SMOTE N = 1252 p_class 0 = 0.7               644       14266       6508  \n",
       "After SMOTE N = 1252 p_class 0 = 0.75              651       14266       6508  \n",
       "After SMOTE N = 1252 p_class 0 = 0.8               650       14266       6508  \n",
       "After SMOTE N = 1252 p_class 0 = 0.85              652       14266       6508  \n",
       "After SMOTE N = 1252 p_class 0 = 0.9               688       14266       6508  \n",
       "After SMOTE N = 1252 p_class 0 = 0.95              693       14266       6508  \n",
       "After SMOTE N = 1252 p_class 0 = 1.0               656       14266       6508  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "N = len(df_holdout_filtered)\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1252</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.605</td>\n",
       "      <td>634</td>\n",
       "      <td>612</td>\n",
       "      <td>1246</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.5</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.599</td>\n",
       "      <td>661</td>\n",
       "      <td>616</td>\n",
       "      <td>1277</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.55</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.590</td>\n",
       "      <td>650</td>\n",
       "      <td>640</td>\n",
       "      <td>1290</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.6</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.597</td>\n",
       "      <td>639</td>\n",
       "      <td>628</td>\n",
       "      <td>1267</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.65</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.602</td>\n",
       "      <td>621</td>\n",
       "      <td>626</td>\n",
       "      <td>1247</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.7</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.589</td>\n",
       "      <td>647</td>\n",
       "      <td>644</td>\n",
       "      <td>1291</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.75</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.590</td>\n",
       "      <td>624</td>\n",
       "      <td>651</td>\n",
       "      <td>1275</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.8</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.593</td>\n",
       "      <td>608</td>\n",
       "      <td>650</td>\n",
       "      <td>1258</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.85</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.594</td>\n",
       "      <td>598</td>\n",
       "      <td>652</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.9</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.582</td>\n",
       "      <td>575</td>\n",
       "      <td>688</td>\n",
       "      <td>1263</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 0.95</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.575</td>\n",
       "      <td>603</td>\n",
       "      <td>693</td>\n",
       "      <td>1296</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1252 p_class 0 = 1.0</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.598</td>\n",
       "      <td>569</td>\n",
       "      <td>656</td>\n",
       "      <td>1225</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 1252          0.809     0.605              634   \n",
       "After SMOTE N = 1252 p_class 0 = 0.5      0.804     0.599              661   \n",
       "After SMOTE N = 1252 p_class 0 = 0.55     0.802     0.590              650   \n",
       "After SMOTE N = 1252 p_class 0 = 0.6      0.805     0.597              639   \n",
       "After SMOTE N = 1252 p_class 0 = 0.65     0.808     0.602              621   \n",
       "After SMOTE N = 1252 p_class 0 = 0.7      0.802     0.589              647   \n",
       "After SMOTE N = 1252 p_class 0 = 0.75     0.804     0.590              624   \n",
       "After SMOTE N = 1252 p_class 0 = 0.8      0.807     0.593              608   \n",
       "After SMOTE N = 1252 p_class 0 = 0.85     0.808     0.594              598   \n",
       "After SMOTE N = 1252 p_class 0 = 0.9      0.806     0.582              575   \n",
       "After SMOTE N = 1252 p_class 0 = 0.95     0.801     0.575              603   \n",
       "After SMOTE N = 1252 p_class 0 = 1.0      0.812     0.598              569   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 1252                   612          1246   \n",
       "After SMOTE N = 1252 p_class 0 = 0.5               616          1277   \n",
       "After SMOTE N = 1252 p_class 0 = 0.55              640          1290   \n",
       "After SMOTE N = 1252 p_class 0 = 0.6               628          1267   \n",
       "After SMOTE N = 1252 p_class 0 = 0.65              626          1247   \n",
       "After SMOTE N = 1252 p_class 0 = 0.7               644          1291   \n",
       "After SMOTE N = 1252 p_class 0 = 0.75              651          1275   \n",
       "After SMOTE N = 1252 p_class 0 = 0.8               650          1258   \n",
       "After SMOTE N = 1252 p_class 0 = 0.85              652          1250   \n",
       "After SMOTE N = 1252 p_class 0 = 0.9               688          1263   \n",
       "After SMOTE N = 1252 p_class 0 = 0.95              693          1296   \n",
       "After SMOTE N = 1252 p_class 0 = 1.0               656          1225   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.054           0.190   \n",
       "After RANDOM mitigation N = 1252                 0.038           0.177   \n",
       "After SMOTE N = 1252 p_class 0 = 0.5             0.052           0.201   \n",
       "After SMOTE N = 1252 p_class 0 = 0.55            0.045           0.185   \n",
       "After SMOTE N = 1252 p_class 0 = 0.6             0.041           0.182   \n",
       "After SMOTE N = 1252 p_class 0 = 0.65            0.024           0.163   \n",
       "After SMOTE N = 1252 p_class 0 = 0.7             0.012           0.164   \n",
       "After SMOTE N = 1252 p_class 0 = 0.75            0.031           0.170   \n",
       "After SMOTE N = 1252 p_class 0 = 0.8             0.032           0.170   \n",
       "After SMOTE N = 1252 p_class 0 = 0.85            0.020           0.158   \n",
       "After SMOTE N = 1252 p_class 0 = 0.9             0.030           0.162   \n",
       "After SMOTE N = 1252 p_class 0 = 0.95            0.022           0.163   \n",
       "After SMOTE N = 1252 p_class 0 = 1.0             0.018           0.152   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.172       0.153       0.097  \n",
       "After RANDOM mitigation N = 1252            0.154       0.129       0.072  \n",
       "After SMOTE N = 1252 p_class 0 = 0.5        0.181       0.150       0.084  \n",
       "After SMOTE N = 1252 p_class 0 = 0.55       0.166       0.137       0.073  \n",
       "After SMOTE N = 1252 p_class 0 = 0.6        0.161       0.131       0.072  \n",
       "After SMOTE N = 1252 p_class 0 = 0.65       0.130       0.089       0.033  \n",
       "After SMOTE N = 1252 p_class 0 = 0.7        0.104       0.065       0.018  \n",
       "After SMOTE N = 1252 p_class 0 = 0.75       0.147       0.105       0.049  \n",
       "After SMOTE N = 1252 p_class 0 = 0.8        0.149       0.099       0.036  \n",
       "After SMOTE N = 1252 p_class 0 = 0.85       0.109       0.071       0.020  \n",
       "After SMOTE N = 1252 p_class 0 = 0.9        0.133       0.102       0.052  \n",
       "After SMOTE N = 1252 p_class 0 = 0.95       0.124       0.085       0.033  \n",
       "After SMOTE N = 1252 p_class 0 = 1.0        0.106       0.069       0.018  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_confronto = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_confronto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N  = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.389</td>\n",
       "      <td>652</td>\n",
       "      <td>610</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.5</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.385</td>\n",
       "      <td>638</td>\n",
       "      <td>603</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.55</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.387</td>\n",
       "      <td>629</td>\n",
       "      <td>607</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.6</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.385</td>\n",
       "      <td>660</td>\n",
       "      <td>603</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.65</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.394</td>\n",
       "      <td>659</td>\n",
       "      <td>618</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.7</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.401</td>\n",
       "      <td>633</td>\n",
       "      <td>629</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.75</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.409</td>\n",
       "      <td>623</td>\n",
       "      <td>641</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.8</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.397</td>\n",
       "      <td>610</td>\n",
       "      <td>623</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.85</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.413</td>\n",
       "      <td>567</td>\n",
       "      <td>648</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.9</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.408</td>\n",
       "      <td>581</td>\n",
       "      <td>639</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.95</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.425</td>\n",
       "      <td>580</td>\n",
       "      <td>667</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 1.0</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.427</td>\n",
       "      <td>554</td>\n",
       "      <td>669</td>\n",
       "      <td>14014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 1000          0.806     0.603   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5      0.809     0.609   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55     0.810     0.609   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6      0.806     0.604   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65     0.804     0.598   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7      0.806     0.598   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75     0.806     0.595   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8      0.811     0.605   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85     0.813     0.602   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9      0.813     0.604   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95     0.808     0.591   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0      0.812     0.595   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 1000                     0.132   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5                 0.129   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55                0.127   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6                 0.134   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65                0.133   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7                 0.128   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75                0.126   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8                 0.123   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85                0.115   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9                 0.118   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95                0.117   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0                 0.112   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 1000                     0.389              652   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5                 0.385              638   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55                0.387              629   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6                 0.385              660   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65                0.394              659   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7                 0.401              633   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75                0.409              623   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8                 0.397              610   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85                0.413              567   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9                 0.408              581   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95                0.425              580   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0                 0.427              554   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 1000                   610       14014       6508  \n",
       "After SMOTE N = 1000 p_class 0 = 0.5               603       14014       6508  \n",
       "After SMOTE N = 1000 p_class 0 = 0.55              607       14014       6508  \n",
       "After SMOTE N = 1000 p_class 0 = 0.6               603       14014       6508  \n",
       "After SMOTE N = 1000 p_class 0 = 0.65              618       14014       6508  \n",
       "After SMOTE N = 1000 p_class 0 = 0.7               629       14014       6508  \n",
       "After SMOTE N = 1000 p_class 0 = 0.75              641       14014       6508  \n",
       "After SMOTE N = 1000 p_class 0 = 0.8               623       14014       6508  \n",
       "After SMOTE N = 1000 p_class 0 = 0.85              648       14014       6508  \n",
       "After SMOTE N = 1000 p_class 0 = 0.9               639       14014       6508  \n",
       "After SMOTE N = 1000 p_class 0 = 0.95              667       14014       6508  \n",
       "After SMOTE N = 1000 p_class 0 = 1.0               669       14014       6508  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionari per salvare i risultati\n",
    "N = 1000\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.603</td>\n",
       "      <td>652</td>\n",
       "      <td>610</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.5</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.609</td>\n",
       "      <td>638</td>\n",
       "      <td>603</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.55</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.609</td>\n",
       "      <td>629</td>\n",
       "      <td>607</td>\n",
       "      <td>1236</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.6</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.604</td>\n",
       "      <td>660</td>\n",
       "      <td>603</td>\n",
       "      <td>1263</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.65</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.598</td>\n",
       "      <td>659</td>\n",
       "      <td>618</td>\n",
       "      <td>1277</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.7</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.598</td>\n",
       "      <td>633</td>\n",
       "      <td>629</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.75</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.595</td>\n",
       "      <td>623</td>\n",
       "      <td>641</td>\n",
       "      <td>1264</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.8</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.605</td>\n",
       "      <td>610</td>\n",
       "      <td>623</td>\n",
       "      <td>1233</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.85</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.602</td>\n",
       "      <td>567</td>\n",
       "      <td>648</td>\n",
       "      <td>1215</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.9</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.604</td>\n",
       "      <td>581</td>\n",
       "      <td>639</td>\n",
       "      <td>1220</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.95</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.591</td>\n",
       "      <td>580</td>\n",
       "      <td>667</td>\n",
       "      <td>1247</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 1.0</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.595</td>\n",
       "      <td>554</td>\n",
       "      <td>669</td>\n",
       "      <td>1223</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 1000          0.806     0.603              652   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5      0.809     0.609              638   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55     0.810     0.609              629   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6      0.806     0.604              660   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65     0.804     0.598              659   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7      0.806     0.598              633   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75     0.806     0.595              623   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8      0.811     0.605              610   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85     0.813     0.602              567   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9      0.813     0.604              581   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95     0.808     0.591              580   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0      0.812     0.595              554   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 1000                   610          1262   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5               603          1241   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55              607          1236   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6               603          1263   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65              618          1277   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7               629          1262   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75              641          1264   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8               623          1233   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85              648          1215   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9               639          1220   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95              667          1247   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0               669          1223   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.054           0.190   \n",
       "After RANDOM mitigation N = 1000                 0.038           0.177   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5             0.048           0.191   \n",
       "After SMOTE N = 1000 p_class 0 = 0.55            0.033           0.179   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6             0.048           0.195   \n",
       "After SMOTE N = 1000 p_class 0 = 0.65            0.037           0.184   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7             0.030           0.179   \n",
       "After SMOTE N = 1000 p_class 0 = 0.75            0.029           0.173   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8             0.018           0.145   \n",
       "After SMOTE N = 1000 p_class 0 = 0.85            0.021           0.154   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9             0.015           0.147   \n",
       "After SMOTE N = 1000 p_class 0 = 0.95            0.010           0.142   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0             0.023           0.145   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.172       0.153       0.097  \n",
       "After RANDOM mitigation N = 1000            0.154       0.129       0.072  \n",
       "After SMOTE N = 1000 p_class 0 = 0.5        0.171       0.142       0.081  \n",
       "After SMOTE N = 1000 p_class 0 = 0.55       0.150       0.111       0.054  \n",
       "After SMOTE N = 1000 p_class 0 = 0.6        0.173       0.141       0.082  \n",
       "After SMOTE N = 1000 p_class 0 = 0.65       0.160       0.123       0.061  \n",
       "After SMOTE N = 1000 p_class 0 = 0.7        0.149       0.106       0.051  \n",
       "After SMOTE N = 1000 p_class 0 = 0.75       0.146       0.105       0.049  \n",
       "After SMOTE N = 1000 p_class 0 = 0.8        0.112       0.070       0.018  \n",
       "After SMOTE N = 1000 p_class 0 = 0.85       0.120       0.081       0.034  \n",
       "After SMOTE N = 1000 p_class 0 = 0.9        0.109       0.069       0.018  \n",
       "After SMOTE N = 1000 p_class 0 = 0.95       0.094       0.057       0.010  \n",
       "After SMOTE N = 1000 p_class 0 = 1.0        0.117       0.086       0.040  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_1K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.390</td>\n",
       "      <td>664</td>\n",
       "      <td>611</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.5</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.395</td>\n",
       "      <td>629</td>\n",
       "      <td>619</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.55</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.385</td>\n",
       "      <td>649</td>\n",
       "      <td>603</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.6</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.414</td>\n",
       "      <td>630</td>\n",
       "      <td>649</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.65</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.409</td>\n",
       "      <td>645</td>\n",
       "      <td>642</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.7</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.399</td>\n",
       "      <td>641</td>\n",
       "      <td>625</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.75</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.406</td>\n",
       "      <td>602</td>\n",
       "      <td>637</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.8</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.410</td>\n",
       "      <td>580</td>\n",
       "      <td>643</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.85</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.424</td>\n",
       "      <td>592</td>\n",
       "      <td>665</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.9</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.427</td>\n",
       "      <td>584</td>\n",
       "      <td>670</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.95</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.442</td>\n",
       "      <td>562</td>\n",
       "      <td>693</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 1.0</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.448</td>\n",
       "      <td>545</td>\n",
       "      <td>702</td>\n",
       "      <td>15014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 2000          0.804     0.600   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5      0.808     0.603   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55     0.808     0.607   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6      0.803     0.590   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65     0.802     0.590   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7      0.805     0.598   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75     0.810     0.600   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8      0.812     0.602   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85     0.807     0.590   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9      0.807     0.589   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95     0.807     0.582   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0      0.808     0.581   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 2000                     0.134   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5                 0.127   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55                0.131   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6                 0.128   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65                0.131   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7                 0.130   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75                0.122   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8                 0.117   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85                0.120   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9                 0.118   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95                0.114   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0                 0.110   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 2000                     0.390              664   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5                 0.395              629   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55                0.385              649   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6                 0.414              630   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65                0.409              645   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7                 0.399              641   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75                0.406              602   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8                 0.410              580   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85                0.424              592   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9                 0.427              584   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95                0.442              562   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0                 0.448              545   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 2000                   611       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.5               619       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.55              603       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.6               649       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.65              642       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.7               625       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.75              637       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.8               643       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.85              665       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.9               670       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 0.95              693       15014       6508  \n",
       "After SMOTE N = 2000 p_class 0 = 1.0               702       15014       6508  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.600</td>\n",
       "      <td>664</td>\n",
       "      <td>611</td>\n",
       "      <td>1275</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.5</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.603</td>\n",
       "      <td>629</td>\n",
       "      <td>619</td>\n",
       "      <td>1248</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.55</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.607</td>\n",
       "      <td>649</td>\n",
       "      <td>603</td>\n",
       "      <td>1252</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.6</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.590</td>\n",
       "      <td>630</td>\n",
       "      <td>649</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.65</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.590</td>\n",
       "      <td>645</td>\n",
       "      <td>642</td>\n",
       "      <td>1287</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.7</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.598</td>\n",
       "      <td>641</td>\n",
       "      <td>625</td>\n",
       "      <td>1266</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.75</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.600</td>\n",
       "      <td>602</td>\n",
       "      <td>637</td>\n",
       "      <td>1239</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.8</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.602</td>\n",
       "      <td>580</td>\n",
       "      <td>643</td>\n",
       "      <td>1223</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.85</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.590</td>\n",
       "      <td>592</td>\n",
       "      <td>665</td>\n",
       "      <td>1257</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.9</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.589</td>\n",
       "      <td>584</td>\n",
       "      <td>670</td>\n",
       "      <td>1254</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.95</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.582</td>\n",
       "      <td>562</td>\n",
       "      <td>693</td>\n",
       "      <td>1255</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 1.0</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.581</td>\n",
       "      <td>545</td>\n",
       "      <td>702</td>\n",
       "      <td>1247</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 2000          0.804     0.600              664   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5      0.808     0.603              629   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55     0.808     0.607              649   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6      0.803     0.590              630   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65     0.802     0.590              645   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7      0.805     0.598              641   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75     0.810     0.600              602   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8      0.812     0.602              580   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85     0.807     0.590              592   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9      0.807     0.589              584   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95     0.807     0.582              562   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0      0.808     0.581              545   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 2000                   611          1275   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5               619          1248   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55              603          1252   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6               649          1279   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65              642          1287   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7               625          1266   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75              637          1239   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8               643          1223   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85              665          1257   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9               670          1254   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95              693          1255   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0               702          1247   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.054           0.190   \n",
       "After RANDOM mitigation N = 2000                 0.038           0.177   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5             0.045           0.182   \n",
       "After SMOTE N = 2000 p_class 0 = 0.55            0.051           0.193   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6             0.033           0.165   \n",
       "After SMOTE N = 2000 p_class 0 = 0.65            0.035           0.178   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7             0.032           0.178   \n",
       "After SMOTE N = 2000 p_class 0 = 0.75            0.020           0.169   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8             0.014           0.149   \n",
       "After SMOTE N = 2000 p_class 0 = 0.85            0.014           0.149   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9             0.019           0.147   \n",
       "After SMOTE N = 2000 p_class 0 = 0.95            0.010           0.135   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0             0.015           0.133   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.172       0.153       0.097  \n",
       "After RANDOM mitigation N = 2000            0.154       0.129       0.072  \n",
       "After SMOTE N = 2000 p_class 0 = 0.5        0.164       0.133       0.075  \n",
       "After SMOTE N = 2000 p_class 0 = 0.55       0.175       0.154       0.091  \n",
       "After SMOTE N = 2000 p_class 0 = 0.6        0.142       0.101       0.043  \n",
       "After SMOTE N = 2000 p_class 0 = 0.65       0.145       0.100       0.035  \n",
       "After SMOTE N = 2000 p_class 0 = 0.7        0.147       0.110       0.055  \n",
       "After SMOTE N = 2000 p_class 0 = 0.75       0.120       0.080       0.026  \n",
       "After SMOTE N = 2000 p_class 0 = 0.8        0.099       0.060       0.014  \n",
       "After SMOTE N = 2000 p_class 0 = 0.85       0.100       0.062       0.014  \n",
       "After SMOTE N = 2000 p_class 0 = 0.9        0.110       0.072       0.019  \n",
       "After SMOTE N = 2000 p_class 0 = 0.95       0.092       0.054       0.010  \n",
       "After SMOTE N = 2000 p_class 0 = 1.0        0.094       0.060       0.015  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_2K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.395</td>\n",
       "      <td>622</td>\n",
       "      <td>620</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.5</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.379</td>\n",
       "      <td>668</td>\n",
       "      <td>595</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.55</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.384</td>\n",
       "      <td>656</td>\n",
       "      <td>602</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.6</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.397</td>\n",
       "      <td>682</td>\n",
       "      <td>622</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.65</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.416</td>\n",
       "      <td>642</td>\n",
       "      <td>652</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.7</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.417</td>\n",
       "      <td>624</td>\n",
       "      <td>654</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.75</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.413</td>\n",
       "      <td>584</td>\n",
       "      <td>647</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.8</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.413</td>\n",
       "      <td>606</td>\n",
       "      <td>647</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.85</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.434</td>\n",
       "      <td>577</td>\n",
       "      <td>681</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.9</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.434</td>\n",
       "      <td>557</td>\n",
       "      <td>681</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.95</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.451</td>\n",
       "      <td>535</td>\n",
       "      <td>707</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 1.0</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.438</td>\n",
       "      <td>530</td>\n",
       "      <td>687</td>\n",
       "      <td>16014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 3000          0.809     0.604   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5      0.806     0.606   \n",
       "After SMOTE N = 3000 p_class 0 = 0.55     0.807     0.606   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6      0.800     0.592   \n",
       "After SMOTE N = 3000 p_class 0 = 0.65     0.801     0.586   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7      0.804     0.589   \n",
       "After SMOTE N = 3000 p_class 0 = 0.75     0.811     0.599   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8      0.807     0.595   \n",
       "After SMOTE N = 3000 p_class 0 = 0.85     0.807     0.585   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9      0.810     0.589   \n",
       "After SMOTE N = 3000 p_class 0 = 0.95     0.809     0.581   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0      0.813     0.591   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 3000                     0.126   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5                 0.135   \n",
       "After SMOTE N = 3000 p_class 0 = 0.55                0.133   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6                 0.138   \n",
       "After SMOTE N = 3000 p_class 0 = 0.65                0.130   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7                 0.126   \n",
       "After SMOTE N = 3000 p_class 0 = 0.75                0.118   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8                 0.123   \n",
       "After SMOTE N = 3000 p_class 0 = 0.85                0.117   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9                 0.113   \n",
       "After SMOTE N = 3000 p_class 0 = 0.95                0.108   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0                 0.107   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 3000                     0.395              622   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5                 0.379              668   \n",
       "After SMOTE N = 3000 p_class 0 = 0.55                0.384              656   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6                 0.397              682   \n",
       "After SMOTE N = 3000 p_class 0 = 0.65                0.416              642   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7                 0.417              624   \n",
       "After SMOTE N = 3000 p_class 0 = 0.75                0.413              584   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8                 0.413              606   \n",
       "After SMOTE N = 3000 p_class 0 = 0.85                0.434              577   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9                 0.434              557   \n",
       "After SMOTE N = 3000 p_class 0 = 0.95                0.451              535   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0                 0.438              530   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 3000                   620       16014       6508  \n",
       "After SMOTE N = 3000 p_class 0 = 0.5               595       16014       6508  \n",
       "After SMOTE N = 3000 p_class 0 = 0.55              602       16014       6508  \n",
       "After SMOTE N = 3000 p_class 0 = 0.6               622       16014       6508  \n",
       "After SMOTE N = 3000 p_class 0 = 0.65              652       16014       6508  \n",
       "After SMOTE N = 3000 p_class 0 = 0.7               654       16014       6508  \n",
       "After SMOTE N = 3000 p_class 0 = 0.75              647       16014       6508  \n",
       "After SMOTE N = 3000 p_class 0 = 0.8               647       16014       6508  \n",
       "After SMOTE N = 3000 p_class 0 = 0.85              681       16014       6508  \n",
       "After SMOTE N = 3000 p_class 0 = 0.9               681       16014       6508  \n",
       "After SMOTE N = 3000 p_class 0 = 0.95              707       16014       6508  \n",
       "After SMOTE N = 3000 p_class 0 = 1.0               687       16014       6508  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 3000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.604</td>\n",
       "      <td>622</td>\n",
       "      <td>620</td>\n",
       "      <td>1242</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.5</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.606</td>\n",
       "      <td>668</td>\n",
       "      <td>595</td>\n",
       "      <td>1263</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.55</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.606</td>\n",
       "      <td>656</td>\n",
       "      <td>602</td>\n",
       "      <td>1258</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.6</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.592</td>\n",
       "      <td>682</td>\n",
       "      <td>622</td>\n",
       "      <td>1304</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.65</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.586</td>\n",
       "      <td>642</td>\n",
       "      <td>652</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.7</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.589</td>\n",
       "      <td>624</td>\n",
       "      <td>654</td>\n",
       "      <td>1278</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.75</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.599</td>\n",
       "      <td>584</td>\n",
       "      <td>647</td>\n",
       "      <td>1231</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.8</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.595</td>\n",
       "      <td>606</td>\n",
       "      <td>647</td>\n",
       "      <td>1253</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.85</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.585</td>\n",
       "      <td>577</td>\n",
       "      <td>681</td>\n",
       "      <td>1258</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.9</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.589</td>\n",
       "      <td>557</td>\n",
       "      <td>681</td>\n",
       "      <td>1238</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 0.95</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.581</td>\n",
       "      <td>535</td>\n",
       "      <td>707</td>\n",
       "      <td>1242</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 3000 p_class 0 = 1.0</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.591</td>\n",
       "      <td>530</td>\n",
       "      <td>687</td>\n",
       "      <td>1217</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 3000          0.809     0.604              622   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5      0.806     0.606              668   \n",
       "After SMOTE N = 3000 p_class 0 = 0.55     0.807     0.606              656   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6      0.800     0.592              682   \n",
       "After SMOTE N = 3000 p_class 0 = 0.65     0.801     0.586              642   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7      0.804     0.589              624   \n",
       "After SMOTE N = 3000 p_class 0 = 0.75     0.811     0.599              584   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8      0.807     0.595              606   \n",
       "After SMOTE N = 3000 p_class 0 = 0.85     0.807     0.585              577   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9      0.810     0.589              557   \n",
       "After SMOTE N = 3000 p_class 0 = 0.95     0.809     0.581              535   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0      0.813     0.591              530   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 3000                   620          1242   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5               595          1263   \n",
       "After SMOTE N = 3000 p_class 0 = 0.55              602          1258   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6               622          1304   \n",
       "After SMOTE N = 3000 p_class 0 = 0.65              652          1294   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7               654          1278   \n",
       "After SMOTE N = 3000 p_class 0 = 0.75              647          1231   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8               647          1253   \n",
       "After SMOTE N = 3000 p_class 0 = 0.85              681          1258   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9               681          1238   \n",
       "After SMOTE N = 3000 p_class 0 = 0.95              707          1242   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0               687          1217   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.054           0.190   \n",
       "After RANDOM mitigation N = 3000                 0.038           0.177   \n",
       "After SMOTE N = 3000 p_class 0 = 0.5             0.043           0.191   \n",
       "After SMOTE N = 3000 p_class 0 = 0.55            0.037           0.184   \n",
       "After SMOTE N = 3000 p_class 0 = 0.6             0.019           0.174   \n",
       "After SMOTE N = 3000 p_class 0 = 0.65            0.018           0.163   \n",
       "After SMOTE N = 3000 p_class 0 = 0.7             0.041           0.168   \n",
       "After SMOTE N = 3000 p_class 0 = 0.75            0.012           0.145   \n",
       "After SMOTE N = 3000 p_class 0 = 0.8             0.020           0.152   \n",
       "After SMOTE N = 3000 p_class 0 = 0.85            0.008           0.140   \n",
       "After SMOTE N = 3000 p_class 0 = 0.9             0.010           0.134   \n",
       "After SMOTE N = 3000 p_class 0 = 0.95            0.006           0.125   \n",
       "After SMOTE N = 3000 p_class 0 = 1.0             0.015           0.127   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.172       0.153       0.097  \n",
       "After RANDOM mitigation N = 3000            0.154       0.129       0.072  \n",
       "After SMOTE N = 3000 p_class 0 = 0.5        0.169       0.139       0.077  \n",
       "After SMOTE N = 3000 p_class 0 = 0.55       0.158       0.124       0.065  \n",
       "After SMOTE N = 3000 p_class 0 = 0.6        0.127       0.082       0.028  \n",
       "After SMOTE N = 3000 p_class 0 = 0.65       0.104       0.068       0.018  \n",
       "After SMOTE N = 3000 p_class 0 = 0.7        0.152       0.117       0.057  \n",
       "After SMOTE N = 3000 p_class 0 = 0.75       0.087       0.052       0.012  \n",
       "After SMOTE N = 3000 p_class 0 = 0.8        0.114       0.073       0.020  \n",
       "After SMOTE N = 3000 p_class 0 = 0.85       0.092       0.059       0.011  \n",
       "After SMOTE N = 3000 p_class 0 = 0.9        0.087       0.053       0.010  \n",
       "After SMOTE N = 3000 p_class 0 = 0.95       0.077       0.042       0.006  \n",
       "After SMOTE N = 3000 p_class 0 = 1.0        0.088       0.055       0.015  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_3K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_3K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 4000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.388</td>\n",
       "      <td>634</td>\n",
       "      <td>609</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.5</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.378</td>\n",
       "      <td>684</td>\n",
       "      <td>593</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.55</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.392</td>\n",
       "      <td>656</td>\n",
       "      <td>614</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.6</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.391</td>\n",
       "      <td>647</td>\n",
       "      <td>613</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.65</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.410</td>\n",
       "      <td>604</td>\n",
       "      <td>643</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.7</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.417</td>\n",
       "      <td>649</td>\n",
       "      <td>654</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.75</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.418</td>\n",
       "      <td>596</td>\n",
       "      <td>655</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.8</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.438</td>\n",
       "      <td>580</td>\n",
       "      <td>687</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.85</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.424</td>\n",
       "      <td>583</td>\n",
       "      <td>665</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.9</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.452</td>\n",
       "      <td>557</td>\n",
       "      <td>708</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.95</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.465</td>\n",
       "      <td>562</td>\n",
       "      <td>729</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1.0</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.448</td>\n",
       "      <td>505</td>\n",
       "      <td>703</td>\n",
       "      <td>17014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 4000          0.809     0.607   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5      0.804     0.604   \n",
       "After SMOTE N = 4000 p_class 0 = 0.55     0.805     0.600   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6      0.806     0.603   \n",
       "After SMOTE N = 4000 p_class 0 = 0.65     0.808     0.597   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7      0.800     0.584   \n",
       "After SMOTE N = 4000 p_class 0 = 0.75     0.808     0.593   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8      0.805     0.582   \n",
       "After SMOTE N = 4000 p_class 0 = 0.85     0.808     0.591   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9      0.806     0.576   \n",
       "After SMOTE N = 4000 p_class 0 = 0.95     0.802     0.565   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0      0.814     0.589   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 4000                     0.128   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5                 0.138   \n",
       "After SMOTE N = 4000 p_class 0 = 0.55                0.133   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6                 0.131   \n",
       "After SMOTE N = 4000 p_class 0 = 0.65                0.122   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7                 0.131   \n",
       "After SMOTE N = 4000 p_class 0 = 0.75                0.121   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8                 0.117   \n",
       "After SMOTE N = 4000 p_class 0 = 0.85                0.118   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9                 0.113   \n",
       "After SMOTE N = 4000 p_class 0 = 0.95                0.114   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0                 0.102   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 4000                     0.388              634   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5                 0.378              684   \n",
       "After SMOTE N = 4000 p_class 0 = 0.55                0.392              656   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6                 0.391              647   \n",
       "After SMOTE N = 4000 p_class 0 = 0.65                0.410              604   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7                 0.417              649   \n",
       "After SMOTE N = 4000 p_class 0 = 0.75                0.418              596   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8                 0.438              580   \n",
       "After SMOTE N = 4000 p_class 0 = 0.85                0.424              583   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9                 0.452              557   \n",
       "After SMOTE N = 4000 p_class 0 = 0.95                0.465              562   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0                 0.448              505   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 4000                   609       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.5               593       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.55              614       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.6               613       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.65              643       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.7               654       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.75              655       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.8               687       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.85              665       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.9               708       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 0.95              729       17014       6508  \n",
       "After SMOTE N = 4000 p_class 0 = 1.0               703       17014       6508  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 4000</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.607</td>\n",
       "      <td>634</td>\n",
       "      <td>609</td>\n",
       "      <td>1243</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.5</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.604</td>\n",
       "      <td>684</td>\n",
       "      <td>593</td>\n",
       "      <td>1277</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.55</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.600</td>\n",
       "      <td>656</td>\n",
       "      <td>614</td>\n",
       "      <td>1270</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.6</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.603</td>\n",
       "      <td>647</td>\n",
       "      <td>613</td>\n",
       "      <td>1260</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.65</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.597</td>\n",
       "      <td>604</td>\n",
       "      <td>643</td>\n",
       "      <td>1247</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.7</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.584</td>\n",
       "      <td>649</td>\n",
       "      <td>654</td>\n",
       "      <td>1303</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.75</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.593</td>\n",
       "      <td>596</td>\n",
       "      <td>655</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.8</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.582</td>\n",
       "      <td>580</td>\n",
       "      <td>687</td>\n",
       "      <td>1267</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.85</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.591</td>\n",
       "      <td>583</td>\n",
       "      <td>665</td>\n",
       "      <td>1248</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.9</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.576</td>\n",
       "      <td>557</td>\n",
       "      <td>708</td>\n",
       "      <td>1265</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 0.95</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.565</td>\n",
       "      <td>562</td>\n",
       "      <td>729</td>\n",
       "      <td>1291</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 4000 p_class 0 = 1.0</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.589</td>\n",
       "      <td>505</td>\n",
       "      <td>703</td>\n",
       "      <td>1208</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 4000          0.809     0.607              634   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5      0.804     0.604              684   \n",
       "After SMOTE N = 4000 p_class 0 = 0.55     0.805     0.600              656   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6      0.806     0.603              647   \n",
       "After SMOTE N = 4000 p_class 0 = 0.65     0.808     0.597              604   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7      0.800     0.584              649   \n",
       "After SMOTE N = 4000 p_class 0 = 0.75     0.808     0.593              596   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8      0.805     0.582              580   \n",
       "After SMOTE N = 4000 p_class 0 = 0.85     0.808     0.591              583   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9      0.806     0.576              557   \n",
       "After SMOTE N = 4000 p_class 0 = 0.95     0.802     0.565              562   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0      0.814     0.589              505   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 4000                   609          1243   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5               593          1277   \n",
       "After SMOTE N = 4000 p_class 0 = 0.55              614          1270   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6               613          1260   \n",
       "After SMOTE N = 4000 p_class 0 = 0.65              643          1247   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7               654          1303   \n",
       "After SMOTE N = 4000 p_class 0 = 0.75              655          1251   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8               687          1267   \n",
       "After SMOTE N = 4000 p_class 0 = 0.85              665          1248   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9               708          1265   \n",
       "After SMOTE N = 4000 p_class 0 = 0.95              729          1291   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0               703          1208   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.054           0.190   \n",
       "After RANDOM mitigation N = 4000                 0.038           0.177   \n",
       "After SMOTE N = 4000 p_class 0 = 0.5             0.055           0.200   \n",
       "After SMOTE N = 4000 p_class 0 = 0.55            0.032           0.185   \n",
       "After SMOTE N = 4000 p_class 0 = 0.6             0.029           0.181   \n",
       "After SMOTE N = 4000 p_class 0 = 0.65            0.045           0.178   \n",
       "After SMOTE N = 4000 p_class 0 = 0.7             0.029           0.174   \n",
       "After SMOTE N = 4000 p_class 0 = 0.75            0.012           0.152   \n",
       "After SMOTE N = 4000 p_class 0 = 0.8             0.011           0.139   \n",
       "After SMOTE N = 4000 p_class 0 = 0.85            0.007           0.143   \n",
       "After SMOTE N = 4000 p_class 0 = 0.9             0.013           0.132   \n",
       "After SMOTE N = 4000 p_class 0 = 0.95            0.023           0.133   \n",
       "After SMOTE N = 4000 p_class 0 = 1.0             0.016           0.112   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.172       0.153       0.097  \n",
       "After RANDOM mitigation N = 4000            0.154       0.129       0.072  \n",
       "After SMOTE N = 4000 p_class 0 = 0.5        0.182       0.154       0.085  \n",
       "After SMOTE N = 4000 p_class 0 = 0.55       0.150       0.109       0.050  \n",
       "After SMOTE N = 4000 p_class 0 = 0.6        0.138       0.092       0.029  \n",
       "After SMOTE N = 4000 p_class 0 = 0.65       0.158       0.137       0.081  \n",
       "After SMOTE N = 4000 p_class 0 = 0.7        0.138       0.092       0.029  \n",
       "After SMOTE N = 4000 p_class 0 = 0.75       0.103       0.066       0.017  \n",
       "After SMOTE N = 4000 p_class 0 = 0.8        0.085       0.052       0.011  \n",
       "After SMOTE N = 4000 p_class 0 = 0.85       0.090       0.054       0.007  \n",
       "After SMOTE N = 4000 p_class 0 = 0.9        0.090       0.049       0.013  \n",
       "After SMOTE N = 4000 p_class 0 = 0.95       0.109       0.072       0.023  \n",
       "After SMOTE N = 4000 p_class 0 = 1.0        0.093       0.062       0.016  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_4K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_4K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.402</td>\n",
       "      <td>654</td>\n",
       "      <td>631</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.378</td>\n",
       "      <td>669</td>\n",
       "      <td>593</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.55</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.388</td>\n",
       "      <td>642</td>\n",
       "      <td>609</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.399</td>\n",
       "      <td>644</td>\n",
       "      <td>626</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.65</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.419</td>\n",
       "      <td>625</td>\n",
       "      <td>657</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.411</td>\n",
       "      <td>608</td>\n",
       "      <td>644</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.75</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.434</td>\n",
       "      <td>600</td>\n",
       "      <td>681</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.432</td>\n",
       "      <td>590</td>\n",
       "      <td>677</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.85</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.442</td>\n",
       "      <td>553</td>\n",
       "      <td>693</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.453</td>\n",
       "      <td>519</td>\n",
       "      <td>710</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.95</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.454</td>\n",
       "      <td>532</td>\n",
       "      <td>712</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 1.0</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.461</td>\n",
       "      <td>503</td>\n",
       "      <td>723</td>\n",
       "      <td>18014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 5000          0.803     0.593   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5      0.806     0.607   \n",
       "After SMOTE N = 5000 p_class 0 = 0.55     0.808     0.605   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6      0.805     0.597   \n",
       "After SMOTE N = 5000 p_class 0 = 0.65     0.803     0.587   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7      0.808     0.596   \n",
       "After SMOTE N = 5000 p_class 0 = 0.75     0.803     0.581   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8      0.805     0.584   \n",
       "After SMOTE N = 5000 p_class 0 = 0.85     0.809     0.584   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9      0.811     0.583   \n",
       "After SMOTE N = 5000 p_class 0 = 0.95     0.809     0.579   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0      0.812     0.580   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 5000                     0.132   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                 0.135   \n",
       "After SMOTE N = 5000 p_class 0 = 0.55                0.130   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                 0.130   \n",
       "After SMOTE N = 5000 p_class 0 = 0.65                0.127   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                 0.123   \n",
       "After SMOTE N = 5000 p_class 0 = 0.75                0.121   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                 0.119   \n",
       "After SMOTE N = 5000 p_class 0 = 0.85                0.112   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                 0.105   \n",
       "After SMOTE N = 5000 p_class 0 = 0.95                0.108   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0                 0.102   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 5000                     0.402              654   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5                 0.378              669   \n",
       "After SMOTE N = 5000 p_class 0 = 0.55                0.388              642   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6                 0.399              644   \n",
       "After SMOTE N = 5000 p_class 0 = 0.65                0.419              625   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7                 0.411              608   \n",
       "After SMOTE N = 5000 p_class 0 = 0.75                0.434              600   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8                 0.432              590   \n",
       "After SMOTE N = 5000 p_class 0 = 0.85                0.442              553   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9                 0.453              519   \n",
       "After SMOTE N = 5000 p_class 0 = 0.95                0.454              532   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0                 0.461              503   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 5000                   631       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5               593       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.55              609       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6               626       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.65              657       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7               644       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.75              681       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8               677       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.85              693       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9               710       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 0.95              712       18014       6508  \n",
       "After SMOTE N = 5000 p_class 0 = 1.0               723       18014       6508  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 5000</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>654</td>\n",
       "      <td>631</td>\n",
       "      <td>1285</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.5</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.607</td>\n",
       "      <td>669</td>\n",
       "      <td>593</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.55</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.605</td>\n",
       "      <td>642</td>\n",
       "      <td>609</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.6</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.597</td>\n",
       "      <td>644</td>\n",
       "      <td>626</td>\n",
       "      <td>1270</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.65</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.587</td>\n",
       "      <td>625</td>\n",
       "      <td>657</td>\n",
       "      <td>1282</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.7</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.596</td>\n",
       "      <td>608</td>\n",
       "      <td>644</td>\n",
       "      <td>1252</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.75</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.581</td>\n",
       "      <td>600</td>\n",
       "      <td>681</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.8</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.584</td>\n",
       "      <td>590</td>\n",
       "      <td>677</td>\n",
       "      <td>1267</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.85</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.584</td>\n",
       "      <td>553</td>\n",
       "      <td>693</td>\n",
       "      <td>1246</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.9</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.583</td>\n",
       "      <td>519</td>\n",
       "      <td>710</td>\n",
       "      <td>1229</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 0.95</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.579</td>\n",
       "      <td>532</td>\n",
       "      <td>712</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 5000 p_class 0 = 1.0</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.580</td>\n",
       "      <td>503</td>\n",
       "      <td>723</td>\n",
       "      <td>1226</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 5000          0.803     0.593              654   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5      0.806     0.607              669   \n",
       "After SMOTE N = 5000 p_class 0 = 0.55     0.808     0.605              642   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6      0.805     0.597              644   \n",
       "After SMOTE N = 5000 p_class 0 = 0.65     0.803     0.587              625   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7      0.808     0.596              608   \n",
       "After SMOTE N = 5000 p_class 0 = 0.75     0.803     0.581              600   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8      0.805     0.584              590   \n",
       "After SMOTE N = 5000 p_class 0 = 0.85     0.809     0.584              553   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9      0.811     0.583              519   \n",
       "After SMOTE N = 5000 p_class 0 = 0.95     0.809     0.579              532   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0      0.812     0.580              503   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 5000                   631          1285   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5               593          1262   \n",
       "After SMOTE N = 5000 p_class 0 = 0.55              609          1251   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6               626          1270   \n",
       "After SMOTE N = 5000 p_class 0 = 0.65              657          1282   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7               644          1252   \n",
       "After SMOTE N = 5000 p_class 0 = 0.75              681          1281   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8               677          1267   \n",
       "After SMOTE N = 5000 p_class 0 = 0.85              693          1246   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9               710          1229   \n",
       "After SMOTE N = 5000 p_class 0 = 0.95              712          1244   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0               723          1226   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.054           0.190   \n",
       "After RANDOM mitigation N = 5000                 0.038           0.177   \n",
       "After SMOTE N = 5000 p_class 0 = 0.5             0.050           0.198   \n",
       "After SMOTE N = 5000 p_class 0 = 0.55            0.043           0.180   \n",
       "After SMOTE N = 5000 p_class 0 = 0.6             0.022           0.169   \n",
       "After SMOTE N = 5000 p_class 0 = 0.65            0.037           0.177   \n",
       "After SMOTE N = 5000 p_class 0 = 0.7             0.012           0.159   \n",
       "After SMOTE N = 5000 p_class 0 = 0.75            0.022           0.157   \n",
       "After SMOTE N = 5000 p_class 0 = 0.8             0.009           0.141   \n",
       "After SMOTE N = 5000 p_class 0 = 0.85            0.013           0.133   \n",
       "After SMOTE N = 5000 p_class 0 = 0.9             0.015           0.123   \n",
       "After SMOTE N = 5000 p_class 0 = 0.95            0.010           0.133   \n",
       "After SMOTE N = 5000 p_class 0 = 1.0             0.011           0.112   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.172       0.153       0.097  \n",
       "After RANDOM mitigation N = 5000            0.154       0.129       0.072  \n",
       "After SMOTE N = 5000 p_class 0 = 0.5        0.183       0.147       0.081  \n",
       "After SMOTE N = 5000 p_class 0 = 0.55       0.161       0.130       0.072  \n",
       "After SMOTE N = 5000 p_class 0 = 0.6        0.132       0.085       0.031  \n",
       "After SMOTE N = 5000 p_class 0 = 0.65       0.148       0.109       0.047  \n",
       "After SMOTE N = 5000 p_class 0 = 0.7        0.102       0.063       0.012  \n",
       "After SMOTE N = 5000 p_class 0 = 0.75       0.118       0.075       0.022  \n",
       "After SMOTE N = 5000 p_class 0 = 0.8        0.089       0.050       0.009  \n",
       "After SMOTE N = 5000 p_class 0 = 0.85       0.084       0.047       0.013  \n",
       "After SMOTE N = 5000 p_class 0 = 0.9        0.090       0.060       0.015  \n",
       "After SMOTE N = 5000 p_class 0 = 0.95       0.079       0.043       0.010  \n",
       "After SMOTE N = 5000 p_class 0 = 1.0        0.082       0.053       0.011  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_5K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_5K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.407</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>13014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.386</td>\n",
       "      <td>651</td>\n",
       "      <td>606</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.5</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.394</td>\n",
       "      <td>693</td>\n",
       "      <td>618</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.55</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.397</td>\n",
       "      <td>680</td>\n",
       "      <td>623</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.6</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.385</td>\n",
       "      <td>642</td>\n",
       "      <td>603</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.65</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.404</td>\n",
       "      <td>617</td>\n",
       "      <td>633</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.7</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.420</td>\n",
       "      <td>599</td>\n",
       "      <td>659</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.75</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.432</td>\n",
       "      <td>581</td>\n",
       "      <td>678</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.8</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.427</td>\n",
       "      <td>573</td>\n",
       "      <td>670</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.85</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.448</td>\n",
       "      <td>571</td>\n",
       "      <td>703</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.9</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.455</td>\n",
       "      <td>528</td>\n",
       "      <td>714</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.95</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.457</td>\n",
       "      <td>548</td>\n",
       "      <td>716</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 1.0</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.475</td>\n",
       "      <td>520</td>\n",
       "      <td>745</td>\n",
       "      <td>19014</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  \\\n",
       "Before Mitigation                         0.803     0.593   \n",
       "After RANDOM mitigation N = 6000          0.807     0.605   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5      0.799     0.592   \n",
       "After SMOTE N = 6000 p_class 0 = 0.55     0.800     0.592   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6      0.809     0.608   \n",
       "After SMOTE N = 6000 p_class 0 = 0.65     0.808     0.599   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7      0.807     0.591   \n",
       "After SMOTE N = 6000 p_class 0 = 0.75     0.807     0.586   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8      0.809     0.591   \n",
       "After SMOTE N = 6000 p_class 0 = 0.85     0.804     0.576   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9      0.809     0.579   \n",
       "After SMOTE N = 6000 p_class 0 = 0.95     0.806     0.574   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0      0.806     0.565   \n",
       "\n",
       "Metrics                                False Positive Rate  \\\n",
       "Before Mitigation                                    0.130   \n",
       "After RANDOM mitigation N = 6000                     0.132   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5                 0.140   \n",
       "After SMOTE N = 6000 p_class 0 = 0.55                0.138   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6                 0.130   \n",
       "After SMOTE N = 6000 p_class 0 = 0.65                0.125   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7                 0.121   \n",
       "After SMOTE N = 6000 p_class 0 = 0.75                0.118   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8                 0.116   \n",
       "After SMOTE N = 6000 p_class 0 = 0.85                0.116   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9                 0.107   \n",
       "After SMOTE N = 6000 p_class 0 = 0.95                0.111   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0                 0.105   \n",
       "\n",
       "Metrics                                False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                    0.407              641   \n",
       "After RANDOM mitigation N = 6000                     0.386              651   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5                 0.394              693   \n",
       "After SMOTE N = 6000 p_class 0 = 0.55                0.397              680   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6                 0.385              642   \n",
       "After SMOTE N = 6000 p_class 0 = 0.65                0.404              617   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7                 0.420              599   \n",
       "After SMOTE N = 6000 p_class 0 = 0.75                0.432              581   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8                 0.427              573   \n",
       "After SMOTE N = 6000 p_class 0 = 0.85                0.448              571   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9                 0.455              528   \n",
       "After SMOTE N = 6000 p_class 0 = 0.95                0.457              548   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0                 0.475              520   \n",
       "\n",
       "Metrics                                False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                  638       13014       6508  \n",
       "After RANDOM mitigation N = 6000                   606       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.5               618       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.55              623       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.6               603       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.65              633       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.7               659       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.75              678       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.8               670       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.85              703       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.9               714       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 0.95              716       19014       6508  \n",
       "After SMOTE N = 6000 p_class 0 = 1.0               745       19014       6508  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 6000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.593</td>\n",
       "      <td>641</td>\n",
       "      <td>638</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 6000</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.605</td>\n",
       "      <td>651</td>\n",
       "      <td>606</td>\n",
       "      <td>1257</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.5</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.592</td>\n",
       "      <td>693</td>\n",
       "      <td>618</td>\n",
       "      <td>1311</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.55</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.592</td>\n",
       "      <td>680</td>\n",
       "      <td>623</td>\n",
       "      <td>1303</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.6</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.608</td>\n",
       "      <td>642</td>\n",
       "      <td>603</td>\n",
       "      <td>1245</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.65</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.599</td>\n",
       "      <td>617</td>\n",
       "      <td>633</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.7</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.591</td>\n",
       "      <td>599</td>\n",
       "      <td>659</td>\n",
       "      <td>1258</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.75</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.586</td>\n",
       "      <td>581</td>\n",
       "      <td>678</td>\n",
       "      <td>1259</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.8</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.591</td>\n",
       "      <td>573</td>\n",
       "      <td>670</td>\n",
       "      <td>1243</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.85</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.576</td>\n",
       "      <td>571</td>\n",
       "      <td>703</td>\n",
       "      <td>1274</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.9</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.579</td>\n",
       "      <td>528</td>\n",
       "      <td>714</td>\n",
       "      <td>1242</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 0.95</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.574</td>\n",
       "      <td>548</td>\n",
       "      <td>716</td>\n",
       "      <td>1264</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 6000 p_class 0 = 1.0</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.565</td>\n",
       "      <td>520</td>\n",
       "      <td>745</td>\n",
       "      <td>1265</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                                Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                         0.803     0.593              641   \n",
       "After RANDOM mitigation N = 6000          0.807     0.605              651   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5      0.799     0.592              693   \n",
       "After SMOTE N = 6000 p_class 0 = 0.55     0.800     0.592              680   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6      0.809     0.608              642   \n",
       "After SMOTE N = 6000 p_class 0 = 0.65     0.808     0.599              617   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7      0.807     0.591              599   \n",
       "After SMOTE N = 6000 p_class 0 = 0.75     0.807     0.586              581   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8      0.809     0.591              573   \n",
       "After SMOTE N = 6000 p_class 0 = 0.85     0.804     0.576              571   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9      0.809     0.579              528   \n",
       "After SMOTE N = 6000 p_class 0 = 0.95     0.806     0.574              548   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0      0.806     0.565              520   \n",
       "\n",
       "Metrics                                False Negatives  Total Errors  \\\n",
       "Before Mitigation                                  638          1279   \n",
       "After RANDOM mitigation N = 6000                   606          1257   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5               618          1311   \n",
       "After SMOTE N = 6000 p_class 0 = 0.55              623          1303   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6               603          1245   \n",
       "After SMOTE N = 6000 p_class 0 = 0.65              633          1250   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7               659          1258   \n",
       "After SMOTE N = 6000 p_class 0 = 0.75              678          1259   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8               670          1243   \n",
       "After SMOTE N = 6000 p_class 0 = 0.85              703          1274   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9               714          1242   \n",
       "After SMOTE N = 6000 p_class 0 = 0.95              716          1264   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0               745          1265   \n",
       "\n",
       "Metrics                                Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                                0.054           0.190   \n",
       "After RANDOM mitigation N = 6000                 0.038           0.177   \n",
       "After SMOTE N = 6000 p_class 0 = 0.5             0.024           0.191   \n",
       "After SMOTE N = 6000 p_class 0 = 0.55            0.048           0.201   \n",
       "After SMOTE N = 6000 p_class 0 = 0.6             0.036           0.181   \n",
       "After SMOTE N = 6000 p_class 0 = 0.65            0.013           0.150   \n",
       "After SMOTE N = 6000 p_class 0 = 0.7             0.015           0.157   \n",
       "After SMOTE N = 6000 p_class 0 = 0.75            0.023           0.150   \n",
       "After SMOTE N = 6000 p_class 0 = 0.8             0.015           0.140   \n",
       "After SMOTE N = 6000 p_class 0 = 0.85            0.022           0.141   \n",
       "After SMOTE N = 6000 p_class 0 = 0.9             0.010           0.124   \n",
       "After SMOTE N = 6000 p_class 0 = 0.95            0.014           0.118   \n",
       "After SMOTE N = 6000 p_class 0 = 1.0             0.015           0.108   \n",
       "\n",
       "Metrics                                Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                           0.172       0.153       0.097  \n",
       "After RANDOM mitigation N = 6000            0.154       0.129       0.072  \n",
       "After SMOTE N = 6000 p_class 0 = 0.5        0.142       0.093       0.031  \n",
       "After SMOTE N = 6000 p_class 0 = 0.55       0.181       0.140       0.072  \n",
       "After SMOTE N = 6000 p_class 0 = 0.6        0.151       0.109       0.046  \n",
       "After SMOTE N = 6000 p_class 0 = 0.65       0.097       0.058       0.013  \n",
       "After SMOTE N = 6000 p_class 0 = 0.7        0.104       0.064       0.015  \n",
       "After SMOTE N = 6000 p_class 0 = 0.75       0.123       0.085       0.031  \n",
       "After SMOTE N = 6000 p_class 0 = 0.8        0.102       0.060       0.015  \n",
       "After SMOTE N = 6000 p_class 0 = 0.85       0.109       0.070       0.022  \n",
       "After SMOTE N = 6000 p_class 0 = 0.9        0.081       0.043       0.010  \n",
       "After SMOTE N = 6000 p_class 0 = 0.95       0.091       0.057       0.014  \n",
       "After SMOTE N = 6000 p_class 0 = 1.0        0.087       0.055       0.015  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_6K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_6K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N = 7000\\n# Dizionari per salvare i risultati\\nX_train_mit_SMOTE_dict = {}\\ny_train_mit_SMOTE_dict = {}\\ny_pred_SMOTE_dict = {}\\nmetrics_results_compare = {}\\nfp_div_results = {}  # Divergenza nei falsi positivi\\n\\n\\noriginal_size = len(X_to_SMOTE)\\n\\nfor p in p_values:\\n    # Definizione della strategia di campionamento\\n    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\\n    \\n    # Applicazione di SMOTENC\\n    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\\n    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\n    \\n    # Estrazione dei campioni generati\\n    X_generated = X_sampled_SMOTE[-N:]\\n    y_generated = y_sampled_SMOTE[-N:]\\n    \\n    # Creazione del dataset di training con SMOTE\\n    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\\n    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\\n    \\n    # Addestramento del modello\\n    classifier = DecisionTreeClassifier(random_state=seed)\\n    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\\n    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\\n    \\n    # Calcolo delle metriche\\n    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\\n    \\n    # Analisi della divergenza sui falsi positivi\\n    df_test_class = X_test.copy()\\n    df_test_class[\\'y_test_true\\'] = y_test\\n    df_test_class[\\'y_pred\\'] = y_pred_SMOTE_dict[p]\\n    \\n    # Calcolo falsi positivi\\n    y_trues = df_test_class[\"y_test_true\"]\\n    y_preds = df_test_class[\"y_pred\"]\\n    df_test_class[\\'fp\\'] = get_false_positive_rate_outcome(y_trues, y_preds)\\n\\n    # Aggiunta delle feature calcolate a df_test\\n    df_test[\\'fp\\'] = df_test_class[\\'fp\\']\\n    df_test[\\'y_pred\\'] = df_test_class[\\'y_pred\\']\\n\\n    # Analisi della divergenza\\n    fp_diver = DivergenceExplorer(df_test)\\n    attributes = [\\'workclass\\', \\'fnlwgt\\', \\'education\\', \\'marital-status\\', \\'occupation\\', \\'relationship\\',\\n                  \\'race\\', \\'sex\\', \\'capital-gain\\', \\'capital-loss\\', \\'native-country\\', \\n                  \\'age_group\\', \\'edu_num_group\\', \\'hours_per_week_group\\']\\n    \\n    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\\'fp\\'])\\n    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\\n\\n    # Pruning della divergenza\\n    fp_details = DivergencePatternProcessor(FP_fm, \\'fp\\')\\n    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\\n    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\\n\\n    # Salvataggio della divergenza nel dizionario\\n    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\\n\\n\\n# Valori randomici per confronto senza mitigazione\\ndf_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\\ndf_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\\ndf_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\\nX_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\\ny_train_mitigated_random_smote = df_train_mitigated_random_smote[\\'income\\']\\n\\nclassifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\\nclassifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\\ny_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\\n\\naccuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\\n\\n# Creazione della tabella dei risultati\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    \\'Metrics\\': [\\'Accuracy\\', \\'F1 Score\\', \\'False Positive Rate\\', \\'False Negative Rate\\', \\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\'],\\n    \\'Before Mitigation\\': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\\n    \\'After RANDOM mitigation N = {}\\'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\\n})\\n\\nfor p in p_values:\\n    metrics_after_fp_SMOTE[f\\'After SMOTE N = {N} p_class 0 = {p}\\'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\\n\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index(\\'Metrics\\').T\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n\\n# Mostrare la tabella finale\\nmetrics_after_fp_SMOTE'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''N = 7000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Dizionario per salvare i risultati della divergenza\\nfp_div_results = {}\\n\\n# Lista degli esperimenti con l\\'ordine desiderato\\nexperiments = {\\n    \"no_mitigation\": y_pred,  # Prima Before Mitigation\\n    \"random\": y_mitigated_pred_random,  # Poi Random\\n    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\\n}\\n\\n# Iteriamo su ogni esperimento nell\\'ordine corretto\\nfor exp_name, preds in experiments.items():\\n    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\\n    if exp_name == \"SMOTE\":\\n        iter_values = preds  # Lista dei valori di p\\n    else:\\n        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\\n\\n    for p in iter_values:\\n        # Creazione del DataFrame per il test set\\n        df_test_class = X_test.copy()\\n        df_test_class[\\'y_test_true\\'] = y_test\\n        \\n        # Se l\\'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\\n        df_test_class[\\'y_pred\\'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\\n\\n        # Calcolo falsi positivi\\n        y_trues = df_test_class[\"y_test_true\"]\\n        y_preds = df_test_class[\"y_pred\"]\\n        df_test_class[\\'fp\\'] = get_false_positive_rate_outcome(y_trues, y_preds)\\n\\n        # Aggiunta delle feature calcolate a df_test\\n        df_test[\\'fp\\'] = df_test_class[\\'fp\\']\\n        df_test[\\'y_pred\\'] = df_test_class[\\'y_pred\\']\\n\\n        # Analisi della divergenza\\n        fp_diver = DivergenceExplorer(df_test)\\n        attributes = [\\'workclass\\', \\'fnlwgt\\', \\'education\\', \\'marital-status\\', \\'occupation\\', \\'relationship\\',\\n                      \\'race\\', \\'sex\\', \\'capital-gain\\', \\'capital-loss\\', \\'native-country\\', \\n                      \\'age_group\\', \\'edu_num_group\\', \\'hours_per_week_group\\']\\n        \\n        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\\'fp\\'])\\n        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\\n\\n        # Pruning\\n        fp_details = DivergencePatternProcessor(FP_fm, \\'fp\\')\\n        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\\n        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\\n\\n        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\\n        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\\n        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\\n\\n# Calcolo delle metriche dai risultati della divergenza\\nresults = {\\n    key: {\\n        \"media\": np.nanmean(fp_div_list),\\n        \"media_primi10\": np.nanmean(fp_div_list[:10]),\\n        \"media_primi20\": np.nanmean(fp_div_list[:20]),\\n        \"media_primi40\": np.nanmean(fp_div_list[:40]),\\n        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\\n    }\\n    for key, fp_div_list in fp_div_results.items()\\n}\\n\\n\\n# Creazione della tabella dei risultati con le nuove metriche\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    \\'Metrics\\': [\\'Accuracy\\', \\'F1 Score\\', \\'False Positives\\', \\'False Negatives\\', \\'Total Errors\\', \\n                \\'Mean Divergence\\', \\'Max Divergence\\', \\'Top 10 Div\\', \\'Top 20 Div\\', \\'Top 40 Div\\'],\\n    \\'Before Mitigation\\': [\\n        accuracy_before, f1_score_before, fp_before, fn_before, \\n        fp_before + fn_before, results[\\'no_mitigation\\'][\\'media\\'], results[\\'no_mitigation\\'][\\'massimo_valore_assoluto\\'], \\n        results[\\'no_mitigation\\'][\\'media_primi10\\'], results[\\'no_mitigation\\'][\\'media_primi20\\'], results[\\'no_mitigation\\'][\\'media_primi40\\']\\n    ],\\n    \\'After RANDOM mitigation N = {}\\'.format(N): [\\n        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \\n        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \\n        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\\n        results[\\'random\\'][\\'media\\'], results[\\'random\\'][\\'massimo_valore_assoluto\\'],\\n        results[\\'random\\'][\\'media_primi10\\'], results[\\'random\\'][\\'media_primi20\\'], results[\\'random\\'][\\'media_primi40\\']\\n    ]\\n})\\n\\n# Aggiunta delle colonne per ogni valore di p\\nfor p in p_values:\\n    if (\\'SMOTE\\', p) in results:\\n        metrics_after_fp_SMOTE[f\\'After SMOTE N = {N} p_class 0 = {p}\\'] = [\\n            metrics_results_compare[p][0],  # Accuracy\\n            metrics_results_compare[p][1],  # F1 Score\\n            metrics_results_compare[p][4],  # False Positives\\n            metrics_results_compare[p][5],  # False Negatives\\n            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\\n            results[(\\'SMOTE\\', p)][\\'media\\'],\\n            results[(\\'SMOTE\\', p)][\\'massimo_valore_assoluto\\'],\\n            results[(\\'SMOTE\\', p)][\\'media_primi10\\'],\\n            results[(\\'SMOTE\\', p)][\\'media_primi20\\'],\\n            results[(\\'SMOTE\\', p)][\\'media_primi40\\']\\n        ]\\n\\n# Trasformare la tabella in formato leggibile\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index(\\'Metrics\\').T\\n\\n# Castare i valori interi per alcune metriche\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Total Errors\\']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n\\nmetrics_after_fp_SMOTE_7K = metrics_after_fp_SMOTE\\nmetrics_after_fp_SMOTE_7K\\n\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_7K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_7K\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N = 8000\\n# Dizionari per salvare i risultati\\nX_train_mit_SMOTE_dict = {}\\ny_train_mit_SMOTE_dict = {}\\ny_pred_SMOTE_dict = {}\\nmetrics_results_compare = {}\\nfp_div_results = {}  # Divergenza nei falsi positivi\\n\\noriginal_size = len(X_to_SMOTE)\\n\\nfor p in p_values:\\n    # Definizione della strategia di campionamento\\n    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\\n    \\n    # Applicazione di SMOTENC\\n    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\\n    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\n    \\n    # Estrazione dei campioni generati\\n    X_generated = X_sampled_SMOTE[-N:]\\n    y_generated = y_sampled_SMOTE[-N:]\\n    \\n    # Creazione del dataset di training con SMOTE\\n    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\\n    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\\n    \\n    # Addestramento del modello\\n    classifier = DecisionTreeClassifier(random_state=seed)\\n    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\\n    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\\n    \\n    # Calcolo delle metriche\\n    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\\n    \\n    # Analisi della divergenza sui falsi positivi\\n    df_test_class = X_test.copy()\\n    df_test_class[\\'y_test_true\\'] = y_test\\n    df_test_class[\\'y_pred\\'] = y_pred_SMOTE_dict[p]\\n    \\n    # Calcolo falsi positivi\\n    y_trues = df_test_class[\"y_test_true\"]\\n    y_preds = df_test_class[\"y_pred\"]\\n    df_test_class[\\'fp\\'] = get_false_positive_rate_outcome(y_trues, y_preds)\\n\\n    # Aggiunta delle feature calcolate a df_test\\n    df_test[\\'fp\\'] = df_test_class[\\'fp\\']\\n    df_test[\\'y_pred\\'] = df_test_class[\\'y_pred\\']\\n\\n    # Analisi della divergenza\\n    fp_diver = DivergenceExplorer(df_test)\\n    attributes = [\\'workclass\\', \\'fnlwgt\\', \\'education\\', \\'marital-status\\', \\'occupation\\', \\'relationship\\',\\n                  \\'race\\', \\'sex\\', \\'capital-gain\\', \\'capital-loss\\', \\'native-country\\', \\n                  \\'age_group\\', \\'edu_num_group\\', \\'hours_per_week_group\\']\\n    \\n    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\\'fp\\'])\\n    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\\n\\n    # Pruning della divergenza\\n    fp_details = DivergencePatternProcessor(FP_fm, \\'fp\\')\\n    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\\n    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\\n\\n    # Salvataggio della divergenza nel dizionario\\n    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\\n\\n\\n# Valori randomici per confronto senza mitigazione\\ndf_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\\ndf_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\\ndf_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\\nX_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\\ny_train_mitigated_random_smote = df_train_mitigated_random_smote[\\'income\\']\\n\\nclassifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\\nclassifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\\ny_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\\n\\naccuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\\n\\n# Creazione della tabella dei risultati\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    \\'Metrics\\': [\\'Accuracy\\', \\'F1 Score\\', \\'False Positive Rate\\', \\'False Negative Rate\\', \\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\'],\\n    \\'Before Mitigation\\': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\\n    \\'After RANDOM mitigation N = {}\\'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\\n})\\n\\nfor p in p_values:\\n    metrics_after_fp_SMOTE[f\\'After SMOTE N = {N} p_class 0 = {p}\\'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\\n\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index(\\'Metrics\\').T\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n\\n# Mostrare la tabella finale\\nmetrics_after_fp_SMOTE'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''N = 8000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Dizionario per salvare i risultati della divergenza\\nfp_div_results = {}\\n\\n# Lista degli esperimenti con l\\'ordine desiderato\\nexperiments = {\\n    \"no_mitigation\": y_pred,  # Prima Before Mitigation\\n    \"random\": y_mitigated_pred_random,  # Poi Random\\n    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\\n}\\n\\n# Iteriamo su ogni esperimento nell\\'ordine corretto\\nfor exp_name, preds in experiments.items():\\n    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\\n    if exp_name == \"SMOTE\":\\n        iter_values = preds  # Lista dei valori di p\\n    else:\\n        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\\n\\n    for p in iter_values:\\n        # Creazione del DataFrame per il test set\\n        df_test_class = X_test.copy()\\n        df_test_class[\\'y_test_true\\'] = y_test\\n        \\n        # Se l\\'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\\n        df_test_class[\\'y_pred\\'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\\n\\n        # Calcolo falsi positivi\\n        y_trues = df_test_class[\"y_test_true\"]\\n        y_preds = df_test_class[\"y_pred\"]\\n        df_test_class[\\'fp\\'] = get_false_positive_rate_outcome(y_trues, y_preds)\\n\\n        # Aggiunta delle feature calcolate a df_test\\n        df_test[\\'fp\\'] = df_test_class[\\'fp\\']\\n        df_test[\\'y_pred\\'] = df_test_class[\\'y_pred\\']\\n\\n        # Analisi della divergenza\\n        fp_diver = DivergenceExplorer(df_test)\\n        attributes = [\\'workclass\\', \\'fnlwgt\\', \\'education\\', \\'marital-status\\', \\'occupation\\', \\'relationship\\',\\n                      \\'race\\', \\'sex\\', \\'capital-gain\\', \\'capital-loss\\', \\'native-country\\', \\n                      \\'age_group\\', \\'edu_num_group\\', \\'hours_per_week_group\\']\\n        \\n        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\\'fp\\'])\\n        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\\n\\n        # Pruning\\n        fp_details = DivergencePatternProcessor(FP_fm, \\'fp\\')\\n        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\\n        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\\n\\n        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\\n        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\\n        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\\n\\n# Calcolo delle metriche dai risultati della divergenza\\nresults = {\\n    key: {\\n        \"media\": np.nanmean(fp_div_list),\\n        \"media_primi10\": np.nanmean(fp_div_list[:10]),\\n        \"media_primi20\": np.nanmean(fp_div_list[:20]),\\n        \"media_primi40\": np.nanmean(fp_div_list[:40]),\\n        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\\n    }\\n    for key, fp_div_list in fp_div_results.items()\\n}\\n\\n\\n# Creazione della tabella dei risultati con le nuove metriche\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    \\'Metrics\\': [\\'Accuracy\\', \\'F1 Score\\', \\'False Positives\\', \\'False Negatives\\', \\'Total Errors\\', \\n                \\'Mean Divergence\\', \\'Max Divergence\\', \\'Top 10 Div\\', \\'Top 20 Div\\', \\'Top 40 Div\\'],\\n    \\'Before Mitigation\\': [\\n        accuracy_before, f1_score_before, fp_before, fn_before, \\n        fp_before + fn_before, results[\\'no_mitigation\\'][\\'media\\'], results[\\'no_mitigation\\'][\\'massimo_valore_assoluto\\'], \\n        results[\\'no_mitigation\\'][\\'media_primi10\\'], results[\\'no_mitigation\\'][\\'media_primi20\\'], results[\\'no_mitigation\\'][\\'media_primi40\\']\\n    ],\\n    \\'After RANDOM mitigation N = {}\\'.format(N): [\\n        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \\n        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \\n        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\\n        results[\\'random\\'][\\'media\\'], results[\\'random\\'][\\'massimo_valore_assoluto\\'],\\n        results[\\'random\\'][\\'media_primi10\\'], results[\\'random\\'][\\'media_primi20\\'], results[\\'random\\'][\\'media_primi40\\']\\n    ]\\n})\\n\\n# Aggiunta delle colonne per ogni valore di p\\nfor p in p_values:\\n    if (\\'SMOTE\\', p) in results:\\n        metrics_after_fp_SMOTE[f\\'After SMOTE N = {N} p_class 0 = {p}\\'] = [\\n            metrics_results_compare[p][0],  # Accuracy\\n            metrics_results_compare[p][1],  # F1 Score\\n            metrics_results_compare[p][4],  # False Positives\\n            metrics_results_compare[p][5],  # False Negatives\\n            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\\n            results[(\\'SMOTE\\', p)][\\'media\\'],\\n            results[(\\'SMOTE\\', p)][\\'massimo_valore_assoluto\\'],\\n            results[(\\'SMOTE\\', p)][\\'media_primi10\\'],\\n            results[(\\'SMOTE\\', p)][\\'media_primi20\\'],\\n            results[(\\'SMOTE\\', p)][\\'media_primi40\\']\\n        ]\\n\\n# Trasformare la tabella in formato leggibile\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index(\\'Metrics\\').T\\n\\n# Castare i valori interi per alcune metriche\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Total Errors\\']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n\\nmetrics_after_fp_SMOTE_8K = metrics_after_fp_SMOTE\\nmetrics_after_fp_SMOTE_8K\\n\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_8K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_8K\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N = 9000\\n# Dizionari per salvare i risultati\\nX_train_mit_SMOTE_dict = {}\\ny_train_mit_SMOTE_dict = {}\\ny_pred_SMOTE_dict = {}\\nmetrics_results_compare = {}\\nfp_div_results = {}  # Divergenza nei falsi positivi\\n\\n\\noriginal_size = len(X_to_SMOTE)\\n\\nfor p in p_values:\\n    # Definizione della strategia di campionamento\\n    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\\n    \\n    # Applicazione di SMOTENC\\n    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\\n    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\n    \\n    # Estrazione dei campioni generati\\n    X_generated = X_sampled_SMOTE[-N:]\\n    y_generated = y_sampled_SMOTE[-N:]\\n    \\n    # Creazione del dataset di training con SMOTE\\n    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\\n    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\\n    \\n    # Addestramento del modello\\n    classifier = DecisionTreeClassifier(random_state=seed)\\n    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\\n    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\\n    \\n    # Calcolo delle metriche\\n    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\\n    \\n    # Analisi della divergenza sui falsi positivi\\n    df_test_class = X_test.copy()\\n    df_test_class[\\'y_test_true\\'] = y_test\\n    df_test_class[\\'y_pred\\'] = y_pred_SMOTE_dict[p]\\n    \\n    # Calcolo falsi positivi\\n    y_trues = df_test_class[\"y_test_true\"]\\n    y_preds = df_test_class[\"y_pred\"]\\n    df_test_class[\\'fp\\'] = get_false_positive_rate_outcome(y_trues, y_preds)\\n\\n    # Aggiunta delle feature calcolate a df_test\\n    df_test[\\'fp\\'] = df_test_class[\\'fp\\']\\n    df_test[\\'y_pred\\'] = df_test_class[\\'y_pred\\']\\n\\n    # Analisi della divergenza\\n    fp_diver = DivergenceExplorer(df_test)\\n    attributes = [\\'workclass\\', \\'fnlwgt\\', \\'education\\', \\'marital-status\\', \\'occupation\\', \\'relationship\\',\\n                  \\'race\\', \\'sex\\', \\'capital-gain\\', \\'capital-loss\\', \\'native-country\\', \\n                  \\'age_group\\', \\'edu_num_group\\', \\'hours_per_week_group\\']\\n    \\n    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\\'fp\\'])\\n    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\\n\\n    # Pruning della divergenza\\n    fp_details = DivergencePatternProcessor(FP_fm, \\'fp\\')\\n    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\\n    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\\n\\n    # Salvataggio della divergenza nel dizionario\\n    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\\n\\n\\n# Valori randomici per confronto senza mitigazione\\ndf_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\\ndf_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\\ndf_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\\nX_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\\ny_train_mitigated_random_smote = df_train_mitigated_random_smote[\\'income\\']\\n\\nclassifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\\nclassifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\\ny_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\\n\\naccuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\\n\\n# Creazione della tabella dei risultati\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    \\'Metrics\\': [\\'Accuracy\\', \\'F1 Score\\', \\'False Positive Rate\\', \\'False Negative Rate\\', \\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\'],\\n    \\'Before Mitigation\\': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\\n    \\'After RANDOM mitigation N = {}\\'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\\n})\\n\\nfor p in p_values:\\n    metrics_after_fp_SMOTE[f\\'After SMOTE N = {N} p_class 0 = {p}\\'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\\n\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index(\\'Metrics\\').T\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n\\n# Mostrare la tabella finale\\nmetrics_after_fp_SMOTE'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''N = 9000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Dizionario per salvare i risultati della divergenza\\nfp_div_results = {}\\n\\n# Lista degli esperimenti con l\\'ordine desiderato\\nexperiments = {\\n    \"no_mitigation\": y_pred,  # Prima Before Mitigation\\n    \"random\": y_mitigated_pred_random,  # Poi Random\\n    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\\n}\\n\\n# Iteriamo su ogni esperimento nell\\'ordine corretto\\nfor exp_name, preds in experiments.items():\\n    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\\n    if exp_name == \"SMOTE\":\\n        iter_values = preds  # Lista dei valori di p\\n    else:\\n        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\\n\\n    for p in iter_values:\\n        # Creazione del DataFrame per il test set\\n        df_test_class = X_test.copy()\\n        df_test_class[\\'y_test_true\\'] = y_test\\n        \\n        # Se l\\'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\\n        df_test_class[\\'y_pred\\'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\\n\\n        # Calcolo falsi positivi\\n        y_trues = df_test_class[\"y_test_true\"]\\n        y_preds = df_test_class[\"y_pred\"]\\n        df_test_class[\\'fp\\'] = get_false_positive_rate_outcome(y_trues, y_preds)\\n\\n        # Aggiunta delle feature calcolate a df_test\\n        df_test[\\'fp\\'] = df_test_class[\\'fp\\']\\n        df_test[\\'y_pred\\'] = df_test_class[\\'y_pred\\']\\n\\n        # Analisi della divergenza\\n        fp_diver = DivergenceExplorer(df_test)\\n        attributes = [\\'workclass\\', \\'fnlwgt\\', \\'education\\', \\'marital-status\\', \\'occupation\\', \\'relationship\\',\\n                      \\'race\\', \\'sex\\', \\'capital-gain\\', \\'capital-loss\\', \\'native-country\\', \\n                      \\'age_group\\', \\'edu_num_group\\', \\'hours_per_week_group\\']\\n        \\n        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\\'fp\\'])\\n        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\\n\\n        # Pruning\\n        fp_details = DivergencePatternProcessor(FP_fm, \\'fp\\')\\n        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\\n        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\\n\\n        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\\n        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\\n        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\\n\\n# Calcolo delle metriche dai risultati della divergenza\\nresults = {\\n    key: {\\n        \"media\": np.nanmean(fp_div_list),\\n        \"media_primi10\": np.nanmean(fp_div_list[:10]),\\n        \"media_primi20\": np.nanmean(fp_div_list[:20]),\\n        \"media_primi40\": np.nanmean(fp_div_list[:40]),\\n        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\\n    }\\n    for key, fp_div_list in fp_div_results.items()\\n}\\n\\n\\n# Creazione della tabella dei risultati con le nuove metriche\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    \\'Metrics\\': [\\'Accuracy\\', \\'F1 Score\\', \\'False Positives\\', \\'False Negatives\\', \\'Total Errors\\', \\n                \\'Mean Divergence\\', \\'Max Divergence\\', \\'Top 10 Div\\', \\'Top 20 Div\\', \\'Top 40 Div\\'],\\n    \\'Before Mitigation\\': [\\n        accuracy_before, f1_score_before, fp_before, fn_before, \\n        fp_before + fn_before, results[\\'no_mitigation\\'][\\'media\\'], results[\\'no_mitigation\\'][\\'massimo_valore_assoluto\\'], \\n        results[\\'no_mitigation\\'][\\'media_primi10\\'], results[\\'no_mitigation\\'][\\'media_primi20\\'], results[\\'no_mitigation\\'][\\'media_primi40\\']\\n    ],\\n    \\'After RANDOM mitigation N = {}\\'.format(N): [\\n        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \\n        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \\n        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\\n        results[\\'random\\'][\\'media\\'], results[\\'random\\'][\\'massimo_valore_assoluto\\'],\\n        results[\\'random\\'][\\'media_primi10\\'], results[\\'random\\'][\\'media_primi20\\'], results[\\'random\\'][\\'media_primi40\\']\\n    ]\\n})\\n\\n# Aggiunta delle colonne per ogni valore di p\\nfor p in p_values:\\n    if (\\'SMOTE\\', p) in results:\\n        metrics_after_fp_SMOTE[f\\'After SMOTE N = {N} p_class 0 = {p}\\'] = [\\n            metrics_results_compare[p][0],  # Accuracy\\n            metrics_results_compare[p][1],  # F1 Score\\n            metrics_results_compare[p][4],  # False Positives\\n            metrics_results_compare[p][5],  # False Negatives\\n            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\\n            results[(\\'SMOTE\\', p)][\\'media\\'],\\n            results[(\\'SMOTE\\', p)][\\'massimo_valore_assoluto\\'],\\n            results[(\\'SMOTE\\', p)][\\'media_primi10\\'],\\n            results[(\\'SMOTE\\', p)][\\'media_primi20\\'],\\n            results[(\\'SMOTE\\', p)][\\'media_primi40\\']\\n        ]\\n\\n# Trasformare la tabella in formato leggibile\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index(\\'Metrics\\').T\\n\\n# Castare i valori interi per alcune metriche\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Total Errors\\']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n\\nmetrics_after_fp_SMOTE_9K = metrics_after_fp_SMOTE\\nmetrics_after_fp_SMOTE_9K\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_9K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_9K\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N = 10000\\n# Dizionari per salvare i risultati\\nX_train_mit_SMOTE_dict = {}\\ny_train_mit_SMOTE_dict = {}\\ny_pred_SMOTE_dict = {}\\nmetrics_results_compare = {}\\nfp_div_results = {}  # Divergenza nei falsi positivi\\n\\noriginal_size = len(X_to_SMOTE)\\n\\nfor p in p_values:\\n    # Definizione della strategia di campionamento\\n    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\\n    \\n    # Applicazione di SMOTENC\\n    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\\n    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\\n    \\n    # Estrazione dei campioni generati\\n    X_generated = X_sampled_SMOTE[-N:]\\n    y_generated = y_sampled_SMOTE[-N:]\\n    \\n    # Creazione del dataset di training con SMOTE\\n    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\\n    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\\n    \\n    # Addestramento del modello\\n    classifier = DecisionTreeClassifier(random_state=seed)\\n    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\\n    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\\n    \\n    # Calcolo delle metriche\\n    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\\n    \\n    # Analisi della divergenza sui falsi positivi\\n    df_test_class = X_test.copy()\\n    df_test_class[\\'y_test_true\\'] = y_test\\n    df_test_class[\\'y_pred\\'] = y_pred_SMOTE_dict[p]\\n    \\n    # Calcolo falsi positivi\\n    y_trues = df_test_class[\"y_test_true\"]\\n    y_preds = df_test_class[\"y_pred\"]\\n    df_test_class[\\'fp\\'] = get_false_positive_rate_outcome(y_trues, y_preds)\\n\\n    # Aggiunta delle feature calcolate a df_test\\n    df_test[\\'fp\\'] = df_test_class[\\'fp\\']\\n    df_test[\\'y_pred\\'] = df_test_class[\\'y_pred\\']\\n\\n    # Analisi della divergenza\\n    fp_diver = DivergenceExplorer(df_test)\\n    attributes = [\\'workclass\\', \\'fnlwgt\\', \\'education\\', \\'marital-status\\', \\'occupation\\', \\'relationship\\',\\n                  \\'race\\', \\'sex\\', \\'capital-gain\\', \\'capital-loss\\', \\'native-country\\', \\n                  \\'age_group\\', \\'edu_num_group\\', \\'hours_per_week_group\\']\\n    \\n    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\\'fp\\'])\\n    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\\n\\n    # Pruning della divergenza\\n    fp_details = DivergencePatternProcessor(FP_fm, \\'fp\\')\\n    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\\n    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\\n\\n    # Salvataggio della divergenza nel dizionario\\n    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\\n\\n\\n# Valori randomici per confronto senza mitigazione\\ndf_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\\ndf_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\\ndf_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\\nX_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\\ny_train_mitigated_random_smote = df_train_mitigated_random_smote[\\'income\\']\\n\\nclassifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\\nclassifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\\ny_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\\n\\naccuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\\n\\n# Creazione della tabella dei risultati\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    \\'Metrics\\': [\\'Accuracy\\', \\'F1 Score\\', \\'False Positive Rate\\', \\'False Negative Rate\\', \\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\'],\\n    \\'Before Mitigation\\': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\\n    \\'After RANDOM mitigation N = {}\\'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\\n})\\n\\nfor p in p_values:\\n    metrics_after_fp_SMOTE[f\\'After SMOTE N = {N} p_class 0 = {p}\\'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\\n\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index(\\'Metrics\\').T\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Train Size\\', \\'Test Size\\']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n\\n# Mostrare la tabella finale\\nmetrics_after_fp_SMOTE'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''N = 10000\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "fp_div_results = {}  # Divergenza nei falsi positivi\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    # Definizione della strategia di campionamento\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    # Applicazione di SMOTENC\n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    # Estrazione dei campioni generati\n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    # Creazione del dataset di training con SMOTE\n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    # Analisi della divergenza sui falsi positivi\n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    \n",
    "    # Calcolo falsi positivi\n",
    "    y_trues = df_test_class[\"y_test_true\"]\n",
    "    y_preds = df_test_class[\"y_pred\"]\n",
    "    df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "    # Aggiunta delle feature calcolate a df_test\n",
    "    df_test['fp'] = df_test_class['fp']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "    # Analisi della divergenza\n",
    "    fp_diver = DivergenceExplorer(df_test)\n",
    "    attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                  'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                  'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "    \n",
    "    FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "    # Pruning della divergenza\n",
    "    fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "    df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "    df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "    # Salvataggio della divergenza nel dizionario\n",
    "    fp_div_results[p] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"income\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['income']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = DecisionTreeClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "# Creazione della tabella dei risultati\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Dizionario per salvare i risultati della divergenza\\nfp_div_results = {}\\n\\n# Lista degli esperimenti con l\\'ordine desiderato\\nexperiments = {\\n    \"no_mitigation\": y_pred,  # Prima Before Mitigation\\n    \"random\": y_mitigated_pred_random,  # Poi Random\\n    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\\n}\\n\\n# Iteriamo su ogni esperimento nell\\'ordine corretto\\nfor exp_name, preds in experiments.items():\\n    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\\n    if exp_name == \"SMOTE\":\\n        iter_values = preds  # Lista dei valori di p\\n    else:\\n        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\\n\\n    for p in iter_values:\\n        # Creazione del DataFrame per il test set\\n        df_test_class = X_test.copy()\\n        df_test_class[\\'y_test_true\\'] = y_test\\n        \\n        # Se l\\'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\\n        df_test_class[\\'y_pred\\'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\\n\\n        # Calcolo falsi positivi\\n        y_trues = df_test_class[\"y_test_true\"]\\n        y_preds = df_test_class[\"y_pred\"]\\n        df_test_class[\\'fp\\'] = get_false_positive_rate_outcome(y_trues, y_preds)\\n\\n        # Aggiunta delle feature calcolate a df_test\\n        df_test[\\'fp\\'] = df_test_class[\\'fp\\']\\n        df_test[\\'y_pred\\'] = df_test_class[\\'y_pred\\']\\n\\n        # Analisi della divergenza\\n        fp_diver = DivergenceExplorer(df_test)\\n        attributes = [\\'workclass\\', \\'fnlwgt\\', \\'education\\', \\'marital-status\\', \\'occupation\\', \\'relationship\\',\\n                      \\'race\\', \\'sex\\', \\'capital-gain\\', \\'capital-loss\\', \\'native-country\\', \\n                      \\'age_group\\', \\'edu_num_group\\', \\'hours_per_week_group\\']\\n        \\n        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=[\\'fp\\'])\\n        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\\n\\n        # Pruning\\n        fp_details = DivergencePatternProcessor(FP_fm, \\'fp\\')\\n        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\\n        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\\n\\n        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\\n        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\\n        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\\n\\n# Calcolo delle metriche dai risultati della divergenza\\nresults = {\\n    key: {\\n        \"media\": np.nanmean(fp_div_list),\\n        \"media_primi10\": np.nanmean(fp_div_list[:10]),\\n        \"media_primi20\": np.nanmean(fp_div_list[:20]),\\n        \"media_primi40\": np.nanmean(fp_div_list[:40]),\\n        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\\n    }\\n    for key, fp_div_list in fp_div_results.items()\\n}\\n\\n\\n# Creazione della tabella dei risultati con le nuove metriche\\nmetrics_after_fp_SMOTE = pd.DataFrame({\\n    \\'Metrics\\': [\\'Accuracy\\', \\'F1 Score\\', \\'False Positives\\', \\'False Negatives\\', \\'Total Errors\\', \\n                \\'Mean Divergence\\', \\'Max Divergence\\', \\'Top 10 Div\\', \\'Top 20 Div\\', \\'Top 40 Div\\'],\\n    \\'Before Mitigation\\': [\\n        accuracy_before, f1_score_before, fp_before, fn_before, \\n        fp_before + fn_before, results[\\'no_mitigation\\'][\\'media\\'], results[\\'no_mitigation\\'][\\'massimo_valore_assoluto\\'], \\n        results[\\'no_mitigation\\'][\\'media_primi10\\'], results[\\'no_mitigation\\'][\\'media_primi20\\'], results[\\'no_mitigation\\'][\\'media_primi40\\']\\n    ],\\n    \\'After RANDOM mitigation N = {}\\'.format(N): [\\n        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \\n        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \\n        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\\n        results[\\'random\\'][\\'media\\'], results[\\'random\\'][\\'massimo_valore_assoluto\\'],\\n        results[\\'random\\'][\\'media_primi10\\'], results[\\'random\\'][\\'media_primi20\\'], results[\\'random\\'][\\'media_primi40\\']\\n    ]\\n})\\n\\n# Aggiunta delle colonne per ogni valore di p\\nfor p in p_values:\\n    if (\\'SMOTE\\', p) in results:\\n        metrics_after_fp_SMOTE[f\\'After SMOTE N = {N} p_class 0 = {p}\\'] = [\\n            metrics_results_compare[p][0],  # Accuracy\\n            metrics_results_compare[p][1],  # F1 Score\\n            metrics_results_compare[p][4],  # False Positives\\n            metrics_results_compare[p][5],  # False Negatives\\n            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\\n            results[(\\'SMOTE\\', p)][\\'media\\'],\\n            results[(\\'SMOTE\\', p)][\\'massimo_valore_assoluto\\'],\\n            results[(\\'SMOTE\\', p)][\\'media_primi10\\'],\\n            results[(\\'SMOTE\\', p)][\\'media_primi20\\'],\\n            results[(\\'SMOTE\\', p)][\\'media_primi40\\']\\n        ]\\n\\n# Trasformare la tabella in formato leggibile\\nmetrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index(\\'Metrics\\').T\\n\\n# Castare i valori interi per alcune metriche\\nmetrics_to_cast = [\\'False Positives\\', \\'False Negatives\\', \\'Total Errors\\']\\nfor metric in metrics_to_cast:\\n    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\\n\\nmetrics_after_fp_SMOTE_10K = metrics_after_fp_SMOTE\\nmetrics_after_fp_SMOTE_10K\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Dizionario per salvare i risultati della divergenza\n",
    "fp_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo falsi positivi\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['fp'] = get_false_positive_rate_outcome(y_trues, y_preds)\n",
    "\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['fp'] = df_test_class['fp']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        fp_diver = DivergenceExplorer(df_test)\n",
    "        attributes = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                      'race', 'sex', 'capital-gain', 'capital-loss', 'native-country', \n",
    "                      'age_group', 'edu_num_group', 'hours_per_week_group']\n",
    "        \n",
    "        FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['fp'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"fp_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        fp_details = DivergencePatternProcessor(FP_fm, 'fp')\n",
    "        df_pruned_fp = fp_details.redundancy_pruning(th_redundancy=0.01)\n",
    "        df_pruned_fp = df_pruned_fp.sort_values(\"fp_div\", ascending=False)\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        fp_div_results[key] = df_pruned_fp[\"fp_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in fp_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "metrics_after_fp_SMOTE_10K = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_10K\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "salvo dati che mi servono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati salvati in false_positives_K.json\n",
      "‚úÖ Variabili salvate con successo in false_positives_K.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"false_positives_K.json\"\n",
    "\n",
    "# Controlla se il file esiste gi√† per evitare di sovrascrivere\n",
    "if os.path.exists(json_filename):\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        false_positives_data = json.load(f)\n",
    "else:\n",
    "    false_positives_data = {}\n",
    "\n",
    "# Lista dei diversi metrics_after_fp_SMOTE_XK\n",
    "metrics_dict = {\n",
    "    \"1K_run6\": metrics_after_fp_SMOTE_1K,\n",
    "    \"2K_run6\": metrics_after_fp_SMOTE_2K,\n",
    "    \"3K_run6\": metrics_after_fp_SMOTE_3K,\n",
    "    \"4K_run6\": metrics_after_fp_SMOTE_4K,\n",
    "    \"5K_run6\": metrics_after_fp_SMOTE_5K,\n",
    "    \"6K_run6\": metrics_after_fp_SMOTE_6K\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni dataset e salviamo i falsi positivi\n",
    "for J, metrics in metrics_dict.items():\n",
    "    false_positives_data[f\"N={J}\"] = metrics[\"False Positives\"].to_dict()\n",
    "\n",
    "# Salviamo il JSON aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(false_positives_data, f, indent=4)\n",
    "\n",
    "print(f\"Dati salvati in {json_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "#per i parametri # Nome del file JSON\n",
    "json_filename = \"false_positives_K.json\"\n",
    "\n",
    "# Valori da salvare (sostituiscili con i tuoi valori reali)\n",
    "min_sup_run6 = min_sup\n",
    "percentage_run6 = percentage\n",
    "th_redundancy_run6 = pruning\n",
    "K_run6 = K\n",
    "L_run6 = filtered_instances  # Supponiamo sia la lunghezza di filtered_instances\n",
    "\n",
    "# 1Ô∏è‚É£ Caricare i dati esistenti (se il file esiste)\n",
    "try:\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        false_positives_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    false_positives_data = {}  # Se il file non esiste, inizializza un dizionario vuoto\n",
    "\n",
    "# 2Ô∏è‚É£ Aggiungere le nuove variabili sotto una chiave dedicata\n",
    "false_positives_data[\"run6_parameters\"] = {\n",
    "    \"min_sup\": min_sup_run6,\n",
    "    \"percentage\": percentage_run6,\n",
    "    \"th_redundancy\": th_redundancy_run6,\n",
    "    \"K\": percentage,\n",
    "    \"L\": L_run6\n",
    "}\n",
    "\n",
    "# 3Ô∏è‚É£ Salvare il file aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(false_positives_data, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ Variabili salvate con successo in\", json_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT: andamento di falsi positivi e di falsi negativi al variare di N e p di appartenere alla classe 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"false_positives_K.json\"\n",
    "\n",
    "# Caricare i dati dal file JSON\n",
    "with open(json_filename, \"r\") as f:\n",
    "    false_positives_data = json.load(f)\n",
    "\n",
    "# Estrarre parametri dal JSON\n",
    "run6_params = false_positives_data.get(\"run6_parameters\", {})\n",
    "min_sup = run6_params.get(\"min_sup\", \"N/A\")\n",
    "percentage = run6_params.get(\"percentage\", \"N/A\")\n",
    "th_redundancy = run6_params.get(\"th_redundancy\", \"N/A\")\n",
    "L = run6_params.get(\"L\", \"N/A\")\n",
    "K = int((percentage / 100) * L)  # K rappresenta il numero di sottogruppi\n",
    "\n",
    "# Lista dei valori di p da 0.5 a 1.0 con step 0.05\n",
    "p_values = np.arange(0.5, 1.05, 0.05)\n",
    "\n",
    "# Definiamo i colori per ogni N\n",
    "colors = [\"blue\", \"red\", \"green\", \"orange\", \"brown\", \"pink\"]\n",
    "labels = [f\"N={k}K\" for k in range(1, 7)]\n",
    "\n",
    "# Creazione della figura\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig.suptitle(\"FALSE POSITIVE MITIGATION\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Disegniamo la linea tratteggiata \"Before Mitigation\"\n",
    "before_mitigation = false_positives_data.get(\"N=1K_run6\", {}).get(\"Before Mitigation\", None)\n",
    "if before_mitigation is not None:\n",
    "    ax.axhline(y=before_mitigation, color=\"purple\", linestyle=\"--\", linewidth=2, label=\"Before Mitigation\")\n",
    "\n",
    "# Aggiungere linee verticali per ogni valore di p\n",
    "for p in p_values:\n",
    "    ax.axvline(x=p, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Loop sui vari N (da 1K a 6K)\n",
    "legend_handles = []\n",
    "for i, n in enumerate(range(1, 7)):\n",
    "    N_key = f\"N={n}K_run6\"\n",
    "    if N_key not in false_positives_data:\n",
    "        continue\n",
    "    \n",
    "    data = false_positives_data[N_key]\n",
    "    \n",
    "    # Estrarre i valori di falsi positivi per ogni p\n",
    "    false_positives = [data.get(f\"After SMOTE N = {n*1000} p_class 0 = {round(p, 2)}\", None) for p in p_values]\n",
    "    \n",
    "    # Filtriamo solo i valori validi\n",
    "    p_values_filtered = [p for j, p in enumerate(p_values) if false_positives[j] is not None]\n",
    "    false_positives_filtered = [fp for fp in false_positives if fp is not None]\n",
    "    \n",
    "    # Plottiamo la linea corrispondente\n",
    "    line, = ax.plot(\n",
    "        p_values_filtered, false_positives_filtered, \n",
    "        marker=\"o\", linestyle=\"-\", color=colors[i], label=labels[i]\n",
    "    )\n",
    "    legend_handles.append(line)\n",
    "\n",
    "# Impostazioni asse\n",
    "ax.set_title(f\"Minsup = {min_sup}, pruning = {th_redundancy}, K% = {percentage}, subgroups: {K}/{L}\")\n",
    "ax.set_xlabel(\"p_class 0\")\n",
    "ax.set_ylabel(\"False Positives\")\n",
    "ax.grid()\n",
    "\n",
    "# Aggiungere la leggenda\n",
    "ax.legend(handles=legend_handles, loc=\"upper right\", fontsize=10, frameon=True, title=\"Legend\")\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
