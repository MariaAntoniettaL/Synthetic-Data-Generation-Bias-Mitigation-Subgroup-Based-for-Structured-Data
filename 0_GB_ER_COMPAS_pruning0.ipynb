{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ANALISI CONDOTTA CON LA FEATURE error (PASSATA A BOOLEAN OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_compas import preprocessing_funct_not_enc, encoding_funct, K_subgroups_dataset_and_or, metrics_to_compare,encoding_funct_SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import torch\n",
    "\n",
    "from divexplorer import DivergenceExplorer\n",
    "from divexplorer import DivergencePatternProcessor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il CSV\n",
    "df = pd.read_csv(\"cox-violent-parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "seed = 42\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning = 0.00\n",
    "epsilon = pruning\n",
    "min_sup = 0.15\n",
    "percentage = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "VALIDATION SET ROWS:  2439\n",
      "HOLDOUT SET ROWS:  2440\n",
      "TEST SET ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test, df_holdout = preprocessing_funct_not_enc(df)\n",
    "#controllo divisione dataset\n",
    "print(f\"TRAIN SET ROWS: \", df_train.shape[0]) \n",
    "print(f\"VALIDATION SET ROWS: \", df_val.shape[0])\n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "VALIDATION SET ROWS:  2439\n",
      "HOLDOUT SET ROWS:  2440\n",
      "TEST SET ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "df_train_enc, df_test_enc, df_holdout_enc, df_val_enc = encoding_funct(df_train=df_train, df_test=df_test, df_holdout=df_holdout, df_val=df_val)\n",
    "#controllo coerenza con numerosit√† precedente\n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0]) \n",
    "print(f\"VALIDATION SET ROWS: \", df_val_enc.shape[0]) \n",
    "print(f\"HOLDOUT SET ROWS: \", df_holdout_enc.shape[0])\n",
    "print(f\"TEST SET ROWS: \", df_test_enc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_no_Violent_Recidivist = df_train_enc.drop(columns = 'Violent_Recidivist')\n",
    "plt.figure(figsize=(4, 3))\n",
    "g = sns.heatmap(df_train_no_Violent_Recidivist.corr(),\n",
    "                annot = False,\n",
    "                cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics            Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation     0.927     0.032                0.002   \n",
       "\n",
       "Metrics            False Negative Rate  False Positives  False Negatives  \\\n",
       "Before Mitigation                0.983                4              175   \n",
       "\n",
       "Metrics            Test Size  \n",
       "Before Mitigation       2439  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_train = df_train_enc['Violent_Recidivist']\n",
    "\n",
    "X_test = df_test_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_test = df_test_enc['Violent_Recidivist']\n",
    "\n",
    "X_val = df_val_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_val = df_val_enc['Violent_Recidivist']\n",
    "\n",
    "X_holdout = df_holdout_enc.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_holdout = df_holdout_enc['Violent_Recidivist']\n",
    "\n",
    "classifier_train = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train.fit(X_train, y_train)\n",
    "y_pred = classifier_train.predict(X_test)\n",
    "cm_classifier = confusion_matrix(y_test, y_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_classifier, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()\n",
    "accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before = metrics_to_compare(y_true = y_test, y_pred = y_pred )\n",
    "metrics_before_df = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_test)],\n",
    "})\n",
    "metrics_before_df = metrics_before_df.set_index('Metrics').T\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_before_df[metric] = metrics_before_df[metric].astype(int)\n",
    "\n",
    "metrics_before_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBGROUPS SEARCH\n",
    "\n",
    "-Identifico i gruppi applicando DivExplorer sul validation not encoded (a cui ho aggiunto la feature sui falsi positivi da passare a boolean outcomes e la feature accuracy che vale 1 se la predizione √® giusta e 0 se sbagliata )\n",
    "\n",
    "-Integro nel training set dati che matchano sottogruppi problematici prendendoli dall'holdout, (primi K = 5, tutte le righe holdout che matchano)\n",
    "\n",
    "-Ripeto training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>y_val_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  race  Recidivism_Risk  Risk_Level  Violent_Recidivism_Risk  \\\n",
       "10676    1     0                4           1                        2   \n",
       "13123    1     2                1           1                        1   \n",
       "2611     1     0                8           0                        6   \n",
       "7945     1     2                1           1                        1   \n",
       "5727     1     2                6           2                        6   \n",
       "\n",
       "       Violent_Risk_Level  Juvenile_Offenses  age_group  Prior_Offensesgroup  \\\n",
       "10676                   1                  0          3                    7   \n",
       "13123                   1                  0          3                    0   \n",
       "2611                    2                  2          2                    1   \n",
       "7945                    1                  0          5                    0   \n",
       "5727                    2                  0          1                    0   \n",
       "\n",
       "       y_val_true  y_pred  \n",
       "10676           0       0  \n",
       "13123           0       0  \n",
       "2611            0       0  \n",
       "7945            0       0  \n",
       "5727            0       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predizioni per il validation set\n",
    "y_pred_val_dt = classifier_train.predict(X_val)\n",
    "\n",
    "df_val_class = X_val.copy()\n",
    "df_val_class['y_val_true'] = y_val\n",
    "df_val_class['y_pred'] = y_pred_val_dt\n",
    "\n",
    "df_val_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = df_val_class[\"y_val_true\"]\n",
    "y_preds = df_val_class[\"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>Recidivism_Risk</th>\n",
       "      <th>Violent_Recidivist</th>\n",
       "      <th>Risk_Level</th>\n",
       "      <th>Violent_Recidivism_Risk</th>\n",
       "      <th>Violent_Risk_Level</th>\n",
       "      <th>Juvenile_Offenses</th>\n",
       "      <th>age_group</th>\n",
       "      <th>Prior_Offensesgroup</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>6-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>35-44</td>\n",
       "      <td>11-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>65-100</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex              race  Recidivism_Risk  Violent_Recidivist Risk_Level  \\\n",
       "10676  Male  African-American                4                   0        Low   \n",
       "13123  Male         Caucasian                1                   0        Low   \n",
       "2611   Male  African-American                8                   0       High   \n",
       "7945   Male         Caucasian                1                   0        Low   \n",
       "5727   Male         Caucasian                6                   0     Medium   \n",
       "\n",
       "       Violent_Recidivism_Risk Violent_Risk_Level  Juvenile_Offenses  \\\n",
       "10676                        2                Low                  0   \n",
       "13123                        1                Low                  0   \n",
       "2611                         6             Medium                  2   \n",
       "7945                         1                Low                  0   \n",
       "5727                         6             Medium                  0   \n",
       "\n",
       "      age_group Prior_Offensesgroup  y_pred  error  \n",
       "10676     45-54                6-10       0      0  \n",
       "13123     45-54                 0-5       0      0  \n",
       "2611      35-44               11-15       0      0  \n",
       "7945     65-100                 0-5       0      0  \n",
       "5727      25-34                 0-5       0      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggiungo la feature accuracy a df_val non encoded che assume valore 1 se la predizione √® giusta 0 se la predizione √® sbagliata\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_val['y_pred'] = df_val_class['y_pred'] \n",
    "df_val['error'] = (df_val_class['y_val_true'] != df_val_class['y_pred']).astype(int)\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['sex', 'race', 'Recidivism_Risk', 'Risk_Level', 'Violent_Recidivism_Risk', 'Violent_Risk_Level', 'Juvenile_Offenses', 'age_group', 'Prior_Offensesgroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemset</th>\n",
       "      <th>error</th>\n",
       "      <th>error_div</th>\n",
       "      <th>error_t</th>\n",
       "      <th>length</th>\n",
       "      <th>support_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.219</td>\n",
       "      <td>(Risk_Level=High, sex=Male)</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.063</td>\n",
       "      <td>4.044</td>\n",
       "      <td>2</td>\n",
       "      <td>534.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.178</td>\n",
       "      <td>(Risk_Level=High, sex=Male, race=African-American)</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.055</td>\n",
       "      <td>3.322</td>\n",
       "      <td>3</td>\n",
       "      <td>435.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.255</td>\n",
       "      <td>(Risk_Level=High)</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.053</td>\n",
       "      <td>3.767</td>\n",
       "      <td>1</td>\n",
       "      <td>621.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.199</td>\n",
       "      <td>(Risk_Level=High, race=African-American)</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.052</td>\n",
       "      <td>3.313</td>\n",
       "      <td>2</td>\n",
       "      <td>486.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.157</td>\n",
       "      <td>(sex=Male, Prior_Offensesgroup=6-10)</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.041</td>\n",
       "      <td>2.498</td>\n",
       "      <td>2</td>\n",
       "      <td>382.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support                                             itemset  error  \\\n",
       "0    0.219                         (Risk_Level=High, sex=Male)  0.137   \n",
       "1    0.178  (Risk_Level=High, sex=Male, race=African-American)  0.129   \n",
       "2    0.255                                   (Risk_Level=High)  0.127   \n",
       "3    0.199            (Risk_Level=High, race=African-American)  0.126   \n",
       "4    0.157                (sex=Male, Prior_Offensesgroup=6-10)  0.115   \n",
       "\n",
       "   error_div  error_t  length  support_count  \n",
       "0      0.063    4.044       2        534.000  \n",
       "1      0.055    3.322       3        435.000  \n",
       "2      0.053    3.767       1        621.000  \n",
       "3      0.052    3.313       2        486.000  \n",
       "4      0.041    2.498       2        382.000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_diver = DivergenceExplorer(df_val)\n",
    "FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=[\"error_div\", \"error_t\"], ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "FP_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pruning \n",
    "error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = FP_fm\n",
    "df_pruned_error = FP_fm\n",
    "#df_pruned_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total subgroups 146\n",
      "total problematic 8\n"
     ]
    }
   ],
   "source": [
    "# Numero totale di istanze\n",
    "total_instances = len(df_pruned_error)\n",
    "\n",
    "# Numero di istanze con fp_div > 0 e fp_t > 2\n",
    "filtered_instances = len(df_pruned_error[(df_pruned_error['error_div'] > 0) & (df_pruned_error['error_t'] > 2)])\n",
    "\n",
    "print('total subgroups', total_instances)\n",
    "print('total problematic', filtered_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim original:  (146, 7)\n",
      "Dim pruned th_redundancy  (146, 7)\n"
     ]
    }
   ],
   "source": [
    "prun_size = df_pruned_error.shape\n",
    "original_size = FP_fm.shape\n",
    "print(\"Dim original: \", original_size)\n",
    "print(\"Dim pruned th_redundancy \", prun_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = int((percentage / 100) * filtered_instances)\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION: ADDING DATA: prendo dati dall'hold-out e li aggiungo al train set, questi dati matchano gli itemset trovati prima (i primi 5)\n",
    "\n",
    "1. prendo dati dall'holdout con la funzione K_subgroups_dataset_and_or li aggiungo train \n",
    "2. riapplico encoding tutto\n",
    "3. Decision tree nuovamente e vedo come sono cambiate le performance (ad es Accuracy, false positive rate, false negative rate) overall e per sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_holdout, K) #da aggiungere a train set e ripetere train e test\n",
    "\n",
    "df_combinated = pd.concat([df_holdout_filtered, df_train], ignore_index=True)\n",
    "df_train_mitigated= df_combinated.sample(frac=1, random_state=seed).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377\n"
     ]
    }
   ],
   "source": [
    "print(len(df_holdout_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET ROWS:  10975\n",
      "TRAIN SET MITIGATED ROWS:  11352\n",
      "VALIDATION SET ROWS:  2439\n",
      "FILTERED DF holdout ROWS:  377\n",
      "TEST SET FILTERED ROWS:  2439\n"
     ]
    }
   ],
   "source": [
    "#riapplico funzione di encoding, ma al posto di holdout, uso il df filtrato che devo usare per inserire dati \n",
    "df_train_enc_mit, inutile1, inutile3, inutile2 = encoding_funct(df_train=df_train_mitigated, df_test=df_test, df_holdout=df_holdout_filtered, df_val=df_val)\n",
    "#controllo divisione dataset\n",
    "df_train_enc_mit_fp = df_train_enc_mit  \n",
    "print(f\"TRAIN SET ROWS: \", df_train_enc.shape[0])\n",
    "print(f\"TRAIN SET MITIGATED ROWS: \", df_train_enc_mit.shape[0]) #su 32536, il 40%  dovrebbe essere circa 13014\n",
    "print(f\"VALIDATION SET ROWS: \", inutile1.shape[0]) #su 32536, il 20%  dovrebbe essere circa 6500\n",
    "print(f\"FILTERED DF holdout ROWS: \", inutile3.shape[0])\n",
    "print(f\"TEST SET FILTERED ROWS: \", inutile2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mitigated = df_train_enc_mit.drop(columns = 'Violent_Recidivist', axis = 1)\n",
    "y_train_mitigated = df_train_enc_mit['Violent_Recidivist']\n",
    "\n",
    "\n",
    "classifier_train_mitigated = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated.fit(X_train_mitigated, y_train_mitigated)\n",
    "y_mitigated_pred = classifier_train_mitigated.predict(X_test)\n",
    "#cm_dt = confusion_matrix(y_test, y_mitigated_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=[False, True])\n",
    "#disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377\n",
      "verifica : 377\n"
     ]
    }
   ],
   "source": [
    "#per veriicare cosa accade se aggiungo in modo randomico lo stesso numero di righe al train, ripeto l'analisi facebdo mitigation con righe randomiche (uguali in numero)\n",
    "print(len(df_holdout_filtered))\n",
    "n = len(df_holdout_filtered)\n",
    "df_holdout_sampled = df_holdout_enc.sample(n=len(df_holdout_filtered), replace=True, random_state=seed)\n",
    "print(\"verifica :\", len(df_holdout_sampled)) #verifica\n",
    "\n",
    "\n",
    "\n",
    "df_combinated_random = pd.concat([df_holdout_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random= df_combinated_random.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_mitigated_random = df_train_mitigated_random.drop(columns=\"Violent_Recidivist\", axis = 1)\n",
    "y_train_mitigated_random = df_train_mitigated_random['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_train_mitigated_random.fit(X_train_mitigated_random, y_train_mitigated_random)\n",
    "y_mitigated_pred_random = classifier_train_mitigated_random.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5, fp)</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                    Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation             0.927     0.032                0.002   \n",
       "After Mitigation(K=5, fp)     0.927     0.033                0.001   \n",
       "After RANDOM mitigation       0.927     0.032                0.002   \n",
       "\n",
       "Metrics                    False Negative Rate  False Positives  \\\n",
       "Before Mitigation                        0.983                4   \n",
       "After Mitigation(K=5, fp)                0.983                2   \n",
       "After RANDOM mitigation                  0.983                4   \n",
       "\n",
       "Metrics                    False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                      175       10975       2439  \n",
       "After Mitigation(K=5, fp)              175       11352       2439  \n",
       "After RANDOM mitigation                175       11352       2439  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after = metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred )\n",
    "accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random= metrics_to_compare(y_true = y_test, y_pred = y_mitigated_pred_random)\n",
    "\n",
    "metrics_after_fp = pd.DataFrame({\n",
    "    'Metrics' : ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation' : [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After Mitigation(K=5, fp)': [accuracy_fp_after, f1_score_fp_after, fpr_fp_after, fnr_fp_after, fp_fp_after, fn_fp_after, len(y_train_mitigated), len(y_test)],\n",
    "    'After RANDOM mitigation' : [accuracy_fp_after_random, f1_score_fp_after_random, fpr_fp_after_random, fnr_fp_after_random, fp_fp_after_random, fn_fp_after_random, len(y_train_mitigated_random), len(y_test)]\n",
    "})\n",
    "metrics_after_fp = metrics_after_fp.set_index('Metrics').T\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp[metric] = metrics_after_fp[metric].astype(int)\n",
    "\n",
    "metrics_after_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISI DIVERGENZE\n",
    "\n",
    "\n",
    "Per vedere cosa accade ai sottogruppi: vedo cosa succede alle divergenze del test dopo la mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>media divergenze</th>\n",
       "      <th>max div</th>\n",
       "      <th>media div primi 10</th>\n",
       "      <th>media div primi 20</th>\n",
       "      <th>media div primi 40</th>\n",
       "      <th># new samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After Mitigation(K=5 fp)</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.018</td>\n",
       "      <td>377.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM Mitigation(K=5 fp)</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "      <td>377.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                          Accuracy  F1 Score  media divergenze  \\\n",
       "Before Mitigation                   0.927     0.032            -0.013   \n",
       "After Mitigation(K=5 fp)            0.927     0.033            -0.012   \n",
       "After RANDOM Mitigation(K=5 fp)     0.927     0.032            -0.013   \n",
       "\n",
       "Metrics                          max div  media div primi 10  \\\n",
       "Before Mitigation                  0.057               0.039   \n",
       "After Mitigation(K=5 fp)           0.056               0.038   \n",
       "After RANDOM Mitigation(K=5 fp)    0.060               0.040   \n",
       "\n",
       "Metrics                          media div primi 20  media div primi 40  \\\n",
       "Before Mitigation                             0.030               0.017   \n",
       "After Mitigation(K=5 fp)                      0.029               0.018   \n",
       "After RANDOM Mitigation(K=5 fp)               0.030               0.018   \n",
       "\n",
       "Metrics                          # new samples  \n",
       "Before Mitigation                        0.000  \n",
       "After Mitigation(K=5 fp)               377.000  \n",
       "After RANDOM Mitigation(K=5 fp)        377.000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all'inizio sul test set senza nessuna mitigation\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_pred\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = FP_fm\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_no_mitigation  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_no_mitigation\n",
    "\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred \n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = FP_fm\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_baseline1  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_baseline1\n",
    "\n",
    "#PER VEDERE COSA SUCCEDE ALLE DIVERGENZE DEI SOTTOGRUPPI CON MITIGATION RADOMICA\n",
    "#prima per la baseline 1 che √® quella che replica il metodo del paper \n",
    "#predizioni per il test set y_mitigated_pred \n",
    "\n",
    "\n",
    "df_test_class = X_test.copy()\n",
    "df_test_class['y_test_true'] = y_test\n",
    "df_test_class['y_pred'] = y_mitigated_pred_random\n",
    "\n",
    "#df_test_class.head()\n",
    "\n",
    "y_trues = df_test_class[\"y_test_true\"]\n",
    "y_preds = df_test_class[\"y_pred\"]\n",
    "\n",
    "df_test_class['error'] = (y_trues != y_preds).astype(int)\n",
    "\n",
    "#aggiungo la feature 'error' a df_val non encoded\n",
    "df_test['error'] = df_test_class['error']\n",
    "\n",
    "#come controllo che sia corretto aggiungo la feature y_pred \n",
    "df_test['y_pred'] = df_test_class['y_pred'] \n",
    "\n",
    "#df_test.head()\n",
    "\n",
    "#sottogruppi\n",
    "\n",
    "fp_diver = DivergenceExplorer(df_test)\n",
    "FP_fm = fp_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#FP_fm.head()\n",
    "#pruning \n",
    "fp_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "df_pruned_error = fp_details.redundancy_pruning(th_redundancy=pruning)\n",
    "df_pruned_error = FP_fm\n",
    "df_pruned_error.head()\n",
    "\n",
    "\n",
    "\n",
    "error_div_list_random_per_confrontare_con_baseline1  = df_pruned_error[\"error_div\"].tolist()\n",
    "#error_div_list_random_per_confrontare_con_baseline1\n",
    "\n",
    "# Calcolo delle medie e del massimo con valore assoluto solo dopo\n",
    "media_error_div_list_no_mitigation = np.nanmean(error_div_list_no_mitigation)\n",
    "media_error_div_list_nomitigation_primi10 = np.nanmean(error_div_list_no_mitigation[:10])\n",
    "media_error_div_list_nomitigation_primi20 = np.nanmean(error_div_list_no_mitigation[:20])\n",
    "media_error_div_list_nomitigation_primi40 = np.nanmean(error_div_list_no_mitigation[:40])\n",
    "massimo_valore_assoluto_error_div_no_mitigation = max(abs(x) for x in error_div_list_no_mitigation)\n",
    "\n",
    "media_error_div_list_baseline1 = np.nanmean(error_div_list_baseline1)\n",
    "media_error_div_list_baseline1_primi10 = np.nanmean(error_div_list_baseline1[:10])\n",
    "media_error_div_list_baseline1_primi20 = np.nanmean(error_div_list_baseline1[:20])\n",
    "media_error_div_list_baseline1_primi40 = np.nanmean(error_div_list_baseline1[:40])\n",
    "error_div_massimo_valore_assoluto_error_div_baseline1 = max(abs(x) for x in error_div_list_baseline1)\n",
    "\n",
    "media_error_div_list_random_per_confrontare_con_baseline1 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1)\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi10 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:10])\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi20 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:20])\n",
    "media_error_div_list_random_per_confrontare_con_baseline1_primi40 = np.nanmean(error_div_list_random_per_confrontare_con_baseline1[:40])\n",
    "massimo_valore_assoluto_error_div_random_per_confrontare_con_baseline1 = max(abs(x) for x in error_div_list_random_per_confrontare_con_baseline1)\n",
    "\n",
    "# Creazione del DataFrame finale\n",
    "divergence_after_correctness_sottogruppi = pd.DataFrame({\n",
    "    'Metrics': [\n",
    "        'Accuracy', 'F1 Score', 'media divergenze', 'max div', 'media div primi 10', 'media div primi 20', 'media div primi 40', '# new samples'\n",
    "    ],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, media_error_div_list_no_mitigation, massimo_valore_assoluto_error_div_no_mitigation,\n",
    "        media_error_div_list_nomitigation_primi10, media_error_div_list_nomitigation_primi20, media_error_div_list_nomitigation_primi40, 0\n",
    "    ],\n",
    "    'After Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after, f1_score_fp_after, media_error_div_list_baseline1, error_div_massimo_valore_assoluto_error_div_baseline1,\n",
    "        media_error_div_list_baseline1_primi10, media_error_div_list_baseline1_primi20, media_error_div_list_baseline1_primi40, len(df_holdout_filtered)\n",
    "    ],\n",
    "    'After RANDOM Mitigation(K=5 fp)': [\n",
    "        accuracy_fp_after_random, f1_score_fp_after_random, media_error_div_list_random_per_confrontare_con_baseline1,\n",
    "        massimo_valore_assoluto_error_div_random_per_confrontare_con_baseline1, media_error_div_list_random_per_confrontare_con_baseline1_primi10,\n",
    "        media_error_div_list_random_per_confrontare_con_baseline1_primi20, media_error_div_list_random_per_confrontare_con_baseline1_primi40,\n",
    "        len(df_holdout_filtered)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Trasposizione per visualizzazione\n",
    "divergence_after_correctness_sottogruppi = divergence_after_correctness_sottogruppi.set_index('Metrics').T\n",
    "\n",
    "divergence_after_correctness_sottogruppi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SIMULANDO DATI ATTRAVERSO SMOTE\n",
    "\n",
    "SEGUE CODICE USANDO SMOTE \n",
    "DIVIDO IN TRAIN, TEST E VALIDATION -- ora uso quelli gia esistenti\n",
    "DIV EXPLORER SUL VALIDATION  -- gi√† fatto \n",
    "GENERO NUOVI DATI CON SMOTE a partire dai dati di divexplorer sul validation\n",
    "INSERISCO QUESTI NUOVI DATI NEL TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe del dataset filtrato 361\n",
      "numero di dati simulati con smotenc 598\n",
      "Violent_Recidivist\n",
      "0    299\n",
      "1    299\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "df_val_filtered = K_subgroups_dataset_and_or(df_pruned_error, df_val, K)\n",
    "print(\"Righe del dataset filtrato\",len(df_val_filtered))\n",
    "#df_val_filtered.head() #var categoriche e numeriche \n",
    "#print(len(df_val_filtered)) #--2610 con = 5\n",
    "df_val_filtered, inutile12, inutile222 = encoding_funct_SMOTE(df_val_filtered, df_test, df_holdout)\n",
    "X_to_SMOTE =  df_val_filtered.drop(columns = ['error', 'y_pred', 'Violent_Recidivist'], axis = 1)\n",
    "y_to_SMOTE = df_val_filtered[\"Violent_Recidivist\"]\n",
    "X_to_SMOTE.head()\n",
    "\n",
    "categorical_features = [0, 1, 7, 8]\n",
    "\n",
    "smote_nc = SMOTENC( categorical_features=categorical_features, random_state=seed)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "\n",
    "print(\"numero di dati simulati con smotenc\",len(y_resampled))\n",
    "\n",
    "class_counts = y_resampled.value_counts()\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIAS MITIGATION SMOTENC\n",
    "\n",
    "- FISSO N VARIA p, p √® la probabilit√† che il campione simulato sia di classe 0 qui (perch√® voglio diminuire il numero di falsi positivi)\n",
    "- FISSO p VARIA N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 299)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_1 = df_val_filtered['Violent_Recidivist'].sum()\n",
    "count_0 = len(df_val_filtered) - count_1\n",
    "count_1, count_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per confronto con targeted\n",
    "N come len_df_holdout_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = np.arange(0.0, 1.05, 0.1)\n",
    "p_values = np.round(p_values, 2).tolist()\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = a targeted (holdout filtrato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 377</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 1 = 0.0</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.955</td>\n",
       "      <td>19</td>\n",
       "      <td>170</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 1 = 0.1</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.949</td>\n",
       "      <td>9</td>\n",
       "      <td>169</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 1 = 0.2</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.955</td>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 1 = 0.3</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.955</td>\n",
       "      <td>6</td>\n",
       "      <td>170</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 1 = 0.4</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.961</td>\n",
       "      <td>6</td>\n",
       "      <td>171</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 1 = 0.5</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.966</td>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 1 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 1 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 1 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.966</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 1 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11352</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                              Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                       0.927     0.032                0.002   \n",
       "After RANDOM mitigation N = 377         0.927     0.032                0.002   \n",
       "After SMOTE N = 377 p_class 1 = 0.0     0.923     0.078                0.008   \n",
       "After SMOTE N = 377 p_class 1 = 0.1     0.927     0.092                0.004   \n",
       "After SMOTE N = 377 p_class 1 = 0.2     0.927     0.082                0.004   \n",
       "After SMOTE N = 377 p_class 1 = 0.3     0.928     0.083                0.003   \n",
       "After SMOTE N = 377 p_class 1 = 0.4     0.927     0.073                0.003   \n",
       "After SMOTE N = 377 p_class 1 = 0.5     0.928     0.064                0.001   \n",
       "After SMOTE N = 377 p_class 1 = 0.6     0.927     0.053                0.002   \n",
       "After SMOTE N = 377 p_class 1 = 0.7     0.927     0.043                0.002   \n",
       "After SMOTE N = 377 p_class 1 = 0.8     0.928     0.054                0.001   \n",
       "After SMOTE N = 377 p_class 1 = 0.9     0.928     0.064                0.002   \n",
       "After SMOTE N = 377 p_class 1 = 1.0     0.927     0.043                0.002   \n",
       "\n",
       "Metrics                              False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                  0.983                4   \n",
       "After RANDOM mitigation N = 377                    0.983                4   \n",
       "After SMOTE N = 377 p_class 1 = 0.0                0.955               19   \n",
       "After SMOTE N = 377 p_class 1 = 0.1                0.949                9   \n",
       "After SMOTE N = 377 p_class 1 = 0.2                0.955                9   \n",
       "After SMOTE N = 377 p_class 1 = 0.3                0.955                6   \n",
       "After SMOTE N = 377 p_class 1 = 0.4                0.961                6   \n",
       "After SMOTE N = 377 p_class 1 = 0.5                0.966                3   \n",
       "After SMOTE N = 377 p_class 1 = 0.6                0.972                5   \n",
       "After SMOTE N = 377 p_class 1 = 0.7                0.978                4   \n",
       "After SMOTE N = 377 p_class 1 = 0.8                0.972                3   \n",
       "After SMOTE N = 377 p_class 1 = 0.9                0.966                4   \n",
       "After SMOTE N = 377 p_class 1 = 1.0                0.978                4   \n",
       "\n",
       "Metrics                              False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                175       10975       2439  \n",
       "After RANDOM mitigation N = 377                  175       11352       2439  \n",
       "After SMOTE N = 377 p_class 1 = 0.0              170       11352       2439  \n",
       "After SMOTE N = 377 p_class 1 = 0.1              169       11352       2439  \n",
       "After SMOTE N = 377 p_class 1 = 0.2              170       11352       2439  \n",
       "After SMOTE N = 377 p_class 1 = 0.3              170       11352       2439  \n",
       "After SMOTE N = 377 p_class 1 = 0.4              171       11352       2439  \n",
       "After SMOTE N = 377 p_class 1 = 0.5              172       11352       2439  \n",
       "After SMOTE N = 377 p_class 1 = 0.6              173       11352       2439  \n",
       "After SMOTE N = 377 p_class 1 = 0.7              174       11352       2439  \n",
       "After SMOTE N = 377 p_class 1 = 0.8              173       11352       2439  \n",
       "After SMOTE N = 377 p_class 1 = 0.9              172       11352       2439  \n",
       "After SMOTE N = 377 p_class 1 = 1.0              174       11352       2439  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df_holdout_filtered)\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = FP_fm\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 377\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 377</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 0 = 0.0</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.078</td>\n",
       "      <td>19</td>\n",
       "      <td>170</td>\n",
       "      <td>189</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 0 = 0.1</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.092</td>\n",
       "      <td>9</td>\n",
       "      <td>169</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 0 = 0.2</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.082</td>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 0 = 0.3</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.083</td>\n",
       "      <td>6</td>\n",
       "      <td>170</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 0 = 0.4</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.073</td>\n",
       "      <td>6</td>\n",
       "      <td>171</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 0 = 0.5</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.064</td>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 0 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 0 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 0 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.064</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 377 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                              Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                       0.927     0.032                4   \n",
       "After RANDOM mitigation N = 377         0.927     0.032                4   \n",
       "After SMOTE N = 377 p_class 0 = 0.0     0.923     0.078               19   \n",
       "After SMOTE N = 377 p_class 0 = 0.1     0.927     0.092                9   \n",
       "After SMOTE N = 377 p_class 0 = 0.2     0.927     0.082                9   \n",
       "After SMOTE N = 377 p_class 0 = 0.3     0.928     0.083                6   \n",
       "After SMOTE N = 377 p_class 0 = 0.4     0.927     0.073                6   \n",
       "After SMOTE N = 377 p_class 0 = 0.5     0.928     0.064                3   \n",
       "After SMOTE N = 377 p_class 0 = 0.6     0.927     0.053                5   \n",
       "After SMOTE N = 377 p_class 0 = 0.7     0.927     0.043                4   \n",
       "After SMOTE N = 377 p_class 0 = 0.8     0.928     0.054                3   \n",
       "After SMOTE N = 377 p_class 0 = 0.9     0.928     0.064                4   \n",
       "After SMOTE N = 377 p_class 0 = 1.0     0.927     0.043                4   \n",
       "\n",
       "Metrics                              False Negatives  Total Errors  \\\n",
       "Before Mitigation                                175           179   \n",
       "After RANDOM mitigation N = 377                  175           179   \n",
       "After SMOTE N = 377 p_class 0 = 0.0              170           189   \n",
       "After SMOTE N = 377 p_class 0 = 0.1              169           178   \n",
       "After SMOTE N = 377 p_class 0 = 0.2              170           179   \n",
       "After SMOTE N = 377 p_class 0 = 0.3              170           176   \n",
       "After SMOTE N = 377 p_class 0 = 0.4              171           177   \n",
       "After SMOTE N = 377 p_class 0 = 0.5              172           175   \n",
       "After SMOTE N = 377 p_class 0 = 0.6              173           178   \n",
       "After SMOTE N = 377 p_class 0 = 0.7              174           178   \n",
       "After SMOTE N = 377 p_class 0 = 0.8              173           176   \n",
       "After SMOTE N = 377 p_class 0 = 0.9              172           176   \n",
       "After SMOTE N = 377 p_class 0 = 1.0              174           178   \n",
       "\n",
       "Metrics                              Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                             -0.013           0.057   \n",
       "After RANDOM mitigation N = 377               -0.013           0.060   \n",
       "After SMOTE N = 377 p_class 0 = 0.0           -0.016           0.068   \n",
       "After SMOTE N = 377 p_class 0 = 0.1           -0.013           0.055   \n",
       "After SMOTE N = 377 p_class 0 = 0.2           -0.013           0.056   \n",
       "After SMOTE N = 377 p_class 0 = 0.3           -0.012           0.051   \n",
       "After SMOTE N = 377 p_class 0 = 0.4           -0.012           0.056   \n",
       "After SMOTE N = 377 p_class 0 = 0.5           -0.012           0.057   \n",
       "After SMOTE N = 377 p_class 0 = 0.6           -0.013           0.058   \n",
       "After SMOTE N = 377 p_class 0 = 0.7           -0.012           0.055   \n",
       "After SMOTE N = 377 p_class 0 = 0.8           -0.012           0.056   \n",
       "After SMOTE N = 377 p_class 0 = 0.9           -0.012           0.059   \n",
       "After SMOTE N = 377 p_class 0 = 1.0           -0.012           0.055   \n",
       "\n",
       "Metrics                              Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                         0.039       0.030       0.017  \n",
       "After RANDOM mitigation N = 377           0.040       0.030       0.018  \n",
       "After SMOTE N = 377 p_class 0 = 0.0       0.044       0.031       0.017  \n",
       "After SMOTE N = 377 p_class 0 = 0.1       0.039       0.030       0.017  \n",
       "After SMOTE N = 377 p_class 0 = 0.2       0.039       0.029       0.016  \n",
       "After SMOTE N = 377 p_class 0 = 0.3       0.037       0.028       0.017  \n",
       "After SMOTE N = 377 p_class 0 = 0.4       0.038       0.029       0.017  \n",
       "After SMOTE N = 377 p_class 0 = 0.5       0.038       0.029       0.018  \n",
       "After SMOTE N = 377 p_class 0 = 0.6       0.039       0.030       0.017  \n",
       "After SMOTE N = 377 p_class 0 = 0.7       0.038       0.029       0.017  \n",
       "After SMOTE N = 377 p_class 0 = 0.8       0.039       0.029       0.017  \n",
       "After SMOTE N = 377 p_class 0 = 0.9       0.040       0.030       0.017  \n",
       "After SMOTE N = 377 p_class 0 = 1.0       0.038       0.029       0.017  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_confronto = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_confronto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 500</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.0</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.955</td>\n",
       "      <td>23</td>\n",
       "      <td>170</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.1</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.955</td>\n",
       "      <td>19</td>\n",
       "      <td>170</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.2</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.978</td>\n",
       "      <td>11</td>\n",
       "      <td>174</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.3</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.972</td>\n",
       "      <td>13</td>\n",
       "      <td>173</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.4</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.966</td>\n",
       "      <td>6</td>\n",
       "      <td>172</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.5</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.961</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.966</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.7</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.966</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.961</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 1 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                              Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                       0.927     0.032                0.002   \n",
       "After RANDOM mitigation N = 500         0.926     0.032                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 0.0     0.921     0.077                0.010   \n",
       "After SMOTE N = 500 p_class 1 = 0.1     0.923     0.078                0.008   \n",
       "After SMOTE N = 500 p_class 1 = 0.2     0.924     0.041                0.005   \n",
       "After SMOTE N = 500 p_class 1 = 0.3     0.924     0.051                0.006   \n",
       "After SMOTE N = 500 p_class 1 = 0.4     0.927     0.063                0.003   \n",
       "After SMOTE N = 500 p_class 1 = 0.5     0.928     0.074                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 0.6     0.927     0.063                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 0.7     0.928     0.064                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 0.8     0.927     0.043                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 0.9     0.928     0.074                0.002   \n",
       "After SMOTE N = 500 p_class 1 = 1.0     0.927     0.043                0.002   \n",
       "\n",
       "Metrics                              False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                  0.983                4   \n",
       "After RANDOM mitigation N = 500                    0.983                5   \n",
       "After SMOTE N = 500 p_class 1 = 0.0                0.955               23   \n",
       "After SMOTE N = 500 p_class 1 = 0.1                0.955               19   \n",
       "After SMOTE N = 500 p_class 1 = 0.2                0.978               11   \n",
       "After SMOTE N = 500 p_class 1 = 0.3                0.972               13   \n",
       "After SMOTE N = 500 p_class 1 = 0.4                0.966                6   \n",
       "After SMOTE N = 500 p_class 1 = 0.5                0.961                5   \n",
       "After SMOTE N = 500 p_class 1 = 0.6                0.966                5   \n",
       "After SMOTE N = 500 p_class 1 = 0.7                0.966                4   \n",
       "After SMOTE N = 500 p_class 1 = 0.8                0.978                4   \n",
       "After SMOTE N = 500 p_class 1 = 0.9                0.961                4   \n",
       "After SMOTE N = 500 p_class 1 = 1.0                0.978                4   \n",
       "\n",
       "Metrics                              False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                175       10975       2439  \n",
       "After RANDOM mitigation N = 500                  175       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.0              170       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.1              170       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.2              174       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.3              173       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.4              172       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.5              171       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.6              172       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.7              172       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.8              174       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 0.9              171       11475       2439  \n",
       "After SMOTE N = 500 p_class 1 = 1.0              174       11475       2439  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 500\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = FP_fm\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 500</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.032</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>180</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.0</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.077</td>\n",
       "      <td>23</td>\n",
       "      <td>170</td>\n",
       "      <td>193</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.1</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.078</td>\n",
       "      <td>19</td>\n",
       "      <td>170</td>\n",
       "      <td>189</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.2</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.041</td>\n",
       "      <td>11</td>\n",
       "      <td>174</td>\n",
       "      <td>185</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.3</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.051</td>\n",
       "      <td>13</td>\n",
       "      <td>173</td>\n",
       "      <td>186</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.4</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.063</td>\n",
       "      <td>6</td>\n",
       "      <td>172</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.5</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.074</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.063</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.7</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.064</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.074</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 500 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                              Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                       0.927     0.032                4   \n",
       "After RANDOM mitigation N = 500         0.926     0.032                5   \n",
       "After SMOTE N = 500 p_class 0 = 0.0     0.921     0.077               23   \n",
       "After SMOTE N = 500 p_class 0 = 0.1     0.923     0.078               19   \n",
       "After SMOTE N = 500 p_class 0 = 0.2     0.924     0.041               11   \n",
       "After SMOTE N = 500 p_class 0 = 0.3     0.924     0.051               13   \n",
       "After SMOTE N = 500 p_class 0 = 0.4     0.927     0.063                6   \n",
       "After SMOTE N = 500 p_class 0 = 0.5     0.928     0.074                5   \n",
       "After SMOTE N = 500 p_class 0 = 0.6     0.927     0.063                5   \n",
       "After SMOTE N = 500 p_class 0 = 0.7     0.928     0.064                4   \n",
       "After SMOTE N = 500 p_class 0 = 0.8     0.927     0.043                4   \n",
       "After SMOTE N = 500 p_class 0 = 0.9     0.928     0.074                4   \n",
       "After SMOTE N = 500 p_class 0 = 1.0     0.927     0.043                4   \n",
       "\n",
       "Metrics                              False Negatives  Total Errors  \\\n",
       "Before Mitigation                                175           179   \n",
       "After RANDOM mitigation N = 500                  175           180   \n",
       "After SMOTE N = 500 p_class 0 = 0.0              170           193   \n",
       "After SMOTE N = 500 p_class 0 = 0.1              170           189   \n",
       "After SMOTE N = 500 p_class 0 = 0.2              174           185   \n",
       "After SMOTE N = 500 p_class 0 = 0.3              173           186   \n",
       "After SMOTE N = 500 p_class 0 = 0.4              172           178   \n",
       "After SMOTE N = 500 p_class 0 = 0.5              171           176   \n",
       "After SMOTE N = 500 p_class 0 = 0.6              172           177   \n",
       "After SMOTE N = 500 p_class 0 = 0.7              172           176   \n",
       "After SMOTE N = 500 p_class 0 = 0.8              174           178   \n",
       "After SMOTE N = 500 p_class 0 = 0.9              171           175   \n",
       "After SMOTE N = 500 p_class 0 = 1.0              174           178   \n",
       "\n",
       "Metrics                              Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                             -0.013           0.057   \n",
       "After RANDOM mitigation N = 500               -0.013           0.060   \n",
       "After SMOTE N = 500 p_class 0 = 0.0           -0.017           0.073   \n",
       "After SMOTE N = 500 p_class 0 = 0.1           -0.016           0.068   \n",
       "After SMOTE N = 500 p_class 0 = 0.2           -0.015           0.062   \n",
       "After SMOTE N = 500 p_class 0 = 0.3           -0.015           0.062   \n",
       "After SMOTE N = 500 p_class 0 = 0.4           -0.013           0.055   \n",
       "After SMOTE N = 500 p_class 0 = 0.5           -0.012           0.054   \n",
       "After SMOTE N = 500 p_class 0 = 0.6           -0.012           0.056   \n",
       "After SMOTE N = 500 p_class 0 = 0.7           -0.012           0.056   \n",
       "After SMOTE N = 500 p_class 0 = 0.8           -0.012           0.055   \n",
       "After SMOTE N = 500 p_class 0 = 0.9           -0.012           0.057   \n",
       "After SMOTE N = 500 p_class 0 = 1.0           -0.013           0.055   \n",
       "\n",
       "Metrics                              Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                         0.039       0.030       0.017  \n",
       "After RANDOM mitigation N = 500           0.040       0.030       0.018  \n",
       "After SMOTE N = 500 p_class 0 = 0.0       0.045       0.031       0.016  \n",
       "After SMOTE N = 500 p_class 0 = 0.1       0.044       0.032       0.017  \n",
       "After SMOTE N = 500 p_class 0 = 0.2       0.040       0.029       0.016  \n",
       "After SMOTE N = 500 p_class 0 = 0.3       0.040       0.030       0.016  \n",
       "After SMOTE N = 500 p_class 0 = 0.4       0.038       0.029       0.017  \n",
       "After SMOTE N = 500 p_class 0 = 0.5       0.038       0.029       0.017  \n",
       "After SMOTE N = 500 p_class 0 = 0.6       0.038       0.029       0.017  \n",
       "After SMOTE N = 500 p_class 0 = 0.7       0.038       0.029       0.017  \n",
       "After SMOTE N = 500 p_class 0 = 0.8       0.038       0.029       0.017  \n",
       "After SMOTE N = 500 p_class 0 = 0.9       0.039       0.029       0.017  \n",
       "After SMOTE N = 500 p_class 0 = 1.0       0.038       0.029       0.017  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.0</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.938</td>\n",
       "      <td>36</td>\n",
       "      <td>167</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.1</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.944</td>\n",
       "      <td>32</td>\n",
       "      <td>168</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.2</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.961</td>\n",
       "      <td>15</td>\n",
       "      <td>171</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.3</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.955</td>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.4</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.983</td>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.5</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.978</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.978</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 1 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>11975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.927     0.032                0.002   \n",
       "After RANDOM mitigation N = 1000         0.928     0.054                0.001   \n",
       "After SMOTE N = 1000 p_class 1 = 0.0     0.917     0.098                0.016   \n",
       "After SMOTE N = 1000 p_class 1 = 0.1     0.918     0.091                0.014   \n",
       "After SMOTE N = 1000 p_class 1 = 0.2     0.924     0.070                0.007   \n",
       "After SMOTE N = 1000 p_class 1 = 0.3     0.926     0.081                0.005   \n",
       "After SMOTE N = 1000 p_class 1 = 0.4     0.926     0.032                0.003   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5     0.926     0.043                0.003   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6     0.927     0.043                0.002   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7     0.927     0.053                0.002   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8     0.928     0.054                0.001   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9     0.926     0.043                0.003   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0     0.927     0.053                0.002   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.983                4   \n",
       "After RANDOM mitigation N = 1000                    0.972                3   \n",
       "After SMOTE N = 1000 p_class 1 = 0.0                0.938               36   \n",
       "After SMOTE N = 1000 p_class 1 = 0.1                0.944               32   \n",
       "After SMOTE N = 1000 p_class 1 = 0.2                0.961               15   \n",
       "After SMOTE N = 1000 p_class 1 = 0.3                0.955               11   \n",
       "After SMOTE N = 1000 p_class 1 = 0.4                0.983                6   \n",
       "After SMOTE N = 1000 p_class 1 = 0.5                0.978                6   \n",
       "After SMOTE N = 1000 p_class 1 = 0.6                0.978                4   \n",
       "After SMOTE N = 1000 p_class 1 = 0.7                0.972                4   \n",
       "After SMOTE N = 1000 p_class 1 = 0.8                0.972                2   \n",
       "After SMOTE N = 1000 p_class 1 = 0.9                0.978                6   \n",
       "After SMOTE N = 1000 p_class 1 = 1.0                0.972                4   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 175       10975       2439  \n",
       "After RANDOM mitigation N = 1000                  173       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.0              167       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.1              168       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.2              171       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.3              170       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.4              175       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.5              174       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.6              174       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.7              173       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.8              173       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 0.9              174       11975       2439  \n",
       "After SMOTE N = 1000 p_class 1 = 1.0              173       11975       2439  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = FP_fm\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1000</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.0</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.098</td>\n",
       "      <td>36</td>\n",
       "      <td>167</td>\n",
       "      <td>203</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.1</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.091</td>\n",
       "      <td>32</td>\n",
       "      <td>168</td>\n",
       "      <td>200</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.2</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.070</td>\n",
       "      <td>15</td>\n",
       "      <td>171</td>\n",
       "      <td>186</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.3</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.081</td>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>181</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.4</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.032</td>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>181</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.5</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>180</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.8</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 0.9</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>180</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1000 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.927     0.032                4   \n",
       "After RANDOM mitigation N = 1000         0.928     0.054                3   \n",
       "After SMOTE N = 1000 p_class 0 = 0.0     0.917     0.098               36   \n",
       "After SMOTE N = 1000 p_class 0 = 0.1     0.918     0.091               32   \n",
       "After SMOTE N = 1000 p_class 0 = 0.2     0.924     0.070               15   \n",
       "After SMOTE N = 1000 p_class 0 = 0.3     0.926     0.081               11   \n",
       "After SMOTE N = 1000 p_class 0 = 0.4     0.926     0.032                6   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5     0.926     0.043                6   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6     0.927     0.043                4   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7     0.927     0.053                4   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8     0.928     0.054                2   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9     0.926     0.043                6   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0     0.927     0.053                4   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 175           179   \n",
       "After RANDOM mitigation N = 1000                  173           176   \n",
       "After SMOTE N = 1000 p_class 0 = 0.0              167           203   \n",
       "After SMOTE N = 1000 p_class 0 = 0.1              168           200   \n",
       "After SMOTE N = 1000 p_class 0 = 0.2              171           186   \n",
       "After SMOTE N = 1000 p_class 0 = 0.3              170           181   \n",
       "After SMOTE N = 1000 p_class 0 = 0.4              175           181   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5              174           180   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6              174           178   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7              173           177   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8              173           175   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9              174           180   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0              173           177   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                              -0.013           0.057   \n",
       "After RANDOM mitigation N = 1000               -0.013           0.060   \n",
       "After SMOTE N = 1000 p_class 0 = 0.0           -0.019           0.089   \n",
       "After SMOTE N = 1000 p_class 0 = 0.1           -0.019           0.083   \n",
       "After SMOTE N = 1000 p_class 0 = 0.2           -0.015           0.064   \n",
       "After SMOTE N = 1000 p_class 0 = 0.3           -0.013           0.058   \n",
       "After SMOTE N = 1000 p_class 0 = 0.4           -0.013           0.058   \n",
       "After SMOTE N = 1000 p_class 0 = 0.5           -0.013           0.057   \n",
       "After SMOTE N = 1000 p_class 0 = 0.6           -0.012           0.055   \n",
       "After SMOTE N = 1000 p_class 0 = 0.7           -0.012           0.058   \n",
       "After SMOTE N = 1000 p_class 0 = 0.8           -0.012           0.057   \n",
       "After SMOTE N = 1000 p_class 0 = 0.9           -0.013           0.059   \n",
       "After SMOTE N = 1000 p_class 0 = 1.0           -0.012           0.056   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.039       0.030       0.017  \n",
       "After RANDOM mitigation N = 1000           0.040       0.030       0.018  \n",
       "After SMOTE N = 1000 p_class 0 = 0.0       0.052       0.034       0.017  \n",
       "After SMOTE N = 1000 p_class 0 = 0.1       0.050       0.034       0.016  \n",
       "After SMOTE N = 1000 p_class 0 = 0.2       0.041       0.030       0.016  \n",
       "After SMOTE N = 1000 p_class 0 = 0.3       0.040       0.030       0.017  \n",
       "After SMOTE N = 1000 p_class 0 = 0.4       0.039       0.029       0.017  \n",
       "After SMOTE N = 1000 p_class 0 = 0.5       0.039       0.029       0.017  \n",
       "After SMOTE N = 1000 p_class 0 = 0.6       0.038       0.029       0.017  \n",
       "After SMOTE N = 1000 p_class 0 = 0.7       0.039       0.030       0.018  \n",
       "After SMOTE N = 1000 p_class 0 = 0.8       0.039       0.029       0.017  \n",
       "After SMOTE N = 1000 p_class 0 = 0.9       0.039       0.030       0.018  \n",
       "After SMOTE N = 1000 p_class 0 = 1.0       0.038       0.029       0.017  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_1000 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1500</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.0</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.927</td>\n",
       "      <td>41</td>\n",
       "      <td>165</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.1</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.944</td>\n",
       "      <td>37</td>\n",
       "      <td>168</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.2</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.938</td>\n",
       "      <td>22</td>\n",
       "      <td>167</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.3</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.949</td>\n",
       "      <td>17</td>\n",
       "      <td>169</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.4</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.978</td>\n",
       "      <td>14</td>\n",
       "      <td>174</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.5</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.972</td>\n",
       "      <td>7</td>\n",
       "      <td>173</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 0.9</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 1 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>12475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.927     0.032                0.002   \n",
       "After RANDOM mitigation N = 1500         0.928     0.054                0.001   \n",
       "After SMOTE N = 1500 p_class 1 = 0.0     0.916     0.112                0.018   \n",
       "After SMOTE N = 1500 p_class 1 = 0.1     0.916     0.089                0.016   \n",
       "After SMOTE N = 1500 p_class 1 = 0.2     0.923     0.104                0.010   \n",
       "After SMOTE N = 1500 p_class 1 = 0.3     0.924     0.088                0.008   \n",
       "After SMOTE N = 1500 p_class 1 = 0.4     0.923     0.041                0.006   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5     0.926     0.053                0.003   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6     0.927     0.053                0.002   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7     0.927     0.033                0.001   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8     0.927     0.053                0.002   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9     0.927     0.043                0.002   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0     0.927     0.032                0.002   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.983                4   \n",
       "After RANDOM mitigation N = 1500                    0.972                2   \n",
       "After SMOTE N = 1500 p_class 1 = 0.0                0.927               41   \n",
       "After SMOTE N = 1500 p_class 1 = 0.1                0.944               37   \n",
       "After SMOTE N = 1500 p_class 1 = 0.2                0.938               22   \n",
       "After SMOTE N = 1500 p_class 1 = 0.3                0.949               17   \n",
       "After SMOTE N = 1500 p_class 1 = 0.4                0.978               14   \n",
       "After SMOTE N = 1500 p_class 1 = 0.5                0.972                7   \n",
       "After SMOTE N = 1500 p_class 1 = 0.6                0.972                4   \n",
       "After SMOTE N = 1500 p_class 1 = 0.7                0.983                3   \n",
       "After SMOTE N = 1500 p_class 1 = 0.8                0.972                4   \n",
       "After SMOTE N = 1500 p_class 1 = 0.9                0.978                4   \n",
       "After SMOTE N = 1500 p_class 1 = 1.0                0.983                4   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 175       10975       2439  \n",
       "After RANDOM mitigation N = 1500                  173       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.0              165       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.1              168       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.2              167       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.3              169       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.4              174       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.5              173       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.6              173       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.7              175       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.8              173       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 0.9              174       12475       2439  \n",
       "After SMOTE N = 1500 p_class 1 = 1.0              175       12475       2439  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1500\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = FP_fm\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 1500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 1500</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.0</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.112</td>\n",
       "      <td>41</td>\n",
       "      <td>165</td>\n",
       "      <td>206</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.1</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.089</td>\n",
       "      <td>37</td>\n",
       "      <td>168</td>\n",
       "      <td>205</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.2</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.104</td>\n",
       "      <td>22</td>\n",
       "      <td>167</td>\n",
       "      <td>189</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.3</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.088</td>\n",
       "      <td>17</td>\n",
       "      <td>169</td>\n",
       "      <td>186</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.4</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.041</td>\n",
       "      <td>14</td>\n",
       "      <td>174</td>\n",
       "      <td>188</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.5</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.053</td>\n",
       "      <td>7</td>\n",
       "      <td>173</td>\n",
       "      <td>180</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 0.9</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 1500 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.927     0.032                4   \n",
       "After RANDOM mitigation N = 1500         0.928     0.054                2   \n",
       "After SMOTE N = 1500 p_class 0 = 0.0     0.916     0.112               41   \n",
       "After SMOTE N = 1500 p_class 0 = 0.1     0.916     0.089               37   \n",
       "After SMOTE N = 1500 p_class 0 = 0.2     0.923     0.104               22   \n",
       "After SMOTE N = 1500 p_class 0 = 0.3     0.924     0.088               17   \n",
       "After SMOTE N = 1500 p_class 0 = 0.4     0.923     0.041               14   \n",
       "After SMOTE N = 1500 p_class 0 = 0.5     0.926     0.053                7   \n",
       "After SMOTE N = 1500 p_class 0 = 0.6     0.927     0.053                4   \n",
       "After SMOTE N = 1500 p_class 0 = 0.7     0.927     0.033                3   \n",
       "After SMOTE N = 1500 p_class 0 = 0.8     0.927     0.053                4   \n",
       "After SMOTE N = 1500 p_class 0 = 0.9     0.927     0.043                4   \n",
       "After SMOTE N = 1500 p_class 0 = 1.0     0.927     0.032                4   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 175           179   \n",
       "After RANDOM mitigation N = 1500                  173           175   \n",
       "After SMOTE N = 1500 p_class 0 = 0.0              165           206   \n",
       "After SMOTE N = 1500 p_class 0 = 0.1              168           205   \n",
       "After SMOTE N = 1500 p_class 0 = 0.2              167           189   \n",
       "After SMOTE N = 1500 p_class 0 = 0.3              169           186   \n",
       "After SMOTE N = 1500 p_class 0 = 0.4              174           188   \n",
       "After SMOTE N = 1500 p_class 0 = 0.5              173           180   \n",
       "After SMOTE N = 1500 p_class 0 = 0.6              173           177   \n",
       "After SMOTE N = 1500 p_class 0 = 0.7              175           178   \n",
       "After SMOTE N = 1500 p_class 0 = 0.8              173           177   \n",
       "After SMOTE N = 1500 p_class 0 = 0.9              174           178   \n",
       "After SMOTE N = 1500 p_class 0 = 1.0              175           179   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                              -0.013           0.057   \n",
       "After RANDOM mitigation N = 1500               -0.013           0.060   \n",
       "After SMOTE N = 1500 p_class 0 = 0.0           -0.020           0.091   \n",
       "After SMOTE N = 1500 p_class 0 = 0.1           -0.020           0.090   \n",
       "After SMOTE N = 1500 p_class 0 = 0.2           -0.016           0.069   \n",
       "After SMOTE N = 1500 p_class 0 = 0.3           -0.015           0.064   \n",
       "After SMOTE N = 1500 p_class 0 = 0.4           -0.016           0.066   \n",
       "After SMOTE N = 1500 p_class 0 = 0.5           -0.013           0.055   \n",
       "After SMOTE N = 1500 p_class 0 = 0.6           -0.012           0.056   \n",
       "After SMOTE N = 1500 p_class 0 = 0.7           -0.012           0.055   \n",
       "After SMOTE N = 1500 p_class 0 = 0.8           -0.012           0.056   \n",
       "After SMOTE N = 1500 p_class 0 = 0.9           -0.013           0.058   \n",
       "After SMOTE N = 1500 p_class 0 = 1.0           -0.013           0.055   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.039       0.030       0.017  \n",
       "After RANDOM mitigation N = 1500           0.040       0.030       0.018  \n",
       "After SMOTE N = 1500 p_class 0 = 0.0       0.057       0.037       0.018  \n",
       "After SMOTE N = 1500 p_class 0 = 0.1       0.055       0.036       0.018  \n",
       "After SMOTE N = 1500 p_class 0 = 0.2       0.042       0.030       0.016  \n",
       "After SMOTE N = 1500 p_class 0 = 0.3       0.041       0.030       0.016  \n",
       "After SMOTE N = 1500 p_class 0 = 0.4       0.041       0.030       0.016  \n",
       "After SMOTE N = 1500 p_class 0 = 0.5       0.039       0.029       0.017  \n",
       "After SMOTE N = 1500 p_class 0 = 0.6       0.038       0.029       0.017  \n",
       "After SMOTE N = 1500 p_class 0 = 0.7       0.038       0.029       0.017  \n",
       "After SMOTE N = 1500 p_class 0 = 0.8       0.038       0.029       0.017  \n",
       "After SMOTE N = 1500 p_class 0 = 0.9       0.039       0.030       0.017  \n",
       "After SMOTE N = 1500 p_class 0 = 1.0       0.038       0.029       0.017  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_1500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_1500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.0</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.904</td>\n",
       "      <td>56</td>\n",
       "      <td>161</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.1</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.927</td>\n",
       "      <td>39</td>\n",
       "      <td>165</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.2</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.938</td>\n",
       "      <td>34</td>\n",
       "      <td>167</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.3</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.949</td>\n",
       "      <td>24</td>\n",
       "      <td>169</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.4</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.966</td>\n",
       "      <td>15</td>\n",
       "      <td>172</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.5</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.972</td>\n",
       "      <td>10</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.6</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.966</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.7</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.978</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 1 = 1.0</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>12975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.927     0.032                0.002   \n",
       "After RANDOM mitigation N = 2000         0.927     0.053                0.002   \n",
       "After SMOTE N = 2000 p_class 1 = 0.0     0.911     0.135                0.025   \n",
       "After SMOTE N = 2000 p_class 1 = 0.1     0.916     0.113                0.017   \n",
       "After SMOTE N = 2000 p_class 1 = 0.2     0.918     0.099                0.015   \n",
       "After SMOTE N = 2000 p_class 1 = 0.3     0.921     0.085                0.011   \n",
       "After SMOTE N = 2000 p_class 1 = 0.4     0.923     0.060                0.007   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5     0.925     0.052                0.004   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6     0.928     0.064                0.002   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7     0.926     0.043                0.003   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8     0.927     0.053                0.002   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9     0.928     0.054                0.001   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0     0.928     0.054                0.001   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.983                4   \n",
       "After RANDOM mitigation N = 2000                    0.972                4   \n",
       "After SMOTE N = 2000 p_class 1 = 0.0                0.904               56   \n",
       "After SMOTE N = 2000 p_class 1 = 0.1                0.927               39   \n",
       "After SMOTE N = 2000 p_class 1 = 0.2                0.938               34   \n",
       "After SMOTE N = 2000 p_class 1 = 0.3                0.949               24   \n",
       "After SMOTE N = 2000 p_class 1 = 0.4                0.966               15   \n",
       "After SMOTE N = 2000 p_class 1 = 0.5                0.972               10   \n",
       "After SMOTE N = 2000 p_class 1 = 0.6                0.966                4   \n",
       "After SMOTE N = 2000 p_class 1 = 0.7                0.978                6   \n",
       "After SMOTE N = 2000 p_class 1 = 0.8                0.972                4   \n",
       "After SMOTE N = 2000 p_class 1 = 0.9                0.972                2   \n",
       "After SMOTE N = 2000 p_class 1 = 1.0                0.972                3   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 175       10975       2439  \n",
       "After RANDOM mitigation N = 2000                  173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.0              161       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.1              165       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.2              167       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.3              169       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.4              172       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.5              173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.6              172       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.7              174       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.8              173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 0.9              173       12975       2439  \n",
       "After SMOTE N = 2000 p_class 1 = 1.0              173       12975       2439  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2000\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = FP_fm\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2000</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.0</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.135</td>\n",
       "      <td>56</td>\n",
       "      <td>161</td>\n",
       "      <td>217</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.1</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.113</td>\n",
       "      <td>39</td>\n",
       "      <td>165</td>\n",
       "      <td>204</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.2</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.099</td>\n",
       "      <td>34</td>\n",
       "      <td>167</td>\n",
       "      <td>201</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.3</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.085</td>\n",
       "      <td>24</td>\n",
       "      <td>169</td>\n",
       "      <td>193</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.4</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.060</td>\n",
       "      <td>15</td>\n",
       "      <td>172</td>\n",
       "      <td>187</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.5</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.052</td>\n",
       "      <td>10</td>\n",
       "      <td>173</td>\n",
       "      <td>183</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.6</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.064</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.7</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.043</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>180</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2000 p_class 0 = 1.0</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.927     0.032                4   \n",
       "After RANDOM mitigation N = 2000         0.927     0.053                4   \n",
       "After SMOTE N = 2000 p_class 0 = 0.0     0.911     0.135               56   \n",
       "After SMOTE N = 2000 p_class 0 = 0.1     0.916     0.113               39   \n",
       "After SMOTE N = 2000 p_class 0 = 0.2     0.918     0.099               34   \n",
       "After SMOTE N = 2000 p_class 0 = 0.3     0.921     0.085               24   \n",
       "After SMOTE N = 2000 p_class 0 = 0.4     0.923     0.060               15   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5     0.925     0.052               10   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6     0.928     0.064                4   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7     0.926     0.043                6   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8     0.927     0.053                4   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9     0.928     0.054                2   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0     0.928     0.054                3   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 175           179   \n",
       "After RANDOM mitigation N = 2000                  173           177   \n",
       "After SMOTE N = 2000 p_class 0 = 0.0              161           217   \n",
       "After SMOTE N = 2000 p_class 0 = 0.1              165           204   \n",
       "After SMOTE N = 2000 p_class 0 = 0.2              167           201   \n",
       "After SMOTE N = 2000 p_class 0 = 0.3              169           193   \n",
       "After SMOTE N = 2000 p_class 0 = 0.4              172           187   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5              173           183   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6              172           176   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7              174           180   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8              173           177   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9              173           175   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0              173           176   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                              -0.013           0.057   \n",
       "After RANDOM mitigation N = 2000               -0.013           0.060   \n",
       "After SMOTE N = 2000 p_class 0 = 0.0           -0.023           0.108   \n",
       "After SMOTE N = 2000 p_class 0 = 0.1           -0.020           0.090   \n",
       "After SMOTE N = 2000 p_class 0 = 0.2           -0.019           0.086   \n",
       "After SMOTE N = 2000 p_class 0 = 0.3           -0.017           0.073   \n",
       "After SMOTE N = 2000 p_class 0 = 0.4           -0.015           0.065   \n",
       "After SMOTE N = 2000 p_class 0 = 0.5           -0.014           0.059   \n",
       "After SMOTE N = 2000 p_class 0 = 0.6           -0.012           0.056   \n",
       "After SMOTE N = 2000 p_class 0 = 0.7           -0.013           0.057   \n",
       "After SMOTE N = 2000 p_class 0 = 0.8           -0.012           0.056   \n",
       "After SMOTE N = 2000 p_class 0 = 0.9           -0.012           0.054   \n",
       "After SMOTE N = 2000 p_class 0 = 1.0           -0.012           0.056   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.039       0.030       0.017  \n",
       "After RANDOM mitigation N = 2000           0.040       0.030       0.018  \n",
       "After SMOTE N = 2000 p_class 0 = 0.0       0.063       0.040       0.019  \n",
       "After SMOTE N = 2000 p_class 0 = 0.1       0.055       0.036       0.018  \n",
       "After SMOTE N = 2000 p_class 0 = 0.2       0.054       0.036       0.018  \n",
       "After SMOTE N = 2000 p_class 0 = 0.3       0.048       0.033       0.017  \n",
       "After SMOTE N = 2000 p_class 0 = 0.4       0.042       0.030       0.016  \n",
       "After SMOTE N = 2000 p_class 0 = 0.5       0.040       0.030       0.017  \n",
       "After SMOTE N = 2000 p_class 0 = 0.6       0.038       0.029       0.018  \n",
       "After SMOTE N = 2000 p_class 0 = 0.7       0.039       0.030       0.017  \n",
       "After SMOTE N = 2000 p_class 0 = 0.8       0.038       0.029       0.017  \n",
       "After SMOTE N = 2000 p_class 0 = 0.9       0.037       0.029       0.017  \n",
       "After SMOTE N = 2000 p_class 0 = 1.0       0.038       0.029       0.018  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_2000 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.983</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>10975</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2500</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.0</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.910</td>\n",
       "      <td>66</td>\n",
       "      <td>162</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.1</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.910</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.2</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.933</td>\n",
       "      <td>41</td>\n",
       "      <td>166</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.3</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.949</td>\n",
       "      <td>27</td>\n",
       "      <td>169</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.4</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.961</td>\n",
       "      <td>15</td>\n",
       "      <td>171</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.5</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.972</td>\n",
       "      <td>11</td>\n",
       "      <td>173</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.972</td>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.966</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 1 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>13475</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positive Rate  \\\n",
       "Before Mitigation                        0.927     0.032                0.002   \n",
       "After RANDOM mitigation N = 2500         0.927     0.033                0.001   \n",
       "After SMOTE N = 2500 p_class 1 = 0.0     0.907     0.123                0.029   \n",
       "After SMOTE N = 2500 p_class 1 = 0.1     0.912     0.130                0.023   \n",
       "After SMOTE N = 2500 p_class 1 = 0.2     0.915     0.104                0.018   \n",
       "After SMOTE N = 2500 p_class 1 = 0.3     0.920     0.084                0.012   \n",
       "After SMOTE N = 2500 p_class 1 = 0.4     0.924     0.070                0.007   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5     0.925     0.052                0.005   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6     0.927     0.053                0.003   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7     0.927     0.053                0.002   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8     0.927     0.053                0.002   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9     0.928     0.064                0.002   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0     0.927     0.033                0.001   \n",
       "\n",
       "Metrics                               False Negative Rate  False Positives  \\\n",
       "Before Mitigation                                   0.983                4   \n",
       "After RANDOM mitigation N = 2500                    0.983                3   \n",
       "After SMOTE N = 2500 p_class 1 = 0.0                0.910               66   \n",
       "After SMOTE N = 2500 p_class 1 = 0.1                0.910               53   \n",
       "After SMOTE N = 2500 p_class 1 = 0.2                0.933               41   \n",
       "After SMOTE N = 2500 p_class 1 = 0.3                0.949               27   \n",
       "After SMOTE N = 2500 p_class 1 = 0.4                0.961               15   \n",
       "After SMOTE N = 2500 p_class 1 = 0.5                0.972               11   \n",
       "After SMOTE N = 2500 p_class 1 = 0.6                0.972                6   \n",
       "After SMOTE N = 2500 p_class 1 = 0.7                0.972                4   \n",
       "After SMOTE N = 2500 p_class 1 = 0.8                0.972                4   \n",
       "After SMOTE N = 2500 p_class 1 = 0.9                0.966                4   \n",
       "After SMOTE N = 2500 p_class 1 = 1.0                0.983                3   \n",
       "\n",
       "Metrics                               False Negatives  Train Size  Test Size  \n",
       "Before Mitigation                                 175       10975       2439  \n",
       "After RANDOM mitigation N = 2500                  175       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.0              162       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.1              162       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.2              166       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.3              169       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.4              171       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.5              173       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.6              173       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.7              173       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.8              173       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 0.9              172       13475       2439  \n",
       "After SMOTE N = 2500 p_class 1 = 1.0              175       13475       2439  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2500\n",
    "\n",
    "# Dizionari per salvare i risultati\n",
    "X_train_mit_SMOTE_dict = {}\n",
    "y_train_mit_SMOTE_dict = {}\n",
    "y_pred_SMOTE_dict = {}\n",
    "metrics_results_compare = {}\n",
    "error_div_results = {}\n",
    "\n",
    "original_size = len(X_to_SMOTE)\n",
    "\n",
    "for p in p_values:\n",
    "    sampling_strategy = {0: count_0 + int(N * p), 1: count_1 + int(N * (1 - p))}\n",
    "    \n",
    "    smote_nc = SMOTENC(sampling_strategy=sampling_strategy, categorical_features=categorical_features, random_state=seed)\n",
    "    X_sampled_SMOTE, y_sampled_SMOTE = smote_nc.fit_resample(X_to_SMOTE, y_to_SMOTE)\n",
    "    \n",
    "    X_generated = X_sampled_SMOTE[-N:]\n",
    "    y_generated = y_sampled_SMOTE[-N:]\n",
    "    \n",
    "    X_train_mit_SMOTE_dict[p] = pd.concat([X_train, X_generated], ignore_index=True)\n",
    "    y_train_mit_SMOTE_dict[p] = pd.concat([y_train, y_generated], ignore_index=True)\n",
    "    \n",
    "    classifier = GradientBoostingClassifier(random_state=seed)\n",
    "    classifier.fit(X_train_mit_SMOTE_dict[p], y_train_mit_SMOTE_dict[p])\n",
    "    y_pred_SMOTE_dict[p] = classifier.predict(X_test)\n",
    "    \n",
    "    metrics_results_compare[p] = metrics_to_compare(y_true=y_test, y_pred=y_pred_SMOTE_dict[p])\n",
    "    \n",
    "    df_test_class = X_test.copy()\n",
    "    df_test_class['y_test_true'] = y_test\n",
    "    df_test_class['y_pred'] = y_pred_SMOTE_dict[p]\n",
    "    df_test_class['error'] = (df_test_class[\"y_test_true\"] != df_test_class[\"y_pred\"]).astype(int)\n",
    "\n",
    "    \n",
    "    df_test['error'] = df_test_class['error']\n",
    "    df_test['y_pred'] = df_test_class['y_pred']\n",
    "    \n",
    "    error_diver = DivergenceExplorer(df_test)\n",
    "    \n",
    "    FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "    FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "    \n",
    "    error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "    df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "    df_pruned_error = FP_fm\n",
    "    \n",
    "    error_div_results[p] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Valori randomici per confronto senza mitigazione\n",
    "df_holdout_smote_sampled = df_holdout_enc.sample(n=N, replace=True, random_state=seed)\n",
    "df_combinated_random_smote = pd.concat([df_holdout_smote_sampled, df_train_enc], ignore_index=True)\n",
    "df_train_mitigated_random_smote = df_combinated_random_smote.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "X_train_mitigated_random_smote = df_train_mitigated_random_smote.drop(columns=\"Violent_Recidivist\", axis=1)\n",
    "y_train_mitigated_random_smote = df_train_mitigated_random_smote['Violent_Recidivist']\n",
    "\n",
    "classifier_train_mitigated_random_smote_p = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_train_mitigated_random_smote_p.fit(X_train_mitigated_random_smote, y_train_mitigated_random_smote)\n",
    "y_mitigated_pred_random_smote_p = classifier_train_mitigated_random_smote_p.predict(X_test)\n",
    "\n",
    "accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p = metrics_to_compare(y_true=y_test, y_pred=y_mitigated_pred_random_smote_p)\n",
    "\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positive Rate', 'False Negative Rate', 'False Positives', 'False Negatives', 'Train Size', 'Test Size'],\n",
    "    'Before Mitigation': [accuracy_before, f1_score_before, fpr_before, fnr_before, fp_before, fn_before, len(y_train), len(y_test)],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, fpr_fp_after_SMOTE_random_p, fnr_fp_after_SMOTE_random_p, fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, len(X_train_mitigated_random_smote), len(y_mitigated_pred_random_smote_p)]\n",
    "})\n",
    "\n",
    "for p in p_values:\n",
    "    metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 1 = {p}'] = list(metrics_results_compare[p]) + [len(X_train_mit_SMOTE_dict[p]), len(y_pred_SMOTE_dict[p])]\n",
    "\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Train Size', 'Test Size']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "# Mostrare la tabella finale\n",
    "metrics_after_fp_SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di punti aggiunti 2500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Total Errors</th>\n",
       "      <th>Mean Divergence</th>\n",
       "      <th>Max Divergence</th>\n",
       "      <th>Top 10 Div</th>\n",
       "      <th>Top 20 Div</th>\n",
       "      <th>Top 40 Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before Mitigation</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After RANDOM mitigation N = 2500</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.0</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.123</td>\n",
       "      <td>66</td>\n",
       "      <td>162</td>\n",
       "      <td>228</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.1</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.130</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>215</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.2</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.104</td>\n",
       "      <td>41</td>\n",
       "      <td>166</td>\n",
       "      <td>207</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.3</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.084</td>\n",
       "      <td>27</td>\n",
       "      <td>169</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.4</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.070</td>\n",
       "      <td>15</td>\n",
       "      <td>171</td>\n",
       "      <td>186</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.5</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.052</td>\n",
       "      <td>11</td>\n",
       "      <td>173</td>\n",
       "      <td>184</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.6</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.7</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.8</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.053</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 0.9</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.064</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After SMOTE N = 2500 p_class 0 = 1.0</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.033</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                               Accuracy  F1 Score  False Positives  \\\n",
       "Before Mitigation                        0.927     0.032                4   \n",
       "After RANDOM mitigation N = 2500         0.927     0.033                3   \n",
       "After SMOTE N = 2500 p_class 0 = 0.0     0.907     0.123               66   \n",
       "After SMOTE N = 2500 p_class 0 = 0.1     0.912     0.130               53   \n",
       "After SMOTE N = 2500 p_class 0 = 0.2     0.915     0.104               41   \n",
       "After SMOTE N = 2500 p_class 0 = 0.3     0.920     0.084               27   \n",
       "After SMOTE N = 2500 p_class 0 = 0.4     0.924     0.070               15   \n",
       "After SMOTE N = 2500 p_class 0 = 0.5     0.925     0.052               11   \n",
       "After SMOTE N = 2500 p_class 0 = 0.6     0.927     0.053                6   \n",
       "After SMOTE N = 2500 p_class 0 = 0.7     0.927     0.053                4   \n",
       "After SMOTE N = 2500 p_class 0 = 0.8     0.927     0.053                4   \n",
       "After SMOTE N = 2500 p_class 0 = 0.9     0.928     0.064                4   \n",
       "After SMOTE N = 2500 p_class 0 = 1.0     0.927     0.033                3   \n",
       "\n",
       "Metrics                               False Negatives  Total Errors  \\\n",
       "Before Mitigation                                 175           179   \n",
       "After RANDOM mitigation N = 2500                  175           178   \n",
       "After SMOTE N = 2500 p_class 0 = 0.0              162           228   \n",
       "After SMOTE N = 2500 p_class 0 = 0.1              162           215   \n",
       "After SMOTE N = 2500 p_class 0 = 0.2              166           207   \n",
       "After SMOTE N = 2500 p_class 0 = 0.3              169           196   \n",
       "After SMOTE N = 2500 p_class 0 = 0.4              171           186   \n",
       "After SMOTE N = 2500 p_class 0 = 0.5              173           184   \n",
       "After SMOTE N = 2500 p_class 0 = 0.6              173           179   \n",
       "After SMOTE N = 2500 p_class 0 = 0.7              173           177   \n",
       "After SMOTE N = 2500 p_class 0 = 0.8              173           177   \n",
       "After SMOTE N = 2500 p_class 0 = 0.9              172           176   \n",
       "After SMOTE N = 2500 p_class 0 = 1.0              175           178   \n",
       "\n",
       "Metrics                               Mean Divergence  Max Divergence  \\\n",
       "Before Mitigation                              -0.013           0.057   \n",
       "After RANDOM mitigation N = 2500               -0.013           0.060   \n",
       "After SMOTE N = 2500 p_class 0 = 0.0           -0.026           0.122   \n",
       "After SMOTE N = 2500 p_class 0 = 0.1           -0.022           0.104   \n",
       "After SMOTE N = 2500 p_class 0 = 0.2           -0.021           0.093   \n",
       "After SMOTE N = 2500 p_class 0 = 0.3           -0.018           0.079   \n",
       "After SMOTE N = 2500 p_class 0 = 0.4           -0.015           0.064   \n",
       "After SMOTE N = 2500 p_class 0 = 0.5           -0.014           0.059   \n",
       "After SMOTE N = 2500 p_class 0 = 0.6           -0.013           0.055   \n",
       "After SMOTE N = 2500 p_class 0 = 0.7           -0.012           0.056   \n",
       "After SMOTE N = 2500 p_class 0 = 0.8           -0.012           0.056   \n",
       "After SMOTE N = 2500 p_class 0 = 0.9           -0.012           0.056   \n",
       "After SMOTE N = 2500 p_class 0 = 1.0           -0.012           0.055   \n",
       "\n",
       "Metrics                               Top 10 Div  Top 20 Div  Top 40 Div  \n",
       "Before Mitigation                          0.039       0.030       0.017  \n",
       "After RANDOM mitigation N = 2500           0.040       0.030       0.018  \n",
       "After SMOTE N = 2500 p_class 0 = 0.0       0.070       0.043       0.019  \n",
       "After SMOTE N = 2500 p_class 0 = 0.1       0.063       0.040       0.019  \n",
       "After SMOTE N = 2500 p_class 0 = 0.2       0.055       0.036       0.018  \n",
       "After SMOTE N = 2500 p_class 0 = 0.3       0.050       0.034       0.017  \n",
       "After SMOTE N = 2500 p_class 0 = 0.4       0.040       0.029       0.016  \n",
       "After SMOTE N = 2500 p_class 0 = 0.5       0.039       0.029       0.016  \n",
       "After SMOTE N = 2500 p_class 0 = 0.6       0.038       0.029       0.017  \n",
       "After SMOTE N = 2500 p_class 0 = 0.7       0.038       0.029       0.017  \n",
       "After SMOTE N = 2500 p_class 0 = 0.8       0.038       0.029       0.017  \n",
       "After SMOTE N = 2500 p_class 0 = 0.9       0.038       0.029       0.017  \n",
       "After SMOTE N = 2500 p_class 0 = 1.0       0.038       0.029       0.017  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dizionario per salvare i risultati della divergenza\n",
    "error_div_results = {}\n",
    "\n",
    "# Lista degli esperimenti con l'ordine desiderato\n",
    "experiments = {\n",
    "    \"no_mitigation\": y_pred,  # Prima Before Mitigation\n",
    "    \"random\": y_mitigated_pred_random,  # Poi Random\n",
    "    \"SMOTE\": p_values  # Infine SMOTE per tutti i valori di p\n",
    "}\n",
    "\n",
    "# Iteriamo su ogni esperimento nell'ordine corretto\n",
    "for exp_name, preds in experiments.items():\n",
    "    # Se √® \"SMOTE\", iteriamo su p_values, altrimenti √® un unico array di predizioni\n",
    "    if exp_name == \"SMOTE\":\n",
    "        iter_values = preds  # Lista dei valori di p\n",
    "    else:\n",
    "        iter_values = [None]  # Solo una iterazione, con chiave fissa per il dizionario\n",
    "\n",
    "    for p in iter_values:\n",
    "        # Creazione del DataFrame per il test set\n",
    "        df_test_class = X_test.copy()\n",
    "        df_test_class['y_test_true'] = y_test\n",
    "        \n",
    "        # Se l'esperimento √® SMOTE, usiamo il dizionario dei risultati, altrimenti prendiamo direttamente il valore\n",
    "        df_test_class['y_pred'] = y_pred_SMOTE_dict[p] if exp_name == \"SMOTE\" else preds\n",
    "\n",
    "        # Calcolo errori\n",
    "        y_trues = df_test_class[\"y_test_true\"]\n",
    "        y_preds = df_test_class[\"y_pred\"]\n",
    "        df_test_class['error'] =  (y_trues != y_preds).astype(int)\n",
    "        # Aggiunta delle feature calcolate a df_test\n",
    "        df_test['error'] = df_test_class['error']\n",
    "        df_test['y_pred'] = df_test_class['y_pred']\n",
    "\n",
    "        # Analisi della divergenza\n",
    "        error_diver = DivergenceExplorer(df_test)\n",
    "        \n",
    "        FP_fm = error_diver.get_pattern_divergence(min_support=min_sup, attributes=attributes, boolean_outcomes=['error'])\n",
    "        FP_fm = FP_fm.sort_values(by=\"error_div\", ascending=False, ignore_index=True)\n",
    "\n",
    "        # Pruning\n",
    "        error_details = DivergencePatternProcessor(FP_fm, 'error')\n",
    "        df_pruned_error = error_details.redundancy_pruning(th_redundancy=epsilon)\n",
    "        df_pruned_error = FP_fm\n",
    "\n",
    "        # Salviamo i risultati in un dizionario con una chiave fissa per no_mitigation/random\n",
    "        key = (exp_name, p) if exp_name == \"SMOTE\" else exp_name\n",
    "        error_div_results[key] = df_pruned_error[\"error_div\"].tolist()\n",
    "\n",
    "# Calcolo delle metriche dai risultati della divergenza\n",
    "results = {\n",
    "    key: {\n",
    "        \"media\": np.nanmean(fp_div_list),\n",
    "        \"media_primi10\": np.nanmean(fp_div_list[:10]),\n",
    "        \"media_primi20\": np.nanmean(fp_div_list[:20]),\n",
    "        \"media_primi40\": np.nanmean(fp_div_list[:40]),\n",
    "        \"massimo_valore_assoluto\": np.nanmax(np.abs(fp_div_list))\n",
    "    }\n",
    "    for key, fp_div_list in error_div_results.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Creazione della tabella dei risultati con le nuove metriche\n",
    "metrics_after_fp_SMOTE = pd.DataFrame({\n",
    "    'Metrics': ['Accuracy', 'F1 Score', 'False Positives', 'False Negatives', 'Total Errors', \n",
    "                'Mean Divergence', 'Max Divergence', 'Top 10 Div', 'Top 20 Div', 'Top 40 Div'],\n",
    "    'Before Mitigation': [\n",
    "        accuracy_before, f1_score_before, fp_before, fn_before, \n",
    "        fp_before + fn_before, results['no_mitigation']['media'], results['no_mitigation']['massimo_valore_assoluto'], \n",
    "        results['no_mitigation']['media_primi10'], results['no_mitigation']['media_primi20'], results['no_mitigation']['media_primi40']\n",
    "    ],\n",
    "    'After RANDOM mitigation N = {}'.format(N): [\n",
    "        accuracy_fp_after_SMOTE_random_p, f1_score_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p, fn_fp_after_SMOTE_random_p, \n",
    "        fp_fp_after_SMOTE_random_p + fn_fp_after_SMOTE_random_p,\n",
    "        results['random']['media'], results['random']['massimo_valore_assoluto'],\n",
    "        results['random']['media_primi10'], results['random']['media_primi20'], results['random']['media_primi40']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Aggiunta delle colonne per ogni valore di p\n",
    "for p in p_values:\n",
    "    if ('SMOTE', p) in results:\n",
    "        metrics_after_fp_SMOTE[f'After SMOTE N = {N} p_class 0 = {p}'] = [\n",
    "            metrics_results_compare[p][0],  # Accuracy\n",
    "            metrics_results_compare[p][1],  # F1 Score\n",
    "            metrics_results_compare[p][4],  # False Positives\n",
    "            metrics_results_compare[p][5],  # False Negatives\n",
    "            metrics_results_compare[p][4] + metrics_results_compare[p][5],  # Total Errors\n",
    "            results[('SMOTE', p)]['media'],\n",
    "            results[('SMOTE', p)]['massimo_valore_assoluto'],\n",
    "            results[('SMOTE', p)]['media_primi10'],\n",
    "            results[('SMOTE', p)]['media_primi20'],\n",
    "            results[('SMOTE', p)]['media_primi40']\n",
    "        ]\n",
    "\n",
    "# Trasformare la tabella in formato leggibile\n",
    "metrics_after_fp_SMOTE = metrics_after_fp_SMOTE.set_index('Metrics').T\n",
    "\n",
    "# Castare i valori interi per alcune metriche\n",
    "metrics_to_cast = ['False Positives', 'False Negatives', 'Total Errors']\n",
    "for metric in metrics_to_cast:\n",
    "    metrics_after_fp_SMOTE[metric] = metrics_after_fp_SMOTE[metric].astype(int)\n",
    "\n",
    "print(\"numero di punti aggiunti\", N)\n",
    "metrics_after_fp_SMOTE_2500 = metrics_after_fp_SMOTE\n",
    "metrics_after_fp_SMOTE_2500\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dati salvati correttamente in error_K_compas.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"error_K_compas.json\"\n",
    "\n",
    "# 1Ô∏è‚É£ Controlla se il file esiste e carica i dati\n",
    "if os.path.exists(json_filename):\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        error_data = json.load(f)\n",
    "else:\n",
    "    error_data = {}\n",
    "\n",
    "# 2Ô∏è‚É£ Salvataggio dei parametri principali\n",
    "error_data[\"run6_parameters\"] = {\n",
    "    \"min_sup\": min_sup,\n",
    "    \"percentage\": percentage,\n",
    "    \"th_redundancy\": pruning,\n",
    "    \"K\": K,\n",
    "    \"L\": filtered_instances  # Supponiamo che sia la lunghezza di filtered_instances\n",
    "}\n",
    "\n",
    "# 3Ô∏è‚É£ Dizionario con i dataset da salvare\n",
    "metrics_dict = {\n",
    "    \"1K\": metrics_after_fp_SMOTE_500,\n",
    "    \"2K\": metrics_after_fp_SMOTE_1000,\n",
    "    \"3K\": metrics_after_fp_SMOTE_1500,\n",
    "    \"4K\": metrics_after_fp_SMOTE_2000,\n",
    "    \"5K\": metrics_after_fp_SMOTE_2500\n",
    "}\n",
    "\n",
    "# 4Ô∏è‚É£ Loop per salvare i valori di errore\n",
    "for J, metrics in metrics_dict.items():\n",
    "    run_name = f\"N={J}_run6\"  # Nome corretto della run\n",
    "    error_data[run_name] = {}  # Inizializziamo il dizionario per la run\n",
    "    \n",
    "    for key, val in metrics[\"Total Errors\"].items():\n",
    "        # Se √® \"Before Mitigation\", lo salviamo direttamente\n",
    "        if \"Before Mitigation\" in key:\n",
    "            json_key = \"Before Mitigation\"\n",
    "        else:\n",
    "            # Estrai p_class 0 se presente nella stringa\n",
    "            parts = key.split(\"p_class 0 = \")\n",
    "            if len(parts) > 1:\n",
    "                try:\n",
    "                    p_value = round(float(parts[1]), 2)\n",
    "                except ValueError:\n",
    "                    continue  # Se non √® un numero, lo ignoriamo\n",
    "            else:\n",
    "                p_value = \"unknown\"\n",
    "\n",
    "            json_key = f\"After SMOTE N = {J}000 p_class 0 = {p_value}\"\n",
    "\n",
    "        error_data[run_name][json_key] = val  # Salva il valore degli errori\n",
    "\n",
    "# 5Ô∏è‚É£ Salvare il JSON aggiornato\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(error_data, f, indent=4)\n",
    "\n",
    "print(f\"‚úÖ Dati salvati correttamente in {json_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAJJCAYAAACgQAbrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd1gU19fA8e+y9C5IFQR77xVjwYY1Ro2xxF5i4ou9JRpjF3uPJSZGzc/YYtQkdjRir9hij0bFAmIFEZSy8/6xYeNKR3ABz+d59pG5c+fOmWXAPdw796oURVEQQgghhBBCCJFuRoYOQAghhBBCCCFyG0mkhBBCCCGEECKDJJESQgghhBBCiAySREoIIYQQQgghMkgSKSGEEEIIIYTIIEmkhBBCCCGEECKDJJESQgghhBBCiAySREoIIYQQQgghMkgSKSGEEEIIIYTIIEmkhBBCCCGEECKDJJESQohMCgoKQqVSpfnq0aOH3nHJ1TEyMsLKyooSJUrQs2dPzpw5k+w53+bYRGFhYYwfP55atWqRP39+TE1NcXBwoEqVKowYMYJ//vkn2eNWrlyZ7PmNjY1xdHSkZs2aTJ48mYiIiAy9jz169EjS5qZNm5Kt26lTpyR1g4KCdPvf/J6sXLkSAF9f33R9r9I61tvbO8XrOHXqFP3796dSpUo4OjpiYmKCtbU1xYoVo3Xr1sydO5e7d++meHxYWBgmJiZ6MbRr106vzvjx4zN8HYn335vH3rp1K9k4Dh48SK9evShRogQ2NjaYmZnh7u5O8+bN+e6773j58mWyx735Hn/yySdJ6gwfPlyvjhBC5GaSSAkhRA6gKArR0dFcu3aNlStXUqNGDbZv357lx65atYrChQszYcIEjh49yuPHj4mLi+Pp06ecPn2aWbNmUaJECWbMmJHu2BMSEnjy5AnHjx/nm2++oWbNmjx//jzdxydnwYIFScru37/Pxo0b36rd7PDs2TPat29PtWrVWLRoEWfPnuXJkyfEx8fz4sULrl+/zm+//cbQoUPp06dPiu3873//Iz4+Xq/sjz/+4MmTJ9l9CQBERUXRoUMH6taty4oVK7h27RpRUVHExsYSGhrKjh07+OKLLyhVqhTBwcFptvfrr79y+vTpdxC5EEIYhrGhAxBCiLyiQ4cOVK1aNUl52bJlUzymatWqdOjQgZcvX3L06FFdAhQXF8eYMWNo3rx5lh27bt06vd4xCwsLOnbsSNGiRbl79y5r167l2bNnxMfH8+WXX2JkZMTw4cNTPP8XX3xBkSJFePz4MevWrdP1cFy5coUVK1YwcODAFI9Ny/79+zl//jzly5fXlS1evDhJopFe/fr1o2XLlnplI0aM0H2d+F6+rlq1amm2++LFC5o0acKJEyd0Zfb29rRq1YpixYqhKAp37tzh6NGjXLhwIdW2Vq1alaQsNjaWNWvW0L9/fwD8/PywtrbWq7NkyRJdL2K+fPkYPXq03v7U7r9EGo2GDh066CXgxYoVo02bNtjY2OjdX7du3aJx48YcP36cYsWKpdimoih8/fXX7NixI83zCyFErqQIIYTIlH379imA7rVixYp0Hff6Md27d9fbV6NGDd0+MzOzLDs2MjJScXR01O23s7NTLly4oFfnzp07ioeHh14bISEhuv0rVqzQO/++fft0+y5fvqy37/PPP0/Xe6EoitK9e3fdcUZGRrqve/furavz8uVLxcnJSQEUtVqdYhwZ+Z6k9l6+rl69erp6Xl5eevtGjRql107Tpk2Vp0+fJtvO1atXlVWrViW778SJE3rtFC9eXPd1lSpVUowtrfheN27cOL1z3Lx5U7fv559/1tvXrFkz5dWrV3rHr1y5Msm1phTH668DBw7o6gwbNkxvnxBC5GYytE8IIXKQAgUK6L7Onz9/lh3766+/8vjxY932gAEDKFOmjF4dDw8PvvnmG932q1ev+PHHHzN87uTOn1758uWjdu3aAKxZs0YX85o1a3j48CEArVq1ylTbWS0uLo5Fixbptl1cXPjll1+wt7dPtn7x4sXp1q1bsvtWrFih+9rDw0NvaGVwcDB//fVX1gSdgmXLlum+NjIyYt68eZiamurV6d69Oz4+PrrtnTt3cvv27WTbc3JyQq1WAzBq1KhsiFgIIQxPEikhhMgiO3fuZNasWUled+7cSfPYly9f8ueffxIYGKgra9++fbrOm55jDx48qLed3EQAQJLhbW8el5wnT54wefJk3XZKEw2k16BBgwCIiYnh+++/B/57ZsrGxoaePXtmuu2sdPLkSSIjI3XbHTt2TDLsLj1evXrFunXrdNvt27enWbNmeglZ4sQX2SEhIYGjR4/qtitUqEDx4sWTrZve+6NgwYJ07doVgMOHD7Nt27YsilYIIXIOSaSEECKLrF+/nhEjRiR53bhxI8VjVq1ahUqlwsLCgoYNG/L8+XNUKhVdunQhICAg1fNl5NjQ0FC9bS8vr2TbtLOzw87OLsXjXle/fn1UKhWOjo66HpR8+fLxv//9jwoVKqQae2ratGlDwYIFAe1zUfv27ePs2bOAdoY/GxubTLedle7du6e3XaJECb3tr776KtlZ9F6fZRDgt99+4+nTp7rtTp06YWpqStu2bXVlP//8c6afD0vL48ePiY2N1W2ndG8kty+1+2P8+PG6Xq0xY8agKMpbRiqEEDmLJFJCCJHDVKlShbFjx2Jubv5Oj80KvXr1SndPWkrUajX+/v4A3LlzR9ezoVKpGDBgwFvHmF0yO533671NRYsW1U1Y0rFjR135gwcP0j2LY07h5eXF559/DsDZs2dZv369gSMSQoisJYmUEEJkkRUrVqAoSpKXr69visdUrVqVGTNm0KdPH91f70+dOkXdunV58OBBqufLyLFubm562yk92xIREaG3DtSbx73uiy++YNKkSdSpU0dXNnv2bPr27Ztq3OnRp08fLC0tgf96fpo1a5bqLHHv2pvPhV29elVvu0WLFsycOZNevXql2Mb9+/fZvXu3bvv1oXMNGjTA2dlZt51dw/scHR31nodK6d5Ibl9q9wfA119/jZWVFQBjx47Ntl41IYQwBEmkhBDCgMqUKcOIESP4/vvv9aa/DgsLSzKN9dsc+3qyA6S4HtOGDRtSPe51HTp0YMyYMQQFBdGsWTNd+cqVK9P1bFVqHBwc6NKli17Z20ynnh2qVaumN8xww4YNxMTE6Lbr1KnD8OHDadOmTYpt/O9//yMhIUG3PWXKFL2FjsPDw3X7tm3bpjdhSFZRq9V6k0icP3+e69evJ1s3I/cHaCfgSHzm7e+//5ZeKSFEniKJlBBC5BAdO3akXr16uu1Vq1bp1gd622M//vhjHBwcdNsLFy7k8uXLem3cv3+fSZMm6bZNTU3TNbGDkZERCxYs0M3SBtreh7f1euJUsmRJ/Pz83rrNrGRiYsL//d//6bbv379Ply5diI6OTncbGellio2N5eeff85IiOn2ei9iQkICQ4YMIS4uTq/O//73P44cOaLbbtq0aarPUyUaMWIE+fLlA7RJvhBC5BWyIK8QQmSRnTt38ujRoyTldnZ2fPbZZ+lq4+uvv2b//v2A9gPttGnT9KamzuyxNjY2fPvtt3z66acAPHv2jKpVqyZZkPf1SQ+mTJmim/QhLUWLFqVDhw6sWbMGgKCgII4cOUKtWrXSdXxyypQpw65du4iOjqZIkSKZfgYpO40ZM4bAwEBOnz4NwKZNmzh8+DAfffQR3t7exMTEsG/fvmSPPXbsGFeuXNFt16hRA29v7yT19u7dq7uv3nah45R07NiR1atX6xbP3bp1K2XLlqVNmzZYW1tz/Phxtm7dqqufL18+5s+fn6627e3tGTlypEyDLoTIewy5iJUQQuRmby7+mtLrzUVSX9+X3EKw1apV0+03NTVV7ty5kyXHKop2UV0LC4tU41Wr1cr06dOTtJ3agryKoih//fWXolKp9BZ1TY/XF+R1dHRMs/6b77shF+RVFEV59OiR0rJly3TdC6ampsrJkycVRVGUzz//XG8h4tu3byd7/m+++UavjXPnzmUovkSpLcirKIry/Plz5ZNPPknzGry9vZVTp06l+j69uYjwixcvFFdX1yRtCSFEbiZD+4QQIod5/S/3sbGxeouzvu2xPXr04MaNG4wdO5aaNWvi4OCAsbExdnZ2VKpUiWHDhnH16lVGjhyZ4bjLli3Lhx9+qNvesWOHrqcmL3N0dOSPP/5g//799O7dm1KlSmFra4tarcbW1pYyZcrQqVMnvv/+e+7fv0/VqlV5+fKl3vNCjRo1SrH3r0ePHnq9ca8v3puVrK2t2bBhA0FBQfTo0YNixYphZWWFiYkJrq6uNG3alCVLlnDp0iWqVKmSobYtLS0ZM2ZMtsQthBCGolIUWdhBCCGEEEIIITJCeqSEEEIIIYQQIoMkkRJCCCGEEEKIDJJESgghhBBCCCEySBIpIYQQQgghhMggSaSEEEIIIYQQIoMkkRJCCCGEEEKIDJJESgghhBBCCCEySBIpIYQQQgghhMggSaSEEEIIIYQQIoMkkRJCCCGEEEKIDJJESgghhBBCCCEySBIpIYQQQgghhMggSaSEEEIIIYQQIoMkkRJCCCGEEEKIDJJESgghhBBCCCEySBIpIYQQQgghhMggSaSEEEIIIYQQIoMkkRJCCCGEEEKIDJJESgghhBBCCCEySBIpIYQQQgghhMggSaSEEEIIIYQQIoMkkRJCCCGEEEKIDJJESohcSKVSMX78eEOHId4D3t7e9OjRw9BhCPFOBAUFoVKp2Lhxo6FDEULkApJICWEgK1euRKVSoVKpOHToUJL9iqLg6emJSqWiZcuWBogw97l8+TJNmzbF2toaBwcHunbtysOHD9N17Pr16+nSpQvFihVDpVLh6+ubbL3ED1rJvY4dO5aFVyOy2pEjR6hduzaWlpa4uroycOBAoqKi0n388uXLKVWqFObm5hQrVoyFCxe+VTwqlYr+/fsnKQ8ICEClUtGrVy80Gg2vXr1iwIABODk54eHhweTJk5Mcc/fuXaytrTl8+PBbxZQZMTEx9O7dm7Jly2JnZ4e1tTUVKlRg/vz5xMXFJan/7Nkz+vbti5OTE1ZWVtSvX5/Tp0+/87hF1tFoNKxcuZJWrVrh6emJlZUVZcuWZfLkybx8+TLF4z7++GOaN2+u2w4ODqZly5a4urpibW1N+fLlWbBgAQkJCe/iMoTIMGNDByDE+87c3Jw1a9ZQu3ZtvfL9+/dz9+5dzMzMkhwTExODsbH8+L7u7t271K1bFzs7OwICAoiKimLWrFn89ddfnDhxAlNT01SPX7JkCcHBwVSrVo3Hjx+neb6BAwdSrVo1vbKiRYu+1TXkRFevXsXIKPf/ze3s2bM0bNiQUqVKMWfOHO7evcusWbP4+++/2bFjR5rHf/fdd3zxxRd8/PHHDB06lIMHDzJw4ECio6P58ssvsyzOadOm8fXXX9O9e3d++OEHjIyMmDlzJj/99BNff/01z58/Z+LEiRQpUoROnTrpjhsxYgStWrXigw8+yLJY0ismJoaLFy/SvHlzvL29MTIy4siRIwwZMoTjx4+zZs0aXV2NRkOLFi04d+4cI0aMIH/+/CxevBhfX1+Cg4MpVqzYO49fvL3o6Gh69uxJzZo1+eKLL3B2dubo0aOMGzeOvXv38ueff6JSqfSOiYuLIzAwkKlTpwLaJKpWrVoUK1aML7/8EktLS3bs2MGgQYO4ceMG8+fPN8SlCZE6RQhhECtWrFAApW3btkr+/PmVuLg4vf2fffaZUqVKFcXLy0tp0aKFgaLMPfr166dYWFgot2/f1pUFBgYqgPLdd9+leXxISIiSkJCgKIqilClTRqlXr16y9fbt26cAyi+//JIlcb8tjUajREdHGzqMHK9Zs2aKm5ubEhERoSv7/vvvFUDZtWtXqsdGR0crjo6OSX4OO3furFhZWSlPnjzJVEyA4u/vr9ueMWOGAijdunXT3YuKoig1atRQJkyYoNvu3r270rFjR932wYMHFSsrK+XOnTuZiiO79O/fXwGU0NBQXdn69euT/PyEh4cr9vb2SqdOnQwRpp539fMdExOj9z3O7V69eqUcPnw4SfmECRMUQAkMDEyyb+/evQqg3Lx5U1EU7f95pqamyuPHj/Xq1a1bV7G1tc2WuIV4W7n/z4xC5HKdOnXi8ePHBAYG6spiY2PZuHEjn376abLHvPmM1Pjx41GpVFy/fp0ePXpgb2+PnZ0dPXv2JDo6Wu/YwMBAateujb29PdbW1pQoUYLRo0fr9icOObx165becYlD2oKCgnRlvr6+lC1bVveXRAsLCwoVKsTSpUsz/4Zk0q+//krLli0pWLCgrqxRo0YUL16cDRs2pHm8p6dnhntenj9/Tnx8fIZjfVPie37gwAE+//xzHB0dsbW1pVu3bjx9+lSvrre3Ny1btmTXrl1UrVoVCwsLvvvuO27duoVKpWLlypVJ2n+b++XNZ6QSYz18+DBDhw7VDc9q06ZNkmGUGo2G8ePH4+7ujqWlJfXr1+fSpUvv/LmryMhIAgMD6dKlC7a2trrybt26YW1tneb9sW/fPh4/fsz//d//6ZX7+/vz4sULtm3b9tYxzpkzh5EjR9KlSxdWrFihdy/GxMSQL18+3baDg4Pu+6TRaBg0aBAjR47Ew8PjrePISt7e3oB2KF+ijRs34uLiQtu2bXVlTk5OtG/fnt9++41Xr15l+DzPnz9n8ODBeHt7Y2ZmhrOzM40bN9YbLpjSPefr65vsMN6EhARGjx6Nq6srVlZWtGrVijt37iSpt2jRIgoXLoyFhQXVq1fn4MGDSdpM/N25bt06xowZQ4ECBbC0tCQyMhKAX375hSpVqmBhYUH+/Pnp0qUL9+7dS1ecPXr00L3PgO73wKxZs5g7dy5eXl5YWFhQr149Lly4oHdsWFgYPXv2xMPDAzMzM9zc3Pjoo4/0fvdHRERw5coVIiIikpz7daamptSqVStJeZs2bQDtsOs3bdu2jdKlS+vij4yMxNzcHHt7e716bm5uWFhYpHp+IQxFxgYJYWDe3t74+Piwdu1amjVrBsCOHTuIiIigY8eOLFiwIN1ttW/fnkKFCjF16lROnz7NDz/8gLOzM9OnTwfg4sWLtGzZkvLlyzNx4kTMzMy4fv36Wz1X8fTpU5o3b0779u3p1KkTGzZsoF+/fpiamtKrV69Uj42IiEj2GYo3mZubY21tneL+e/fuER4eTtWqVZPsq169Otu3b0/7QjKoZ8+eREVFoVarqVOnDjNnzkz2/BnRv39/7O3tGT9+PFevXmXJkiXcvn1b90Es0dWrV+nUqROff/45n332GSVKlMjU+dK6X1IzYMAA8uXLx7hx47h16xbz5s2jf//+rF+/Xldn1KhRzJgxgw8//JAmTZpw7tw5mjRpkuozE697+vRpup6NsLS0xNLSMsX9f/31F/Hx8Um+P6amplSsWJEzZ86k2n7i/jePr1KlCkZGRpw5c4YuXbqkGWdK5s+fz7Bhw/j0009ZuXJlkoS+WrVqLFu2DF9fX6Kioli7dq3u2arly5fz6NEjRowYkaFzajQanjx5kq66dnZ2mJiYpFkvNjaWyMhIYmJiOHXqFLNmzcLLy0tvyOuZM2eoXLlykmusXr06y5Yt49q1a5QrVy5D1/LFF1+wceNG+vfvT+nSpXn8+DGHDh3i8uXLVK5cOUNtJZoyZQoqlYovv/yS8PBw5s2bR6NGjTh79qzuQ/2SJUvo378/derUYciQIdy6dYvWrVuTL1++ZJPaSZMmYWpqyvDhw3n16hWmpqasXLmSnj17Uq1aNaZOncqDBw+YP38+hw8f5syZM0mSivT66aefeP78Of7+/rx8+ZL58+fToEED/vrrL1xcXADt80kXL15kwIABeHt7Ex4eTmBgICEhIbrkZvPmzfTs2ZMVK1Zk6o8fYWFhAOTPnz/Jvu3bt+s9/+vr68v69ev5/PPPGTp0qG5o36ZNm5g5c2bG3wQh3gVDd4kJ8b5KHNp38uRJ5dtvv1VsbGx0Q7Q++eQTpX79+oqiKMkO7QOUcePG6bbHjRunAEqvXr306rVp00ZxdHTUbc+dO1cBlIcPH6YZV+Jwi0SJQ1727dunK6tXr54CKLNnz9aVvXr1SqlYsaLi7OysxMbGpvoeJB6f1qt79+6ptnPy5EkFUH766ack+0aMGKEAysuXL1Nt43WpDe07fPiw8vHHHyvLly9XfvvtN2Xq1KmKo6OjYm5urpw+fTrd53hd4ntepUoVvfcscajXb7/9pivz8vJSAGXnzp16bdy8eVMBlBUrViRpP7P3S+L5Xn//E2Nt1KiRotFodOVDhgxR1Gq18uzZM0VRFCUsLEwxNjZWWrdurdfe+PHj0/U9ff1a03q9fm3J+eWXXxRAOXDgQJJ9n3zyieLq6prq8f7+/oparU52n5OTk94wu4wAdNfYqVMnJT4+Ptl6d+7cUcqUKaO73jp16ijPnz9Xnj17pjg5OSnr1q3L8LkT75f0vF7/mU/N2rVr9Y6rWrWqcv78eb06VlZWSe47RVGUbdu2JXtfp4ednZ3eEMnkvHkfJ6pXr57ez3ri77kCBQookZGRuvINGzYogDJ//nxFUbS/5xwdHZVq1arpDcteuXKlAiTbZuHChfWG4cbGxirOzs5K2bJllZiYGF351q1bFUAZO3ZsinEm6t69u+Ll5aXbTvy+WlhYKHfv3tWVHz9+XAGUIUOGKIqiKE+fPlUAZebMmSm/acp/P+/J/V5Jj0aNGim2trbK06dP9cr/+eefJPdWfHy80r9/f8XExER3D6nVamXJkiWZOrcQ74L0SAmRA7Rv357BgwezdetWmjZtytatWzPUE5Xoiy++0NuuU6cOmzdvJjIyEltbW91fN3/77Td69uyZJZMIGBsb8/nnn+u2TU1N+fzzz+nXrx/BwcHUrFkzxWNnz56dZOhactzd3VPdHxMTA5DsxBzm5ua6Osntz6hatWrpDWFp1aoV7dq1o3z58owaNYqdO3dmuu2+ffvq/eW/X79+jB49mu3bt9OqVStdeaFChWjSpEmmz5MorfslrVhf7yWrU6cOc+fO5fbt25QvX569e/cSHx+fZDjcgAED0j11/88//6z73qamcOHCqe5P6/5I6xwxMTEpTlaSnuNT8+DBA0D7PVWr1cnW8fDw4MyZM1y8eBFTU1NKliyJkZERQ4cOpUSJEnTo0IFDhw4xbNgw7t+/T5s2bZg1a1aqE6y4urrqDSdOTYUKFdJVr379+gQGBvLs2TP27t3LuXPnePHihV6dlH4OX/85zSh7e3uOHz/O/fv30/xdkV7dunXDxsZGt92uXTvc3NzYvn07AwcO5NSpUzx+/JipU6fqTfzTuXNnhgwZkmyb3bt31xuidurUKcLDwxk/frzu+gFatGhByZIl2bZtGxMmTMhU/K1bt6ZAgQK67erVq1OjRg22b9/OnDlzsLCwwNTUlKCgIHr37q03dPR1PXr0yPQw3ICAAPbs2cPixYuT9Kxt27YNOzs7vUmW1Go1RYoUoUmTJnzyySeYm5uzdu1aBgwYgKurK61bt85UHEJkJ0mkhMgBnJycaNSoEWvWrCE6OpqEhATatWuX4XZefz4I0P3n+PTpU2xtbenQoQM//PADffr04auvvqJhw4a0bduWdu3aZTqpcnd3x8rKSq+sePHigHa8fmqJVJUqVTJ1zjclfjhJ7vmKxGFk2TnGvmjRonz00Uds2rSJhISEFD8Qp+XNGcusra1xc3NL8rxaoUKFMhuqnrTul8weC3D79m0g6UyGDg4OKX5oe1NWzUCX1v2R1r1hYWFBbGxssvvSc3xqunfvzv379wkICCB//vwpfgg3MTGhYsWKuu0rV66wePFijhw5wpMnT2jRogVfffUV9evXp2fPnkyZMiXVD+Hm5uY0atQo03Enx8XFRTdsrF27dgQEBNC4cWP+/vtvXF1dAe17mdU/pzNmzKB79+54enpSpUoVmjdvTrdu3dJMsFPz5s+iSqWiaNGiup/FlO5vY2NjvWeWXvfmz21iG8kNzS1ZsmSyy2KkV3KzH77+vKiZmRnTp09n2LBhuLi4ULNmTVq2bEm3bt1036u3sX79esaMGUPv3r3p169fkv3btm3Dz89PLwmdNm0a8+fP5++//9YN5W7fvj3169fH39+fli1bymy1IseRySaEyCE+/fRTduzYwdKlS2nWrFmmxsan9AFeURRA+yHlwIED7Nmzh65du3L+/Hk6dOhA48aNdc+ivDlFbaLsWMfjyZMnhIWFpflK60FnNzc3AEJDQ5PsCw0NxcHBIUt6o1Lj6elJbGxskr/AZ4fkPmxm5vuW1v2Smrc5Nr0ePnyYrvsjrbWg0ro/0urFcHNzIyEhgfDwcL3y2NhYHj9+/Fa9IMbGxmzYsIF69eoxbNgwVqxYka7jhgwZQpcuXahcuTLbtm3DwcGBUaNGUbNmTUaOHMnPP/+c6vEJCQnpem/DwsJSTCLT0q5dO6Kiovjtt990ZW5ubil+HyDt3ufktG/fnn/++YeFCxfi7u7OzJkzKVOmjN609u/y91pK3ibhzo74Bw8ezLVr15g6dSrm5uZ88803lCpVKs1nBtMSGBhIt27daNGiRbITD0VHRxMUFKS3fhTA4sWLadCgQZLnYVu1asX9+/eT/EFJiJxAEikhcog2bdpgZGTEsWPHUpytLysYGRnRsGFD5syZw6VLl5gyZQp//vkn+/btA/7rWXh9pi3476+nb7p//36S5OHatWsAKf5lNlHbtm1xc3NL8zVo0KBU2ylQoABOTk6cOnUqyb4TJ07o/SU/u/zzzz9pToqRlr///ltvOyoqitDQ0DTfR8j49y27eXl5AXD9+nW98sePH6drOCdoJ1lIz/0xa9asVNspW7YsxsbGSe6P2NhYzp49m+b9kbj/zeNPnTqFRqN56/vL3Nyc33//nUqVKvHZZ5+xefPmVOtv3bqVI0eOEBAQAGh/BhOTRdAmI2/O+vamO3fupOu9dXNz48iRI5m6rsRheq//IaRixYqcPn0ajUajV/f48eNYWlrqerMzys3Njf/7v/9jy5Yt3Lx5E0dHR6ZMmaLbny9fviQ/G5Dyz8ebP4uKonD9+nXdz2JK93d8fHy6P/AntnH16tUk+65evarbnxXxg/b38pu/S4oUKcKwYcPYvXs3Fy5cIDY2ltmzZ6cr/uQcP36cNm3aULVqVTZs2JBsD9Kff/7Jq1evdJMrJXrw4EGyiWHihERZMUOqEFlN+kiFyCGsra1ZsmQJt27d4sMPP8yWczx58gQHBwe9ssQPgYnDbYoUKQLAgQMHdPsSEhJYtmxZsm3Gx8fz3XffMXToUED74fS7777DyckpzaF7WfWMFGhnoFq1ahV37tzB09MTgL1793Lt2jW94VJxcXHcuHEDOzs7vQ+f6fXw4UOcnJz0ys6dO8fvv/9Os2bN3uq5s2XLltGzZ0/dc1JLliwhPj4+yQeO5Nja2pI/f34OHDjA4MGDdeWLFy/OdDxvo2HDhhgbG7NkyRIaN26sK//222/T3UZWPSNlZ2dHo0aNWL16Nd98843u2Zf//e9/REVF8cknn+jqRkdHExISQv78+XUzjTVo0AAHBweWLFmi91f0JUuWYGlpSYsWLdJ9TSmxtbVl586d1KlTh06dOrFt2zYaNmyYpF5sbCxDhw5lzJgxODs7A9ohddevXyc+Ph5jY2MuX76c5vCsrHxG6tGjRzg6OibpNfnhhx8A/dkO27Vrx8aNG9m0aZNu+PKjR4/45Zdf+PDDDzPcc5yQkEBUVBR2dna6MmdnZ9zd3fWGEBYpUoSDBw8SGxure3Zs69at3LlzJ9n756effmLUqFG6e2Xjxo2EhobqFl+uWrUqjo6OfP/99/Ts2VOXMPz888/p/kNB1apVcXZ2ZunSpfTq1Ut37Tt27ODy5cuMHTtWL/7t27fr/f45d+4chw8f1v2+e92WLVu4d++e7jmpEydOcPz4cd3vhujoaIyMjPSezSpSpAg2NjZ671tERAShoaG4ubnpvcfJuXz5Mi1atMDb25utW7em2AO3fft2qlatqhsGmqh48eIEBgby+PFjHB0dAe33d8OGDdjY2Oj+bxIiJ5FESogcpHv37tna/sSJEzlw4AAtWrTAy8uL8PBwFi9ejIeHh+6h3zJlylCzZk1GjRqlS7zWrVuX4l8D3d3dmT59Ordu3aJ48eKsX7+es2fPsmzZsjSnTM6qZ6QARo8ezS+//EL9+vUZNGgQUVFRzJw5k3LlytGzZ09dvXv37lGqVCm6d++ut+bSgQMHOHDgAKBNll68eMHkyZMBqFu3LnXr1gWgQ4cOWFhYUKtWLZydnbl06RLLli3D0tKSadOm6cU0fvx4JkyYwL59+5JdA+ZNsbGxNGzYkPbt23P16lUWL15M7dq19SaaSE2fPn2YNm0affr0oWrVqhw4cEDXO/iuubi4MGjQIGbPnk2rVq1o2rQp586dY8eOHeTPnz/FoUqvy6pnpEA7nXWtWrWoV68effv25e7du8yePRs/Pz+aNm2qq3fixAnq16/PuHHjdJNiWFhYMGnSJPz9/fnkk09o0qQJBw8eZPXq1UyZMkXvjxNBQUFJjk8vJycnAgMD+eCDD2jdujV79+6levXqenXmz58PoNdL27x5c/z9/fn000+pVasWkyZNok+fPqmeKyufkVq9ejVLly6ldevWFC5cmOfPn7Nr1y4CAwP58MMPadCgga5uu3btqFmzJj179uTSpUvkz5+fxYsXk5CQkOSZrh49erBq1Spu3ryZYq/s8+fP8fDwoF27dlSoUAFra2v27NnDyZMn9XpW+vTpw8aNG2natCnt27fnxo0brF69OsUP5w4ODtSuXZuePXvy4MED5s2bR9GiRfnss88A7aQ648ePZ8CAATRo0ID27dtz69YtVq5cSZEiRdJ1f5uYmDB9+nR69uxJvXr16NSpk276c29vb70/APXq1Ys5c+bQpEkTevfuTXh4OEuXLqVMmTK69aheV7RoUWrXrk2/fv149eoV8+bNw9HRkZEjRwLa3qnE3zWlS5fG2NiYzZs38+DBAzp27KhrJ73Tnz9//pwmTZrw9OlTRowYkWRttSJFiuDj4wNoE6nXfycn+uqrr+jSpQs1atSgb9++WFhYsHbtWoKDg5k8eXK6puAX4p0z7KSBQry/Xp/+PDUZmf78zWnN35zKfO/evcpHH32kuLu7K6ampoq7u7vSqVMn5dq1a3rH3bhxQ2nUqJFiZmamuLi4KKNHj1YCAwOTnf68TJkyyqlTpxQfHx/F3Nxc8fLyUr799tuMvyFZ4MKFC4qfn59iaWmp2NvbK507d1bCwsL06iROD/zmVMiJ72Fyr9ff6/nz5yvVq1dXHBwcFGNjY8XNzU3p0qWL8vfffyeJZ9iwYYpKpVIuX76catyJ36f9+/crffv2VfLly6dYW1srnTt3Vh4/fqxXN7n7IVF0dLTSu3dvxc7OTrGxsVHat2+vhIeHZ/p+STxfctOfv3nfJjc9fnx8vPLNN98orq6uioWFhdKgQQPl8uXLiqOjo/LFF1+k+p5kh4MHDyq1atVSzM3NFScnJ8Xf319vimtF+e86kptSfdmyZUqJEiUUU1NTpUiRIsrcuXP1poBXFEX5448/FEBZunRpmvEAyU7bffnyZSV//vyKg4ODcuHCBV15WFiYYmNjo/z+++9JjtmxY4dSsmRJxd7eXunWrZvy4sWLNM+fVU6ePKl88sknSsGCBRUzMzPFyspKqVy5sjJnzhy9qcETPXnyROndu7fi6OioWFpaKvXq1Uv29+DHH3+sWFhYJJk6+3WvXr1SRowYoVSoUEGxsbFRrKyslAoVKiiLFy9OUnf27NlKgQIFFDMzM+WDDz5QTp06leL052vXrlVGjRqlODs7KxYWFkqLFi2U27dvJ2lzwYIFipeXl2JmZqZUr15dOXz4sFKlShWladOmSdr85Zdfkr2G9evXK5UqVVLMzMwUBwcHpXPnznpTlydavXq1UrhwYcXU1FSpWLGismvXrhSnP585c6Yye/ZsxdPTUzEzM1Pq1KmjnDt3Tlfv0aNHir+/v1KyZEnFyspKsbOzU2rUqKFs2LBB75zpnf48ren0E3+HXLhwQQGUEydOJNvOzp07lXr16in58+dXTE1NlXLlyqXrZ0kIQ1EpShY+GSyEeK/4+vry6NEjLly4YOhQcqTq1avj5eXFL7/8kmq9xEU5T548+daL+uZ0z549I1++fEyePJmvv/7a0OFkuZEjR7J27VquX7+e7ROc5HUuLi5069YtVy3GqtFocHJyom3btnz//ffv/Py3bt2iUKFCzJw5k+HDh7/z86dlxowZzJkzh9DQ0HT12gmR08nQPiGEyAaRkZGcO3eOVatWGToUg4mJiUnynMS8efMA0jXUMTfat28f33zzjSRRb+nixYvExMTonknKiV6+fImZmZleQvDTTz/x5MmTPHt/vy1vb2/mzp0rSZTIMySREkKIbGBra5vsejnvk/Xr17Ny5UqaN2+OtbU1hw4dYu3atfj5+WXp8085ycmTJw0dQp6Q0rM/OcmxY8cYMmQIn3zyCY6Ojpw+fZrly5dTtmxZvQlMxH/at29v6BCEyFKSSAkhhMgW5cuXx9jYmBkzZhAZGambgCJxEg8hcjNvb288PT1ZsGCBbmKebt26MW3aNN3MgEKIvE2ekRJCCCGEEEKIDJIFeYUQQgghhBAigySREkIIIYQQQogMkmek0E5Xev/+fWxsbGQmGSGEEEIIId5jiqLw/Plz3N3dMTJKud9JEing/v37eHp6GjoMIYQQQgghRA5x584dPDw8Utxv0ERq6tSpbNq0iStXrmBhYUGtWrWYPn06JUqU0NX5/PPP2bNnD/fv38fa2lpXp2TJkro6ISEh9OvXj3379mFtbU337t2ZOnUqxsbpuzwbGxtA+2bZ2tpm7UVmUFxcHLt378bPzw8TExODxiJyB7lnREbJPSMySu4ZkVFyz4iMykn3TGRkJJ6enrocISUGTaT279+Pv78/1apVIz4+ntGjR+Pn58elS5ewsrICoEqVKnTu3JmCBQvy5MkTxo8fj5+fHzdv3kStVpOQkECLFi1wdXXlyJEjhIaG0q1bN0xMTAgICEhXHInD+WxtbXNEImVpaYmtra3BbyKRO8g9IzJK7hmRUXLPiIySe0ZkVE68Z9J65MegidTOnTv1tleuXImzszPBwcHUrVsXgL59++r2e3t7M3nyZCpUqMCtW7coUqQIu3fv5tKlS+zZswcXFxcqVqzIpEmT+PLLLxk/frys5SCEEEIIIYTIcjnqGamIiAgAHBwckt3/4sULVqxYQaFChXTPNB09epRy5crh4uKiq9ekSRP69evHxYsXqVSpUpJ2Xr16xatXr3Tbiaunx8XFERcXl2XXkxmJ5zd0HCL3kHtGZJTcMyKj5J4RGSX3jMionHTPpDeGHLMgr0ajoVWrVjx79oxDhw7p7Vu8eDEjR47kxYsXlChRgm3btlGkSBFA22N1+/Ztdu3apasfHR2NlZUV27dvp1mzZknONX78eCZMmJCkfM2aNVhaWmbxlQkhhBBCCCFyi+joaD799FMiIiJSfewnx/RI+fv7c+HChSRJFEDnzp1p3LgxoaGhzJo1i/bt23P48GHMzc0zda5Ro0YxdOhQ3XbiA2V+fn454hmpwMBAGjdunGPGh4qcTe4ZkVFyz4iMkntGZFRevmcSEhKIj48nh/RF5Bnx8fEcOXKEWrVqpXvCuMxQqVSo1WrUanWKz0AljlZLS45IpPr378/WrVs5cOBAslMM2tnZYWdnR7FixahZsyb58uVj8+bNdOrUCVdXV06cOKFX/8GDBwC4uromez4zMzPMzMySlJuYmOSYH/acFIvIHeSeERkl94zIKLlnREbltXsmKiqKu3fvShKVDRRFwdXVldDQ0HeyrqulpSVubm7JzqeQ3nvWoImUoigMGDCAzZs3ExQURKFChdJ1jKIoumecfHx8mDJlCuHh4Tg7OwMQGBiIra0tpUuXztb4hRBCCCHE+yEhIYG7d+9iaWmJk5PTO/mw/z7RaDRERUVhbW2d6iK4b0tRFGJjY3n48CE3b96kWLFimT6fQRMpf39/1qxZw2+//YaNjQ1hYWGAtgfKwsKCf/75h/Xr1+Pn54eTkxN3795l2rRpWFhY0Lx5cwD8/PwoXbo0Xbt2ZcaMGYSFhTFmzBj8/f2T7XUSQgghhBAio+Li4lAUBScnJywsLAwdTp6j0WiIjY3F3Nw8WxMpAAsLC0xMTLh9+7bunJmRvVGmYcmSJURERODr64ubm5vutX79egDMzc05ePAgzZs3p2jRonTo0AEbGxuOHDmi631Sq9Vs3boVtVqNj48PXbp0oVu3bkycONGQlyaEEEIIIfIg6YnKG7IiWTP40L7UuLu7s3379jTb8fLySlc9IYQQQgghhMgKBu2REkIIIYQQQrwfevToQevWrQ0dRpaRREoIIYQQQohcJK8lJLmVJFJCCCGEEEIIkUGSSAkhhBBCCJFHXLhwgWbNmmFtbY2Liwtdu3bl0aNHuv3Pnz+nc+fOWFlZ4ebmxty5c/H19WXw4MG6Oq9evWL48OEUKFAAKysratSoQVBQkG7/ypUrsbe3Z9euXZQqVQpra2uaNm1KaGiork5CQgJDhw7F3t4eR0dHRo4cmefW35JEKgfRJCQQfvIk8efOEX7yJJqEBEOHJIQQQgghcolnz57RoEEDKlWqxKlTp9i5cycPHjygffv2ujpDhw7l8OHD/P777wQGBnLw4EFOnz6t107//v05evQo69at4/z583zyySc0bdqUv//+W1cnOjqaWbNm8b///Y8DBw4QEhLC8OHDdftnz57NypUr+fHHHzl06BBPnjxh8+bN2f8mvEMGnbVP/OdOYCDBU6cS/eABAPvXr8fSxYUqo0bh2bixgaMTQgghhBA53bfffkulSpUICAjQlf344494enpy7do13NzcWLVqFWvWrKFhw4YArFixAnd3d139kJAQVqxYQUhIiK58+PDh7Ny5kxUrVujajouLY+nSpRQpUgTQJl+vLz80b948Ro0aRdu2bQFYunQpu3btyt434B2TRCoHuBMYyMEhQ+CN7s7o8HAODhlCnblzJZkSQgghhBCpOnfuHPv27cPa2jrJvhs3bhATE0NcXBzVq1fXldvZ2VGiRAnd9l9//UVCQgLFixfXO/7Vq1c4Ojrqti0tLXVJFICbmxvh4eEAREREEBoaSo0aNXT7jY2NqVq1ap4a3ieJlIFpEhIInjo1SRIFaMtUKoKnTaNAgwYYqdXvPkAhhBBCCJErREVF8eGHHzJ9+vQk+9zc3Lh+/Xq62lCr1QQHB6N+47Pn6wmaiYmJ3j6VSpWnkqT0kGekDOxhcLBuOF+yFIXosDAeBge/u6CEEEIIIUSuU7lyZS5evIi3tzdFixbVe1lZWVG4cGFMTEw4efKk7piIiAiuXbum265UqRIJCQmEh4cnacPV1TVdcdjZ2eHm5sbx48d1ZfHx8QTnsc+z0iNlYDEPH2ZpPSGEEEIIkfdFRERw9uxZvbK+ffvy/fff06lTJ0aOHImDgwPXr19n3bp1/PDDD9jY2NC9e3dGjBiBg4MDzs7OjBs3DiMjI1QqFQDFixenc+fOdOvWjdmzZ1OpUiUePnzI3r17KV++PC1atEhXfIMGDWLatGkUK1aMkiVLMmfOHJ49e5bF74JhSSJlYBZOTllaTwghhBBC5H1BQUFUqlRJr6x3794cPnyYL7/8Ej8/P169eoWXlxdNmzbFyEg7EG3OnDl88cUXtGzZEltbW0aOHMmdO3cwNzfXtbNixQomT57MsGHDuHfvHvnz56dmzZq0bNky3fENGzaM0NBQunfvjpGREb169aJNmzZERERkzRuQA6iU920wYzIiIyOxs7MjIiICW1vbd3puTUICvzduTHR4ePLPSQGWrq602r1bnpESyYqLi2P79u00b948yXhlIZIj94zIKLlnREblxXvm5cuX3Lx5k0KFCuklHbndixcvKFCgALNnz6Z3794Gi0Oj0RAZGYmtra0u6ctOqX0/05sbyDNSBmakVlNl1Cjtxr9dqm+qMGiQJFFCCCGEEOKtnTlzhrVr13Ljxg1Onz5N586dAfjoo48MHFnuI4lUDuDZuDF15s7F0tlZr1z1b/IUevSoIcISQgghhBB50KxZs6hQoQKNGjXixYsXHDx4kPz58xs6rFxHnpHKITwbN6ZAgwaEHj/OsT17qNmoESbm5uzt3p1bv/+OZ8OGeDZqZOgwhRBCCCFELlapUqU8N3ueoUiPVA5ipFbjXK0axhUq4FytGs6VK1OqVy8ATkyYwMvHjw0coRBCCCGEEAIkkcrxyvn7Y1+8OK+ePOHEhAnv3UJnQgghhBBC5ESSSOVwalNTfKZOxcjYmLt793Lz998NHZIQQgghhBDvPUmkcoF8JUtSzt8fgOCAAF6Ehho4IiGEEEIIId5vkkjlEqV69cKxQgXioqI4/s03KBqNoUMSQgghhBDivSWJVC5hZGyMT0AAanNzwo4e5e916wwdkhBCCCGEEO8tSaRyEVtvbyoOHQrAmdmzibx928ARCSGEEEII8X6SRCqXKd6pEy41a5Lw8iXHRo9Gk5Bg6JCEEEIIIUQ6JSRAUBCsXav99118lOvRowcqlYpp06bplW/ZsgWVSpWpNsePH49KpdJ7lSxZUq/Oy5cv8ff3x9HREWtraz7++GMePHigVyckJIQWLVpgbW1NsWLFGDlyJPHx8br9K1euxN7eXu+Yy5cv4+npySeffEJsbGym4s8KkkjlMiojI2pOnoyJtTWPzp7l8o8/GjokIYQQQgiRDps2gbc31K8Pn36q/dfbW1ue3czNzZk+fTpPnz7NsjbLlClDaGio7nXo0CG9/UOGDOGPP/7gl19+Yf/+/dy/f5+2bdvq9ickJNCiRQtiY2M5dOgQixcvZtWqVYwdOzbFc548eZI6derQtGlT1q9fj6mpaZZdT0ZJIpULWbm5UWXUKAD++vZbnl65YuCIhBBCCCFEajZtgnbt4O5d/fJ797Tl2Z1MNWrUCFdXV6ZOnZplbRobG+Pq6qp75c+fX7cvIiKC5cuXM2fOHBo0aECVKlVYsWIFR44c4dixYwDs3r2bS5cusXr1aipWrEjjxo2ZMGECixYtSran6c8//6RBgwb07t2b77//HiMjw6YykkjlUoU++giPBg3QxMdzdNQoEgzYrSmEEEII8b5RFHjxIn2vyEgYOFB7THLtAAwapK2XnvaSayctarWagIAAFi5cyN03szm0Q+ysra1TfQUEBOgd8/fff+Pu7k7hwoXp3LkzISEhun3BwcHExcXRqFEjXVnJkiUpWLAgR48eBeDo0aOUK1cOFxcXXZ0mTZoQGRnJxYsX9c61efNmWrRowZgxY5g+fXrG34BsYGzoAETmqFQqqo8fz8MzZ3h27Rp/LV5MxcGDDR2WEEIIIcR7IToarK2zpi1F0fZU2dmlr35UFFhZZfw8bdq0oWLFiowbN47ly5fr7XN3d+fs2bOpHu/g4KD7ukaNGqxcuZISJUoQGhrKhAkTqFOnDhcuXMDGxoawsDBMTU2TPN/k4uJCWFgYAGFhYXpJVOL+xH2JoqKi+OSTTxg9ejRffvllRi8720gilYuZOzpSfdw4Dg4ezOXlyyng64tTxYqGDksIIYQQQuRQ06dPp0GDBgwfPlyv3NjYmKJFi6a7nWbNmum+Ll++PDVq1MDLy4sNGzbQu3fvLIsXwMLCgtq1a/P999/TqVMnSpUqlaXtZ5YM7cvlPBs3xvvDD1E0Go6NHk18dLShQxJCCCGEyPMsLbU9Q+l5bd+evja3b09fe5aWmY+7bt26NGnShFH/Pm+fKDND+15nb29P8eLFuX79OgCurq7Exsby7NkzvXoPHjzA1dVVV+fNWfwStxPrgHZY4pYtW6hcuTL169fn8uXLmb7+rCQ9UnlA1dGjeXDiBM9v3+bs3LlU/fprQ4ckhBBCCJGnqVTpH17n5wceHtqJJZJ7vkml0u738wO1OmvjTM60adOoWLEiJUqU0JVldGjfm6Kiorhx4wZdu3YFoEqVKpiYmLB3714+/vhjAK5evUpISAg+Pj4A+Pj4MGXKFMLDw3UTVQQGBmJra0vp0qX12jczM2PTpk20a9eO+vXr8+effyap865Jj1QeYGprS81JkwC4tmYNYf/OhCKEEEIIIQxPrYb587Vfv7lsU+L2vHnvJokCKFeuHJ07d2bBggW6ssShfam9Xk+khg8fzv79+7l16xZHjhyhTZs2qNVqOnXqBICdnR29e/dm6NCh7Nu3j+DgYHr27ImPjw81a9YEwM/Pj9KlS9O1a1fOnTvH3r17GTt2LP7+/piZmSWJ28zMjF9//ZUaNWpQv379JBNSvGuSSOURbh98QLEOHQA49vXXxD5/buCIhBBCCCFEorZtYeNGKFBAv9zDQ1v+2vJK78TEiRPRaDSZPv7u3bt06tSJEiVK0L59exwdHTl27BhOTk66OnPnzqVly5Z8/PHH1K1bF1dXVza9Ns+7Wq1m69atqNVqPvjgAz7//HO6du3KxIkTUzyvqakpGzdupFatWtSvX58LFy5k+hrelgzty0MqDR9O6JEjRN25Q/DUqfikMo5VCCGEEEK8W23bwkcfwcGDEBoKbm5Qp07290StXLkySZm3tzevXr3KdJvr1q1Ls465uTmLFi1i0aJFKdbx8vJi+/btaDQaIiMjsbW11VsfqkePHvTo0UPvGBMTEzZv3pzp2LOK9EjlIcaWlvgEBKAyMuLmb79x988/DR2SEEIIIYR4jVoNvr7QqZP233c1nE9kPUmk8hinypUp1bMnACfGj+flkycGjkgIIYQQQoi8RxKpPKhc//7YFy/Oy8ePOTlhAkpmlr8WQgghhBBCpEgSqTxIbWqKT0AARsbG3Nmzh1tbtxo6JCGEEEIIIfIUSaTyqHylSlH2//4PgFNTpvAiNNTAEQkhhBBCCJF3SCKVh5Xu3RvH8uWJe/6c42PHyhA/IYQQQgghsogkUnmYkbExPgEBqM3NCTtyhL/TMU2lEEIIIYQQIm2SSOVxtoUKUXHIEADOzJ7N89u3DRyREEIIIYQQuZ8kUu+B4p9+ikv16iTExHB09Gg0CQmGDkkIIYQQQohcTRKp94DKyIiaU6ZgbGXFo7NnubJihaFDEkIIIYQQIleTROo9YeXuTpVRowA4/+23PLt2zcARCSGEEEK8hxISICgI1q7V/vsORgr16NEDlUrFtGnT9Mq3bNmCSqXKVJsHDhzgww8/xN3dHZVKxZYtW5LUURSFsWPH4ubmhoWFBY0aNeLvv//Wq/PkyRM6d+6Mvb09Xl5e9OnTh6ioKL0658+fp06dOpibm+Pp6cmMGTP09o8fP56KFSvqlR08eBB7e3sGDx6cbROuSSL1HincujUFfH3RxMVx5KuvSIiNNXRIQgghhBDvj02bwNsb6teHTz/V/uvtrS3PZubm5kyfPp2nT59mSXsvXrygQoUKLFq0KMU6M2bMYMGCBSxdupTjx49jZWVFkyZNePnypa5O586duXjxIrt27WLdunUcPHiQvn376vZHRkbi5+eHl5cXwcHBzJw5k/Hjx7Ns2bIUz7tt2zaaNGnC0KFDmTdvXqaTxbRIIvUeUalUVB8/HjN7e55dvcqFJUsMHZIQQgghxPth0yZo1w7u3tUvv3dPW57NyVSjRo1wdXVl6tSpWdJes2bNmDx5Mm3atEl2v6IozJs3jzFjxvDRRx9Rvnx5fvrpJ+7fv6/rvbp8+TI7d+7khx9+oEaNGvj4+DB//nzWrVvH/fv3Afj555+JjY3lxx9/pEyZMnTs2JGBAwcyZ86cZM+7Zs0a2rZty4wZMxg7dmyWXGtKJJF6z1g4OVFt3DgALv3wA4/OnzdwREIIIYQQuZCiwIsX6XtFRsLAgdpjkmsHYNAgbb30tJeJoWpqtZqAgAAWLlzI3TeTOSAkJARra+tUXwEBAek+382bNwkLC6NRo0a6Mjs7O2rUqMHRo0cBOHr0KPb29lStWlVXp1GjRhgZGXH8+HFdnbp162Jqaqqr06RJE65evZqkd23RokX07NmTH3/8kf79+6c71swyzvYziBynoJ8f3i1bcmvrVo6OGkWzjRsxtrAwdFhCCCGEELlHdDRYW2dNW4qi7amys0tf/agosLLK8GnatGlDxYoVGTduHMuXL9fb5+7uztmzZ1M93sHBId3nCgsLA8DFxUWv3MXFRbcvLCwMZ2dnvf3GxsY4ODjo1SlUqFCSNhL35cuXD9D2bvXv35/ly5fTuXPndMf5NiSRek9VHT2aBydP8vzWLc7Om0fVfyeiEEIIIYQQedf06dNp0KABw4cP1ys3NjamaNGiBorq7Xl4eGBvb8/MmTNp1qwZbm5u2X5OGdr3njK1s6PGxIkAXFu9mrBjxwwckRBCCCFELmJpqe0ZSs9r+/b0tbl9e/ras7TMdNh169alSZMmjHrjj+hZPbTP1dUVgAcPHuiVP3jwQLfP1dWV8PBwvf3x8fE8efJEr05ybbx+DgAbGxv27NmDlZUV9evXJzQ0NN2xZpb0SL3H3GvXpmiHDlxfv55jX39N8y1bMLWxMXRYQgghhBA5n0qV/uF1fn7g4aGdWCK555tUKu1+Pz9Qq7M2zmRMmzaNihUrUqJECV1ZVg/tK1SoEK6uruzdu1c3NXlkZCTHjx+nX79+APj4+PDs2TOCg4OpVKkSAH/++ScajYYaNWro6nz99dfExcVhYmICQGBgICVKlNAN60uUL18+9uzZg5+fH76+vuzbtw93d/d0x5xR0iP1nqs0bBjWnp5Eh4Vx+o21BYQQQgghRBZQq2H+fO3Xb07Fnbg9b947SaIAypUrR+fOnVmwYIGuLHFoX2qv1xOpqKgozp49q0u+bt68ydmzZwkJCfn3slQMHjyYyZMn8/vvv/PXX3/RrVs33N3dad26NQClSpWiadOmfPbZZ5w4cYJjx44xcOBAOnbsqEuAPv30U0xNTenduzcXL15k/fr1zJ8/n6FDhyZ7bfb29gQGBpIvXz58fX11s/9lB0mk3nMmVlbUnDIFVCr+2bKFu3/+aeiQhBBCCCHynrZtYeNGKFBAv9zDQ1vetu07DWfixIloNJpMH3/q1CkqVaqk60kaOnQolSpV0ptyfOTIkQwYMIC+fftSrVo1oqKi2LlzJ+bm5ro6P//8MyVLlqRx48a0b9+eDz74QG+NKDs7O3bv3s3NmzepUqUKw4YNY+zYsXprTb0p8Zj8+fNTr1497t27l+nrTI1Kya6lfnORyMhI7OzsiIiIwNbW1qCxxMXFsX37dpo3b67rvnwXzsyaxeUVKzB3dKT5li2YZ6DrVhiWoe4ZkXvJPSMySu4ZkVF58Z55+fIlN2/epFChQnqJQIYlJMDBgxAaCm5uUKfOO+uJysk0Gg2RkZHY2tpiZJT9fT2pfT/TmxtIj5QAoPyAAdgVLcrLx485OXEikl8LIYQQQmQDtRp8faFTJ+2/kkTlWpJICQDUZmb4TJuGytiYO4GB3Nq2zdAhCSGEEEIIkWNJIiV0HEqVouwXXwBwasoUot+YalIIIYQQQgihJYmU0FPms89wKFuWuMhIjn/zjQzxE0IIIYQQIhmSSAk9RsbG+EyditrMjNDDh7m+YYOhQxJCCCGEECLHkURKJGFXuDAVhgwB4MzMmTz/dz0AIYQQQgghhJYkUiJZJTp3xqV6deJjYjg2ejSahARDhySEEEIIIUSOIYmUSJbKyIiaU6ZgbGXFwzNnuLJqlaFDEkIIIYQQIseQREqkyMrdnSpffQXA+QULePb33waOSAghhBBCiJxBEimRqsJt2uBerx6auDiOfvUVCbGxhg5JCCGEEEIIg5NESqRKpVJRY8IEzOzteXrlCheWLjV0SEIIIYQQuVaCJoGgW0Gs/WstQbeCSNBk/3PoPXr0QKVSMW3aNL3yLVu2oFKpMtXmgQMH+PDDD3F3d0elUrFly5YUz/v6q2nTpnp1njx5QufOnbG3t8fLy4s+ffoQFRWlV+f8+fPUqVMHc3NzPD09mTFjht7+8ePHU7FiRb2ygwcPYm9vz+DBg7NtOR9JpESaLJycqDZ2LACXfviBR+fPGzgiIYQQQojcZ9PlTXjP96b+qvp8uulT6q+qj/d8bzZd3pTt5zY3N2f69Ok8ffo0S9p78eIFFSpUYNGiRanWa9q0KaGhobrX2rVr9fZ37tyZixcvsmvXLtatW8fBgwfp27evbn9kZCR+fn54eXkRHBzMzJkzGT9+PMuWLUvxnNu2baNJkyYMHTqUefPmZTpZTIskUiJdCjZpglfz5igJCRwbPZr4ly8NHZIQQgghRK6x6fIm2m1ox93Iu3rl9yLv0W5Du2xPpho1aoSrqytTp07NkvaaNWvG5MmTadOmTar1zMzMcHV11b3y5cun23f58mV27tzJDz/8QI0aNfDx8WH+/PmsW7eO+/fvA/Dzzz8TGxvLjz/+SJkyZejYsSMDBw5kzpw5yZ5vzZo1tG3blhkzZjD2346A7CKJlEi3ql9/jYWTE5E3b3Ju7lxDhyOEEEIIYTCKovAi9kW6XpEvIxm4YyAKSYeYJZYN2jGIyJeR6WovM0PV1Go1AQEBLFy4kLt37ybZHxISgrW1daqvgICADJ83KCgIZ2dnSpQoQb9+/Xj8+LFu39GjR7G3t6dq1aq6skaNGmFkZMTx48d1derWrYupqamuTpMmTbh69WqS3rVFixbRs2dPfvzxR/r375/hWDPKONvPkIqpU6eyadMmrly5goWFBbVq1WL69OmUKFEC0I6ZHDduHLt37yYkJAQnJydat27NpEmTsLOz07UTEhJCv3792LdvH9bW1nTv3p2pU6dibGzQy8tzzOztqTFpEkFffMHV1avxaNAAlxo1DB2WEEIIIcQ7Fx0XjfVU6yxpS0Hh7vO72E23S7syEDUqCitTqwyfp02bNlSsWJFx48axfPlyvX3u7u6cPXs21eMdHBwydL6mTZvStm1bChUqxI0bNxg9ejTNmjXj6NGjqNVqwsLCcHZ21jvG2NgYBwcHwsLCAAgLC6NQoUJ6dVxcXHT7Enu4Ll++TP/+/Vm+fDmdO3fOUJyZZdBMY//+/fj7+1OtWjXi4+MZPXo0fn5+XLp0CSsrK+7fv8/9+/eZNWsWpUuX5vbt23zxxRfcv3+fjRs3ApCQkECLFi1wdXXlyJEjhIaG0q1bN0xMTDKVNYvUudepQ9FPPuH6L79wbMwYmm/ejIl11vwSEUIIIYQQ2Wv69Ok0aNCA4cOH65UbGxtTtGjRLD1Xx44ddV+XK1eO8uXLU6RIEYKCgmjYsGGWnsvDwwN7e3tmzpxJs2bNcHNzy9L2k2PQRGrnzp162ytXrsTZ2Zng4GDq1q1L2bJl+fXXX3X7ixQpwpQpU+jSpQvx8fEYGxuze/duLl26xJ49e3BxcaFixYpMmjSJL7/8kvHjx+t1A4qsUWnECEKPHuXF3bsET59OzUmTDB2SEEIIIcQ7ZWliSdSoqLQrAgduH6D5muZp1tv+6XbqetVN17kzq27dujRp0oRRo0bRo0cPXXlISAilS5dO9djRo0czevToTJ+7cOHC5M+fn+vXr9OwYUNcXV0JDw/XqxMfH8+TJ09wdXUFwNXVlQcPHujVSdxOrANgY2PDnj17aNy4MfXr12ffvn3ZnkzlqLFvERERQOrdhhEREdja2uqG7R09epRy5crpuvhAO26yX79+XLx4kUqVKiVp49WrV7x69Uq3HRkZCUBcXBxxcXFZci2ZlXh+Q8eRKlNTqk2cSFDv3vyzaRNu9erhXq+eoaN6b+WKe0bkKHLPiIySe0ZkVF68Z+Li4lAUBY1Gg0ajAcDC2CJdxzYq1AgPGw/uPb+X7HNSKlR42HrQqFAj1EbqNNtTFCVDz0kl1k+MOyAggMqVK1O8eHEANBoNrq6unD59OtV2HBwcdG286fX3JSV3797l8ePHuLi4oNFoqFGjBs+ePePkyZNUrlwZgL1796LRaKhWrZquzjfffMOrV68wMTEBYPfu3ZQoUQI7Ozs0Go3uvbCzs2P37t00bdoUX19f9u7di7u7e4rxKopCXFwcarX+e57e+zbHJFIajYbBgwfzwQcfULZs2WTrPHr0iEmTJulNiRgWFqaXRIH+uMnkTJ06lQkTJiQp3717N5aWmc/ws1JgYKChQ0iTSe3axB08yJGvv8Zi0CBUVhkfqyuyTm64Z0TOIveMyCi5Z0RG5aV7xtjYGFdXV6KiooiNjc3w8QF1A+i+rTsqVHrJlArt1NxT6kzhRdSLLIv3dXFxccTHx+s6D7y8vPjkk09YuHAh8F+nwpvPKyUnsW5UVBQ3b97UlV+5coXDhw9jb2+Pp6cnUVFRTJ8+nVatWuHi4sLNmzcZN24chQsXxsfHh8jISAoUKEDDhg3p06cPc+bMIS4ujgEDBtC2bVusra2JjIykZcuWTJw4ke7duzNo0CAuX77MggULmDJlii6WV69ekZCQQGRkJEZGRvzyyy+0a9cOX19f/vjjj2R7pmJjY4mJieHAgQPEx8fr7YuOjk7X+5pjEil/f38uXLjAoUOHkt0fGRlJixYtKF26NOPHj3+rc40aNYqhQ4fqte3p6Ymfnx+2trZv1fbbiouLIzAwkMaNG+uy7pwqoWFD9nz6KZE3buBw4gQ1Z8zItnn6Rcpy0z0jcga5Z0RGyT0jMiov3jMvX77kzp07WFtbY25unuHjO1fujIWFBUN2DeHu8/9mzfOw9WCO3xzalmqbleHqMTExwdjYWO9zbkBAAJs3bwbI1Off06dP6z3n9PXXXwPQrVs3VqxYgYmJCVevXqVz5848e/YMd3d3GjduzMSJE3FyctIdt27dOgYMGEDr1q1RqVR8/PHHzJ8/H+t/n8G3tbVl165dDBgwgPr165M/f36++eYbBg4cqGvDzMwMtVqtuw5bW1sCAwNp3rw5rVq14s8//6RAgQJ68b98+RILCwvq1q2b5PuZmKClJUckUv3792fr1q0cOHAADw+PJPufP39O06ZNsbGxYfPmzXo/kK6urpw4cUKvfnLjJl9nZmaGmZlZknITE5Mc88Oek2JJiYmJCbWmTWNXp07cDQzkfmAg3i1aGDqs91ZuuGdEziL3jMgouWdERuWleyYhIQGVSoWRkRFGRplbQahdmXa0KdWGgyEHCX0eipuNG3UK1knXcL63sWrVqiRlhQsX1nvUJaMaNGiQ6vBCKysrdu/enWY7+fPnZ+3atWg0GiIjI7G1tU3y/lasWJGDBw+m2MaECROSjDazt7fnyJEjKR5jZGSESqVK9h5N7z1r0HWkFEWhf//+bN68mT///DPJ1Ibw32rGpqam/P7770kyRh8fH/766y+9B9UCAwOxtbVN84E58fYcSpem7OefA3Bq8mSi33gYUAghhBBC/EdtpMbX25dO5Trh6+2b7UmUyD4GTaT8/f1ZvXo1a9aswcbGhrCwMMLCwoiJiQH+S6JevHjB8uXLiYyM1NVJSEgAwM/Pj9KlS9O1a1fOnTvHrl27GDNmDP7+/sn2OomsV+azz3AoU4bYyEiOjx2bqUXihBBCCCGEyE0MmkgtWbKEiIgIfH19cXNz073Wr18PaMdeHj9+nL/++ouiRYvq1blz5w6gXaV569atqNVqfHx86NKlC926dWPixImGvLT3ipGJCT5Tp2JkakrooUNc/+UXQ4ckhBBCCCFEtjLoM1Jp9Vz4+vqmq3fDy8uL7du3Z1VYIhPsihSh4uDBnJ4xgzMzZuBasyY2BQsaOiwhhBBCCCGyhUF7pETeUqJrV5yrVSM+JoZjX3+N5t/hl0IIIYQQQuQ1kkiJLKMyMqLm5MkYW1ry8PRprv70k6FDEkIIIYQQIltIIiWylLWHB5W//BKAc/Pn8+z6dQNHJIQQQgghRNaTREpkuSIff4x7vXpo4uI4OmoUmrg4Q4ckhBBCCCFElpJESmQ5lUpFjQkTMLWz4+mlS1z47jtDhySEEEIIIUSWkkRKZAsLJyeqjR0LwMVly3j8118GjkgIIYQQQoisI4mUyDZeTZvi1awZSkICR0ePJv7lS0OHJIQQQghhWJoEeBAEt9Zq/9Vk/yzHPXr0QKVSMW3aNL3yLVu2oFKpMtXm1KlTqVatGjY2Njg7O9O6dWuuXr2qV+fly5f4+/vj6OiItbU1H3/8MQ8ePNCrExISQosWLbC2tqZYsWKMHDmS+Ph4vTpBQUFUrlwZMzMzihYtysqVK5NcX+vWrfXKNm7ciLm5ObNnz87U9aWHJFIiW1UdMwYLJyci//mHc/PnGzocIYQQQgjDubMJfveGvfXhyKfaf3/31pZnM3Nzc6ZPn87Tp0+zpL39+/fj7+/PsWPHCAwMJC4uDj8/P168eKGrM2TIEP744w9++eUX9u/fz/3792nbtq1uf0JCAi1atCA2NpZDhw6xePFiVq1axdh/RzUB3Lx5kxYtWlC/fn3Onj3L4MGD6dOnD7t27Uoxth9++IHOnTuzZMkShg0bliXXmxxJpES2MrO3p/rEiQBc/d//eHDypIEjEkIIIYQwgDub4GA7iL6rXx59T1uezclUo0aNcHV1ZerUqVnS3s6dO+nRowdlypShQoUKrFy5kpCQEIKDgwGIiIhg+fLlzJkzhwYNGlClShVWrFjBkSNHOHbsGAC7d+/m0qVLrF69mooVK9K4cWMmTJjAokWLiI2NBWDp0qUUKlSI2bNnU6pUKfr370+7du2YO3dusnHNmDGDAQMGsG7dOnr27Jkl15oSSaREtitQty5F2rUDReHY118TFxVl6JCEEEIIId6OokD8i/S9YiPh1EBASa4h7T+nBmnrpac9Jbl2UqdWqwkICGDhwoXcvXs3yf6QkBCsra1TfQUEBKTYfkREBAAODg4ABAcHExcXR6NGjXR1SpYsScGCBTl69CgAR48epVy5cri4uOjqNGnShMjISC5evKir83obiXUS23jdl19+yaRJk9i6dStt2rRJ71uTacbZfgYhgMojRxJ27Bgv7t7l9IwZ1Pi3l0oIIYQQIldKiIYN1lnUmAIxd2GjXfqqt48CY6sMn6VNmzZUrFiRcePGsXz5cr197u7unD17NtXjE5OkN2k0GgYPHswHH3xA2bJlAQgLC8PU1BR7e3u9ui4uLoSFhenqvJ5EJe5P3JdancjISGJiYrCwsABgx44d/Pbbb+zdu5cGDRqkeh1ZRRIp8U6YWFnhM2UKe3r04Mavv+LRsCEF6tUzdFhCCCGEEO+V6dOn06BBA4YPH65XbmxsTNGiRTPVpr+/PxcuXODQoUNZEWKmlC9fnkePHjFu3DiqV6+OtXVWJbkpk0QqJ9EkoArfT4H4A6jCrcCtPhipDR1VlnGuWpWS3bpxZdUqjo8dS4vffsPsjb9SCCGEEELkCmpLbc9QeoQfgKDmadfz3Q7OddN37kyqW7cuTZo0YdSoUfTo0UNXHhISQunSpVM9dvTo0YwePVqvrH///mzdupUDBw7g4eGhK3d1dSU2NpZnz57p9Uo9ePAAV1dXXZ0TJ07otZc4q9/rdd6c6e/BgwfY2trqeqMAChQowMaNG6lfvz5NmzZlx44d2NjYpPFuvB1JpHKKO5sgeBDG0XepCrB/Dlh6QJX54Nk2raNzjQqDBnH/4EEi//mHk5MmUTsbp6QUQgghhMg2KlX6h9e5+mk/10XfI/nnpFTa/a5+7+SP6NOmTaNixYqUKFFCV5bRoX2KojBgwAA2b95MUFAQhQoV0qtbpUoVTExM2Lt3Lx9//DEAV69eJSQkBB8fHwB8fHyYMmUK4eHh5M+fH4DAwEBsbW11SZ2Pjw/bt2/XazswMFDXxuu8vLzYv3+/LpnauXNntiZTMtlETmDgWVzeJbWZGT5Tp6JSqwnZuZNbb/xgCCGEEELkOUZq7R/HAXhz3aZ/t6vMe2cjkcqVK0fnzp1ZsGCBrixxaF9qr9cTKX9/f1avXs2aNWuwsbEhLCyMsLAwYmJiALCzs6N3794MHTqUffv2ERwcTM+ePfHx8aFmzZoA+Pn5Ubp0abp27cq5c+fYu3cvY8eOxd/fHzMzMwC++OIL/vnnH0aOHMmVK1dYvHgxGzZsYMiQIclem6enJ0FBQYSHh+smrsgukkgZmiYBggeR6iwuwYPfyWJt74pj2bKU+fxzAE5NmkR0eLiBIxJCCCGEyGaebaHORrAsoF9u6aEtf8cjkCZOnIhGo8n08UuWLCEiIgJfX1/c3Nx0r/Xr1+vqzJ07l5YtW/Lxxx9Tt25dXF1d2bTpvw4CtVrN1q1bUavVfPDBB3z++ed07dqVia9NSlaoUCG2bdtGYGAgFSpUYPbs2fzwww80adIkxdg8PDwICgri0aNH2ZpMydA+Q3t4MGlPlB4Fou9o67n4vquosl3Zvn25v38/Ty5e5PjYsfguWZLplbWFEEIIIXIFz7ZQ4CPt57qYULBwA6c62d4TtXLlyiRl3t7evHr1KtNtKumYgt3c3JxFixaxaNGiFOt4eXmxfft2NBoNkZGR2NraYmSk39fj6+vLmTNnUmwjuesrUKAA165dSzPGtyE9UoYWE5q19XIJIxMTfAICMDI1JfTgQW5s3GjokIQQQgghsp+RWvvHce9O2n/z0MRi7xtJpAzNwi1r6+UidkWLUmHQIABOz5hBVDKLwwkhhBBCCJETSSJlaE51tGNjkzx4mEgFlp7aenlQyW7dcK5alfjoaI59/TXKW4zVFUIIIYQQ4l2RRMrQUp3FBUCBSrPybLevysiImlOmYGxpSfipU1z56SdDhySEEEIIIUSaJJHKCVKaxSXx2/Ps/DsP6V2y9vCg8siRAJybP5+I69cNHJEQQgghhBCpk0Qqp/BsC61uEV8vkFNmQ4mvFwgfrNHuuzQVHh03bHzZrEi7drjVqYMmNpajo0ejiYszdEhCCCGEEEKkSBKpnMRIjeJcj3vGdVGc64FXB/D6FBQNHO0G8dGGjjDbqFQqakyciKmtLU8uXuTCsmWGDkkIIYQQQogUSSKV01X7Fizc4fk1ODvK0NFkK0tnZ6p+8w0AF7/7jscXLhg4IiGEEEIIIZIniVROZ5oPaizXfn1tAYT9adh4spl38+YUbNoUJSGBo6NGEf/ypaFDEkIIIYQQIglJpHID96ZQ9HPt18d6QmyEYePJZtW++Qbz/PmJ/Ocfzi9YYOhwhBBCCCGESEISqdyi0iywLgzRIXB6iKGjyVZm9vbUmDgRgCs//cSDkycNHJEQQgghRNbQJCTw4MQJbm3bxoMTJ9AkJGT7OXv06IFKpWLatGl65Vu2bEGlSmkt09RNnTqVatWqYWNjg7OzM61bt+bq1at6dXx9fVGpVHqvL774Qq9OSEgILVq0wNrammLFijFy5Eji4+P16gQFBVG5cmXMzMwoWrQoK1euTHJ9rVu31ivbuHEj5ubmzJ49O1PXlx6SSOUWJtZQcyWggn9WwN0/DB1RtipQrx5FPv4YFIWjo0dz78CBd/oLRwghhBAiq90JDOT3xo3Z27MnR0aOZG/PnvzeuDF3AgOz/dzm5uZMnz6dp0+fZkl7+/fvx9/fn2PHjhEYGEhcXBx+fn68ePFCr95nn31GaGio7jVjxgzdvoSEBFq0aEFsbCyHDh1i8eLFrFq1irFjx+rq3Lx5kxYtWlC/fn3Onj3L4MGD6dOnD7t27Uoxth9++IHOnTuzZMkShg0bliXXmxzjbGtZZD3nOlBqGFyeBSc+g/wXwDy/oaPKNpVHjuTun38Sff8++/v105VburhQZdQoPBs3NmB0QgghhBDpdycwkINDhoCi6JVHh4dzcMgQ6sydm62fbRo1asT169eZOnWqXjKTWTt37tTbXrlyJc7OzgQHB1O3bl1duaWlJa6ursm2sXv3bi5dusSePXtwcnKicOHCTJgwgVGjRjF+/HhMTU1ZunQphQoV0vUslSpVikOHDjF37lyaNGmSpM0ZM2Ywbtw41q1bR5s2bd76OlMjPVK5TflJYFcGXj6Ak/2S/DDmJWFHj/Iqmb+aJP7CeRd/vRFCCCGESI6iKMRHR6frFfv8OacCApL/3KYooCicmjqV2OfP09WekonPf2q1moCAABYuXMjdu3eT7A8JCcHa2jrVV0BAQIrtR0Ron+F3cHDQK//555/Jnz8/ZcuWZdSoUURH/7ecz9GjRylXrhwuLi66siZNmhAZGcnFixd1dRo1aqTXZpMmTTh69GiSGL788ksmTZrE1q1bsz2JAumRyn3U5uDzP9hVHe5shNtrwftTQ0eV5TQJCQRPnZr8TkUBlYrgadMo0KABRmr1uw1OCCGEEO+9hJgYNlSrlmXtxTx4wMaaNdNVt/3JkxhbWmb4HG3atKFixYqMGzeO5cuX6+1zd3fn7NmzqR7/ZpKUSKPRMHjwYD744APKli2rK//000/x8vLC3d2d8+fP8+WXX3L16lU2bdoEQFhYmF4SBei2w8LCUq0TGRlJTEwMFhYWAOzYsYPffvuNvXv30qBBgzTeiawhiVRu5FAJyo6Fv8bCSX9wrgeWBQwdVZZ6GBxM9IMHKVdQFKLDwngYHIxL9ervLjAhhBBCiFxs+vTpNGjQgOHDh+uVGxsbU7Ro0Uy16e/vz4ULFzh06JBeed++fXVflytXDjc3Nxo2bMiNGzcoUqRIps6VkvLly/Po0SPGjRtH9erVsba2ztL2kyOJVG5VZhTc+wOenITjvcF3B2Ry1pWcKObhwyytJ4QQQgiRldQWFrRP58zC4cHBBL0xW11yfJcuxblKlXSdO7Pq1q1LkyZNGDVqFD169NCVh4SEULp06VSPHT16NKNHj9Yr69+/P1u3buXAgQN4eHikenyNGjUAuH79OkWKFMHV1ZUTJ07o1Xnw7x/SE5+rcnV11ZW9XsfW1lbXGwVQoEABNm7cSP369WnatCk7duzAxsYm1XjeliRSuZWRMfj8BDsrQeguuP4dFEv7BzS3sHByytJ6QgghhBBZSaVSpXt4nWutWli6uBAdHp78c1IqFZYuLrjWqvVOHlmYNm0aFStWpESJErqyjA7tUxSFAQMGsHnzZoKCgihUqFCa501s383NDQAfHx+mTJlCeHg4+fNrJ1ALDAzE1tZWl9T5+Piwfft2vXYCAwPx8fFJ0r6Xlxf79+/XJVM7d+7M1mRKJpvIzexKQoV/nyM6Mxye3zBsPFnIqUoVLF1c0uxli4+JeUcRCSGEEEJkjpFaTZVRo7Qbb362+Xe7yldfvbPnvsuVK0fnzp1ZsGCBrixxaF9qr9cTKX9/f1avXs2aNWuwsbEhLCyMsLAwYv79bHbjxg0mTZpEcHAwt27d4vfff6dbt27UrVuX8uXLA+Dn50fp0qXp2rUr586dY+/evYwdOxZ/f3/MzMwA+OKLL/jnn38YOXIkV65cYfHixWzYsIEhQ5JfV9XT05OgoCDCw8N1E1dkF0mkcrsSA8HZF+JfwLHuoMkbayyl+gvnNQcGDOCfLVveTVBCCCGEEJnk2bgxdebOxdLZWa/c0sUl26c+T87EiRPRaDSZPn7JkiVERETg6+uLm5ub7rV+/XoATE1N2bNnD35+fpQsWZJhw4bx8ccf88cf/62Fqlar2bp1K2q1mg8++IDPP/+crl27MnHiRF2dQoUKsW3bNgIDA6lQoQKzZ8/mhx9+SHbq80QeHh4EBQXx6NGjbE2mZGhfbqcygporYHt5eHgYrsyB0iMMHVWWSPyFEzx1qt7EE5aurlQaPpx7+/dz648/OPb118Q8fEjpPn0yvTq3EEIIIUR282zcmAINGvAwOJiYhw+xcHLCqUqVbO+JWrlyZZIyb29vXr16lek205qC3dPTk/3796fZjpeXF9u3b0ej0RAZGYmtrS1GRvp9Pb6+vpw5cybFNpK7vgIFCnDt2rU0z/82JJHKC6y9ocpcON4Hzo8B92ZgXzbNw3KD1H7hFGzSBIv8+bm8YgXn5s0j5tEjqnz5JSoj6WgVQgghRM5kpFbLjMN5hHzizCsK9wL3FqCJhaPdICHW0BFlmcRfON4tWuBSvbrurzYqIyMqDR9O5ZEjAbi2ejWHR4wgITbvXLsQQgghhMiZJJHKK1QqqPE9mDrA0zNwcbKhI3pnSnbvTq0ZMzAyNiZk506CPv+c2OfPDR2WEEIIIYTIwySRykss3KDaEu3XFwPgcfrWNsgLvFu0wHfpUowtLXlw4gR7uneXNaaEEEIIIUS2kUQqr/FqD16dQEnQDvGLf3+mB3f18aHRqlWYOzry7OpVdnfuTOStW4YOSwghhBBC5EGSSOVFVb/V9k5FXoFzo9Oun4c4lC6N388/Y12wIC/u3SOwSxcenT9v6LCEEEIIkUekNVudyB3eZur3RDJrX15k5gA1lkNQc7g6Dzw+AhdfQ0f1zlh7euK3ejVB/frx5OJF9vbqRZ25c3GvU8fQoQkhhBAilzIxMUGlUvHw4UOcnJxkyZUsptFoiI2N5eXLl0mmP89KiqIQGxvLw4cPMTIywtTUNNNtSSKVV7k3g6J94foyONYDmp8HE1tDR/XOmDs60nDFCg4NGULo4cPs9/enxsSJFG7d2tChCSGEECIXUqvVeHh4cPfuXW7JowNZTlEUYmJisLCweCdJqqWlJQULFnyrpE0Sqbys0iwIDYQXN+H0UKjxg6EjeqdMrKyo++23HB87VhbuFUIIIcRbs7a2plixYsTFxRk6lDwnLi6OAwcOULduXUxMTLL1XGq1GmNj47f+PCiJVF5mYgM+q2BPPbixHAp8BB4fGjqqd0ptaopPQAAWTk5c/vFHWbhXCCGEEG9FrVaj/ndNS5F11Go18fHxmJubZ3silVXkk2Re51wHSg7Vfn3iM3j5yLDxGIDKyIhKw4ZR+csvAVm4VwghhBBCvD1JpN4HFSaDXWl4+QBO/R+8p7PNlOzWjVozZ8rCvUIIIYQQ4q1JIvU+UJuDz0+gMoaQX+D2OkNHZDDezZvj+913GFtZycK9QgghhBAi0ySRel84VIGyY7Rfn/KH6PuGjceAXGvWTLpw782bhg5LCCGEEELkIpJIvU/KjNYmVLFP4Xjv93aIH4BDqVKycK8QQgghhMg0SaTeJ0Ym2iF+RmYQuhNufG/oiAwqceFeh7JlefXsGXt79eLegQOGDksIIYQQQuQCkki9b+xKQ4UA7denh0LUP4aNx8DMHR1p+OOPuH3wAQkxMRzo359/Nm82dFhCCCGEECKHk0TqfVRyMDjXg/gXcLQHaBIMHZFBmVhZUW/RIrxbtUJJSODYmDFc/P57lPd46KMQQgghhEidJFLvI5UR1FwBxtbw8CBcnWfoiAzOyMQEn4AASvXqBcC5efMInjoVRaMxcGRCCCGEECInkkTqfWVdCCrP1X597mt4dtGw8eQAKpVKf+Hen3+WhXuFEEIIIUSyJJF6nxXpDe4tQPMKjnYDTZyhI8oR3ly4d1/fvrJwrxBCCCGE0COJ1PtMpYIa34OpAzw9DRemGDqiHOP1hXvDT56UhXuFEEIIIYQeSaTedxZuUG2x9uuLk+HxScPGk4MkWbj3009l4V4hhBBCCAFIIiUAvDpAwQ6gJGiH+MXHGDqiHCNx4V4bLy9e3L8vC/cKIYQQQghAEimRqNoiMHeFyCvaySeEjrWnJ41l4V4hhBBCCPEaSaSElpkj1Fiu/frqPHiw36Dh5DTmDg7ahXtr15aFe4UQQgghhCRS4jUFmkORPoACx3pAnMxU9zoTKyvqffsthWThXiGEEEKI954kUkJf5Tlg5Q0vbsHpoYaOJscxMjGhZkAApXv3Bv5buFeTkGDgyIQQQgghxLskiZTQZ2IDNVcCKrjxA9zbZuiIchyVSkXFoUOp/NVXgHbh3iOycK8QQgghxHtFEimRlEs9KDFY+/XxPvDqsUHDyalKdu3638K9u3bJwr1CCCGEEO8RgyZSU6dOpVq1atjY2ODs7Ezr1q25evWqXp1ly5bh6+uLra0tKpWKZ8+eJWnnyZMndO7cGVtbW+zt7enduzdRUVHv6CryqApTwLYUvAyDk/6GjibHSrJwb7duRIeHGzosIYQQQgiRzQyaSO3fvx9/f3+OHTtGYGAgcXFx+Pn58eLFC12d6OhomjZtyujRo1Nsp3Pnzly8eJHAwEC2bt3KgQMH6Nu377u4hLzL2AJ8fgKVGkLWw+31ho4ox9JbuPfaNQI7d5aFe4UQQggh8jhjQ558586detsrV67E2dmZ4OBg6tatC8DgwYMBCAoKSraNy5cvs3PnTk6ePEnVqlUBWLhwIc2bN2fWrFm4u7tnW/x5nmNVKDMGLkyAk/8HznXBws3QUeVIDqVK4bdmDfv69uX57dsEdulCvSVLyF++vKFDE0IIIYQQ2cCgidSbIiIiAHBwcEj3MUePHsXe3l6XRAE0atQIIyMjjh8/Tps2bZIc8+rVK169eqXbjoyMBCAuLo64uLjMhp8lEs9v6Dh0SoxEfe8PjJ6eRnO0Nwm1t4BKZeiociQzFxfqr1jBwQEDeHrxInt79sRnxgzc/v2jQHbJcfeMyPHknhEZJfeMyCi5Z0RG5aR7Jr0x5JhESqPRMHjwYD744APKli2b7uPCwsJwdnbWKzM2NsbBwYGwsLBkj5k6dSoTJkxIUr57924sLS0zFng2CQwMNHQIOjaantTjL9RhOzj3+1BCTBobOqQcTWnXDnVcHAnXrnFo8GBM27TBpEqVbD9vTrpnRO4g94zIKLlnREbJPSMyKifcM9HR0emql2MSKX9/fy5cuMChQ4ey/VyjRo1i6ND/1kiKjIzE09MTPz8/bG1ts/38qYmLiyMwMJDGjRtjYmJi0Fj0XI2G819SUbOKsvUGglUhQ0eUo2latuTUhAnc3rqV2F9/pbi7OyV79UKVDb15OfaeETmW3DMio+SeERkl94zIqJx0zySOVktLjkik+vfvr5skwsPDI0PHurq6Ev7GLGnx8fE8efIEV1fXZI8xMzPDzMwsSbmJiYnBv3GJclIsAJQeBqFbUT08iMmpz6DhPlDJ7PkpMjGh1rRpWLm4cGn5ci4sXEjs48dU/uorjNTqbDplDrtnRI4n94zIKLlnREbJPSMyKifcM+k9v0E/CSuKQv/+/dm8eTN//vknhQplvJfDx8eHZ8+eERwcrCv7888/0Wg01KhRIyvDfb8ZqcFnJRhbQfgBuDLP0BHleHoL96pUXFuzRrtw72vP5wkhhBBCiNzJoImUv78/q1evZs2aNdjY2BAWFkZYWBgxMTG6OmFhYZw9e5br168D8Ndff3H27FmePHkCQKlSpWjatCmfffYZJ06c4PDhw/Tv35+OHTvKjH1ZzbowVJ6j/frcaIi4ZNh4comSXbvywesL937+uSzcK4QQQgiRyxk0kVqyZAkRERH4+vri5uame61f/9+aRUuXLqVSpUp89tlnANStW5dKlSrx+++/6+r8/PPPlCxZkoYNG9K8eXNq167NsmXL3vn1vBeKfAZuzUDzCo52A43hZ1bJDbyaNZOFe4UQQggh8hCDD+1L7tWjRw9dnfHjx6dZx8HBgTVr1vD8+XMiIiL48ccfsba2fvcX9D5QqaDGD2CaD54Ew8UAQ0eUa7jWrEnjVaswz59fFu4VQgghhMjlZLYAkXGW7lB1kfbrC5O1CZVIl3ylSuH388/YeHnx4v59Art04dH584YOSwghhBBCZJAkUiJzvDpCwfagxGuH+CW8NHREuYa1hweNV6/GoWxZXj17xt6ePbm3f7+hwxJCCCGEEBkgiZTIHJUKqi0Gc1ftpBPnxhg6olzF3MGBhj/+iFudOiS8fMmBAQO4sXmzocMSQgghhBDpJImUyDwzR+3zUgBX5minRRfpZmJlRb2FCyn00UcoCQkcHzOGi8uWoSiKoUMTQgghhBBpkERKvJ0CLaBIb0CBoz0gTqb1zggjExNqTplC6T59ADg3fz7BAQFoEhIMHJkQQgghhEiNJFLi7VWeA1Ze8OImnBlu6GhyHZVKRcUhQ6gyapRu4d7Dw4fLwr1CCCGEEDmYJFLi7ZnYQs2V2q+vL4P7OwwaTm5VoksX7cK9Jibc2b1bFu4VQgghhMjBJJESWcPFF0oM1n59vDe8emLIaHItr2bN8F26VBbuFUIIIYTI4SSRElmnQgDYloSYUDjlb+hoci1ZuFcIIYQQIueTREpkHWML8PkJVGq4vQ5ubzB0RLlWsgv3njtn6LCEEEIIIcS/JJESWcuxGpQZrf36ZD9t75TIlMSFex3LldMu3NurlyzcK4QQQgiRQ0giJbJemTGQrxLEPoHjn4Gsi5RpsnCvEEIIIUTOJImUyHpqU+0QPyNTuL8N/vnR0BHlasaWliku3KtJSCD85Eniz50j/ORJWX9KCCGEEOIdMTZ0ACKPsi8L5SfD2ZEQPBhcGoK1t6GjyrUSF+61cHbm0vffc27+fMKDg3n299/EPHgAwP7167F0caHKqFF4Nm5s4IiFEEIIIfI26ZES2afkUHCqDfFRcKwHKBpDR5SrqVQqKg4eTJXR2mfQQg8d0iVRiaLDwzk4ZAh3AgMNEaIQQgghxHtDEimRfYzU4LMKjK0gfD9cXWDoiPKEYh07Ympnl/zOf59HC542TYb5CSGEEEJkI0mkRPayLgyVZmu/PjcKIq4YNp484GFwMLERESlXUBSiw8J4GBz87oISQgghhHjPSCIlsl/RvuDWFBJewtFuoIk3dES5WszDh1laTwghhBBCZJwkUiL7qVRQ4wcwsYcnJ+HiVENHlKtZODllaT0hhBBCCJFxkkiJd8OyAFRbpP36wkR4ctqw8eRiTlWqYOniok1QU2Dp6opTlSrvMCohhBBCiPeLJFI5SIImgf2393Pg6QH2395PgiaPTRbg1Qk824ESrx3il/DS0BHlSkZqNVVGjdJupJBMlerVCyO1+h1GJYQQQgjxfpFEKofYdHkT3vO9afxzY+bcnkPjnxvjPd+bTZc3GTq0rKNSQbUlYO4CERfh/DeGjijX8mzcmDpz52Lp7KxXbmRiAsDf69YRFxVliNCEEEIIId4LkkjlAJsub6LdhnbcjbyrV34v8h7tNrTLW8mUeX6o/r3268uzIfygYePJxTwbN6ZVYCD1vv8esw4dqPf997TauRMLFxci//mHI19+iaKRtbuEEEIIIbKDJFIGlqBJYNDOQSgoSfYllg3eOThvDfPz+BAK9wQU7UK9cdJzkllGajXO1aphXKECztWqYenqSt0FCzAyNeVeUBB/LVpk6BCFEEIIIfIkSaQM7GDIwSQ9Ua9TULgTeYceW3qwLHgZO/7ewV8P/uLZy2coStLkK9eoMg8sC0LUP3BmuKGjyVMcy5alxoQJAFxYupQ7gYEGjkgIIYQQIu8xNnQA77vQ56Hpqrf6r9Ws/mu1Xpm1qTWetp542nniYeOBp53nf9u2HnjaemJjZpMdYb89E1vwWQl7G8D178CjNbg3NXRUeUahVq14cvkyV3/6iaOjRmHj5YV98eKGDksIIYQQIs+QRMrA3Gzc0lWvVfFWaNBwJ+IOdyLv8CTmCVGxUVx+dJnLjy6neJydmd1/CZbtvwnWGwmXpYllVl1OxrjUh+ID4doCON4bWlwA03yGiSUPqjRsGBF//03Y0aMcGDiQJuvWYWZvb+iwhBBCCCHyBEmkDKxOwTp42HpwL/Jess9JqVDhYevBpg6bUBv9N531i9gX3Ht+T5dYJf57N/KubjviVYT2FR7BhfALKcbgYOGgS6ySS7g8bD0wMzbLluun4lQI2wWRV+Fkf/jg5+w5z3vIyNiYD2bNYmeHDkTducPhESPwXbIEI2P5sRdCCCGEeFvyicrA1EZq5jedT7sN7VCh0kumVGjXCJrXdJ5eEgVgZWpFccfiFHdMebjW81fP9RKrxH/vPr+r246KjeJJzBOexDzh3INzKbblbOWsGy74etKVmHAVsCmAidok42+AsSXU/AkCa8HtNeDZBgq206uSoEngYMhBQp+H4mbjRp2CdZK8HyJ5Zvb21Fu4kN2ffkrYkSOcnTuXyiNGGDosIYQQQohcTxKpHKBtqbZsbL+RQTsH6U084WHrwbym82hbqm2m2rUxs6GUUylKOZVKdr+iKES8itAmV28mXIm9WxF3iImPIfxFOOEvwjkdejrZtlSocLV21Xs+682Ey83GDWOjZG65/NWh9Ci4OBlOfgFOtcHCFdBODZ/c+zK/6fxMvy/vG/vixakZEMChIUO4snIl+UqVolDLloYOSwghhBAiV5NEKodoW6otH5X4iH3/7GPHoR00q92M+oXrZ2vPi0qlwt7cHntze8q5lEu2jqIoPIl5opdYJSZaiQnY3ci7vEp4RWhUKKFRoZy4dyLZttQqNW42bslOkFHQoSkVbbdgEnkBTvSFur+x6cpm2m1ol2TIY+L6Whvbb5RkKp0K+vlRpm9fLi5bxomxY7ErVAiHMmUMHZYQQgghRK4liVQOojZSU8+rHi8uvqCeV70cMXxNpVLhaOmIo6UjFV0rJltHURQeRj/Uf07rjYTr3vN7xGvidYnX0btHk7RTxhSCC4LZvT8I+Kk4k+8m/9yYgoIKFYN3DuajEh/liPcpNyg/YABPr17l/v792skn1q/HIn9+Q4clhBBCCJErSSIl3ppKpcLZyhlnK2equFdJto5G0fAg6kGKE2PcibzD5ef3+eaxhhn5ob/Rdb4DQlI4Z+L6WgdDDuLr7Ztdl5anqIyMqDV9Ors7dSLy5k0ODRlCg+XLUZuaGjo0IYQQQohcRxIp8U4YqYxws3HDzcaN6gWqJ1snXhNP2PN7RB5shW3keVa4QKN7JNMn9Z/0rsMltExtbKi7cCG7Onbk4enTBE+bRvWxYw0dlhBCCCFErmNk6ACESGRsZIyHnRe29X4lwcicBpYwwD71Y9K7Dpf4j22hQtSaORNUKq6vX8/1DRsMHZIQQgghRK4jiZTIeWyKoqo0C4BpjlAimVnVVajwtPWkTsE67zi4vKFA3bpUGDQIgFNTpvDwdPKzMQohhBBCiORJIiVyJKPi/8cDmwpYGMEqV2hgAR2toZ6F9qZVUJJdX0ukX+k+fSjYtCma+HgODh5MdFiYoUMSQgghhMg1JJESOZNKhUvDrcQZmVLDHPZ6wFo3CPKAW97QxgryW8qMc29DpVJRc9Ik7EuU4OXjxxwYOJD4ly8NHZYQQgghRK4giZTIuR6fwEQTm6TYwwQ2usHWvb3QKBoDBJZ3GFtaUnfhQszs7Xly8SInJkxAUVKb3kMIIYQQQoAkUiKn0iRA8KBkd6n+/be/+gYb/lr77mLKo6wLFKD2nDmo1Gpu/f47V3/6ydAhCSGEEELkeJJIiZzp4UGIvpvibiMVFDSBLQeH8TJehqO9LZcaNag8ciQAZ2bNIuxo0gWThRBCCCHEfySREjlTTPrWh/o/swds3dcPEpIOARQZU7xzZwp99BGKRsOhYcOIunPH0CEJIYQQQuRYkkiJnMkifetD1bWEdg9XotnkDMd6wf2doInL5uDyJpVKRfVx43AsV47YiAgODBxI3IsXhg5LCCGEECJHkkRK5ExOdcDSg/+eiHqTCsXMmXWxjoTGg1FcBPyzAoKawSZXOP4ZhO0BTfy7jDrXU5uZUWf+fMzz5+fZtWscGzNGJp8QQgghhEhGphKpmJgYoqOjddu3b99m3rx57N69O8sCey8lJKDav58CBw6g2r8fEhIMHZHhGKmhyvx/N95MprTbqupLcK63AY+b0OCemmeen4K5M8Q+gRs/wJ+NYbMbnPgCHuzTTmAh0mTp4kKdefMwMjbmzu7dXFy2zNAhCSGEEELkOJlKpD766CN++ndmr2fPnlGjRg1mz57NRx99xJIlS7I0wPfGpk3g7Y1x48ZUnTMH48aNwdtbW/6+8mwLdTaCZQH9cksPbblnWxoUakCzYi3YF51Az/vR0Po+NNgLRT8Hs/zw6hFc/w72NoAtBeCkP4QfkKQqDU6VKlH1m28AOL9wIfeCggwbkBBCCCFEDpOpROr06dPUqVMHgI0bN+Li4sLt27f56aefWLBgQZYG+F7YtAnatYO7b8xSd++etvx9T6Za3YKG+6DWGu2/rW5qy/81o/EMjFRGbLmyhQN3DoNrA6i+FNqEQv3dUKQPmDrAywfw92LYUw9+84RTg+DhYZC1qJJVtF07inXsCIrC4ZEjifjnH0OHJIQQQgiRY2QqkYqOjsbGxgaA3bt307ZtW4yMjKhZsya3b9/O0gDzvIQEGDQIknsOJbFs8GAZ5ufiC96dtP8aqfV2l3YqzWeVPwNg+O7h/y3Sa2QMbo2hxvfQNgx8d0DhHmBip50V8NoCCKwNv3lB8FB4dCz578N7rMpXX+FctSrxL15wYMAAYiMjDR2SEEIIIUSOkKlEqmjRomzZsoU7d+6wa9cu/Pz8AAgPD8fW1jZLA8zzDh5M2hP1OkWBO3e09USKJvhOwNrUmpP3T7L+wvqkFYxMwL0p1FwBbcOh3lbw7gomttr1qq7Ohd0+8Js3nBkBj09KUgUYmZhQe84cLF1deX7rFke+/BLN+5zUCyGEEEL8K1OJ1NixYxk+fDje3t7UqFEDHx8fQNs7ValSpSwNMM8LTd96ScycCcePy4f7FLhYu/DVB18BMGrvqNQX6VWbQoEWUOsnaPsA6v4GXp+CsTVEh8DlWbCrOvxeBM5+BU9Ov9fvu7mjI3UXLkRtbs79Awc4v3ChoUMSQgghhDC4TCVS7dq1IyQkhFOnTrFz505decOGDZk7d26WBfdecEvfekls3w41a0KhQjByJJw69V5/uE/OEJ8hFLApwO2I2yw4ns5n9dTm4NEKPvhZ21NV51co2AHUlvDiJlyaDjurwB/F4dzX8PT8e/m+O5QuTY2JEwG49P333H7t514IIYQQ4n2U4UQqLi4OY2NjHj16RKVKlTAy+q+J6tWrU7JkySwNMM+rUwc8PECVwnpJKhXkzw8dOoCVFdy+re2dqlYNihaFUaPgzJn38sP9myxNLJnSYAoAUw5O4VH0o4w1YGyhncSi9jr4+CHU3gCe7UBtAVHX4WIA7KgA20rB+bHw7GI2XEXO5d2iBaV69gTg2JgxPL1yxcARCSGEEEIYToYTKRMTEwoWLEiCPCeRNdRqmP/veklvJlOJ2999B+vWwcOH8Ouv0L49WFrCP//AtGlQuTKUKAFjxsD597PHJFHXCl2p6FqRyFeRTNw/MfMNGVtCwU+gzi/anqpaa8GjDRiZQeRVuDAJtpeFbWXgr4kQ8X4kFRWGDMG1Vi0SYmI4MGAAL58+NXRIQgghhBAGkamhfV9//TWjR4/myZMnWR3P+6ltW9i4EQq8sV6Sh4e2vO2/U31bWGi/Xr8ewsO1/378MZibw99/w5QpUKEClC4N48bBpUvv/loMzEhlxGy/2QAsObWEa4+vvX2jJtbg3RHqboKPw8FnNRRoBUamEHEJ/hqn7aXaXh4uTIHIv9/+nDmUkVpN7VmzsPb05MX9+xweOhRNfLyhwxJCCCGEeOcylUh9++23HDhwAHd3d0qUKEHlypX1XiIT2raFW7eIDwzk1NChxAcGws2b/yVRb7Ky0vZMbdyo7alaswZatwYzM7hyBSZOhDJloGxZ7ddXr77TyzGkBoUa0KJYC+I18Xy558usbdzEFgp1hnq/aSeqqLkK3FtoZwV89hecHwNbi8OOynBxGkTlvbWXTO3sqPvttxhbWvLgxAnOzJxp6JCEEEIIId4548wc1Lp16ywOQwCgVqPUq8e9Fy+oUK+edthfelhbQ6dO2ldkJPz+O2zYADt3wsWL2t6pceOgfHlt8tWhg/b5qjxsRuMZ7Ly+U7tI7+0D1PWqm/UnMbWHwt20r9incGcLhGyAsD3w9Iz2dW4UOFSFgu3Bqz1YeWV9HAZgX7QoPtOmcXDgQK6uXk2+UqUoLL8XhBBCCPEeyVQiNW7cuKyOQ2QVW1vo0kX7evYMfvtNm1Tt3q19fur8ee2zVJUqaROqTz6BwoUNHXWWS1ykd2nwUobvHs6xPscwUmWqAzZ9TPNBkZ7a16vHcGczhKyHB3/Ck1Pa19mR4FhDm1QV/ASsPLMvnnfAs2FDyv7f/3Fh8WJOTJiAbeHC5C9f3tBhCSGEEEK8E2/1yTI4OJjVq1ezevVqzpw5k1Uxiaxibw/du8O2bfDgASxfDn5+2p6uM2fgq6+gSBHtDICzZmlnBMxDxvuO1y3Su+7Cund3YjNHKNoHGgRCmzCothRc6oPKCB4fhzPD4LeCsPsDuDIfou+/u9iyWLl+/fBo2BBNbCwHBw0i5uFDQ4ckhBBCCPFOZCqRCg8Pp0GDBlSrVo2BAwcycOBAqlSpQsOGDXkoH6RyJgcH6NULdu2CsDBYtgwaNgQjI+2aVCNGgLe3dq2quXPhzh1DR/zWMrRIb3Yxd4Jin0PDP6H1Paj6LTjXBVTw6AicHgxbPCCwLlxbBDFh7z7Gt6AyMsJn6lTsihQhJjycg4MHkxAba+iwhBBCCCGyXaYSqQEDBvD8+XMuXrzIkydPePLkCRcuXCAyMpKBAwdmdYwiq+XPD599Bnv2QGgoLFkCvr7a6daPH4ehQ6FgQahdGxYsgPu5t8ckcZHekIiQ9C/Sm10sXKG4PzTaD63vQpX54PQBoMDDg3CqP2x2hz314e+l8DLcsPGmk4mVFXUXLsTE1pZHZ89yavJklPd4Cn4hhBBCvB8ylUjt3LmTxYsXU6pUKV1Z6dKlWbRoETt27Miy4MQ74OwMX3wB+/ZpE6aFC7WLBKtUcPgwDBqknYa9Xj1YtEjbm5WLWJpYEtAwAMjkIr3ZxdIdSgyExoeg9R2oPAccawIKhAfByX6w2Q32NoLr38PLFOLWJKAK30+B+AOowveDxjDru9l4efHBzJmojIy48euv/L3uHQ6lFEIIIYQwgEwlUhqNBhMTkyTlJiYmaDSatw5KGIirK/TvDwcOaIf2zZsHtWppF/g9cEC7r0ABaNAAli7VrmWVC3Qp30W3SO+EoAmGDicpSw8oOQSaHIWPbkGlmeBQDRQNPNgLJ/rCZlfY1xRu/Aiv/l2/7c4m+N0b4/2NqfpqDsb7G8Pv3tpyA3CvXZsKQ4YAEDxtGuGnThkkDiGEEEKIdyFTiVSDBg0YNGgQ918b8nXv3j2GDBlCw4YNsyw4YUAFCmh7ow4fhpAQmD0batQAjUbbe9WvH7i5QePG8P338PixoSNO0euL9C4NXsrVRzl4TS0rLyg1HJqegFY3oOI0yFcZlAQI3QXHe2uTqh1V+H/27ju8qfL94/g7SfeG7tJC2XuWLVuGTBERFBX3RGWq4B5fFyLLvX5ukCEgKgiILNmUvTe0pS0t0L2T8/vj6UoHTfe6X9eVqyQ9OTkJh5A7z/PcH7bdCUmh5vdPCoNtYyutmGr50EM0GDYMLSODbVOnkliNp4UKIYQQQtxMiQN54+LiCAwMpHHjxjRu3JiGDRsSFxfHxx9/XNbHKCpbQIBaN7VrlwoJnj0bOndWRdU//8Djj4O3N9x2G3z3Hdy4UdlHnE/ukN6ZG2dW9uFYxqkRtHoRhgbDiNPQ/h1waw+mdLixv5A7Za5NCp5SKdP8dDod3d56izotW5J6/Tpbn3uOjOTkCj8OIYQQQojyVqJCKiAggP379/PXX38xZcoUpkyZwpo1a9i/fz/+/v5lfYyiKgkMVB3+9u6Fs2fhvfdUJpXRqDoCPvywKqqGD4cff4TY2Mo+4mwfDvoQg86QHdJbrbg0hdYvwbCD0P2HIjbWIClENbCoBFb29vRZuBDbOnW4ceIEu197TZpPCCGEEKLGKXYhlZ6ejpWVFceOHWPQoEE8++yzPPvsswwcOLA8jk9UZY0bqyyq/fvh1Cn43/+gXTtIT4c1a1SGlZcXjBoFv/wCcXGVergtPVvyWKfHAJi+fjomrZqu59PnX59YoOTw8j2Om3D086PXvHnorKy4tGYNJ777rtKORQghhBCiPBS7kLK2tqZ+/foYjZXTHUxUUc2awcsvw6FDcPw4vPkmtGoFaWnwxx9w332qqBozBn79FRISKuUws0J6913ZV7EhvWXJ3rdstysn3l26EPTiiwAcmjePK//9V6nHI4QQQghRlko0te/ll1/mpZde4vr162V9PKImaNkSXnsNjh2Do0fh1VdVoZWaCitXwj33qKLqrrtg2TJITLz5/oxG2LwZFi9WP0tRxFeJkN7S8uytOv2hK3wbvR3U6Vhhh1SYpvfcQ+M770Qzmdj+/PPEX7pU2YckhBBCCFEmStxsYuvWrfj5+dG8eXM6depkdrHUe++9R5cuXXB2dsbLy4vRo0dz6pR5R7WUlBQmTZqEu7s7Tk5O3HnnnURGRpptc/nyZYYPH46DgwNeXl48//zzZGRklOSpibLWujW89RacPKlGq156CZo0geRkWL4cxo1TRdXdd8OKFer23FasUOuy+veHCRPUz8BAdXsJTe0xFX8X/6oR0lsSeoMK8wUKLaZMKfDvIEiJqrDDKohOp6PzK6/g0aED6XFxbH32WdKLKpyFEEIIIaoBq5LcafTo0WXy4Fu2bGHSpEl06dKFjIwMXnrpJQYPHszx48dxdHQEYOrUqfz1118sW7YMV1dXnnnmGcaMGcP27dsBMBqNDB8+HB8fH3bs2EF4eDgTJ07E2tqad999t0yOU5QBnU6tn2rXTq2lOngQliyBpUtVJ8AlS9TFyUmtqRo3ThVVEyaoHKvcwsJg7FhViI0ZU+xDcbB24J0B7/DAqgd4Z9s7PNThITwdPcvmeVaUgDHQezkETzZvge4QAE2fhpNz4Ppe2HAL9F8HTg0r7VANNjb0nj+fv8eNI/bcOXbOmkXv+fPR6Uv0PY4QQgghRNWgFVN6err25ptvaiEhIcW9a5GuXr2qAdqWLVs0TdO0mJgYzdraWlu2bFn2NidOnNAAbefOnZqmadqaNWs0vV6vRUREZG/z+eefay4uLlpqaqpFjxsbG6sBWmxsbBk+m5JJS0vTVq1apaWlpVX2oVQMk0nT9u7VtBkzNK1+fU1TZZO66HTm1/P+LiBA0zIySvSwRpNR6/BFB4030J7565kyflIVyJihpYdu0PYun6alh27QNGPm6xF7UtNWNdC0X9C033w07dr+Sj1MTdO0qEOHtMXt22u/tGqlHf7008o+nFqt1r3PiFKTc0YUl5wzoriq0jljaW1Q7BEpKysrPvzwQyZOnFjWNR2xma2y69atC0BwcDDp6elmHQFbtGhB/fr12blzJ927d2fnzp20bdsWb2/v7G2GDBnCU089xbFjx+jYMf86kdTUVFJTU7Ovx2V2k0tPTyc9Pb3Mn1dxZD1+ZR9HhWrfXl3eeQfdnj3oli9H/8sv6KKjC7+PpkFICBmbNqH17Vuih/1gwAcMWTSEL4K/4IlOT9DcvXkJn0DlSq/TkzCrRFrV6YlmNIHRBPaNoP8WrLaNQhd7GO2fvhhvWY7m1b/SjtO1ZUuCXnmFva+/zpFPP8W5cWPqDRhQacdTm9XK9xlRKnLOiOKSc0YUV1U6Zyw9hhJN7RswYABbtmwhMDCwJHcvkMlkYsqUKdxyyy20adMGgIiICGxsbHBzczPb1tvbm4iIiOxtchdRWb/P+l1B3nvvPd588818t69fvx4HB4fSPpUysWHDhso+hMrTvz/19Ho6z5tX5KYH164lrBRrbjq7dGZf3D4e/fVRZjWcVeL9VAUFnTNW2ot01b+HZ8ZR9FuGE2w7hStWvSrh6DJZW2PVowcZO3eyY+ZM7J96Cn2ef7+i4tTq9xlRInLOiOKSc0YUV1U4Z5KSkizarkSF1NChQ5k5cyZHjhwhKCgoez1TllGjRhV7n5MmTeLo0aP8VwEtkmfNmsW0adOyr8fFxREQEMDgwYNxcXEp98e/mfT0dDZs2MCgQYOwtrYwL6gG0jk6ggWFVIehQ2lfwhEpgIbRDen0dSd2x+7GqbUTfRr0KfG+KkuR54xxFKY9D6IP/Y0uqXMwtvTF1PTZij/QTKZBg9j69NNE7d2LYcUKbv3lF2wq+d9dbSPvM6K45JwRxSXnjCiuqnTOxFmYfVqiQurpp58GYO7cufl+p9Ppip0x9cwzz/Dnn3+ydetW/P39s2/38fEhLS2NmJgYs1GpyMhIfHx8srfZs2eP2f6yuvplbZOXra0ttra2+W63trau9L+4LFXpWCpF//7g768aS+RtNgGqeYW/P1b9+4PBUOKHaefbjsc6PcYXwV8wc9NMdj+6G72uejZBKPScsbaG3ksheAqc/hjDwekY0q5C+/fU61jRrK3pPW8e68aNIyEkhN0zZ9Lviy/Ql+LvUZRMrX+fEcUm54woLjlnRHFVhXPG0scv0SdGk8lU6KU4RZSmaTzzzDOsXLmSf//9l4YNzTuLBQUFYW1tzcaNG7NvO3XqFJcvX6ZHjx4A9OjRgyNHjnD16tXsbTZs2ICLiwutWrUqydMTVYHBAAsyW3wX9GFf02D+/FIVUVlqREhvUXR61TK9/Xvq+vEPYNeDYKqcech2derQZ+FCDHZ2ROzYwSELRh+FEEIIIaqSYhVSw4YNy24IAfD+++8TExOTff3atWvFKl4mTZrEzz//zKJFi3B2diYiIoKIiAiSM7OEXF1deeSRR5g2bRqbNm0iODiYhx56iB49etC9e3cABg8eTKtWrbj//vs5dOgQ69at45VXXmHSpEkFjjqJamTMGNXivF69gn+fZ+1cSXk7eTOrl1ofVW1Dei2h00HrmdD9O9AZ4MKPsGUUpCdUyuHUadmS7v/7HwAnvvuOi3/+WSnHIYQQQghREsUqpNatW2fW7e7dd9/l+vXr2dczMjLyBerezOeff05sbCz9+vXD19c3+7JkyZLsbebNm8eIESO488476dOnDz4+PqzIFcZqMBj4888/MRgM9OjRg/vuu4+JEyfy1ltvFeepiapqzBi4eBE2bYJFi9TPJ59Uv3v88fwBviU0pfuU7JDeBbsWFH2H6qzRg9BnNRgcIPxv2Dig0oJ7GwwdSqtHHwVg92uvcf348Uo5DiGEEEKI4ipWIaXlWauS93pxaZpW4OXBBx/M3sbOzo5PP/2U69evk5iYyIoVK/KtfWrQoAFr1qwhKSmJqKgo5syZg5VViZZ/iarIYIB+/eCee9TPDz5Qo1TnzsHbb5fJQ2SF9AK8+9+7RCVWTmFRYeoNg1v/BVv3nODehPOVcijtnnsO3969MaamsvXZZ0m5dq1SjkMIIYQQojiq56p6Ubu5uMAnn6g/f/ghHD5cJru9r919dPTpSFxqHG9tqQUjmh7dYNB2cAyE+DOwvidcP1Dhh6E3GLhl9mycAwNJiojgv2nTMFWBDAkhhBBCiJspViGl0+nQ5Vn4n/e6EBVi9Gg17S8jAx57DIrZKbIgep2eOYPnAPBF8BecirZ8mmq15dIcBu8At/aQEgn/9IWIjUXfr4zZuLjQZ+FCrBwdubpvH8EffFDhxyCEEEIIURzFntr34IMPMmbMGMaMGUNKSgpPPvlk9vWHH364vI5TiPw+/liNTu3ZA59+Wia7HNBwACOajSDDlMGL/7xYJvus8ux9YeAW8O4PGfGweShcrPjuha6NG9Pzgw9Ap+PM4sWc++23Cj8GIYQQQghLFauQeuCBB/Dy8sLV1RVXV1fuu+8+/Pz8sq97eXkxceLE8jpWIcz5+an1UgAvvQSXL5fJbmcPnI1BZ+D3U7+z5eKWMtlnlWfjCv3WQv1xqiX6jnvgZMU33fDv3592zzwDwN633iLq4MEKPwYhhBBCCEsUqyPDd999V17HIUTJPP44/PwzbN8OkybB6tWlDplt6dkyO6R3xoYZ1Tqkt1gMtnDLYrDzhtMfw/4pkHwFOrxfocG9rZ94ghsnTxKyYQPbJk/mtqVLcfD2rrDHF0IIIYSwRC34dChqNL0evvoKrK3hzz9V7lQZeLP/mzjbONfskN6C5A3uPTG7woN7dTod3d95B9emTUmJjmbb5MkYc8UuCCGEEEJUBVJIieqvVSs1tQ/g2Wfhxo1S79LL0YuZvWYCKqQ3Ob1s8qqqhQKDe0dWaHCvtaMjfRYuxMbFhWtHjrD3rbdKHbcghBBCCFGWpJASNcOsWdCiBURGwgsvlMkuc4f0Lty9sEz2Wa00ehD6/pEZ3LuuwoN7nevXp9fcuej0es6vWsXpX36psMcWQgghhCiKFFKiZrC1VVP8AL75BraUvklErQvpLYjfUPPg3vU9KzS416dHDzpMnw7A/tmzidi1q8IeWwghhBDiZqSQEjVH796q+QSonykppd5lrQvpLYhHNxi0QwX3Jpyt8ODeFg88QODIkWhGI9unTychNLTCHlsIIYQQojBSSIma5YMPwNcXTp+Gd98t9e5qZUhvQVyaVVpwr06no+sbb1C3dWtSY2LY+uyzZCQlVchjCyGEEEIURgopUbO4uamgXoD334djx0q9y1oZ0luQSgzutbKzo/eCBdi5uxNz+jS7XnlFmk8IIYQQolJJISVqnjFjYNQoSE+Hxx4Dk6nUu6yVIb0FKTC4d36FPLSjry+95s1Db2XF5XXrOP7NNxXyuEIIIYQQBZFCStQ8Oh18+ik4OcHOnfDFF6XeZUvPljwepNZfzdgwA5NW+uKs2soK7m32nLq+fyoceBEq4DXxCgoi6OWXATi0YAFhW7eW+2MKIYQQQhRECilRM/n7w3uZobIzZ0IZNCh4o98b2SG9i48sLvX+qjWdHoLmQ4f31fUTs2HngxUS3Nt03DiajBsHmsaOF14g7uLFcn9MIYQQQoi8pJASNddTT0H37hAfr4J6Syl3SO9L/75Uu0J6C6LTQasXofv3Krj34k8VFtwbNGsWnp06kR4fz9ZnnyU9oeLCgoUQQgghQAopUZMZDPD112BlBatWwYoVpd5lrQ/pLUijB/IE9/aHlKvl+pAGGxt6zZuHvbc3cefPs+PFF9HKYC2cEEIIIYSlpJASNVubNvBiZqe9Z56B2NhS7c7B2oF3B6i26rU2pLcgfkPh1k1g6wHX98H6W8o9uNfew4M+Cxeit7EhbPNmDn/ySbk+nhBCCCFEblJIiZrvlVegaVMID1frpUrp3nb3Zof0vrnlzTI4wBrCoysM2l6hwb3ubdrQ7U31d3Dsyy+5vH59uT6eEEIIIUQWKaREzWdnB199pf78xRfw33+l2p1ep+ejwR+p3e2rxSG9BSkwuPefcn3IhqNG0XziRAB2vfQSMadPl+vjCSGEEEKAFFKitujXDx55RP358cchNbVUu+vfsD8jm43EqBlrd0hvQfIF9w4r9+DejtOn49OjBxnJyWx59llSrl0jcs8eLv71F5F79mAyGsv18YUQQghR+0ghJWqP2bPBywtOnID33y/17j4Y+IGE9BamgoN79VZW3DJnDo7+/iSGhrJq4EA2PvQQO154gY0PPcTqQYMI2bCh3B5fCCGEELWPFFKi9qhbFxZmdtp7911VUJWChPQWocDg3hfKLbjX1s2N5hMmAGBKSzP7XdLVq2ybOlWKKSGEEEKUGSmkRO0ybhwMHw5paWqKXylbZktIbxHyBfd+WG7BvSajkZM//FDwLzUNgOD335dpfkIIIYQoE1JIidpFp4PPPgNHR9V04ptvSrU7L0cvZvWaBUhIb6EqKLg3KjiYpMjIwjfQNJIiIogKDi7TxxVCCCFE7SSFlKh96teHd95Rf37hBdUWvRQkpNdC5RzcmxxlWaaXpdsJIYQQQtyMFFKidnrmGejSRQX0PvdcqXZlb20vIb2WKsfgXntPzzLdTgghhBDiZqSQErWTwQBff61+Ll8Oq1eXanf3truXTr6dJKTXEgUG9+4v9W49g4Jw8PZWUwkLYe/tjWdQUKkfSwghhBBCCilRe7VvDzNmqD8//TTExZV4V3qdnjmD5gAS0muRcgju1RsMBM1S69UKK6Zs69YtdYMRIYQQQgiQQkrUdq+/Do0bQ1gYvPxyqXYlIb3FlB3cOwAyEjKDe0vX+TBg0CB6z5uHg5eX2e227u7ora2JOXGCPW+9hZbZxU8IIYQQoqSkkBK1m709fPml+vOnn8LOnaXanYT0FpONK/Rbkyu4dwKcnFeqXQYMGsSoDRu49bvv6Dl7Nrd+9x13bNpEr3nz0On1nF+xgiOfflpGT0AIIYQQtZUUUkLceis88IDKGnr8cZUxVUK5Q3qnr58uIb2WyBfcOw0OPF+q4F69wYB3164EDh+Od9eu6A0G/Pv3p8urrwJw9PPPObt0aVkcvRBCCCFqKSmkhAD46CPw8ICjR+HDD0u1q6yQ3uDwYAnptVS+4N45sPMBMJa8qC1Ik3HjaPPkkwDsffttwjZvLtP9CyGEEKL2kEJKCAB3d5g/X/357bfh9OkS70pCeksoX3Dvz+US3Nv2mWdodMcdaCYT/02fTvThw2W6fyGEEELUDlJICZFlwgQYMgRSU+GJJ9RUvxKSkN5SyB3cG7G+zIN7dTodXV9/Hd9evTCmpLDl6aeJu3SpzPYvhBBCiNpBCikhsuh08Pnn4OAAmzfD//1fiXclIb2llC+4tyfEnyuz3eutrek1dy51W7cm9cYNNj/xBMnR0WW2fyGEEELUfFJICZFbw4bw1lvqzzNmQGRkiXclIb2lZBbcew42lE1wbxZrR0f6fvYZTgEBJISEsOXpp0lPTCyz/QshhBCiZpNCSoi8Jk+GTp0gJkb9uYQkpLcMZAX31umgpveVQXBvbvYeHvT78kts69Th+rFj/Dd9Oqb09DLbvxBCCCFqLimkhMjLygq+/hoMBliyBP76q8S7kpDeMlBgcO+iMtu9S4MG9P3sMwx2doRv28aeN9+UwF4hhBBCFEkKKSEK0qkTTJ2q/vz005BQ8s5xswfNlpDe0rJ2yQzuHZ8Z3HsvnJhbZrv3aNeOXh99pAJ7V66UwF4hhBBCFEkKKSEK88YbEBgIly9DZpBrSbTwaMETQU8AEtJbKgZbuGURNM+cbnlgeqmDe3Or16+fBPYKIYQQwmJSSAlRGEdH+OIL9eeFC2Hv3hLv6vV+r0tIb1nQ6aHTPOjwgbp+Yg7snFhmwb15A3tDN20qk/0KIYQQouaRQkqImxkyBO69F0wmePRRKGEjAgnpLUM6HbR6Abr/kBnc+0tmcG98mew+d2Dv9hkzJLBXCCGEEAWSQkqIosybB+7ucPgwzC35upwp3acQ4BLA5djLLNi9oAwPsJZqNLFcgnuzA3t795bAXiGEEEIUSgqpKsRohC1bdGzdWo8tW3QYjZV9RAIAT8+cAuqNN+Ds2RLtxt7anndvzQzp3SYhvWXCLLg3OCe412SEyM1wcbH6aSrePya9tTW9PvpIAnuFEEIIUSgppKqIFStUX4NBg6yYO7czgwZZERiobhdVwP33w8CBkJICTz4JJWyPPaHtBDr5diI+LV5CestK3uDevzvBSj81QrVjgvq5OhBCivePSQJ7hRBCCHEzUkhVAStWwNixEBpqfntYmLpdiqkqQKdTjSfs7GDjRvjxxxLtRkJ6y4lLMxi8UxVT6XGQmmeKX1IYbBtb7GIqX2DvtGkS2CuEEEIIQAqpSmc0wuTJBQ9wZN02ZQoyza8qaNxYTe0DmDYNoko2NS93SO8L/7xQdsdX29l6gqmw7n2Z/5iCpxR7mp9ZYO9//0lgrxBCCCEAKaQq3bZt+UeictM0CAlR24kqYNo0aN8erl/PCewtgayQ3tWnVrP54uayO77aLGobJF+5yQYaJIWo7YopX2DvJ5+U/DiFEEIIUSNIIVXJwsPLdjtRzqyt4euvQa+HX36BdetKtJvcIb0z1s+QkN6ykGzhPxJLt8ujXr9+dHntNQCOfvGFBPYKIYQQtZwUUpXM19ey7ebMgb//LnGPA1GWunSB555Tf37ySShhAwIJ6S1j9hb+Y7J1L/FDNLnrLto89RQggb1CCCFEbSeFVCXr3Rv8/VUvg5vZvx+GDoW2beH//g9SUyvm+EQh3n4b6teHixfh9ddLtIvcIb2zNs6SkN7S8uwNDv5AEf+YgqeqVukl1HbSJBqNGZMT2HvoUIn3JYQQQojqSwqpSmYwwILMbNa8xZROl9MsbupUcHaGY8fgkUegQQP43//g2rWKP2YBODnB55+rP8+bpyrdEsgK6Q2JC5GQ3tLSGyAo6zXMW0xlXrd2gbjjsK4bHH4djIU1pyicTqej62uv5QT2TppE3MWLpTlyIYQQQlRDUkhVAWPGwPLlUK+e+e3+/ur2J55QebAhIfDhh+r2yEh49VUICICnn4YzZyrn2Gu1YcPg7rvBZIJHH4WMjGLvQkJ6y1jAGOi9HBzy/GNy8Ifev8HIc1D/LtCMcPQtWN8Nbhwu9sPkDezdJIG9QgghRK0jhVQVMWaMmiW2YUMG06btY8OGDC5cULdncXWFGTPg/HnV56BjR0hOVgMjzZvDHXfAf//JOqoKNX8+1KkDBw7kDC0Wk4T0lrGAMTDqIty6CXouUj9HXVC323lAr6VwyxK1VurGQVjXGY6+A6biFcK5A3sTQ0MlsFcIIYSoZaSQqkIMBujbV6NPnzD69tUwGAreztoaJkyA4GD4918YPlwVT6tWqTVX3bvD0qUlGiARxeXtrTqBALz2Gly4UOxd6HV6Phr8EaBCek9GnyzLI6yd9Abw7geB96if+jz/mBqMg2FHwf92MKXD4VdgfQ+IPV6sh5HAXiGEEKL2kkKqGtPpoH9/+PNPOH4cHnsMbG1hzx4YPx6aNlUDJvHxlX2kNdxDD0G/fpCUBE89VaIhwX6B/RjVfBRGzciL/7xY9sco8rP3gd4rocdPYO0G1/fB2k5w/MNihfbmC+x94w0J7BVCCCFqASmkaoiWLeGrr+DyZTUw4uGhpgpOnarWUb344s2Df0Up6HTqxbe1VblSixaVaDcfDPxAQnormk4HDe+D4UfBdyiYUuHgC/BPH4izfOGhWWDvqlUS2CuEEELUAlJI1TBeXvDmm6qg+uILaNYMYmNh9mxo2BDuvx8OHqzso6yBmjZVFSzAlClQgsYDEtJbiRzqQb+/oNs3YOUM0TtgbXs4uQAs/HvIG9h7RgJ7hRBCiBpNCqkayt5edfs7cQJWr4a+fdWaqZ9/Vk0qbr0V1q6VxhRlasYMaNNGFVEzZpRoF7lDehcdKdnIlighnQ4aP6JGp3wGgjEZ9k+BjQMg4bxFu8gd2LtPAnuFEEKIGk0KqRpOr4eRI2HzZti7V3XrNhhUk4phw9Tn/m+/hZSUyj7SGsDGBr7+Wn0g/+EH+OefYu/Cy9GLl3q/BMBLG1+SkN7K4Fgf+q+HLp+BlSNc3QJr2sGZLyz65kECe4UQQojaQQqpWqRzZ1i8GM6dg2nTVMDv8eMqAqlBA3j77RLNSBO5de8OkyapPz/xhGpAUUyTu02WkN7KptNB06dg2GHw6gMZibD3Kdg0GBIvF3HXPIG9Tz8tgb1CCCFEDSSFVC3UoAF89JF5wO/Vq2qJT/36EvBbau++q17U8+fhrbeKfXcJ6a1CnBqpHKpO88FgBxH/wJq2cO7/bjo6ZRbYGxMjgb1CCCFEDSSFVC2WN+C3UyfzgN/Ro2HbNllHVWzOzvDpp+rPc+ZACaZ2TWg7gSDfIOLT4nlj8xtle3yieHR6aDEZhh4Cjx6QHge7H4EtIyDpSqF3s3Z0pN/nn0tgrxBCCFFDSSElsgN+9+2DTZtgxAhVPP3+O/TpA926ScBvsY0aBWPHgtGoAr6MlucSgQrpnTNYBf1+GfylhPRWBS7NYOA26DAb9DZwZQ381Rou/Fzotw127u4S2CuEEELUUFJIiWw6ncqV/eMP84DfvXtVwG+TJhLwWywLF6phv7174eOPi313CemtgvQGaPU8DD0AdTtDegzsvB+2jYHkyALvkh3Ya28vgb1CCCFEDSKFlChQ7oDf119XAb+XLuUE/L7wggT8FsnXVwV4AbzyinoBi0lCeqso11YweAe0exv01hC6Cta0hsvLCtzco107es2Zkx3Ye7gEhbUQQgghqhYppMRNeXnBG2+ogurLL3MCfj/8UAJ+LfLoo9C7NyQmqi4exRyJyB3SO339dAnprUr01tDmFRiyF9zaQ+o1+G8c/Hc3pORvLJE7sPfYl19KYK8QQghRzUkhJSxibw+PP37zgN81a8Akn/PN6fVqaM/GRr1AJfjw/Ea/N3C2cWZ/+H4J6a2K6rSHIXugzaugM8DlJWp0KvT3fJvmC+z999+KPlohhBBClJFKLaS2bt3KyJEj8fPzQ6fTsWrVKrPfR0ZG8uCDD+Ln54eDgwO33XYbZ/L05U5JSWHSpEm4u7vj5OTEnXfeSWRkwWsVROnlDfi9556cgN/hwyXgt0AtWsDLL6s/P/ccXL9erLt7OnpKSG9VZ7CBdm/B4F1q2l/KVdg6GnZMhLQbZpuaBfY+/7wE9gohhBDVVKUWUomJibRv355Ps1pF56JpGqNHj+b8+fP8/vvvHDhwgAYNGjBw4EASc7UQnjp1Kn/88QfLli1jy5YtXLlyhTFjxlTk06i1OneGRYtU+/SsgN8TJyTgt0AvvqgWnl29qhaYFZOE9FYT7p3htmBo9aJqm37xJ/irDVxZm72JBPYKIYQQNUOlFlJDhw7lf//7H3fccUe+3505c4Zdu3bx+eef06VLF5o3b87nn39OcnIyixcvBiA2NpZvv/2WuXPnMmDAAIKCgvjuu+/YsWMHu3btquinU2vVr58T8DtnjmpGkTvg96mn4PTpyj7KSmZrC19/rf787bdqSK8Y8ob0Xk28WsYHKMqMwQ46vA8D/wPnZpB8BTYPg92PqgwqCgnsjZLgZSGEEKI6sarsAyhMamoqAHZ2dtm36fV6bG1t+e+//3j00UcJDg4mPT2dgQMHZm/TokUL6tevz86dO+nevXuh+87aP0BcnPpwk56eTnolZ7xkPX5lH0dJODiomWtPPQW//aZj/nw9+/fr+eIL+PJLjREjNKZONXHLLRo6XWUfbSXo2hX9E09g+PJLtMceIyM4WC0+s9BdLe5ins889kfs5/V/X2fhbQuB6n3O1GhunWHgHvRHX0N/5mN0575FC9+AsfNXaN4DwMaGWz7+mH8feIDEkBA2PfUU/b75BmtHx3I/NDlnRHHJOSOKS84ZUVxV6Zyx9Bh0WhUJNNHpdKxcuZLRo0cD6gk0adKEbt268eWXX+Lo6Mi8efOYOXMmgwcPZt26dSxatIiHHnrIrCgC6Nq1K/379+eDDz4o8LHeeOMN3nzzzXy3L1q0CAcHhzJ/brWVpsGxY+6sWtWEfft8sm9v2vQGt99+lh49wjEYqsTpV2GsEhMZ8Oyz2F+/zqm77uLkvfcW6/5H4o/w6rlX0aNnYYuF+Nv5l9ORirLkbjxGx9SFOGpq/eYFq9s4ZvMARp09pmvXSP78c0hKwtC0KbYTJ6IzGCr5iIUQQojaKykpiQkTJhAbG4uLi0uh21XZQgogODiYRx55hEOHDmEwGBg4cCB6vR5N01i7dm2JC6mCRqQCAgKIjo6+6YtVEdLT09mwYQODBg3C2tq6Uo+lLJ08CQsX6vn5Zz0pKWo4qkEDjWefNfHQQyacnSv5ACuQbtUqrMaNQ7OyImP3bmjbtlj3H7NsDH+e+ZMRTUew4q4VNfacqXEyEtAffgnDuS8A0BwbYezyNZpnb64fOcLmxx7DmJJC4KhRdH7zTXTlOGwr54woLjlnRHHJOSOKqyqdM3FxcXh4eBRZSFXZqX0AQUFBHDx4kNjYWNLS0vD09KRbt2507twZAB8fH9LS0oiJicHNzS37fpGRkfj4+BSyV7C1tcXW1jbf7dbW1pX+F5elKh1LWWjbVi0Revdd+Owz+PRTuHRJx4wZBt5+28Djj6tpgf61YYDlrrtg9Gh0q1Zh/fTTsH27an1ooQ8Hf8jas2v588yfbA/bzi31bgFq3jlT41jXgW6fQ4M7Ydcj6BLPY7V5IDSfjHf7d+j10UdsffZZLq5ejaOvL+2fe678D0nOGVFMcs6I4pJzRhRXVThnLH38apEj5erqiqenJ2fOnGHfvn3cfvvtgCq0rK2t2bhxY/a2p06d4vLly/To0aOyDlfchKcnvP46XLqkAn6bNzcP+L3vPjhwwPw+RqPqzbB4sfppNFbGkZexTz4BFxfYvRs+/7xYd23h0YInOz8JwLR109h0cRNbb2xly6UtGE014cWp4XwGwvAj0PhRQINT82FtR+q1tpXAXiGEEKIaqdRCKiEhgYMHD3Lw4EEALly4wMGDB7l8+TIAy5YtY/Pmzdkt0AcNGsTo0aMZPHgwoAqsRx55hGnTprFp0yaCg4N56KGH6NGjR6GNJkTVkBXwe/w4/PEH9OunAn5/+QU6dcoJ+F2+HAIDoX9/mDBB/QwMhBUrKvkJlFa9evD+++rPs2aplofF8Hrf17GzsuNAxAGGLBrC3EtzGfTLIAIXBLLiRHV/cWoBaxfo9jX0WwP2fhB/Gv7pRZMm+2jz5OOABPYKIYQQVV2lFlL79u2jY8eOdOzYEYBp06bRsWNHXsv8VjY8PJz777+fFi1a8Nxzz3H//fdntz7PMm/ePEaMGMGdd95Jnz598PHxYUW1/5Rde+j1MGIEbNoE+/apYil3wO9dd0FoqPl9wsJg7NgaUEw98QT07AkJCfDMM6o7h4W2Xd5GSkb+1OOwuDDGLh0rxVR14TcUhh+FhhNBM8GJ2bRt+BWNh/eRwF4hhBCiiqvUQqpfv35ompbv8v333wPw3HPPERISQlpaGpcuXeLtt9/GxsbGbB92dnZ8+umnXL9+ncTERFasWHHT9VGi6goKUiNS58/D1KkU2iI9q96YMqWaT/PT6+Grr8DaGlavht9+s+huRpORyX9PLvB3GurFmfL3FJnmV13Y1IEeP0CfVWDnjS7uOF3afY1fB28J7BVCCCGqsGqxRkrULvXrw6hRNx+g0TQ1G27btoo7rnLRujXMnKn+/OyzEBNT5F22Xd5GaFxoob/X0AiJC2Hb5er+4tQy/rfDsKPQ4G70eiO3DNpMXX+dBPYKIYQQVZQUUqJKCg+3bLt//y3WjLiq6aWXVNeNiAh48cUiNw+Pt+zFeXfbu2y7tA2TZirtEYqKYucBtyyGXkuxdnan39iTONVJIzE0lM1PPUV6YmJlH6EQQgghMkkhJaokX1/Ltnv7bejWDZYsUc0qqiU7OzXFD9TPIobZfJ0te3E2nN9An+/7EDAvgMlrJ7MjZIcUVdVF/btg2FHsmo+i/92XsHXI4MaJE/z37GOYqkDiuxBCCCGkkBJVVO/eKlOqsHVSOh04OoKtLezdC3ffDU2awLx5EB9fscdaJvr0gcceU39+/HHIEzKdW+/6vfF38UdHwS+ODh0eDh5MbD8RV1tXrsRfYeGehdzyf7fQYH4Dpq2bxu7Q3VSRLG5RGHtv6P0bzsO/o++9MRisTYTvPsTuyXeiGavrtwZCCCFEzSGFlKiSDAZYsED9OW8xlXX9xx/VOqk33lD5VJcuwbRpqgB7/vlidxSvfLNng48PnDwJ771X6GYGvYEFt6kXJ28xlXX9yxFf8sPoH4icEckf9/zB/e3ux9nGmdC4UObtmkf3b7vTcEFDXtjwAvuu7JOiqqrS6aDhvXg8foBej/qi02lc2HKOw9O7QNzpEu3SaDKy5dIWyR4TQgghSkkKKVFljRmjcqTq1TO/3d9f3T5mjHnA71dfQYsWEBcHc+ZAo0YFB/xWWW5usHCh+vO776qQrUKMaTmG5eOWU8/F/MXxd/Fn+bjljGk5BgBbK1tGNBvBj3f8yNXnr7Jq/ComtJ2Ak40Tl2Iv8eGOD+nydReafNyEWf/M4kD4ASmqqiIHP+pN2kiXSUMAOLYhjTNv94KT81XbdAutOLGCwAWBDPplkGSPCSGEEKWk0+RTE3Fxcbi6uhIbG4uLi0ulHkt6ejpr1qxh2LBhWFtbV+qxVBVGo1o2FB6u1k717q1GrApiMsHataqQ2rw55/b+/WH6dBg6VHUdr7I0DW6/XaUU9+ypnvhNDthoMrLp/CbW/reWob2G0r9Rfwz6Ql6cXJLTk1l7di1Lji3hz9N/kpSelP27pnWbMq71OMa1Hkdbr7boCptfKSrF4XnvcvSbX9DpNHrfGYJ/r47Q/TtwbnzT+604sYKxS8dmt8jPkjWKmbsAFyIv+b9JFJecM6K4qtI5Y2ltUJU/UgoBqKKpXz+45x71s7AiClTNMXy4CvgNDs4J+N20SQX/tmkD33wDKfmzbKsGnQ4+/RScnGDHjpwmFIUw6A30bdCXPnX60LdBX4uKKAB7a3vGtBzDkrFLuDrjKkvHLuXOlndiZ2XHmetneGfbO7T/oj2tPmvF65te53hU4aNjomK1nTKLxmPGoGk6tq/yJ+rAPljbHk5/VujoVFb2WN4iCiR7TAghhCgpKaREjdWpkwr4vXABZswAFxc4cUL1dGjQAN56C6KjK/soCxAQoKb2gWqHHhZWrg/naOPIXa3vYvm45UQ9H8XiOxczusVobA22nIw+yVtb36L1Z61p81kb3tryFqeiT5Xr8Yib0+l0dHntNfz69MGYoWfr8kbERabDvknw72BIvJS97dXEq/x+8nfuW3GfZI8JIYQQZUwKKVHjBQTAhx+q5hMffaQCf69eVWurAgLgySfhVFWrDZ5+WvV1j4uD556rsId1snHi7jZ3s3L8Sq4+f5Wf7viJkc1GYq235ljUMV7f/DotPm1B+y/a887Wdzh7/WyFHZvIobe2ptdHH1G3TRtSEzU2rexIUrITRG4k7Y8WfLOsO00WNsZ7jjejl4zm12O/WrRfSzPKhBBCCCGFlKhFXFxUV79z52DxYujcWU3x+/JLaNlSLU3aurWKBPwaDPD112BlBStWwKpVFX4ILrYu3NfuPlbfs5qrz1/l+9u/Z1jTYVjprTgceZhXNr1C04+b0unLTnzw3wecv3G+wo+xNovXpWKccSdpHo4kRsbzxQ/ebIvVY2NK4dH03Sy0P089A7TxasPwpsMt2qelGWVCCCGEkEJK1EJWVip3as8e2LIFRo5UxdPq1dC3L3TtCr/+WgUCftu2hRdeUH+eNEmNTlUSNzs3HujwAH9N+IvIGZF8O+pbhjQegkFn4EDEAWZunEnjhY3p8nUX5uyYw6WYS0XvVFjMpJk4EXWCb/d/y6OrH6XVp62oO7suI9aMZ2aXg8TaZuBzzZZ1KxrwVXpTMjAwzBFCmrty5LYX+H38quzsMT3Q1x7udlI/s/4TcLB2oHu97pX5NIUQQohqRQopUWvpdCoHd/VqFd30xBNgZwf79qnGFo0bq4DfSqxf4JVXVNLwlSswa1YlHkiOuvZ1ebjjw/x9399EzIjgqxFfcWvDW9Hr9Oy7so/nNzxP4IJAun/TnXk75xESW90CvSpffGo8G89v5H9b/8ewX4bhPtudVp+14tE/HuXbA99yIvoEoDos3tZrAtYz70VnZ0urK/a0PTUWw7BDULcLuvRY2DkRw/axfHHrG9zhqHExEDb7w2Jf9fNiINzhCEnpSdyx9A4S0hIq9bkLIYQQ1YW0P0fan4scUVHw2WeqcV5UlLrNxQUef1wtVQoIqISD2rQJBgxQld9//6m26LlUlXPmauJVVpxYwZJjS9hycYtZh7ieAT0Z33o8Y1uNxc/Zr9KOsSrSNI3zN86zM3QnO0J2sCNkB0euHsGUpwOfvZU9Xet1pWdAT3r496C7f3c8HT2zfx+2ZQtbn30WzWik9eOP0/7ZSXBiNhx5A0zpYOWElpGApoE+V0d7k6ZOrQlXbfg1No0ufl34a8JfZvsWoqq8z4jqQ84ZUVxV6ZyxtDaQQgoppER+ycnw888wd64arQI1JXDcOJVH1alTBR/Qww/Dd99Bq1YqYdjGJvtXVfGciUiI4Lfjv7Hk2BL+u/xfdlGlQ0fvBr0Z12ocd7a6Ex8nn0o+0oqXnJ7Mviv7sgunnaE7uZp4Nd92DVwbZBdNPQN60s67HdaGm//9nl2+nD2vvw5Al9deo+n48XDjMOycCDGHbnJPHam2XgScSycq+TpN6zZl3X3raFinYWmeqqhBquL7jKja5JwRxVWVzhlLawOrCjwmIaoNe3vVJv2RR8wDfhctUpcKD/idMwf+/BOOH4cPPoBXX62ABy05HycfJnWdxKSukwiLC2P58eUsPb6UHSE72HppK1svbeW5v5+jb4O+jGs9jjEtx+Dl6FXZh10uQmJDzIqm/eH7yTCZL8CzMdgQ5BuUXTT1COhRopG7JmPHkhQZydHPPmPf//6Hvacn/gMGQMcPYdPgm9xTwzY1kn2jf6DPmtc4c/0MPf+vJ2smrKGjb8diH4cQQghRG0ghJcRNZAX8Dh8O+/er9ulLlqjZdps2qW5/06bBffep9VXlpm5dWLBAJQz/739qaKx583J8wLJTz6Uek7tPZnL3yYTEhrDs+DKWHlvK7rDdbLq4iU0XNzFpzSQGNBzAuFaqqHJ3cK/swy6RNGMaByMOZhdNO0J2FJjf5OPkQ8+AnvT0V0VTJ99O2FmVzQnU9umnSY6M5Nxvv7F9xgwG/N//4elmWWBafRtrdjyyg2G/DONQ5CH6ft+XVXevYkDDAWVybEIIIURNIlP7kKl9onhCQmDhQvjqq5xGFF5eqrHe00+Dh0c5PbCmqYpu7VrVJWPTJtDrq+05czHmIsuOLWPp8aXsu7Iv+3aDzsDARgMZ33o8o1uMpo59nUo8ypuLTIhkZ+hOdobsZEfoDvZd2UdKRorZNgadgfY+7bOLpp4BPWng2gCdTlfIXkvPlJHB1mef5crWrdi6uTFo/nO4nLm76Dveshga3E1sSiyjl4xm88XNWOut+emOnxjfZny5Ha+o+qrr+4yoPHLOiOKqSueMrJEqBimkREnExcE336iBosuX1W12dvDAAzB1ajkNGF26pNZJJSWpnKlHH60R58y56+eyR6oORBzIvt1ab82gxoMY33o8tze/HVc710o7xgxTBkevHjUbbSooO6uufV2ztU1d/LrgaONY8ceblMQ/Dz3E9aNHcaznx+D7T2FvCAVu9pavhwbjoMV0Ul3bcv/K+1l2fBkA84fMZ3L3yRVy7KLqqQnvM6JiyTkjiqsqnTNSSBWDFFKiNDIyYPlyNe1vX+bAik6n8qmmT4fevdX1MjNvnppP6OYGR4+SceIEB9eupcPQoVj176/CfKux09dOZ49UHY48nH27jcGGIY2HML71eEY2H4mLbeH/VtPSjXz21zbORYbT2NuXp4f3xsa6eK/L9eTr7ArdlT3atCdsT77W4Dp0tPZqnV009QzoSdO6Tct1tKk4Uq5dY/2995IQEkKdJn4MHL0Jg7WJqBB7khOssHfKwDMgGb1eA9e2EHsk585efTA1n8rUIxtZuPcTAF685UXeu/W9KvP8RMWR/5tEcck5I4qrKp0zUkgVgxRSoixoGmzbpvpC/PFHzu2dO6uCauxY1fmv1IxG6N5dVW329qrFYBZ/fzVENmZMGTxQ5TsRdYJlx5ex5NgSjkcdz77d1mDLsKbDGNd6HCOajcDJxin7dy98t4K5xydjdMpZm2RI8GdaqwXMfqjg18WkmTgZfVIVTZkjTllZTbm52LrQrV637KKpW71ulTpKZon4S5dYf999pF6/jltDH1KvXSE5LqdDioOLiaDnJhBwz6tw4yCcmAuXFoOmGmJozs1YZ9WKO/auIkWDie0n8s3Ib4rsIChqFvm/SRSXnDOiuKrSOSOFVDFIISXK2qlTauDohx8gJXPJTP36MGWK6gRY6tPso49gxoz8t2eNFCxfXmOKqSzHrh5j6bGlLDm2hFPXTmXfbm9lz/BmwxnXahw7dqcz//J9gAa5B000deX5BsuZ/dAY4lPj2RO2J7to2hm6k5iUmHyP2bRu0+yiqYd/D1p5tsKgr34jftGHD/PPAw9gSkvL/8vMc6b3vHkEDBqkbksKhVMfw9kvIT0WgBSDEx9GJfJxjEZQw9tYdtcyswJW1Gzyf5MoLjlnRHFVpXNGCqlikEJKlJeoKPj8c/jkkzIM+DUaITAQQvN3gwPUB2N/f7hwodpP8yuIpmkcuXqEJUeXsPT4Us5eP5vrlzryFVHZvwNdhiNt6zXmaNTRYgfeVmcmo5EVffqQFhNT8AY6HQ7e3oxavx597nMmPR7O/R+cmg+JFwFI0eCnONhg3YZP7/m3xrxG4ubk/yZRXHLOiOKqSueMpbVBRSTgCFFreXrCa6+pHhFffQUtWqgmFXPmQKNGcO+9qq16sWzbVngRBWqOYUiI2q4G0ul0tPNuxzu3vsPpZ06z//H9vNDzRdwMPqArpIgC0IFmncjhq4cxaSYauDbgnjb3sPC2hex7bB+xM2PZ/OBm3r31XUY2H1mjCoSo4ODCiygATSMpIoKo4GDz262docVkGHkGei0F967Y6eAxV1jqcJSjywK5cvYXdc4JIYQQtYzkSAlRAfIG/H70kepeXqKA3/Bwyx7U0u2qOE2D6GhVG4aGqp85Fx2hoR0JDe1IevN2MPbeIvd3m9sUvn34+RIF3lZXyVnDoUW4uGYNdh4euAQGost9IuqtoP5dEDAWorYTf/hNHCP/ob9NEuy5j6Tj/8Oh7Suq459evnkWQghRO0ghJUQFKirgt0UL1ZDv/vtvEvDr62vZg1m6XSXSNLhxo6ACKee20NCcdWY3lWBZYTSkwe21qogCsPe0bHTt3LJlnFu2DBtXVzzat8ejQwc82rfHvW1brB0d1bRRr144D9zA1fDtbFp3OyOtruGQcBJ23geHZkKz56DJ42BTtZtwCCGEEKUlhZQQlaRTJ/jlF3j//ZyA35Mn1fqpl1+GZ56Bp55S0wPN9O6t1kCFhd18StVXX6n5g/Xrl+vzuJm4uMILpKxLUpJl+/L2VmvK/P3Vz6xL1nUPz964vu6P0TFMTfHLS9OhT/Dn6eG9y/ZJVgOeQUE4eHuTdPVqoeeMlaMjbs2bc+PYMdJiY7mydStXtm4FQKfX49asmSqsOnbEs317PP17ctvd55iwZARtrv/HM27gkxQKB1+Ao29D40fVtEDHBhX4TIUQQoiKI4WUEJUsIAA+/BBefRW+/Rbmz1cBv6+/Du+9V0DAr8GgWpyPHYum06HL9cHY7PrixbBypRrimjkTnJ3L9LgTE29eIIWEQHy8Zfvy8MhfIOUukurVA1vbovZiYFqrBXx4aaxqOpG7mMrs2qetnc8vrQ089FCJnnK1pTcYCJo1i21Tp6pRpdzFVGbXvh7vvEPAoEEY09KIOXWKqIMHiT50iOgDB0iKiODGyZPcOHmSM7/+CoCduzseHTrwVrv7+TzDlSbn1jDOTeNDfx/c0yPg1Dw4vVBNB2w5Hdy7VMZTF0IIIcqNdO1DuvaJqqWggF/ICfjt00d99t31wgrqz52MnzGn8USYIYCQafPpPr6B2njLFvULb294+214+GGLOvklJ5tPrStoVOnGDcueT506hY8iZf3Z3r44r9DNFZwjFUDzC/M5/ptqCf/OOzBrVhkHJVcDIRs2EPzeeyRFRmbf5uDjQ9DMmTmtzwuQFBFB9KFDRB04QPShQ9w4fhxTRobZNiaDjvOuiZxxT2ZAt/aMa5aGY+rmnA28+kCL6VBvBOikz1F1I/83ieKSc0YUV1U6Z6T9eTFIISWqoqyA348+UgG/Wf9SO3dWs/vmzwedZqQ32/AlnHB8+Y/emHQGFSN1hwarV6u8qbOZLcLbtiXtvY8IbTnopuuSoqMtO0Zn58JHkbL+7FQJUUNp6UY++2sb5yLDaezty9PDe2NtZWDWLPjgA7XNM8+o17AGdoi/KZPRSPju3ez65x+6DxyIb7du5i3PLZCRksKN48fNRq1Srl3Lt529V108G2h41jmFR70E6ninoHdrBi2mQsOJYOVQVk9LlDP5v0kUl5wzoriq0jljaW0gU/uEqKJ0OjX61KePecDvvn05I1UaBrbQz/x+qLVVKSk6wsJu58rgobSx/5yxx9/E9cgRbEYM5gTDmMEcTtKy0Md3cCi8QMq6VPL3DoWysTYwZXS/fLe//77qwTFlisr2ioiAn366SWOPGkhvMODVpQtWUVF4delS7CIKwMrODs9OnfDs1AlQ2V6JoaFEHTrEfxsWE7JvF/VjbUm+ep3LV+EyXoAXBisTdX2T8fR/HY/At/Hoey92naeDvXcZP0shhBCi/EkhJUQ10Lw5fPGFmp33wgvw/feFb6tpcPWqyqhSbIDJPM/9vMZbTOJThrOGIazjz3pPsqHn67g19cxXNNWpUzOnvk2erGY6TpyoplBGR8OqVeAqTeZKTKfT4RQQgFNAAA1HjGDNmTXct2gcvlc1+qU1ZZSuE/FHTpAWF0dUiCNRIY6wE1j8F051V+LRvB6evUbj0f02XJs2LVFxJ4QQQlQ0KaSEqEY8PWHw4JsXUllatFCdAXMKpLoEBMwnPvVp6nzwIlarVjE67FNGr/sJurwCDz1nSUeHGuHuu8HLC0aPhs2b1ajf2rXgV7u6opebYU2HsfaRjQxfNJzPkg+xvm4if7+3Fo9YfeZUwP1E791G7OUoEq7bkLAzios7vwa+xsrBDo92HVSHwMz26zZVdehTCCFErSaFlBDVjKXxUJ9/Dv36FfSbZqqb3+bNqqPfgQNqmOvzz9UCorFja+ZQVB4DBqheHEOHwuHD0LMnrFuXqzuiKJVu/t3Y/vB2bvvlNs5eP8st3/Vi7b1r6XjHHTS+4w4A0mJiiP5vCdFbfiH6xCWiw+zJSEohYtcuInbtyt6Xa+PGOYVVhw75A4OFEEKISiCFlBDVTFExUjqd+n3vouKS+vVTi61++gleegkuXIBx41RFMW8edO1aHodfpXTsCDt3wpAhcOYM3HIL/PkndO9e2UdWMzT3aM6Oh3cw9JehHIo8RN/v+7Ji/AoGNhoIgI2bG34jnsBvxBMQdwbTiXnE7v6F6EsGosPsibriTMI1A7HnzhF77hznfvtN3c/FJXu0yqNDh5zAYCGEEKICSSElRDWTK0aqsEggy7vR6fUqqGrsWJgzB2bPhh07oFs3mDBBBVlVYqBvRWjYELZvh+HDYe9eNVK1bJm6LkrP19mXLQ9u4Y4ld7Dp4iaG/TKMH+/4kbvb3G2+oUtT9N0+o06Ht6lz5guanv4YUk6RkmggOqIu0QldiQ5z5NqJs6TFxRUeGNyhA54dOuDo74+uGCOrJqORqOBgkqOisPf0xDMoSNZqCSGEuCkppISohsaMUY0SJk9WLcuz+PurImrMmGLu0NFRJQA/+ii88opqD7hoEaxYUW6BvlWJpyf8+y/cdRf8/Tfcfjt8/TW1Lri3vLjaubL23rVMXDWRpceWcs9v9xCREMGU7lPyb2zrDm1ehpYz4OIv2J2ci7/jMfz5CzroMT12JzcMdxJ9MZ3ogweJOniQpPDwQgODs0au6rZujVUh7RkLzNfy9iZo1qyb5msJIYSo3WSSuRDV1JgxcPEibNiQwbRp+9iwIYMLF0pQROVWrx58952a8tevH6SkwLvvQtOmqrIwGsvo6KseJycVuzVxonqaDz+snrok7ZUNWytbFt+5mGe7PgvA1HVTeWHDC5g0U8F3MNhC44dh2BHotxZ8BoJmQh+2DPfLd9Pc+ytumdKb0RvWM/rff+k1dy7NJ07EvX179FZWpFy7RujGjRz86CP+mTiR5d26se6eewh+/30ur1tHUkQEoIqobVOnmhVRAElXr7Jt6lRCNmwo19dFCCFE9SUjUkJUYwYD9O2rkZgYRt++7csuXLZTJzVEs3o1PP+8WkD0+OPw8ccqIbiGfktvba06Ivr6qr4bL78MV66oqZQyy6v09Do9C25bgJ+zH7M2zuLDHR8SkRDBt6O+xdpQSPiiTgd+t6nLjUNwci5cXARR29TFuSkOLaZS/9YHqD9kCADG1FSuHz+ePWKVFRh87fBhrh0+zKmffgLA3tubtNjYgqtlTQOdjuD336fegAEyzU8IIUQ+MiIlhCiYTqfmuB09quYL1qkDR46o/uvDh8Px45V9hOVCp1PBvfPnqz9/+qlql56SUtlHVjPodDpm9prJd7d/h0Fn4KfDPzFy8UgS0hKKvnOd9tDjB7j9IrR6EazdIP4M7H0afq8Ph1+D5EgMtrZ4duxIy4ceos+CBdyxZQuj1q2j5wcf0PSee6jTqhU6g4HkyEiMN/uL1TSSIiKICg4uq6cvhBCiBpFCSghxczY2ajHW2bMwZQpYWcGaNdCuHUyaBFFRlX2E5WLyZFi8WI1SLV8Ot90GsbGVfVQ1x4MdHuSPe/7AwdqBdefW0f+H/lxNvGrZnR3qQYf3YXQIBC0Ax4aQeg2Ovg2/N4Ddj0JsTqGv0+lw8vcncMQIurzyCkOXLeOuXbto/cQTFj1ccg09x4UQQpSOFFJCCMvUravaoh87ppJsjUb47DNo0gQ+/LBGDtmMH6+aTzg7q8ypPn3UVD9RNoY2Hcq/E//F3d6dfVf2ccv/3cL5G+ct34G1EzR/DkaegV7LwL07mFLh3LfwV2vYNAwiNhY4dc/KwQEfC/vcW9nbW35MQgghag0ppIQQxdMsM9B30yYVxBQXpwJ9W7VSfcNrWHeGAQNg61bw8VHBvT16wMmTlX1UNUc3/27seGQHgW6BnL1+lp7f9mR/+P7i7URvgPpjYchOGLQd/O8AdBC+Fv4dCH93ggs/gynd7G6eQUE4eHsXGUC986WXOPnjjxjT0or57IQQQtRkUkgJIUomK9D3++/Bzy8n0LdXL9i9u7KPrkx16KDitZo2hcuX1VPctauyj6rmaObejB0P76C9d3siEyPp+31f/jn/T8l25tkT+qyAkaeh6SQwOMCNg7Dzfvi9IRyfDWkxAOgNBoJmzVL3y1tMZV538PUlPT6e/R98wF+3307Ixo1oNezLAiGEECUjhZQQouSyAn1Pn4Y33gAHB1VxdO8O996rqo4aIiu4t0sXuHZNjVT99VdlH1XNkRXc2z+wPwlpCQz7ZRiLjywu+Q6dm0CXT9Q6qvbvgJ0PJIfBwRdhVQAET4GEiwQMGkTvl8fj4Gze2t/BxUjvV+5m1Lp1dH3zTezc3Um4fJltzz3Hxoce4noNbbYihBDCclJICSFKLyvQ9/RpePBB9W3+okXQvLnqIR4fX9lHWCaygnuHDoXkZNXU8P/+r7KPqubICu4d13oc6aZ0JqyYwLyd80q3U9u60Pol1emv2/+BaxvISIBTC+CPxrD+FgK01xg16SS33neRnqNDufW+i4x6+hQB2uvor/xOk7FjGbl2La0ffxyDrS1X9+7l73Hj2PnSS/nyp4QQQtQeUkgJIcpOVqBvcLB5oG+TJvDVV5CRUdlHWGpOTvD772ogzmiERx6Bd96pcUvDKk1WcO9zXZ8DYNr6aTcP7rWUwRYaPwTDDkO/v8FnEGgmiN4BqMFV7wZJBLaOw7tBEnp95l9o8BQwGbF2dKT95MmM+PNPAkeMAE3jwu+/88ewYRz+9FMykpJKd3xCCCGqHSmkhBBlr2NHNXTz++9qYdHVq/DEE+r29esr++hKzdpa1YszZ6rrr7wCzz6rCitRenqdnvm3zef9W98H4MMdH/LAqgdIN6YXcU8L6HTgNwQGrIeuXxexsQZJISr4N5Ojnx89P/iAwYsX49mxI8aUFI5+9hl/DBvG+ZUr0UylLPiEEEJUG1JICSHKh04Ho0apQN8FC1Sg79GjMGQIDBtW7QN9dTp47z311CS4t+zpdDpe7PUi39/+PQadgZ8P/2x5cK+lrBwt2y45PN9NHu3aMfCnn+g1dy6O/v4kR0Wx65VX+HvcOCJrWLMVIYQQBZNCSghRvmxs4LnnVKDv1KlqOGftWhXo+/TT1T7Q97nnVHCvjU1OcG9MTGUfVc3xQIcHSh7cWxR731Jtp9PpqD9kCCP++IOOM2Zg7eTEjRMn2Pjww2x99lniLl4sm+MUQghRJUkhJYSoGHXrwty5KtD3jjvUPLjPP1frp2bPrtZDOePHq9pQgnvLx9CmQ9n0wCY8HDxKFtxbGM/e4OAP3CRHSmcDjoE33Y3BxoaWDz3EyLVraXrPPegMBkL//Ze/br+d4PfeI1UqayGEqJGkkBJCVKymTWHFCti8GTp1UoG+L74ILVvC0qXVtmtD7uDeI0ckuLesda3Xle0Pb88O7u3xbY/iB/fmpTdA0ILMK4UUU1oarOsCEf8WuTu7unXp8sorDFu5Er++fdEyMjj188/8MXSoBPoKIUQNJIWUEKJy9O0Le/fCDz+oQN+LF9XQzi23VNtA37zBvbfcIsG9ZSl3cO/VxKulC+7NEjAGei8Hh3rmtzsEQOfPoU5HSI2GTYPgxByLCn3Xxo3p99ln9P/6a9yaNSMtLk4CfYUQogaSQkoIUXn0epg4UeVPvfmmCvTduVMF+k6YAJcuVfYRFlvu4N7r19VI1Z9/VvZR1RxZwb0DGg7IDu5ddGRR6XYaMAZGXYRbN0HPRernqAvQ7EkYtB0aPahapR94HraPh3TLctF8e/bktuXLJdBXCCFqKCmkhBCVz9ERXnsNzpyBhx5SbfAWL1aBvi+9pKb/VSOenrBpU05w7+jREtxbllztXFkzYU12cO+9K+5l7s65pdup3gDe/SDwHvVTb1C3W9mrIN8un4PeGi4vg/XdIe6Uhbs1SKCvEELUUFJICSGqDj8/VXEEB0P//pCaqnqMN21a7QJ9HR0luLc85Q3unb5+Os+vf770wb0F0emg6ZNw6xaw94PY4/B3FwhZZfEuJNBXCCFqHimkhBBVT8eOsHFjtQ/0leDe8pU3uHfOzjlMXDmRNGM5NXXw7AG3BYNXH8iIh213wKFXwGT5X6gE+gohRM0hhZQQomrKG+hbt261DPQtKLh3/Phq3e29Sskb3PvLkV8YuXgk8amWrWMqNnsfGPAPNJ+irh97B7YMh9RrxdqNBPoKIUT1J4WUEKJqyx3oO21a/kDfq2UUzlrOnnsOfv1VPZ3ffpPg3rKWO7h3/bn1ZRvcm5feGoLmqcYUBnsIXwd/d4brxWvHni/Q19k5O9B3yzPPSKCvEEJUcVJICSGqhzp14KOP1EjUmDE5gb5Nm+YP9DUaVU7V4sXqZxWZSzduXBUI7jUa0W3ZQr2tW9Ft2VJlXpuykDu4Nzg8mJ7f9uTc9XPl94CB98DgXeDUGBIvwoZb4PwPxd5N7kDfZhMmoDMYCNu0ib9uv519EugrhBBVlhRSQojqpUkTNaSzZQsEBZkH+i5Zon4XGKiaVUyYoH4GBqoQ4CqgUoN7V6yAwECsBg2i89y5WA0aVKVem7KQO7j33I1z9Py/nqUP7r2ZOu3gtr3gNxyMKbDrQdg7CUqwTsuuTh06v/yyWaDvaQn0FUKIKksKKSFE9dSnD+zZAz/+CPXqqUDfu++GsWMhNNR827AwdXsVKRgqJbh3xYpq8dqUhazg3g4+HbKDezec21B+D2hTB/quhrZvAjo48xls7AdJJRtulEBfIYSoHqSQEkJUX3o93H+/CvR94w3VzaEgWR88p0yB9HQwmSr90rCBie3bTHTrYuLGdRO39jfx5+pyerz0dJg8ueDe67lfmxo0zS9vcO/wRcNLH9x7Mzo9tH0N+v4B1m4QvRP+7gRXt5V4lxLoK4QQVZsUUkKI6s/BAfr2vXlIk6ZBSIjq9mAwVImLp4+BXXsNmDCQmGJgxO3l9Fg2NvlHogp6bV56Cf75B06dghqQa+Ri68KaCWsY33p82QX3FqXecLhtH7i1hZRI2DgATi0scYDYTQN9Z80iKSKijJ+AEEIIS0khJYSoGcLDK/sIqr/Zs2HQIGjRQiUK160L7dvDiBHw1FMqUfjHH2HTJtVFsRr0cLe1smXRnYuY3G0yoIJ7Z6yfUT7BvVmcG8PgndBgAmgZEDwZdtwHGYkl3mV2oO9ffxE4cqQK9F29mj+GD+fwJ5+QnljyfQshhCgZq8o+ACGEKBO+vpZtt2oV9OpVrodSEpoG//sfzF+grj/6CLz7rhpQKrX//oPRo4verksXSExUo1Px8XDjhrocPlz4fTw8ICAg5+Lvb369Xj01IlaJ9Do984bMw8/Zjxf/eZGPdn5EREIE/3f7/2FjKKdjs3KEnj+De1c4MB0uLYLYI9B7pSq0SsjR15ee779P83vvZf/s2UTt38/Rzz/n3PLltJs8mYajRqEvk5NGCCFEUaSQEkLUDL17qw/xYWEFT6PS6dTvR4woo+qkbOmAV+eDW2O1nGn2t3AuBn7+GezsSrnzESMse2127sx5bWJj1XTAkBDzS+7bkpIgOlpdDhwo/PG9vc2Lq7wFl58fWJXvf0c6nY4XbnkBHycfHv79YX458gtRSVEsv2s5zrbO5fWg0GIy1O0I/42DmCMqb6rnL1BvWKl27d62LQN//JGQDRs4OHcuCSEh7H7lFU7//DOdXngB727dyuhJCCGEKIwUUkKImsFggAULVAc6nc68YMhqQjF/fpUsonJ79llVd9x/v+rkHh2tBtHc3Eqx05K8Nq6u6tK6dcH71DQ1WpW3uMpbcKWmQmSkuuzbV/C+9Ho1oph3NCv3dR+fMvm7m9h+Ip4OnoxdNjY7uPevCX/hYVuHbX99RnjkOXy9G9N7+NMYrMtotMqrD9wWDNvGwrVdsGUEtH0d2ryqmlSUkE6no/7gwdTr14/TixZx9IsvuHHyJBsffph6/fvTccYMXAIDy+Y5iPxMRojaBsnhYO8Lnr1BX7XfX0QlMxph2zY1Fd3XV30BWMX/TxI3V6mF1NatW/nwww8JDg4mPDyclStXMjrX9JOEhARmzpzJqlWruHbtGg0bNuS5557jySefzN4mJSWF6dOn8+uvv5KamsqQIUP47LPP8Pb2roRnJISoVGPGwPLlakgnd3MFf39VKIwZU2mHVhzjxoGnJ9x+e05w79q1apZciZX1a6PTqTVUWeuoCqJpqhIsaDQr6xIWproKhoWpy+7dBe/LykqNXN2s2PLyUkVZEbKCe4cvGk5weDDtF7RAFxdHhEPmuqkI8N8+gwWtpjHmodnFe10K41APBm6B/VNVe/Qjb8C1fdDzJ7BxK9WuDTY2tHzwQRrefjtHP/uMM0uWELZpE1e2baPp3XfT9qmnsC1VJS7yCVmh1r4l5fq35OAPQQsgoHq8z4gKtmJFwe+/CxZUm/+bRH6VWkglJibSvn17Hn74YcYUcBJNmzaNf//9l59//pnAwEDWr1/P008/jZ+fH6NGjQJg6tSp/PXXXyxbtgxXV1eeeeYZxowZw/bt2yv66QghqoIxY1QFUs2/9evfXwX3Dh2qgnt79oR161QfiBLLfG0yNm3i4Nq1dBg6FKv+/cvvtdHpVEXo6QmdOhW8jckEV68WPn0wJASuXIGMDBW6dfly4Y9nba0+mOQttnIXXB4eoNNlB/f2+rwLkRkxYG++qzBHI2Mvfcjy7yi7YspgA10+Veum9j4JV/5UU/36rFRd/kopK9C36d13c+Cjj7iyZQunf/6Zi6tX0+app2h6990YKnm9Wo0QskKNLpJnmmxSmLq993IppoS5rBy/vFOrs3L8li+XYqqa0mlVJNlPp9PlG5Fq06YN48eP59VXX82+LSgoiKFDh/K///2P2NhYPD09WbRoEWPHjgXg5MmTtGzZkp07d9K9e3eLHjsuLg5XV1diY2NxcXEp0+dVXOnp6axZs4Zhw4ZhbW1dqcciqgc5Z2q2ixdhyBAVlVW3Lvz5J/ToUbp9VrtzxmiEiIibr9cKD7esxbidXXaxZaznS4Dvr4Q7amqRWh46DfwTDVx4N6nspvlluX4Ato2BxItgcIBu30DgPWX6EBE7d7J/9mxiTp8GwKl+fTpOn47/rbeiKyxzrRDV7pwpLyYjrA40H4kyo1MjU6Mu1PppfnLOZDIaITCw8AiKrDWqFy5Uuy/8ylpVOmcsrQ2q9Bqpnj17snr1ah5++GH8/PzYvHkzp0+fZt68eQAEBweTnp7OwIEDs+/TokUL6tevf9NCKjU1ldTU1OzrcXFxgPoLTE9PL8dnVLSsx6/s4xDVh5wzNVu9eqrb+OjRBvbu1XPrrRqLFhkZPrzk34FVy3PGy0tdgoIK/n16Oly5gi4sDEJC0IWGQmgouszpg7rQUHSRkapl+9mzcPYs2wIh/MHCH1LTQYiTkc2rFtBn9JSyfT7ObeDWnRh2T0QfuQF2TMAYtRtTu3dBXzYfINw7d2bg4sVcXL2aI598ogJ9J0/GIyiIDtOnU6dVK4v3VS3PmXKgu7oFq0KLKAANkkLICN+E5tW3wo6rKpJzRtFt2YKVBTl+GZs2ofWVcyb3z8pk6TFU6RGp1NRUHn/8cX788UesrKzQ6/V8/fXXTJw4EYBFixbx0EMPmRVFAF27dqV///588MEHBT7WG2+8wZtvvpnv9kWLFuHg4FB2T0oIIcpISoqB2bO7sH+/N3q9iaefPsTAgTeZ5iby0aenY3ftGvbR0dhfu8bOy2t4tu2pIu/36AE9MyLaYGrUmustWhDTrBkZ9vZF3s8impGW6Ytplr4cgGh9a/bZPU+qzq1s9p/1MKmppG/dSvq2bWqaJGDVsSPWgwejd3Ut08eqyQLT1tA+/asitztvNYwTNveToSuj80RUW/W2bqXz3KKDwM+OHMmJ++7DZGtbAUclipKUlMSECROq94jUxx9/zK5du1i9ejUNGjRg69atTJo0CT8/P7NRqOKaNWsW06ZNy74eFxdHQEAAgwcPrhJT+zZs2MCgQYMqfVhTVA9yztQeI0fCU0+Z+PFHPZ980hFPz3bMnGmimLO05JzJFLO6HhydUeR233Q08YPxMIPOHWbcChh1Wodb07aYundH694drUcPaNSIYv9FZBtJRth4DHsexiPjGENML2Hs+Suau2XT0y12xx0kRURw5OOPufzXX2QcOIB24gTNJ06k+YMPYnWTLxJr/TkTcwjD6fnoLv1q0eaNMtbQ0PQvmu9tmALuQvMdprLFapFaf84AXLyIIXMWVVGa/PEHjTdtQhsxAtNdd6ENHgy1rKiqSudM1my1olTZQio5OZmXXnqJlStXMnz4cADatWvHwYMHmTNnDgMHDsTHx4e0tDRiYmJwy9WRKDIyEh8fn0L3bWtri20BJ6e1tXWl/8VlqUrHIqoHOWdqPmtr+P57Nd3vvffg9dcNREYaWLiwZFPra/s502/Us/jvepEwRyNaIWukXNJ0BLg34mjCOdY0gzXNwCZDY8i5w4zbdZhRP3yFSyqqoUbPnmoBW8+e0LkzFGfUKnAs1G0LW+9AF3cCq823qg5wTZ4sRYGWn2tAAL1mz+ba/fdnB/oe/+orLqxcaVGgb606ZzQNwtfByY8g4p+c2/U2YEor5E46sHIGW090iefQha1CH7ZKrYOrNwLqjwO/oWBVe2a/1KpzJktcnEpUnz9fRUAUxdkZ3NzQhYSg+/VX9L/+Ci4uqnHS+PEwaFClB5tXpKpwzlj6+CUPsChnWeuV9Hla2RoMBkwm1aI2KCgIa2trNm7cmP37U6dOcfnyZXqUdjW2EEJUQTqd+v954UL1588+U//PpqRU9pFVPwZrGxa0UrMTdHkmuWdd/7+mMzgy/SzHnz7Om/3epJVnK9Ks4I/mcP8Y8HpBxx336PjVO4qEtb/DzJmqX72LC3TtClOmwJIlqiFGUVyaw5DdEDAWTOmw92nY/TBkJJftEycn0LfXvHk4BQSQHBXF7ldeYd24cUTmaUFvMhq5uncvGYcOcXXvXkxGY5kfT5ViTIVz/wdr2sLmoaqI0ulVETR4N9yyGNWdJG+Bm3m9x3cw6gwMPQCtZoJTIzAmweWl8N9YWOEF2ydAyCowyj/cGiUjA778Epo0gQ8+UEXUgAEwZ456w877pUjWbd9/D5cuqVD0qVPVt2VxcfDTTypQ3dsbHnoI/v5brQetgYwmI1subWHrja1subQFo6l6vM9U6hqphIQEzp49C0DHjh2ZO3cu/fv3p27dutSvX59+/foRHR3NJ598QoMGDdiyZQtPPfUUc+fO5amnngLgqaeeYs2aNXz//fe4uLjw7LPPArBjxw6Lj0O69onqTM6Z2mvpUhXcm5amPrv//rtlwb1yzphb8d0LTD4+l1CnnP+4AxIMzC8kR+rY1WMsObaEJceWcPra6ezb7bBieIwX4/ckMWxvDI55P+/4++eMWPXoAR07Fvwts6apUZCDL4JmgjqdoPdv4BRYRs/YnDEtLTvQNz0+HkAF+k6fTuzZswS/9x5JkZHZ2zt4exM0axYBgwaVy/FUmtRrcOYLOP0JpESo26ycoPGj0Hyy+etfYI5UAATNz9/6XNPgerAqpC4vhcRLOb+zcgb/21WR5jsYDDVnKlete5/5+2+YPh2OH1fXmzeHDz9UhZBOV3COVEBAwTl+JpMqqpYuhWXLVFfSLHXrqu3HjVM5GVZVdnKZxVacWMHkvycTGpfz2vi7+LPgtgWMaVk5beEtrQ0qtZDavHkz/fv3z3f7Aw88wPfff09ERASzZs1i/fr1XL9+nQYNGvD4448zderU7NatWYG8ixcvNgvkvdnUvrykkBLVmZwztZvq6Ke+vGzb1rLgXjln8jOmp7Htr88IjzyHr3djeg9/usiW55qmceTqEZYcVUXVuRvnsn/nYGXPCLt2jL9Sl6Fbw7E/cES1Qc7Nzk51IezZM6e4yh0mH/EvbB8PqdFgUxdu+RV8y694SblxIzvQVzMaVbhx5gwQM5n///aeN69mFFPxZ+HkPDj/HRgzR//s60Hz56DJ44UHJpuMELUNksPB3hc8exfd8lzT4NqenKIqdyFm7Qr+o1VR5TNQ5Y5VY7XmfeboUZgxQwX9gSp03nwTnnhCzcfOzWgsfsah0Qjbt6uiavlyyPWlBh4ecOedqqjq27datk9fcWIFY5eORcuTy6bLHOFdPm55pRRT1aKQqiqkkBLVmZwz4tAhuO02FbVUv776YrRly8K3l3Om7GmaxoGIAyw9tpSlx5ZyIeZC9u+cbJwY1XgY4/RtGXLKiN2ufbBjB1y/nn9HjRqZj1o1coWdd8P1vWp6Wbt3oNWLZbpuKq/Y8+fZ/+GHhG/dWvhGOh0O3t6MWr/+pmuqqixNg+gdcGIOhP5OdrhunQ7QYroqZsq7kNFMEL0rs6haBslXcn5nUwf874AG48G7f5m1xK9INf59JjISXn8dvv5afeFgbQ3PPQcvvwx16pTPYxqNKqk9q6iKjs75nZeXCvcdNw569aoWRZXRZCRwQaDZSFRuOnT4u/hzYfIFDBWcyyaFVDFkvVjv+L6Dnd7uptv6dvLlntXmoYmLRy0mfH94IffI0WNaD3pMy1m7lRqfyqctP823XUpKCnZ25sdx9+934xfkl3399J+n+fPJP4t8TBsnG545+YzZbeufX8/RxUeLvG/T4U0Z+eVIs9u+6vwVCREJRd530OxBtJ3QNvt69Klofrz1xyLvB/DY3sdw9nXOvh78VTBb3tpS5P3cm7nzwL8PmN224t4VXNxyscj7dnqsE/1e72d221z/otuVAoz5eQyB/QKzr1/cfJEV962w6L7TQqeZXd/85mb2f72/yPsF9g1kzC/qG5qs/6xuzL/B9TMFfDDLo+9rfQl6PCeLJz48nq+7fG3R8U7cOBGP5h7Z148sOsKGFzYUeT8nHyce3/e42W1/PPEHZ/46U+R929zThsEfDja77ZMWn5CWUNhi7xwjvhhBsxHNsq9fCb7Cr7db1nVr0olJ2DrnTLPZOXcnO+fuLPJ+FfEeUZBbPr+XiTO8s4N7P5t1mbD5ywvdPut9Rt4jyv49QkMjxCOEQ40OcajRIW4438j+nYutC7e63UrdH+rQ9aI79VMu45d2Cb+0i7hnRKLL860sjo7QszPcHgt1DgJw5khb1i29m7TUwv+/yv0ekeWHAT9w7fS1Ip9r39f64t/ByMaHHipy2+sJw0gz+mZfr+rvETq9kSatj9K5z2Z8G+SKD/AdCi1ncCW0Ob+OXlLkY0JZv0f8gv76Tpq1P0izdodxdI7P/l1yogNnjrbj1KH2+I+6lx7Temf/rjjvEZXxOcKmtQ1P/PmEWSFV3d8jDFo6nRK20jV+I7aaaiRx2q4d1x9/ge4L7jW7b3l+jtBpRgJSzzH2DqOaNpjri5kEvQtn7Ntxyr49V2wC1ZcweZT2PaI4nyPSDGnEOMUQ4xhDqzdbEesQS0hcCAcjDrL3yt4iH++pP5+ig9ahQj9HpJhSeDn85erd/ryixYfHk87NF/G5BuTP20iKSiI+LL6Arc2lxuXp3KJR6P3yHocxzXxKSHpyukWPaeOc/xu1lBspFt035Xr+RbAJEQkW3Tc9yfz4TRkmi+4HoBnNP0ikJaRZdF871/wfKpKiLfy7ic3fVcfS481Izch33dL7FnQcltw3KTop322JkYkW3TfvG4dm1Cw+XlOG+TSf9CTLzsOCpFy38Dy8kf88jL8ST1p80YVUenL+f0cWH2+ez7OpcZb93VTUe0Refh5pbN8Ow4fDnj3w4Mv+3JHmQ3MK/08mnXR5jyin94g6YXXod6gffelL62Wt2em8k6XHlhIWH8bKyJVwG/ySbEeLky1ofaw1jc4PwoF06hFKACEEEEI9wrBLTIQNW2AD0B94AJq2PUKA+2l2zO/BibBWRONB3t5RpX2PSI4q+ksZABe7DSQnepOS7EFykjsZKeavU1V5j7CxS6Vj3wN0u20XdbxiAMhINxBvczt1hr0Nriqc2HghpJLeI1II3eXJye2D0OlupX6LS7TudoxWXY/j6JpEu267aNdtF2kZS2DP3WqkyrN3sd4jKuNzhGuD/M+1+r5HaLTmKAP5BzdiAQjDj/UM4XJKA7obPPLdt7w/RxzDl7Ffv666Dm3cCEuXkr5oGU6pcXRM/I+Oif8RhzPHac1RWhOGP1lNUcrqc0RKRgpnb5zlsPVh4lziiHWNNfsZ5xJHskOuhjl7itx9PldTrpJwI3/xXZ6fI1KwrBGMFFK5OPs6Fzki5eCZv2Wpg6cDzvWcC9janK1LnkWkOgq8X0EjUgYb8yFNa3trix7Txin/G6BdHTuL7mtXN/9r4eTjVOT9AKwdzIfx9VZ6ix4TQGcwn7Ji42Rj0X0dvfNndDh4WPh345p/ga+lx2tla5XvuqX3Leg4LLmvg0f+89DR2zH/B/EC5D0ndAadxcertzL/sGbtYNl5WNB5Y1fXwvOwTv7z0NnP2aIRKWt78/PQYGOw/O8mz8wpWxcL/24q4D2iIAYbAx4e8O+/ambHmjV6lnA3Y93+oZtj/m+Oc49I5SXvEfmV5j2ii0cX7up3F3MGz2FnyE6+Wf8NK06vIM4xjoMdD3Kw40EcUhxoc7ENHc53oMmV4ezXDOg0E1P/HqIWne/YoX6+dRqmgJ1fKgPe3MyALzeTss+ecJsGhNs04IpNIBE29Qt9j0iJLfrDgY2TDfaenhY9NyurdJxdQ3F2VVNzNj+4Dfc2bfBo3x6Pjh3BZNnfTXm9Rzi5xNLhlm20674TO3v13JMTHTi08xYO7riFAXPuoY5rzqh1VXmPuB7Xjm0b2vHfRiP+jc7RvN0hmrY9jL1jDJz9Ql3svLHyuYMWtxgIuxQI2s0bMVfG5wgrp/wfM6vje0Qzj2v0jV2NX7pqFBJvcOU/l+GcsO8IOj3OVPLnCGtrNb/7ttvYUe8ern++hGZJh2iSchQXLZ7u7KI7u4gz1OG0fTtO2XfA3j1/PEPe94gMfQaxjrHEOsYS4xiTPaq0KW0T8V/FExIbQlRSlNr4wZsfom2aLW6JbrRs2ZLGvo0JcAkgIS2BOTvnFPn0vOy8KvxzhLXJGoqeSCJT+0DWSInqTc4ZkVd6Ojz+uOqoC/D222raftayGjlnKp/RZGR7yHaWHlvK8uPLiUzMWUDu4eDBmBZjGN9mPH0b9DVfGxAVBTv+hshXwSmz+9sfwFIga8BYr4c2bcxzrRo3Lta6KpPRyOpBg0i6elWtJ8pLp8Pey4se773HtcOHiT54kOiDB0mNicm3qVNAAB4dOuDRvj2eHTrg2rQp+vLuNHbjEJz4CC4tBi3z237nptBiGjScWD1znEzpELkJLi2B0JWQljNlFHs/qH+XWtvl0b3AqVwVrUa8z1y8qCINlmRO93R0VNenTYObBFhXGampqgnG0qWqrWtCzqhORsMGhI8bSsjAroT42BMSF0pIbAih8epnSFwIkQmR+ZpAFMTeyp4A1wACXAIIcA3A39nf7HqASwAuti7ZjeKyZK2RCosLK/BxZI1UNSGFlKjO5JwRBdE0eOUVlTkF8PTTKnsKYNOmDNauPcjQoR3o39+qOqxJrtGMJiNbL21lybEl/HbiN6KTchaQezl6MbblWMa1Hkev+r1yPkyYMuDQS3DiQ3U9rRlsbg2b96s8mrw8Pc2bWHTuXOQHwZANG9g2daq6kvujQiFd+zRNI/7SpeyiKvrQIWLOnMlXiFnZ2+Perp0qrjp0wKNdO2wt6dtflKwA3RNzIDInXxLP3tByOtQbWaYFhtFkZNvlbYTHh+Pr7Evv+r0r7sOeMU09x0tLIHQVpMfm/M4hIKeocu9aro1JCj08YzV/n4mNVannWYG6Oh08/LD6VsrXt8i7F6aizhmjyUhkYmR2QRQSG0Lo9YuEnNlHSMQpQjKuE+6oYbLgn4OtwRZ/F1UY+bv4q+IoV4Hk7+JPXfu6+YokS2V17dOZoHm0PW4pVsTYZXDKIxlNL137qgUppER1JueMuJmPP1bRJZoG3bqpCJOwsJzf+/vDggX5Y0xE5cgwZbD54maWHF3CipMruJ6cs1bJ18mXsa1UUdUzoCd6nV51e9v1EGQkqg/QvVdAqp/5dMDgYBU2lpuVlcqxyl1cBQTk+9Ad8vbbBC9aRJI+5xOXg8lE0IQJBLz6apHPJy0+Xo1YHTpE1IEDXDt8mPSE/GsdXBo1wqNDBzwzR65cGjVCp7ew6DGmwsVf4ORciD2mbtMZVLBxy+ng3sWy/RRDlcq9MaZC+HrV/S/0d8jItWbEsYEqqOqPg7pBFVJUFRSXVG3eZzIy4Jtv4LXX1OgvqEDduXOhfftS7bqszhmTZiIqMSqnQIoLVX/OvB4SF8KV+CtkmDKK3JeVpsM/FvxjNQLiICAWAuy8COjYD/9BYwjo1B9PB88SF0mWemfW27isX4R7Ss6/+Wt2JuIGT+Dl94p+nykPUkgVgxRSojqTc0YUZdkymDBBfUbIK+v/x+XLq8GHnFom3ZjOxgsbWXpsKStPriQmJSb7d/Wc63FXq7sY13oc3Z2d0W27E+JPg94WunwGjR/O2VFqKuzfn1NYbd+ueuXnVa9eTmHVs6ca2br7bkyaRpSDA8lWVthnZOCZnKxaW5TgpDEZjcSdP0/0gQOquDp4kPiLF/NtZ+3igkfmqJVnhw64t2uHtWOe9Sup1+DM55kBuplTIwsL0C1DVTX3BgBjClz5WxVVYatVgZ3FqVFOUVWnQ7kUVStWqA7ceT9ZVov3mYICdefMUR18SvlaWXrOaJrGteRr5gVS1qhSnLotNC6UNGPRa4T1Oj1+zn5mo0dZI0hZ172dvNEnJsFff6npi2vWqPeLLK1aqUW348bdPFOjFJa9vYG0xVMBzexlNmnq1bG5Zx53vVrxeXVSSBWDFFKiOpNzRhTFaFSzUbK+YM1Lp1PfGF+4UC2iR2qlNGMaG85tYOnxpaw6uYq41Ljs39V3rc/9LUYxXXeYOtcys5+aPA5BC8GQfwE8mqaKpNyjVgcP5g8MvpkyPGlSbtzgWmZRFX3wINeOHsWYnGy2jU6vx7VpU1VYtfDFw2EHTglL0JlyB+hOhiaPFR6gWwaqcu5NPhnJcGVNZlH1JxhzdWlzbppTVLm1LZOiymiEwEDzkajcquz7TN5AXXd3eOONggN1S6CocwbU9LkAlwDC4sNIzkgudLssOnT4OPkUWiAFuAbg4+SDlb6YaxHj4+GPP1RR9fff5iPZbdvmFFXNmhW+j2JITzPydftBuOoiCzwFTZqOOM2bxw6tx9pG1khVWVJIiepMzhlRlM2boX//ordbvx4GVfwXf6KYUjJSWH9uPUuPLeX3U7+TkKamyumA2X5uTHOMQQ9o7l3R9VoOjgFF7zQxEfbuzSmutm6FuLii7zdihJozGhCQc/H3B/v8HcEsZcrIIOb0aaIyR62iDx4kMfd81Ey2Dhl4NrTBo0tfPPrdT9227bGyu3nnXUslpiXmHxGIDeFQ5CGLcm9ubXgrnf0656wpyfyA6+HgUe7TpAqUkQhhf6mi6spfauQqi0sLVVA1GJ/dBr64wsLUjLg33ih6202boF+/Ej1M2SrjQN341Ph850toXCiHIg8RHB5crH15OXrdtHGDr7MvNuUdGB0bC6tXq6Jq/XrVxShLhw45RVXjxsXetaZpJF65wj9zlpO0/qsit3ef/B1DHu9a7McpDSmkikEKKVGdyTkjirJ4sZraVxRra/WZOGtmV48e4OVV/scnSi45PZm/z/7N0uNL+ePUHySmJzLYARb7QF0DJOgciOiwgMYtHineB/hFi+Dee4verjDu7vmLq9zX69UD2wJGy/IyZUDoSpJ3f0j0kZNEhToQHWbP9QgH8i4B0VlZUadFC7XOKvPiWEBjgJSMFFUk5fnAm3udyY2UG/nuVxZyL9wvbCShjl2d8i220uPVCNXlpXBlLZhyTeVybZ1TVLk0L/ju6XDokKq3swY0L18ucNMCTZ0K77xTqlq7dFJSVBOJd99VIzAAd94JH3xQaFGQlJ5kdr5kTbPLfT33KHFJvNr7VR7o8AD1XOphZ1U2XwiUmRs3YNUq1f3vn3/M54kHBeUUVYGBBd7dmJrK9ePHiT54kKgDB7my9yCmuOgCty3Q6NlMeGd4qZ5CcUkhVQxSSInqTM4ZURRLR6QK0rix+bKZNm2q2LQckS0pPYk1Z9aw5NgSjp7/g0WeqXS0gwwN5iR7kNToSca1GU8brzZF78zSk2biRHVChITkXJLyB30WyMvLvLjKXXD51oHUdXDmY0i8qLbX20LD+6HFVIz2TbI/mGVdkguYu5rh5kBMfUdCvDWO1Yllv20YkamWfYBztnHOV/Akpify4Y4Pi7zvk0FPYmOwMfvAHZFQwLq0AjhYO+QbycpbcLna5Q+6LZH0OAhdrYqq8L9Vi/Usbu2g/jiuOY9n+6Em2UXT3r2QZ+Ylej00agRnz1r2sE5OcPvt6rP3kCGW1dSlpmlqdGXmzJzOlp07k/Lhe4S2CzQvkHKtSypOYe1m55avs11CWgIfbP+gyPtuemAT/QL7leIJVpBr12DlSlVU/fuv+ZTgrl1h3DiSBgwg+urV7HWQN44fx5R7RAvI0KyITAugnu2FIh9SRqSqOCmkRHUm54woStbahbCwQiOB8PdXU+L37Mn5pvn48fzbOzmpUaus4qp79xLNghHlLCEtgb9PrsT92Mv010IAWBIPj0RCA49WjGs1jnGtx9HSs5AF5JaeNHkXvGgaxMSYF1YhIWrhTO4/pxQSDFwHGAzcCmT1lki2gotNyUi5hSvePoR42hDiAqF2qYRocYTEhxISe5nE8HDqXE6kSbQdTa850CDGDoNmPrKTpjdxoW4KFzzTia3vhNbUD3e/BgW2dC6oWClN7k2aMY2wuLBCP6yHxoXmhJsWIavIy/uhPXcB5mRjWfBtzgHGYLr8OwnHl+AYvwGDLmfUYf+FjizZNZ5lu+/iQlQj6tZV7wFZ7wNduqgRppudMgDOzuDmpk6DLC4uMHq0KqoGDQKbMpyxlv2a71hL6LfzCLl6lhBXCPG2I6SpN6FWSRa/5k42Tjctbv1d/HG2zR8OW5WzkkotKgrTsmXc+PVXoo8fJ9rOjih7e5IK+EuMzXDndFIHziR3IMLQnk7DWnPHXdZcmD4IF91V9Lr8r42skaompJAS1ZmcM8ISWd20oMBIoAK7acXEwO7dOctmdu3KmQmTW8uW5tmvzZurb6hFFaBppJyYh83BF9Bj5FiajjuuaJzJ/HK4rVdbxrVWRVUz9zwLyDNPmgydxn/1IdwJfBOg12XVNrnELdg0TX2rnavQMkbtJdXxX+x8Q7LPnatxsOo8/BIL55zU41uUe4MV/jYeNLT1o1WqN4ExDtQNTcHmXCRafP7RMqeAADzat8+eDuhWRGBweebe5J12WNrRkewP+7kLgFwFV2qiPbt25UzR271b/Ruv43id0Z1XMb77Em5tvRErQ86oQ7JDZ2ybjUff4C7VXj33a5P5PqPXJ3NX99fxc7zAlcSGLNv1JiaTPcuXwx13qMdZskR1FM29/M3NTf1+3Di49dab93rIMGVwJf5KvmmauUcByztQ1lJZ5wxgdjxVotNjMaVcv56dE5fdHCbPFyM6TcMtJQWP5GQ8kpO5mNSKNYZ7SB81liEP+jJwYM7fbVbXPg3Miinp2leNSCElqjM5Z4SlCsp3CQhQywUs+TxsNKpRqqwPXTt2wJkz+bdzczOPJ+raVX0TLSpR1A74bywkh5Omt+d9U2v+d+4Q6bmmcnXw6ZA9UtW4rlor8v6sF1iYOpdw15wP0r6xBp6zncbM92Zb9NAmzcTVxKv5P/DGXqZe4lHu4By9bHLW6WxJgo9i4M9E8n0Ettb01EuxVnk3UWkExGr4Z+XfZP70SAKzj7vW1lCvHpq/P/He3kTb2hKdlkb09evEREYWHBjctq0qrDp2LDAweNms+4lavxu3lJz33Bi7dDwHd+Ou936y6HUpqcIaYYTGhxZ/vU6SO8QGQFwAxPlDbAB2aQG0DgigR2t/Bnf3p09QPK5xK+DSUri6CTRTzv3du6n1VAFjs5ua/PTy/dj/s5u0hJzXxsYpneSB3bj/HfPXxmRS7yVZRVV2V36dETf/CPqMDKVdrxBc64dwJcG8uAxPCMeU+1gKYZuBOkccfPFv05MAn2ZlGihrqYJypAJcAph/2/wqW0SZjEZiz55VRVNm85f4AgK/9Y4u3HDowJ6w9uy50oGkFA9GmNYywbCEHsbtORvqdNCnD4wfr/7T8fYGYOP9bxOzexGp1jnflNimm3DrNoFbf5IcqSpPCilRnck5I4rDaIRNmzJYu/YgQ4d2oH9/q1KteYqKwuwb7T17Cl4/0bateROLRo0qJBtU5JYcAf/dBVH/qavNp7NE15IlJ5bzz/l/zAI8g3yDcEpuxZYbPwOaeWWSOV3u+QbL+eDBO7JzbwpbiB8WH2aWe2Ojg3udYZobtMlcG5OhwW8JOn5K8+SGY5NCR1K8HL1UEDGokzkiIv/UwdzXw8PVp/VCpOn1XLO3J9rZmSg3N64ZDKQX8LHIpUEDVVR17EjGrl3sX7NG/SL3SZx5v9733GNRWHF5ikuN41R4CP8Gh7LreAhHQ0K4HBNCml0IuISCawjYJBa9I8w7yLVwrEt/q+u0Tz2NV+IJdLlLXc9bCD6gceqHrBEzs5MGAO+ngug/6QezQNmcwjqUY6EhXLwRQgJXwGBBoKzeCn8X/5xzxbkeAUcuE7BkLf6h8QTEgWf3Aeg+Kn2gblkwmoxsu7yN8PhwfJ196V2/d5WazpcWF0f04cM5aw8PHyYjMf954tK4MTr/DhyN6cBvuzuw73wgmkqXw9ERRo1StdKQIWAXHapGr5csUf9ZZNHrVfvGpk3hq68wahrRufLqPJKTMUClhY9JIVUMUkiJ6kzOGVFc5XnOpKfD4cPmHb0K+AITLy/zUavOnSuxi1dtYkqH/TPg9EJ13fc26PkL14waK0+uZOmxpfx74V+MWhGZUhqgWWFrbSDVmHrzbVFTmFq5ePNsHSvG2URRB3WfdL0d0b6joflkvLy6lP2HyvR0VUwVVGxl3ZYrnFgDYm1tiba3J9rBgSh7e+IL6oSgaQV/E6Bp2GoaXRcsQHeT6YFlTdNUN++TJ+HUKfXz4kXzwSMAG1to0gRatNAIbJpIHf9oUvXRXEuOJiopmuhcl2vJ10i/SfCrqx562kEve2hpAzoNdq/xIy3ZQJ4xwayjxMY5g/uHXiCFooskPXrsjX6kXg0g41rmqFlsAK56fwZ2CeDeEQGM6O+NtVVmYb12rcqDygrUbdFCBeoOGybf2hRA0zTiL15U+W2Zo02x587lH6F1cMA9Mxw7wbUD6462Y/FKV7PGIg4OKglh/HgYOvQm7+WXLuUUVXuLjhGozPAxKaSKQQopUZ3JOSOKq6LPmStXzLNfg4PNcx4BrKygUyfz4irAgvgjUUIXfkHb/Rg6UzJJ+ob8nbiCQ5c7EBIC58Kj2O/4Hglt51m8O2edN562/vi7BNDYI4DmvgE0cFOjSg0NRnzCfsVw4QcwZg5XOvirAN3Gj4FNGXWgK6m0NLVQp6DGGCEhpISGci05mSgHB644OhIjFX+phHsnsN81lfQ69lh51sXRx4c69Rrg7deIgDr18wXKZmSo7KmlS9X05OvXc/bl6wvP9jvCk+dmUGfPenWjuzu8+SY8/niZBOrWFOmJiVw/elQVTpnrm9JiY/Nt51S/vgq+7tABj/btCUtvyrLlBpYuVQV6Fjs7GD5cFU/DhqmRqGK5cAHee0/leBWlEsLHLK0NKu7rEiGEELWSn5+KabnzTnU9JQX2788prnbsUIMCe/aoy4IFajt/f/MmFh06lG1Hr5osMfHmgzAhIfcS6NaGFVPG0Nj7PEMNPVj571f8/N/9gCe06QJtLXigtfNg31PEG22JB84DWwGDQeP2Htt5bshH+Db8PXsReYyuI9e8puPYchxePtZVoymJjQ00bKguBbAD6qWkUC80FLe332bHvn1F7tI5NRVbvV61uXRxUYsEHR1L/K16WqpqApF1SUjM3xlPp1MP5+yccynvfy+appFhSifVmEZy5EV014oeafKNdGJ4ZFZHwRTgInARvdV2bL29SfDx4ZKPD1He3jj4+ODo60tQPR96v+/Np5/W5d9/dSxZAv/9FsmM8Nd4dPE3GDCRhjX/BU3G+b2X6TzQrVYPQmmaRmJYmCqaMi8xp0+jGc1Hmg22ttRt0yYne619e+zc3Tl5EhYvhaVvw7FjOdvb2qoRp3HjYORIdb6VWMOGKmLBkkIqPLwUD1S+pJASQghRoezsctZLTZ+uPhBeumReWB06pD7wL12qLln369w5p7jq0SN7rXKtkpysXpvCiySVn1mUw3HtGThnHz88cR99mqzhp6cm8tyEPZxy/IgdEb58nlz0Pkb37ECT3rbZj30lLIMuPiuZNnQO3Zrsyd7uzwPD+WjNdDYf70fWtK/MHhCFRkkFBICHRxWZlWVnB02aYH/LLWBBIdX16lW887a4tLJS3wbkDmYLCMj3BNPT4eBB8+mxuduFZ/HxMf+ioVMndZiVZfviF7j0v7+K3K5p0HUMVhpJcVYkxlmTFGdNSoIVpowMEsPCSMzdxi8PvY0NDl5e3JuezmN1z+Ngn8z5dFcOmboyL2UGhw92JmGwK/Xr52TEdu5cRc6hcmRMTeX6sWPZuU3RBw6Qcu1avu0cfHzUWr/27fHs0AG35s0xZFbbZ87AR1+o99vDh3PuY20Nt92mXstRo9T3AmWmgMDsUm1XCWRqHzK1T1Rvcs6I4qoO50xioppCn7u4yj2lJ0ujRuYfJtu0UZ9Xq6vUVDXLrLDeCSEhEG1ZnizOzjcvUvz9kNSc7wAAHrpJREFUM79R1kxw5C04+qa6o0dP0rr/isPbPTE6hqnFL3lpOgyJ/iS9ewEbawOkx8O5/4NT87MDdE06Wy7qJrLt6lQOXWxp9lyK6AGRzdbW/JgLeh516lTcB2VTWhqr27cnSacrdI2Ug6Yxas8e9MeOmbe4vHIl//Z+fqQE9eSsRw+2pPdkxYWO7Ai2zRezZTCoXgm5p74GBlatAiE9NZnVfduTGm9FYWukbJ0zGLX2D6xjD0D0TojeATcOYDIaSU6wIimzsEqKtyMpzY+kpDokxlmRdC2ZlOs3Cg+oyiXVZM+1dG+up/twLcMHk6M3TYN86D7Yl7a3+ODo64O1k1O5d+krT0mRkUQfPJg94nTj+HFMGeajgXorK+q0aqWKpsziycHHx2yb8+dzvqw6cCDndisrGDxYFU+33646sZaLkubVVQCZ2ieEEKLacnRUU+KzpsVrmvrGNPfn0mPH1AeB8+fh559z7tetW86Hze7doW7doh/PaIRt29QHfF9f6N277P/fzt33oLAiKTLSsn05ONy8uAgIKMY3xzo9tHsD3DvDjvsgegc2/3RlYetnmHTxVfQa9HYAXwOEG2FbEpiAaa3mY5MeAUcXwtkvIT1zvYWtBzR9Gn2zSTSy86JREa/FzXpApKbCuXPqUtRrkff5577uWkbLsPQ2NgRNmMC2xYvzN5zI/CAYNGECemdndfJ1757zu8uXMW3fybU/d6Bt34l7yAEMV65gd2U5bVhOG+ARbAkmiP12PYlr1QOnQT1of5svXbqUYA1KBbO2tcftvm5Efh6MatuRv2uf233dsK7THOo0h8C71a8yktBf34dj1A4cs4qr1KvAVbP9G6/bkrzfRNI5a5Li3UnqOYIkHz+SIiNJjIggKSKC1OvXsdUn42d7ET/bizl3PgyhhyF0jrqqt3PAyc8ne+qgg48PDplTCbMu1uXwgpuMRqKCg0mOisLe0xPPoCD0RbzRmNLTuXHqlFnhlFTAVDc7d3ez0aY6rVphVcAQ5aVLOcVT7sFVg0Fld40frwKSLXnfLDWDQc3lHjsW9EBzwA2IAU6hTpv58yu8iCoOGZFCRqRE9SbnjCiumnLOxMaqYM+s4mrXLogrID6nRQvz1ustWpgHBheUr+Xvr/5/t7Trbu5O3IUVSRERlo3C2NnlHznKWzS5uZXTaET8Wdh6B8QeBZ0Vu9P74mfaRIBNzoGHpBk4qLuPkU1NcGkxaJnfhDs3gxbToOFEsCp9Q4YiekCUaHTuZqNbxVnvYWnuzY0b6rzMKv5374aEBPU7e5LozD5uYQeDnXfQOX0nzikFPKHAQPMTuF27Kj3suvGT+4n5eTep8TnvLbbO6bjd141bn7EgY0vT1HkYvRMu/A2n14BzLORdT2dwAPeu4NkTPHqARw+MOJEUGUlSZmEVczmCU3sjCDsZQfq1COoYInC2yt9goSDWzs7ZRZVjVoHl7Y1DrsLLqhiNR0I2bCD4vfdIyvVtiYO3N0GzZhEwKCdwNjvwNrMpRIGBt3o9bs2bqyDpjh3xbN8eR3//QkfZQkJUTtfSpeoczKLXq2VK48erIGQPD4ufTtla9gJEzQW3XGu4YgzgOQ3usiyvrqxJ175ikEJKVGdyzojiqqnnjNEIJ06Yry05fTr/dm5uaqCgZ0/IyIC33y544T6oTr2jR8PVqzcvkq5cUY9fFGvrooskd/dKnrKVkQi7H4VLvwIFjy2YHZ5XX2gxHeoNV6NbFSglxfzvoaBiy5L1YqDOi6KKLXt7VXiPHQt6LY27HL7Hz+oSVzIasDzpQYw6G558UhWBO3ao8zGvrMGqrLqoW7fMqVOaBmfPms9nPXo0/8np4KBSrrOKq+7d1UlThaSnJrNr+atcOrKXBm270H3s21jbFqO4jo2Fd99VoxFpaeAATLoN7mgLKYchelfOCGhuzs0yC6vM4sq1VfY5mZAAf/4JyxcnsfffqzhrEbhbhVPXOoImXhE084nE3SYC440I0vOubyuEjaurebHl65tvZMtgY0PIhg1smzq14DcaTaPxXXdhSk0l6uBBEi5fzv84Li6qGURmQwj3tm2LHDG7ciWn0/iOHeYP2bevmrZ3550qiqJShayAbWPJH7+d+S7TezkESI5UlSaFlKjO5JwRxVWbzpno6PyBwUlJlt/fYFAfPPIsPyh026zmCYV9GPfyomp0qiuKMQNWeBT8YTWLwQFu/Rc8ulXccZVAYuLN15yFhBQ8klmQunVV17z0dMsfv2lT83V8rVoVY6ZSXJwaQsgqrnbtUkVGXs2bmzexaNmy0k+0Er3PZGSoLm6vvZYz3HjrrfDRR+aBupoJYk/krLOK3glxJ/Pvz9oV3LvlKq66gbULcXHwxx+qyFi3zjyOoW1bGH9HIiP6hONlp0a3sqYO5r5kWPhGYlOnDunx8WiWvIlkcm3cOKdw6tABl8BAdBb8fUZEwG+/qef13385dZtOB716qeJp7FjVqKRKMBnh9/qQXMD6QQB0Kiph1AWo4OBiWSMlhBCi1vPwUEGRI0ao61mBwTt3wsqV8O+/N79/1iiTXq/WTt1sLY6PT5Weyl880f/dvIgCMCbl5EJVYY6Oqs5o3rzwbeLiii62EhMLbnhSkHvuUZfu3cHTsxQH7+ICgwapC6i5oVnDrlnF1alTOZfvv1fbubqqB88qrrp1K+N2a2VM0+Dvv1Ubz6xhvJsF6ur04NZaXZo8qm5LvaZGqrKKq2t71DkcsV5d1B3BrQ0uHj24t0dP7h3ZkxhjE1b/oVqqr18PR47AkSOOvEITOnRokt39r13j3IerkR4fn11kJRdSbBlTU0mzcEg0cORIAocPx6NdO2yKsajv6lU1SrpkCWzZYj7o1bNnTvFUr57Fuyw7GUmQFKIuiZk/k0Jzbku4oN5HCqWp7aK2gXe/ijrqYpFCSgghRK1hbQ1BQeri7l50IQWwcCE8+WQty/ZMtjC3xdLtqjgXFzVS1KpVwb/XNIiJga++gpkzi97fyJHqUub0emjdWl0ee0zddu2a+bDr7t1q1GrdOnUBVYi0aWM+NNakSdVo+3fkCMyYoaoYUP8w33pLPb/i/KOzdVfTS+sNV9dNGRBzJGfEKmoHJF5Qt8UcgbNfAeBm68HEBj2YOLsHcQt6snJrFxYvdeCff1Qb+oMH4aWX1HvG+PFw110QGKjDxsUFGxcX3Jo1K/BwNE0jLTaWs8uWcWj+/CIP3693b/x697boqUZHqy+Cli5V72G5115265ZTPNWvb9HuSsaYklMUJYZAcmiuYinzkmbhvNqiVOH3GSmkhBBC1EqWRpO0bVvLiigAewtfHEu3q+Z0OtVmvZuFsxgrNPbG3R2GD1cXUNPjjhwxXyx44ULWUAt8+aXazsPDvJ96ly5q/VVFiYhQU/i+/VZVAjY2quvLSy+VTb9tvRXU7aguzSap25IjzKcDXtsHqdEQ9geE/YEL8IC9FQ9MaU/yKz3ZeboH367uya9/1Cc4WEdwMLzwglqillVUBQQU/PA6nQ5bNzc8ck9JvAn7IoYub9zIKZ7++cd8TaZ5kWfRw92cMQ2Sw8xHkMyKpFBIjbJsX1bO4BgA9v7qp0PWxV8VSLseLHofVfh9RgopIYQQtVLv3mpaXlERJhZ+SVyzePZWH3SSwsi/CByy1y541q4Xp1qcM1ZW0LGjukzKLCAiIsybWAQHq2GNP/5Ql6z7tW9v3iGwfv2yH7VKTlZNJN59N6eF4dix8P770LjxTe9aavY+EHCHugAYU+HGwVyjVtvVep3rwdhfD2aA3ccMGAc/3u/HxYQerAvuyc9/9yB4fyf27LFl+nT1Mo0fX/j0Oc+gIBy8vUm6erXQk8bB2xvPoKB8v4qJgd9/V8XThg3ma/M6dMgpnor1spky1HPMPcUu77S7lEgK/nefh8E+pzByzFUgOeQqmGxuMk3RZITDr1Tr9xkppIQQQtRKuSNMMptnZcv67FjFI0zKj94AQQsyu2npMP+Qk/niBM2v8AXgla3anjM+Pqq/9R2ZBURqqkpgzV1cXbmiCqzgYPj4Y7Wdn595E4uOHVVKclGMRnRbtlBv61Z0jo6qx7ZeD7/+quZGZnWm69IF5s5VnRAqg8FWNaDw6AZkdtVLCsmZChi9E24cwJB6hcbWv/F09994ujsYNRtORAaxLrgn20/35P03ejBlii+9eqni5s47c0Yl9QYDQbNmqa59hZw0QTNnZudJxcXB6tWqeCqwEUZm8VTgjEKTURVBuafX5Z12lxKumnUURW+bpyjKO6IUADalTMOuAe8z0rUP6donqjc5Z0RxyTljrqAcqYAA9YHY0hypGitkBQRPVt9UZ3EIUB9uKqElcVVR484ZTVMdNXI3sTh4MH+7Shsb6NzZfEpg3nmMBb04np5qut6ZM+p6QAC8957qyFHV21hmJMH1febFVQHT2i5cDWTn2R7sON2TnWd74hbYjrF3WWW3GN/45tvE/LWI1MRc2WNOJtyGTaDb9Ff54w9VPK1dq+rcLC1bquJp3F0mWjaMMi+S8o4qJV/JyXW7Gb012NfLP4KUe1TJ1rPi1tBVwfcZaX9eDFJIiepMzhlRXHLO5Gc0wrZtEB6uPhf27l0FRxUqi8lIRvgmDu5aS4fuQ7Hy7V+lvyGuKDX+nElKgn37zIurghKQswKDe/RQwV4vvFDwFDZQadOvvgpTp6pQrupI0yDhXE5RFb1DBVjnGeVJTHFgz/mu7DrbAw8PeKTH+5hMGtdCHUhOsMLeKQP3esnoDXD3J8v492hfAtxDCHAPIahFKP27h9CucQhuNllFUhiY0go5qFx0BrD3yz/FLvc6JTvvCs98K1IVe5+R9udCCCGEhQwG6Nevso+iitIb0Lz6EmaVSHuvvlJEZarx54yDA/Tpoy6gCohz58ybWBw5AhcvqsuiRUXvs25dePHF6l1x6nTg3ERdGk1Ut6XHqXbrUaqwMl3diaNdLP1bbaZ/q83Zd9UbwLuBebtvTYNfnxmLvqDBn5h8D64aL9y0SPJRjTaqm2r6PlMNX2khhBBCCFGhdDrVMr1JE5iYWUDExamU6x074M8/Ye/em+/jyhU1jFfTKlBrF/AZqC6AXjOpgOCoHYTtXkE93dpC76rTZa8GAjsv8wIp99Q7xwA10qSXWQRViRRSQgghhBCi+FxcYOBAdWnaFCZMKPo+4VU3E6jM6PTg2gpcW3FpjyP1KLyQyrKTH+gxZmIFHJwoS1VsgqQQQgghhKh2LA3PqtCQrcrn4G7Z87V3L8/0XFFepJASQgghhBClkxWyVVinN51OdeurZcFsbQf05kqMPyZTwa+LyaQjLCaAtgNq1+tSU0ghJYQQQgghSicrZAvyF1NVOmSrfBmsDVz2XAA68hVTJpNaIBXiOR+Dde16XWoKKaSEEEIIIUTpjRkDy5fz/+3de0zVdfzH8Rcc5GKCSk4FRB1eSU9YOhAvw5KiMpPZ1MjQ5gWb0CxnectRWebKvDGzUqf+kSI5dU1NJZUsRVkKSwtRQ6UpYF4hL3H7/P5o8vthYH75xTkHfT42/uBzPt+d1/fsteN5+z3noKCgmuvt2v293ij/yNb/X98Rw5XluVFFJTUfl8KSdsry3Ki+Ix7Mx+V+wJdNAAAA4L8xfLg0bJgq9u5Vzrffqtezz8rjiSceuCtRd+o7Yrgqy4cpZ88PunGpUE0fDpB9xEAFcSWqUWOQAgAAwH/HZpOJitK569cVFhX1wA9Rt9ma2NQrZpCzY+A/xFv7AAAAAMAiBikAAAAAsIhBCgAAAAAsYpACAAAAAIsYpAAAAADAIgYpAAAAALCIQQoAAAAALGKQAgAAAACLGKQAAAAAwCIGKQAAAACwiEEKAAAAACxikAIAAAAAixikAAAAAMAiD2cHcAXGGElSSUmJk5NI5eXlunHjhkpKStSkSRNnx0EjQGdgFZ2BVXQGVtEZWOVKnbk9E9yeEerCICWptLRUkhQcHOzkJAAAAABcQWlpqZo3b17n7W7m30atB0BVVZXOnz8vX19fubm5OTVLSUmJgoOD9fvvv8vPz8+pWdA40BlYRWdgFZ2BVXQGVrlSZ4wxKi0tVWBgoNzd6/4kFFekJLm7u6tdu3bOjlGDn5+f00uExoXOwCo6A6voDKyiM7DKVTpztytRt/FlEwAAAABgEYMUAAAAAFjEIOVivLy8lJycLC8vL2dHQSNBZ2AVnYFVdAZW0RlY1Rg7w5dNAAAAAIBFXJECAAAAAIsYpAAAAADAIgYpAAAAALCIQQoAAAAALGKQcoJly5apY8eO8vb2VkREhLKysu66/+uvv1b37t3l7e0tu92u7du3OygpXIWVzqxYsUIDBw5Uy5Yt1bJlS0VHR/9rx3D/sfo8c1tqaqrc3NwUGxvbsAHhcqx25urVq0pMTFRAQIC8vLzUtWtX/n16wFjtzOLFi9WtWzf5+PgoODhYb775pm7duuWgtHCmffv2aejQoQoMDJSbm5u2bNnyr8dkZGTo8ccfl5eXlzp37qw1a9Y0eE6rGKQcbMOGDZo6daqSk5N15MgRhYWFKSYmRhcuXKh1/4EDBxQXF6fx48crOztbsbGxio2N1bFjxxycHM5itTMZGRmKi4vT3r17lZmZqeDgYD399NM6d+6cg5PDWax25rYzZ85o2rRpGjhwoIOSwlVY7UxZWZmeeuopnTlzRhs3blReXp5WrFihoKAgByeHs1jtzLp16zRjxgwlJycrNzdXq1at0oYNGzRr1iwHJ4czXL9+XWFhYVq2bNk97T99+rSGDBmiJ554Qjk5OXrjjTc0YcIE7dy5s4GTWmTgUOHh4SYxMbH698rKShMYGGg++uijWvePHDnSDBkypMZaRESEmTRpUoPmhOuw2pk7VVRUGF9fX7N27dqGiggXU5/OVFRUmH79+pmVK1easWPHmmHDhjkgKVyF1c4sX77chISEmLKyMkdFhIux2pnExETz5JNP1libOnWq6d+/f4PmhOuRZDZv3nzXPW+//bbp0aNHjbVRo0aZmJiYBkxmHVekHKisrEyHDx9WdHR09Zq7u7uio6OVmZlZ6zGZmZk19ktSTExMnftxf6lPZ+5048YNlZeXy9/fv6FiwoXUtzPvv/++WrdurfHjxzsiJlxIfTrzzTffKDIyUomJiWrTpo169uypefPmqbKy0lGx4UT16Uy/fv10+PDh6rf/5efna/v27XruuecckhmNS2N5/evh7AAPkosXL6qyslJt2rSpsd6mTRsdP3681mOKiopq3V9UVNRgOeE66tOZO02fPl2BgYH/eELC/ak+nfnxxx+1atUq5eTkOCAhXE19OpOfn689e/Zo9OjR2r59u06dOqXJkyervLxcycnJjogNJ6pPZ15++WVdvHhRAwYMkDFGFRUVeu2113hrH2pV1+vfkpIS3bx5Uz4+Pk5KVhNXpID72Pz585WamqrNmzfL29vb2XHggkpLSxUfH68VK1aoVatWzo6DRqKqqkqtW7fWl19+qd69e2vUqFGaPXu2Pv/8c2dHg4vKyMjQvHnz9Nlnn+nIkSPatGmTtm3bprlz5zo7GlBvXJFyoFatWslms6m4uLjGenFxsdq2bVvrMW3btrW0H/eX+nTmtgULFmj+/Pn67rvv9OijjzZkTLgQq5357bffdObMGQ0dOrR6raqqSpLk4eGhvLw8derUqWFDw6nq8zwTEBCgJk2ayGazVa+FhoaqqKhIZWVl8vT0bNDMcK76dGbOnDmKj4/XhAkTJEl2u13Xr19XQkKCZs+eLXd3/m8f/6uu179+fn4uczVK4oqUQ3l6eqp3797avXt39VpVVZV2796tyMjIWo+JjIyssV+S0tPT69yP+0t9OiNJH3/8sebOnasdO3aoT58+jogKF2G1M927d9fRo0eVk5NT/fPCCy9Uf1NScHCwI+PDCerzPNO/f3+dOnWqeuiWpBMnTiggIIAh6gFQn87cuHHjH8PS7UHcGNNwYdEoNZrXv87+tosHTWpqqvHy8jJr1qwxv/76q0lISDAtWrQwRUVFxhhj4uPjzYwZM6r379+/33h4eJgFCxaY3Nxck5ycbJo0aWKOHj3qrFOAg1ntzPz5842np6fZuHGjKSwsrP4pLS111inAwax25k58a9+Dx2pnCgoKjK+vr0lKSjJ5eXlm69atpnXr1uaDDz5w1inAwax2Jjk52fj6+pr169eb/Px8s2vXLtOpUyczcuRIZ50CHKi0tNRkZ2eb7OxsI8ksXLjQZGdnm7NnzxpjjJkxY4aJj4+v3p+fn2+aNm1q3nrrLZObm2uWLVtmbDab2bFjh7NOoVYMUk6QkpJi2rdvbzw9PU14eLg5ePBg9W1RUVFm7NixNfanpaWZrl27Gk9PT9OjRw+zbds2ByeGs1npTIcOHYykf/wkJyc7PjicxurzzP/FIPVgstqZAwcOmIiICOPl5WVCQkLMhx9+aCoqKhycGs5kpTPl5eXm3XffNZ06dTLe3t4mODjYTJ482Vy5csXxweFwe/furfW1ye2OjB071kRFRf3jmF69ehlPT08TEhJiVq9e7fDc/8bNGK6nAgAAAIAVfEYKAAAAACxikAIAAAAAixikAAAAAMAiBikAAAAAsIhBCgAAAAAsYpACAAAAAIsYpAAAAADAIgYpAMADJSMjQ25ubrp69aqzowAAGjEGKQAAHOjy5csaPXq0/Pz81KJFC40fP15//vmns2MBACxikAIAwIFGjx6tX375Renp6dq6dav27dunhIQEZ8cCAFjEIAUAcDmDBg1SUlKSkpKS1Lx5c7Vq1Upz5syRMeaejv/rr780ffp0BQcHy8vLS507d9aqVatq3Xvp0iXFxcUpKChITZs2ld1u1/r162vs2bhxo+x2u3x8fPTwww8rOjpa169fl/T3WwXDw8P10EMPqUWLFurfv7/Onj1b633l5uZqx44dWrlypSIiIjRgwAClpKQoNTVV58+ft/AIAQCcjUEKAOCS1q5dKw8PD2VlZWnJkiVauHChVq5ceU/HjhkzRuvXr9fSpUuVm5urL774Qs2aNat1761bt9S7d29t27ZNx44dU0JCguLj45WVlSVJKiwsVFxcnMaNG6fc3FxlZGRo+PDhMsaooqJCsbGxioqK0s8//6zMzEwlJCTIzc2t1vvKzMxUixYt1KdPn+q16Ohoubu769ChQxYfIQCAM3k4OwAAALUJDg7WokWL5Obmpm7duuno0aNatGiRJk6ceNfjTpw4obS0NKWnpys6OlqSFBISUuf+oKAgTZs2rfr3119/XTt37lRaWprCw8NVWFioiooKDR8+XB06dJAk2e12SX9/3unatWt6/vnn1alTJ0lSaGhonfdVVFSk1q1b11jz8PCQv7+/ioqK7npeAADXwhUpAIBL6tu3b40rO5GRkTp58qQqKyvvelxOTo5sNpuioqLu6X4qKys1d+5c2e12+fv7q1mzZtq5c6cKCgokSWFhYRo8eLDsdrtGjBihFStW6MqVK5Ikf39/vfrqq4qJidHQoUO1ZMkSFRYW1vOMAQCNCYMUAOC+4uPjY2n/J598oiVLlmj69Onau3evcnJyFBMTo7KyMkmSzWZTenq6vv32Wz3yyCNKSUlRt27ddPr0aUnS6tWrlZmZqX79+mnDhg3q2rWrDh48WOt9tW3bVhcuXKixVlFRocuXL6tt27b1OFsAgLMwSAEAXNKdnxk6ePCgunTpIpvNdtfj7Ha7qqqq9P3339/T/ezfv1/Dhg3TK6+8orCwMIWEhOjEiRM19ri5ual///567733lJ2dLU9PT23evLn69scee0wzZ87UgQMH1LNnT61bt67W+4qMjNTVq1d1+PDh6rU9e/aoqqpKERER95QXAOAaGKQAAC6poKBAU6dOVV5entavX6+UlBRNmTLlX4/r2LGjxo4dq3HjxmnLli06ffq0MjIylJaWVuv+Ll26KD09XQcOHFBubq4mTZqk4uLi6tsPHTqkefPm6aefflJBQYE2bdqkP/74Q6GhoTp9+rRmzpypzMxMnT17Vrt27dLJkyfr/JxUaGionnnmGU2cOFFZWVnav3+/kpKS9NJLLykwMLB+DxQAwCn4sgkAgEsaM2aMbt68qfDwcNlsNk2ZMuWe/97S8uXLNWvWLE2ePFmXLl1S+/btNWvWrFr3vvPOO8rPz1dMTIyaNm2qhIQExcbG6tq1a5IkPz8/7du3T4sXL1ZJSYk6dOigTz/9VM8++6yKi4t1/PhxrV27VpcuXVJAQIASExM1adKkOrN99dVXSkpK0uDBg+Xu7q4XX3xRS5cutf4AAQCcys3c6x/lAADAQQYNGqRevXpp8eLFzo4CAECteGsfAAAAAFjEIAUAaFR++OEHNWvWrM4fAAAcgbf2AQAalZs3b+rcuXN13t65c2cHpgEAPKgYpAAAAADAIt7aBwAAAAAWMUgBAAAAgEUMUgAAAABgEYMUAAAAAFjEIAUAAAAAFjFIAQAAAIBFDFIAAAAAYBGDFAAAAABY9D+XKK4QszqNlQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Nome del file JSON\n",
    "json_filename = \"error_K_compas.json\"\n",
    "\n",
    "# Caricare i dati dal file JSON\n",
    "with open(json_filename, \"r\") as f:\n",
    "    error_data = json.load(f)\n",
    "\n",
    "# Estrarre parametri dal JSON\n",
    "run6_params = error_data.get(\"run6_parameters\", {})\n",
    "min_sup = run6_params.get(\"min_sup\", \"N/A\")\n",
    "percentage = run6_params.get(\"percentage\", \"N/A\")\n",
    "th_redundancy = run6_params.get(\"th_redundancy\", \"N/A\")\n",
    "L = run6_params.get(\"L\", \"N/A\")\n",
    "K = int((percentage / 100) * L) if isinstance(percentage, (int, float)) and isinstance(L, int) else \"N/A\"\n",
    "\n",
    "# Lista dei valori di p da 0.0 a 1.0 con step 0.1\n",
    "p_values = np.round(np.arange(0.0, 1.05, 0.1), 2)\n",
    "\n",
    "# Definiamo i colori per ogni N\n",
    "colors = [\"blue\", \"red\", \"green\", \"orange\", \"brown\"]\n",
    "labels = [f\"N={n}K\" for n in range(500, 2501, 500)]\n",
    "\n",
    "# Creazione della figura\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig.suptitle(\"ERROR MITIGATION\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Disegniamo la linea tratteggiata \"Before Mitigation\"\n",
    "before_mitigation_values = [\n",
    "    error_data.get(f\"N={n}K_run6\", {}).get(\"Before Mitigation\", None) for n in range(1, 6)\n",
    "]\n",
    "before_mitigation_values = [val for val in before_mitigation_values if val is not None]\n",
    "\n",
    "# Se esistono valori di \"Before Mitigation\", tracciamo una linea media\n",
    "if before_mitigation_values:\n",
    "    avg_before_mitigation = np.mean(before_mitigation_values)\n",
    "    ax.axhline(y=avg_before_mitigation, color=\"purple\", linestyle=\"--\", linewidth=2, label=\"Before Mitigation\")\n",
    "\n",
    "# Loop sui vari N (da 1K a 5K)\n",
    "legend_handles = []\n",
    "for i, n in enumerate(range(1, 6)):\n",
    "    N_key = f\"N={n}K_run6\"\n",
    "    if N_key not in error_data:\n",
    "        continue\n",
    "\n",
    "    data = error_data[N_key]\n",
    "\n",
    "    # Estrarre i valori di errore\n",
    "    error_filtered = []\n",
    "    p_values_filtered = []\n",
    "    \n",
    "    for p in p_values:\n",
    "        key = f\"After SMOTE N = {n}K000 p_class 0 = {p}\"  # üõ†Ô∏è CORRETTA FORMATT.\n",
    "        if key in data:\n",
    "            error_filtered.append(data[key])\n",
    "            p_values_filtered.append(p)\n",
    "\n",
    "    # Se ci sono dati validi, plottiamo la linea corrispondente\n",
    "    if error_filtered:\n",
    "        line, = ax.plot(\n",
    "            p_values_filtered, error_filtered, \n",
    "            marker=\"o\", linestyle=\"-\", color=colors[i], label=labels[i]\n",
    "        )\n",
    "        legend_handles.append(line)\n",
    "\n",
    "# Impostazioni asse\n",
    "ax.set_title(f\"Minsup = {min_sup}, pruning = {th_redundancy}, K% = {percentage}, subgroups: {K}/{L}\")\n",
    "ax.set_xlabel(\"p_class 0\")\n",
    "ax.set_ylabel(\"Errors\")\n",
    "ax.grid()\n",
    "\n",
    "# Aggiungere la leggenda\n",
    "ax.legend(handles=legend_handles, loc=\"upper right\", fontsize=10, frameon=True, title=\"Legend\")\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
